Script started on 2020-02-17 09:43:49+0000
ubuntu@run-gpu-mg:~/fnd_implementation$ tmux attach[7Pexittime python3 model_grid_search.py --modell=distilbert --model_type=distilroberta-base --dataset_name=fnc_arc[C[C[C[C[C[C[C- --dataset_name=fnc_arcc --dataset_name=fnc_arca --dataset_name=fnc_arcs --dataset_name=fnc_arce --dataset_name=fnc_arcd --dataset_name=fnc_arc[C[C[C[C[C[1P[1P[1P[1P[1P[1P[1P[1P[1P[1P[1P[1P[1P[1P[1@=[1@x[1@l[1@n[1@e[1@t[C[C[C[C[1P[1P[1P[1P[1P[1P[1P[1P[1P[1P[1@x[1@l[1@n[1@e[1@tM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C_.py --mode[1@lM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Ce.py --mod[1@eM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Cv.py --mo[1@dM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Ca.py --m[1@oM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Cl.py --[1@mM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C_.py -[1@-M[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Cs.py [C[1@-M[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Ce.py[1@ M[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Cp.p[1@yM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Ca.[1@p[1@r[1@a[1@t[1@e
python3: can't open file 'model_grid_search_eval_separate.py': [Errno 2] No such file or directory

real	0m0.041s
user	0m0.024s
sys	0m0.017s
ubuntu@run-gpu-mg:~/fnd_implementation$ time python3 model_grid_search_eval_separrate.py --model=xlnet --model_type=xlnet-base-cased --dataset_name=fnc_arcM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Ceval_separa[1PM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Ceval_separat[1PM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Ceval_separate[1PM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Ceval_separate.[1PM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Ceval_separate.p[1PM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Cval_separate.py[1PM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Ceval_separate.py [1PM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Ceval_separate.py -[C[1PM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Ceval_separate.py --[1PM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Ceval_separate.py --m[1PM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Ceval_separate.py --mo[1PM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Ceval_separate.py --mod[1PM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Ceval_separate.py --mode[1PM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Ceval_separate.py --model[1PM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Cval_separate.py --model=[1PM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Ceval_separate.py --model=x[1PM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Ceval_separate.py --model=xl[1PM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Ceval_separate.py --model=xln[1PM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Ceval_separate.py --model=xlne[1PM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C eval_separate.py --model=xln[1@eM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C

/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/home/ubuntu/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/ubuntu/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/ubuntu/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/ubuntu/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/ubuntu/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/ubuntu/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
There are 2 GPU(s) available.
The following GPU is used:  Tesla V100-PCIE-16GB
INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/xlnet-base-cased-config.json from cache at /home/ubuntu/.cache/torch/transformers/c9cc6e53904f7f3679a31ec4af244f4419e25ebc8e71ebf8c558a31cbcf07fc8.8df552e150a401a37ae808caf2a2c86fb6fedaa1f6963d1f21fbf3d0085c9e74
INFO:transformers.configuration_utils:Model config {
  "architectures": [
    "XLNetLMHeadModel"
  ],
  "attn_type": "bi",
  "bi_data": false,
  "clamp_len": -1,
  "d_head": 64,
  "d_inner": 3072,
  "d_model": 768,
  "dropout": 0.1,
  "end_n_top": 5,
  "ff_activation": "gelu",
  "finetuning_task": "multi",
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "mem_len": null,
  "n_head": 12,
  "n_layer": 12,
  "num_labels": 4,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pruned_heads": {},
  "reuse_len": null,
  "same_length": false,
  "start_n_top": 5,
  "summary_activation": "tanh",
  "summary_last_dropout": 0.1,
  "summary_type": "last",
  "summary_use_proj": true,
  "torchscript": false,
  "untie_r": true,
  "use_bfloat16": false,
  "vocab_size": 32000
}

INFO:transformers.tokenization_utils:loading file https://s3.amazonaws.com/models.huggingface.co/bert/xlnet-base-cased-spiece.model from cache at /home/ubuntu/.cache/torch/transformers/dad589d582573df0293448af5109cb6981ca77239ed314e15ca63b7b8a318ddd.8b10bd978b5d01c21303cc761fc9ecd464419b3bf921864a355ba807cfbfafa8
INFO:transformers.configuration_utils:loading configuration file /home/ubuntu/fnd_implementation/xlnet/model_pretrained/config.json
INFO:transformers.configuration_utils:Model config {
  "attn_type": "bi",
  "bi_data": false,
  "clamp_len": -1,
  "d_head": 64,
  "d_inner": 3072,
  "d_model": 768,
  "dropout": 0.1,
  "end_n_top": 5,
  "ff_activation": "gelu",
  "finetuning_task": null,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "mem_len": null,
  "n_head": 12,
  "n_layer": 12,
  "num_labels": 4,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pruned_heads": {},
  "reuse_len": null,
  "same_length": false,
  "start_n_top": 5,
  "summary_activation": "tanh",
  "summary_last_dropout": 0.1,
  "summary_type": "last",
  "summary_use_proj": true,
  "torchscript": false,
  "untie_r": true,
  "use_bfloat16": false,
  "vocab_size": 32000
}

INFO:transformers.modeling_utils:loading weights file /home/ubuntu/fnd_implementation/xlnet/model_pretrained/pytorch_model.bin
INFO:__main__:Loading initialized pretrained model from /home/ubuntu/fnd_implementation/xlnet/model_pretrained
  ******************************************* 
           Freezing Embedding Layers          
  *******************************************
 
name:  transformer.mask_emb
param.requires_grad:  False
=====
name:  transformer.word_embedding.weight
param.requires_grad:  False
=====
name:  transformer.layer.0.rel_attn.q
param.requires_grad:  True
=====
name:  transformer.layer.0.rel_attn.k
param.requires_grad:  True
=====
name:  transformer.layer.0.rel_attn.v
param.requires_grad:  True
=====
name:  transformer.layer.0.rel_attn.o
param.requires_grad:  True
=====
name:  transformer.layer.0.rel_attn.r
param.requires_grad:  True
=====
name:  transformer.layer.0.rel_attn.r_r_bias
param.requires_grad:  True
=====
name:  transformer.layer.0.rel_attn.r_s_bias
param.requires_grad:  True
=====
name:  transformer.layer.0.rel_attn.r_w_bias
param.requires_grad:  True
=====
name:  transformer.layer.0.rel_attn.seg_embed
param.requires_grad:  True
=====
name:  transformer.layer.0.rel_attn.layer_norm.weight
param.requires_grad:  True
=====
name:  transformer.layer.0.rel_attn.layer_norm.bias
param.requires_grad:  True
=====
name:  transformer.layer.0.ff.layer_norm.weight
param.requires_grad:  True
=====
name:  transformer.layer.0.ff.layer_norm.bias
param.requires_grad:  True
=====
name:  transformer.layer.0.ff.layer_1.weight
param.requires_grad:  True
=====
name:  transformer.layer.0.ff.layer_1.bias
param.requires_grad:  True
=====
name:  transformer.layer.0.ff.layer_2.weight
param.requires_grad:  True
=====
name:  transformer.layer.0.ff.layer_2.bias
param.requires_grad:  True
=====
name:  transformer.layer.1.rel_attn.q
param.requires_grad:  True
=====
name:  transformer.layer.1.rel_attn.k
param.requires_grad:  True
=====
name:  transformer.layer.1.rel_attn.v
param.requires_grad:  True
=====
name:  transformer.layer.1.rel_attn.o
param.requires_grad:  True
=====
name:  transformer.layer.1.rel_attn.r
param.requires_grad:  True
=====
name:  transformer.layer.1.rel_attn.r_r_bias
param.requires_grad:  True
=====
name:  transformer.layer.1.rel_attn.r_s_bias
param.requires_grad:  True
=====
name:  transformer.layer.1.rel_attn.r_w_bias
param.requires_grad:  True
=====
name:  transformer.layer.1.rel_attn.seg_embed
param.requires_grad:  True
=====
name:  transformer.layer.1.rel_attn.layer_norm.weight
param.requires_grad:  True
=====
name:  transformer.layer.1.rel_attn.layer_norm.bias
param.requires_grad:  True
=====
name:  transformer.layer.1.ff.layer_norm.weight
param.requires_grad:  True
=====
name:  transformer.layer.1.ff.layer_norm.bias
param.requires_grad:  True
=====
name:  transformer.layer.1.ff.layer_1.weight
param.requires_grad:  True
=====
name:  transformer.layer.1.ff.layer_1.bias
param.requires_grad:  True
=====
name:  transformer.layer.1.ff.layer_2.weight
param.requires_grad:  True
=====
name:  transformer.layer.1.ff.layer_2.bias
param.requires_grad:  True
=====
name:  transformer.layer.2.rel_attn.q
param.requires_grad:  True
=====
name:  transformer.layer.2.rel_attn.k
param.requires_grad:  True
=====
name:  transformer.layer.2.rel_attn.v
param.requires_grad:  True
=====
name:  transformer.layer.2.rel_attn.o
param.requires_grad:  True
=====
name:  transformer.layer.2.rel_attn.r
param.requires_grad:  True
=====
name:  transformer.layer.2.rel_attn.r_r_bias
param.requires_grad:  True
=====
name:  transformer.layer.2.rel_attn.r_s_bias
param.requires_grad:  True
=====
name:  transformer.layer.2.rel_attn.r_w_bias
param.requires_grad:  True
=====
name:  transformer.layer.2.rel_attn.seg_embed
param.requires_grad:  True
=====
name:  transformer.layer.2.rel_attn.layer_norm.weight
param.requires_grad:  True
=====
name:  transformer.layer.2.rel_attn.layer_norm.bias
param.requires_grad:  True
=====
name:  transformer.layer.2.ff.layer_norm.weight
param.requires_grad:  True
=====
name:  transformer.layer.2.ff.layer_norm.bias
param.requires_grad:  True
=====
name:  transformer.layer.2.ff.layer_1.weight
param.requires_grad:  True
=====
name:  transformer.layer.2.ff.layer_1.bias
param.requires_grad:  True
=====
name:  transformer.layer.2.ff.layer_2.weight
param.requires_grad:  True
=====
name:  transformer.layer.2.ff.layer_2.bias
param.requires_grad:  True
=====
name:  transformer.layer.3.rel_attn.q
param.requires_grad:  True
=====
name:  transformer.layer.3.rel_attn.k
param.requires_grad:  True
=====
name:  transformer.layer.3.rel_attn.v
param.requires_grad:  True
=====
name:  transformer.layer.3.rel_attn.o
param.requires_grad:  True
=====
name:  transformer.layer.3.rel_attn.r
param.requires_grad:  True
=====
name:  transformer.layer.3.rel_attn.r_r_bias
param.requires_grad:  True
=====
name:  transformer.layer.3.rel_attn.r_s_bias
param.requires_grad:  True
=====
name:  transformer.layer.3.rel_attn.r_w_bias
param.requires_grad:  True
=====
name:  transformer.layer.3.rel_attn.seg_embed
param.requires_grad:  True
=====
name:  transformer.layer.3.rel_attn.layer_norm.weight
param.requires_grad:  True
=====
name:  transformer.layer.3.rel_attn.layer_norm.bias
param.requires_grad:  True
=====
name:  transformer.layer.3.ff.layer_norm.weight
param.requires_grad:  True
=====
name:  transformer.layer.3.ff.layer_norm.bias
param.requires_grad:  True
=====
name:  transformer.layer.3.ff.layer_1.weight
param.requires_grad:  True
=====
name:  transformer.layer.3.ff.layer_1.bias
param.requires_grad:  True
=====
name:  transformer.layer.3.ff.layer_2.weight
param.requires_grad:  True
=====
name:  transformer.layer.3.ff.layer_2.bias
param.requires_grad:  True
=====
name:  transformer.layer.4.rel_attn.q
param.requires_grad:  True
=====
name:  transformer.layer.4.rel_attn.k
param.requires_grad:  True
=====
name:  transformer.layer.4.rel_attn.v
param.requires_grad:  True
=====
name:  transformer.layer.4.rel_attn.o
param.requires_grad:  True
=====
name:  transformer.layer.4.rel_attn.r
param.requires_grad:  True
=====
name:  transformer.layer.4.rel_attn.r_r_bias
param.requires_grad:  True
=====
name:  transformer.layer.4.rel_attn.r_s_bias
param.requires_grad:  True
=====
name:  transformer.layer.4.rel_attn.r_w_bias
param.requires_grad:  True
=====
name:  transformer.layer.4.rel_attn.seg_embed
param.requires_grad:  True
=====
name:  transformer.layer.4.rel_attn.layer_norm.weight
param.requires_grad:  True
=====
name:  transformer.layer.4.rel_attn.layer_norm.bias
param.requires_grad:  True
=====
name:  transformer.layer.4.ff.layer_norm.weight
param.requires_grad:  True
=====
name:  transformer.layer.4.ff.layer_norm.bias
param.requires_grad:  True
=====
name:  transformer.layer.4.ff.layer_1.weight
param.requires_grad:  True
=====
name:  transformer.layer.4.ff.layer_1.bias
param.requires_grad:  True
=====
name:  transformer.layer.4.ff.layer_2.weight
param.requires_grad:  True
=====
name:  transformer.layer.4.ff.layer_2.bias
param.requires_grad:  True
=====
name:  transformer.layer.5.rel_attn.q
param.requires_grad:  True
=====
name:  transformer.layer.5.rel_attn.k
param.requires_grad:  True
=====
name:  transformer.layer.5.rel_attn.v
param.requires_grad:  True
=====
name:  transformer.layer.5.rel_attn.o
param.requires_grad:  True
=====
name:  transformer.layer.5.rel_attn.r
param.requires_grad:  True
=====
name:  transformer.layer.5.rel_attn.r_r_bias
param.requires_grad:  True
=====
name:  transformer.layer.5.rel_attn.r_s_bias
param.requires_grad:  True
=====
name:  transformer.layer.5.rel_attn.r_w_bias
param.requires_grad:  True
=====
name:  transformer.layer.5.rel_attn.seg_embed
param.requires_grad:  True
=====
name:  transformer.layer.5.rel_attn.layer_norm.weight
param.requires_grad:  True
=====
name:  transformer.layer.5.rel_attn.layer_norm.bias
param.requires_grad:  True
=====
name:  transformer.layer.5.ff.layer_norm.weight
param.requires_grad:  True
=====
name:  transformer.layer.5.ff.layer_norm.bias
param.requires_grad:  True
=====
name:  transformer.layer.5.ff.layer_1.weight
param.requires_grad:  True
=====
name:  transformer.layer.5.ff.layer_1.bias
param.requires_grad:  True
=====
name:  transformer.layer.5.ff.layer_2.weight
param.requires_grad:  True
=====
name:  transformer.layer.5.ff.layer_2.bias
param.requires_grad:  True
=====
name:  transformer.layer.6.rel_attn.q
param.requires_grad:  True
=====
name:  transformer.layer.6.rel_attn.k
param.requires_grad:  True
=====
name:  transformer.layer.6.rel_attn.v
param.requires_grad:  True
=====
name:  transformer.layer.6.rel_attn.o
param.requires_grad:  True
=====
name:  transformer.layer.6.rel_attn.r
param.requires_grad:  True
=====
name:  transformer.layer.6.rel_attn.r_r_bias
param.requires_grad:  True
=====
name:  transformer.layer.6.rel_attn.r_s_bias
param.requires_grad:  True
=====
name:  transformer.layer.6.rel_attn.r_w_bias
param.requires_grad:  True
=====
name:  transformer.layer.6.rel_attn.seg_embed
param.requires_grad:  True
=====
name:  transformer.layer.6.rel_attn.layer_norm.weight
param.requires_grad:  True
=====
name:  transformer.layer.6.rel_attn.layer_norm.bias
param.requires_grad:  True
=====
name:  transformer.layer.6.ff.layer_norm.weight
param.requires_grad:  True
=====
name:  transformer.layer.6.ff.layer_norm.bias
param.requires_grad:  True
=====
name:  transformer.layer.6.ff.layer_1.weight
param.requires_grad:  True
=====
name:  transformer.layer.6.ff.layer_1.bias
param.requires_grad:  True
=====
name:  transformer.layer.6.ff.layer_2.weight
param.requires_grad:  True
=====
name:  transformer.layer.6.ff.layer_2.bias
param.requires_grad:  True
=====
name:  transformer.layer.7.rel_attn.q
param.requires_grad:  True
=====
name:  transformer.layer.7.rel_attn.k
param.requires_grad:  True
=====
name:  transformer.layer.7.rel_attn.v
param.requires_grad:  True
=====
name:  transformer.layer.7.rel_attn.o
param.requires_grad:  True
=====
name:  transformer.layer.7.rel_attn.r
param.requires_grad:  True
=====
name:  transformer.layer.7.rel_attn.r_r_bias
param.requires_grad:  True
=====
name:  transformer.layer.7.rel_attn.r_s_bias
param.requires_grad:  True
=====
name:  transformer.layer.7.rel_attn.r_w_bias
param.requires_grad:  True
=====
name:  transformer.layer.7.rel_attn.seg_embed
param.requires_grad:  True
=====
name:  transformer.layer.7.rel_attn.layer_norm.weight
param.requires_grad:  True
=====
name:  transformer.layer.7.rel_attn.layer_norm.bias
param.requires_grad:  True
=====
name:  transformer.layer.7.ff.layer_norm.weight
param.requires_grad:  True
=====
name:  transformer.layer.7.ff.layer_norm.bias
param.requires_grad:  True
=====
name:  transformer.layer.7.ff.layer_1.weight
param.requires_grad:  True
=====
name:  transformer.layer.7.ff.layer_1.bias
param.requires_grad:  True
=====
name:  transformer.layer.7.ff.layer_2.weight
param.requires_grad:  True
=====
name:  transformer.layer.7.ff.layer_2.bias
param.requires_grad:  True
=====
name:  transformer.layer.8.rel_attn.q
param.requires_grad:  True
=====
name:  transformer.layer.8.rel_attn.k
param.requires_grad:  True
=====
name:  transformer.layer.8.rel_attn.v
param.requires_grad:  True
=====
name:  transformer.layer.8.rel_attn.o
param.requires_grad:  True
=====
name:  transformer.layer.8.rel_attn.r
param.requires_grad:  True
=====
name:  transformer.layer.8.rel_attn.r_r_bias
param.requires_grad:  True
=====
name:  transformer.layer.8.rel_attn.r_s_bias
param.requires_grad:  True
=====
name:  transformer.layer.8.rel_attn.r_w_bias
param.requires_grad:  True
=====
name:  transformer.layer.8.rel_attn.seg_embed
param.requires_grad:  True
=====
name:  transformer.layer.8.rel_attn.layer_norm.weight
param.requires_grad:  True
=====
name:  transformer.layer.8.rel_attn.layer_norm.bias
param.requires_grad:  True
=====
name:  transformer.layer.8.ff.layer_norm.weight
param.requires_grad:  True
=====
name:  transformer.layer.8.ff.layer_norm.bias
param.requires_grad:  True
=====
name:  transformer.layer.8.ff.layer_1.weight
param.requires_grad:  True
=====
name:  transformer.layer.8.ff.layer_1.bias
param.requires_grad:  True
=====
name:  transformer.layer.8.ff.layer_2.weight
param.requires_grad:  True
=====
name:  transformer.layer.8.ff.layer_2.bias
param.requires_grad:  True
=====
name:  transformer.layer.9.rel_attn.q
param.requires_grad:  True
=====
name:  transformer.layer.9.rel_attn.k
param.requires_grad:  True
=====
name:  transformer.layer.9.rel_attn.v
param.requires_grad:  True
=====
name:  transformer.layer.9.rel_attn.o
param.requires_grad:  True
=====
name:  transformer.layer.9.rel_attn.r
param.requires_grad:  True
=====
name:  transformer.layer.9.rel_attn.r_r_bias
param.requires_grad:  True
=====
name:  transformer.layer.9.rel_attn.r_s_bias
param.requires_grad:  True
=====
name:  transformer.layer.9.rel_attn.r_w_bias
param.requires_grad:  True
=====
name:  transformer.layer.9.rel_attn.seg_embed
param.requires_grad:  True
=====
name:  transformer.layer.9.rel_attn.layer_norm.weight
param.requires_grad:  True
=====
name:  transformer.layer.9.rel_attn.layer_norm.bias
param.requires_grad:  True
=====
name:  transformer.layer.9.ff.layer_norm.weight
param.requires_grad:  True
=====
name:  transformer.layer.9.ff.layer_norm.bias
param.requires_grad:  True
=====
name:  transformer.layer.9.ff.layer_1.weight
param.requires_grad:  True
=====
name:  transformer.layer.9.ff.layer_1.bias
param.requires_grad:  True
=====
name:  transformer.layer.9.ff.layer_2.weight
param.requires_grad:  True
=====
name:  transformer.layer.9.ff.layer_2.bias
param.requires_grad:  True
=====
name:  transformer.layer.10.rel_attn.q
param.requires_grad:  True
=====
name:  transformer.layer.10.rel_attn.k
param.requires_grad:  True
=====
name:  transformer.layer.10.rel_attn.v
param.requires_grad:  True
=====
name:  transformer.layer.10.rel_attn.o
param.requires_grad:  True
=====
name:  transformer.layer.10.rel_attn.r
param.requires_grad:  True
=====
name:  transformer.layer.10.rel_attn.r_r_bias
param.requires_grad:  True
=====
name:  transformer.layer.10.rel_attn.r_s_bias
param.requires_grad:  True
=====
name:  transformer.layer.10.rel_attn.r_w_bias
param.requires_grad:  True
=====
name:  transformer.layer.10.rel_attn.seg_embed
param.requires_grad:  True
=====
name:  transformer.layer.10.rel_attn.layer_norm.weight
param.requires_grad:  True
=====
name:  transformer.layer.10.rel_attn.layer_norm.bias
param.requires_grad:  True
=====
name:  transformer.layer.10.ff.layer_norm.weight
param.requires_grad:  True
=====
name:  transformer.layer.10.ff.layer_norm.bias
param.requires_grad:  True
=====
name:  transformer.layer.10.ff.layer_1.weight
param.requires_grad:  True
=====
name:  transformer.layer.10.ff.layer_1.bias
param.requires_grad:  True
=====
name:  transformer.layer.10.ff.layer_2.weight
param.requires_grad:  True
=====
name:  transformer.layer.10.ff.layer_2.bias
param.requires_grad:  True
=====
name:  transformer.layer.11.rel_attn.q
param.requires_grad:  True
=====
name:  transformer.layer.11.rel_attn.k
param.requires_grad:  True
=====
name:  transformer.layer.11.rel_attn.v
param.requires_grad:  True
=====
name:  transformer.layer.11.rel_attn.o
param.requires_grad:  True
=====
name:  transformer.layer.11.rel_attn.r
param.requires_grad:  True
=====
name:  transformer.layer.11.rel_attn.r_r_bias
param.requires_grad:  True
=====
name:  transformer.layer.11.rel_attn.r_s_bias
param.requires_grad:  True
=====
name:  transformer.layer.11.rel_attn.r_w_bias
param.requires_grad:  True
=====
name:  transformer.layer.11.rel_attn.seg_embed
param.requires_grad:  True
=====
name:  transformer.layer.11.rel_attn.layer_norm.weight
param.requires_grad:  True
=====
name:  transformer.layer.11.rel_attn.layer_norm.bias
param.requires_grad:  True
=====
name:  transformer.layer.11.ff.layer_norm.weight
param.requires_grad:  True
=====
name:  transformer.layer.11.ff.layer_norm.bias
param.requires_grad:  True
=====
name:  transformer.layer.11.ff.layer_1.weight
param.requires_grad:  True
=====
name:  transformer.layer.11.ff.layer_1.bias
param.requires_grad:  True
=====
name:  transformer.layer.11.ff.layer_2.weight
param.requires_grad:  True
=====
name:  transformer.layer.11.ff.layer_2.bias
param.requires_grad:  True
=====
name:  sequence_summary.summary.weight
param.requires_grad:  True
=====
name:  sequence_summary.summary.bias
param.requires_grad:  True
=====
name:  logits_proj.weight
param.requires_grad:  True
=====
name:  logits_proj.bias
param.requires_grad:  True
=====

*******************************************
Evaluating the following pipelines 
['/home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_68ed0bc8_2020-02-16_12-37-03inpruwki/', '/home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_7e5c3cae_2020-02-17_06-11-48706tbf3m/', '/home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_79169be0_2020-02-16_21-35-29mxr4y_c3/', '/home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_710075d4_2020-02-16_14-17-18vmsbuhfn/', '/home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_810b96fc_2020-02-17_07-41-00fob42hg8/', '/home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_73ac6694_2020-02-16_18-38-09yg6rkgu9/', '/home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_663ada68_2020-02-16_08-15-41tvoboy27/', '/home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_63040284_2020-02-16_08-15-37nps22yu4/', '/home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_6b999b2a_2020-02-16_12-48-43s6vcnc_d/', '/home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_7bc0aac0_2020-02-17_01-56-25yz5s3qgz/', '/home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_76763a6c_2020-02-16_20-07-53xalizeni/', '/home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_6e514002_2020-02-16_14-09-10gzjh09ia/']

*******************************************

*******************************************
EVALUATING PIPELINE 
{'batch_size_seq_length': 3, 'lr': 3e-05, 'lr_type': 'constant'}
INFO:__main__:Creating features from dataset file at /home/ubuntu/fnd_implementation/data/processed
  0%|                                                 | 0/11898 [00:00<?, ?it/s]  0%|                                       | 1/11898 [00:00<3:11:57,  1.03it/s]  4%|█▌                                   | 501/11898 [00:01<2:08:45,  1.48it/s] 50%|███████████████████▏                  | 6001/11898 [00:01<46:38,  2.11it/s]100%|███████████████████████████████████| 11898/11898 [00:01<00:00, 7679.46it/s]
  ******************************************* 
              Running Evaluation                
  *******************************************
 
  Length dataset evaluation: 11898
  Length dataloader evaluation: 744
  Number of epochs: 3
  Batch size: 16
  ******************************************* 
 
['/home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_68ed0bc8_2020-02-16_12-37-03inpruwki/outputs/checkpoint-3']
INFO:__main__:Evaluate the following checkpoints: ['/home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_68ed0bc8_2020-02-16_12-37-03inpruwki/outputs/checkpoint-3']
INFO:transformers.configuration_utils:loading configuration file /home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_68ed0bc8_2020-02-16_12-37-03inpruwki/outputs/checkpoint-3/config.json
INFO:transformers.configuration_utils:Model config {
  "attn_type": "bi",
  "bi_data": false,
  "clamp_len": -1,
  "d_head": 64,
  "d_inner": 3072,
  "d_model": 768,
  "dropout": 0.1,
  "end_n_top": 5,
  "ff_activation": "gelu",
  "finetuning_task": null,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "mem_len": null,
  "n_head": 12,
  "n_layer": 12,
  "num_labels": 4,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pruned_heads": {},
  "reuse_len": null,
  "same_length": false,
  "start_n_top": 5,
  "summary_activation": "tanh",
  "summary_last_dropout": 0.1,
  "summary_type": "last",
  "summary_use_proj": true,
  "torchscript": false,
  "untie_r": true,
  "use_bfloat16": false,
  "vocab_size": 32000
}

INFO:transformers.modeling_utils:loading weights file /home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_68ed0bc8_2020-02-16_12-37-03inpruwki/outputs/checkpoint-3/pytorch_model.bin
eval_separate.py:214: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0
Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`
  for batch in tqdm_notebook(eval_dataloader, desc="Evaluating"):
HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=744.0, style=ProgressStyle(description_width='initial')), HTML(value='')))
0.1497570.1507710.0757240.0272270.0137070.0029410.0018110.0007190.0003260.0002430.0003950.0002360.0003050.0002110.6597070.2063360.6287010.4615600.8731730.6504721.2267720.9268440.4809480.0219050.0016080.0003230.0005300.4751532.2030570.0764490.0028640.0004750.0003410.0003061.8464191.0891080.7411010.0202230.0009840.4922170.0126000.0005840.0002000.0001930.0023050.0002290.0001900.0005740.0002690.0010010.3924490.0083590.0009250.0002370.3577850.8909370.0161180.0014780.0002160.0001970.3586600.0060700.0002790.0002130.0005750.0019960.4720850.0074570.0078270.0002810.3170660.0464750.5543010.0080250.0005950.0004870.0006000.0005600.0005110.0005310.0017130.0016800.0009240.0003000.0002830.0002850.0002970.0003040.0005370.0004060.0002990.0002870.0003950.0002330.0005100.0001930.0001730.0021320.0009440.0008540.0001530.0009220.5662620.0059150.0006580.0004330.0003800.0001570.2352250.0023130.0001780.0018120.0012050.7963630.4124540.4519780.0050710.0022200.0956870.0013360.0004920.0014340.0002540.4030460.0046420.0003940.0002010.0005810.0001620.0008800.0023490.0003920.0002660.0006130.0003830.0005370.0003010.0004560.0004910.1089340.1497780.0013900.0574380.0028990.0019500.0007720.0004850.0009360.0014150.0008190.0005000.0004900.0517040.8583300.0059450.4650780.0032740.0004380.4823070.9401410.4875460.0033540.0003440.0032171.1248781.1469950.0105911.8642340.4853791.3534861.5287760.1145750.0020080.0007150.0095320.8402180.0052370.0004890.0004730.0001610.0376840.0010930.0003301.0940770.7728391.0276440.0083890.0006410.0027340.3941490.3295400.3448140.0023570.0010170.0086410.0005080.0007690.0006520.0004522.2870640.0121840.0013110.0024710.0011550.3965610.0048480.0005840.0016740.0015021.3972750.2205240.0015200.5368160.0105270.0027910.0323350.5451760.0675440.0011410.8491240.0063500.3839870.3041640.7069300.2980540.4127590.4332780.0020581.3626310.8699810.3149491.6640920.5120340.0027110.0007570.0006540.0034950.0037750.0002160.1570270.0030880.0086210.0010170.0004640.0003360.0003310.0015950.0022190.0176190.0003730.0020460.0480670.0249260.0061270.0033330.1925700.4549240.0030620.3901550.0023860.0025440.0014490.0013171.2252440.7619750.0050230.8132253.3561770.3199070.0030660.0058940.5531350.0046110.0039610.0004320.0003370.4187200.0018320.1628530.0862300.4567180.0021110.0007480.0008360.0127200.0015570.4592821.3016790.7817402.4206530.0092850.3158630.0013940.5580890.0036870.0008940.0006480.0006540.0004490.7491050.7601722.4165071.5310920.5780450.0025190.0002040.0002740.0001890.0006420.0006170.3282291.8476981.4661590.3376671.3557590.0051400.0007040.0018780.0028870.3187100.0976930.0011550.0008950.0002590.0002040.0008560.4146930.0016890.0003700.0004340.0007130.0017810.0020230.4205500.0015220.0005510.0005340.0008840.0010470.0016800.0007700.2895174.0031832.9150260.0232490.0011620.0009030.0007830.6595440.1311460.0469820.0020070.2864870.2256810.0018260.0006300.4291580.0613180.0007840.0006540.3409850.8128690.4954350.4908500.7705720.0022780.0040710.0019680.0008290.0011270.0044390.0022090.0029600.0001830.3543080.0011550.0004100.0006410.8484190.0030730.0032860.0045681.4349650.9669780.4876170.9597560.0401480.0004570.0008260.0009870.0007490.1573801.8957051.6402902.8441411.4699770.9231110.0026010.0002610.0002470.0003680.0002500.0003520.0003670.0002660.0001470.0002610.0003210.0015370.0032030.5099762.9860560.7755460.9453553.2313092.7370310.0070640.0004450.0005510.0005150.0023400.0272970.0022390.0003670.0006380.0002850.0003890.0002810.0003632.8261302.8611410.7913960.2129251.0646550.3718800.0023051.4002052.7325680.4943950.6821690.6767130.2558310.0014990.0016880.0017111.8001221.1441200.0029970.0007860.2829530.6166680.4757870.6128960.0037790.0011490.0009291.3260851.6617301.1110620.5628530.8247440.0224580.0030840.4468640.0249660.1338220.0056392.7684121.8154940.0043190.0002981.0117941.0634640.0034970.0005060.0005040.0005680.0002030.0019620.4802670.2402730.0043340.0009540.6154940.7054350.5469940.2079180.1997410.0005990.0033860.0007350.0003000.0020400.0205620.0025600.0649450.0014520.0006990.0007420.0007520.0009850.8962230.3992481.3058580.1260140.3920840.4481760.0011680.0012510.0002100.0006450.0055500.0010060.3953580.0014510.2999240.4927220.4148720.0021480.0008420.0019760.0020160.0019130.6768640.2245220.3145980.0016150.0015730.0012650.0015680.0018230.0004750.4258100.0031792.1946390.6411680.0018840.0438530.0004440.0012821.2416490.0072880.6220220.3137930.7621751.0660850.7586090.6037810.0015660.0033090.0016770.4155580.0024310.0011390.3597760.0321020.1821580.0160720.0005803.5107340.0086110.0869570.3333910.0031980.0021880.0028660.0345650.2970010.7528230.3912450.2952440.3867711.6231250.2279611.1235270.2992210.2753190.0247450.0202050.8939130.7902100.4098680.4712270.3571570.4440750.7174420.8378190.4912400.8117340.5645390.4493030.6027980.2647590.8793011.3225640.2814780.2747900.4991010.7585460.5623630.6024040.0151310.2145470.1625980.6039070.4759840.3995450.5533831.0907041.0233930.6184150.7942640.7986210.3842090.4834070.2465300.6947930.5598740.4019150.2196570.2428360.1494520.4112500.2668940.7629340.6901300.3353891.7109970.4883450.6856950.4264090.4471100.9474200.9157770.8349760.9569040.3712950.2643530.5374180.7168730.2833110.3042471.2395040.8300001.9174960.2823291.0420550.4189580.8147860.3259570.6352720.2428010.4819960.4263030.5855000.4683210.2857070.2665070.3170210.3691050.6135170.5218560.0637480.3182700.5923050.2717600.5921930.1257240.4203050.2599260.1031100.5193970.9208931.2172350.5550950.3308750.0166470.3959530.5441360.6105560.4773000.3458240.5343950.8918840.5459880.9053060.0077850.7938260.5785800.2080081.0032871.2698280.3327110.5721900.2846570.0686210.4892840.6154450.8001590.5253341.0304760.2595320.4320930.1681370.5129730.2318540.3324450.4628770.8758620.3643240.9379400.4846461.4447910.3143670.7752750.3173990.2982480.5559450.6700590.8320681.2945900.2776170.1533821.1980070.4310540.2863440.8627230.2843250.6193120.3436860.5315640.1621170.9344972.0284501.0639680.5390220.1837390.1298320.2567870.5161681.1830260.2625840.1186560.647115

*******************************************
EVALUATING PIPELINE 
Pipeline directory: /home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_68ed0bc8_2020-02-16_12-37-03inpruwki/
With following parameter combination: {'batch_size_seq_length': 3, 'lr': 3e-05, 'lr_type': 'constant'}
EVALUATION OF CHECKPOINT /home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_68ed0bc8_2020-02-16_12-37-03inpruwki/outputs/checkpoint-3
-------------------------------------------------------------
|           |   agree   | disagree  |  discuss  | unrelated |
-------------------------------------------------------------
|   agree   |    619    |    39     |    99     |     7     |
-------------------------------------------------------------
| disagree  |    114    |    311    |    71     |    15     |
-------------------------------------------------------------
|  discuss  |    253    |    76     |   1517    |    52     |
-------------------------------------------------------------
| unrelated |    51     |    42     |    92     |   8540    |
-------------------------------------------------------------
Score: 8705.5 out of 9226.0	(94.35833513982224%)
Accuracy: 0.92343250966549
F1 overall: 0.7832324585424602
F1 per class: [0.6873958911715713, 0.6353421859039836, 0.8251291813978787, 0.985062575696407]
*******************************************


*******************************************
EVALUATING PIPELINE 
{'batch_size_seq_length': 3, 'lr': 3e-05, 'lr_type': 'cosine'}
INFO:__main__:Creating features from dataset file at /home/ubuntu/fnd_implementation/data/processed
  0%|                                                 | 0/11898 [00:00<?, ?it/s]  0%|                                       | 1/11898 [00:01<3:25:37,  1.04s/it]  4%|█▌                                   | 501/11898 [00:01<2:17:56,  1.38it/s] 46%|█████████████████▌                    | 5501/11898 [00:01<54:11,  1.97it/s]100%|███████████████████████████████████| 11898/11898 [00:01<00:00, 7192.10it/s]
  ******************************************* 
              Running Evaluation                
  *******************************************
 
  Length dataset evaluation: 11898
  Length dataloader evaluation: 744
  Number of epochs: 3
  Batch size: 16
  ******************************************* 
 
['/home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_7e5c3cae_2020-02-17_06-11-48706tbf3m/outputs/checkpoint-3']
INFO:__main__:Evaluate the following checkpoints: ['/home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_7e5c3cae_2020-02-17_06-11-48706tbf3m/outputs/checkpoint-3']
INFO:transformers.configuration_utils:loading configuration file /home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_7e5c3cae_2020-02-17_06-11-48706tbf3m/outputs/checkpoint-3/config.json
INFO:transformers.configuration_utils:Model config {
  "attn_type": "bi",
  "bi_data": false,
  "clamp_len": -1,
  "d_head": 64,
  "d_inner": 3072,
  "d_model": 768,
  "dropout": 0.1,
  "end_n_top": 5,
  "ff_activation": "gelu",
  "finetuning_task": null,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "mem_len": null,
  "n_head": 12,
  "n_layer": 12,
  "num_labels": 4,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pruned_heads": {},
  "reuse_len": null,
  "same_length": false,
  "start_n_top": 5,
  "summary_activation": "tanh",
  "summary_last_dropout": 0.1,
  "summary_type": "last",
  "summary_use_proj": true,
  "torchscript": false,
  "untie_r": true,
  "use_bfloat16": false,
  "vocab_size": 32000
}

INFO:transformers.modeling_utils:loading weights file /home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_7e5c3cae_2020-02-17_06-11-48706tbf3m/outputs/checkpoint-3/pytorch_model.bin
HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=744.0, style=ProgressStyle(description_width='initial')), HTML(value='')))
0.0013450.0015130.0007980.2701410.5239900.1048170.0180140.0026690.0003540.0000600.0000660.0000250.0000380.0000230.9841660.0656590.0042030.6053780.5921991.1615761.8992811.8663480.6990220.0305150.0013970.0000760.0000990.4440041.8463560.0637100.0021430.0001070.0000220.0000190.4235411.6514920.5743610.0156530.0004650.5333530.0134120.0565580.0013680.0001180.5424020.0120750.0002830.0001660.2579213.1514841.9153630.0376810.0008810.0000420.0006541.0124730.0180990.1413650.0024570.0000610.4622410.0076490.0001430.0000290.0006950.0002230.5546500.0083110.0015650.0000420.4630620.4324080.9221970.0126800.0002180.0000510.0000710.0000710.0000560.0000780.0023910.0002700.0001530.0000230.0000200.0000200.0000200.0000210.0000230.0000380.0000210.0000260.0000320.0020320.0000890.0000260.0002380.0002250.0001830.0006060.0000290.0001210.9165710.0089460.0001620.0000470.0000470.0000230.2999250.0027740.0000470.0010800.0015420.0011400.0071430.6090110.0054520.0001020.0000690.0000670.0000780.0003370.0000350.0512440.0008680.0000550.0005920.0000740.0000210.0001390.0005660.0001550.0000670.0001100.0000360.0000580.0000230.0000470.0000450.0403450.0258340.0002910.1487970.0016260.0002630.0000370.0000350.0000600.0188170.0002360.0000720.0000760.1290140.4629830.0030500.4788370.0031000.0162490.4995510.3146840.4733770.0030710.0000490.0013680.0006390.0020320.0007580.2199650.4921910.2363701.0319310.0399290.0005070.0000940.2937272.1908520.0125130.0001380.0000650.0000281.0669410.3934120.0022110.0012650.0009060.0008320.0020580.0001090.0004800.0022350.0002900.0004810.0001270.0001060.3528860.0018840.0001410.0002060.0003352.8876400.0145450.0001790.0001630.0001320.5062670.4468000.0022800.0002900.0004280.9214480.0045300.0001490.4602070.2993590.0017260.6242770.5529270.0027700.0724720.8887890.0054080.0001820.3092960.8765610.4277340.4543670.1397140.0006341.0656890.6265972.8875293.5266950.7182710.0031380.0001040.0000780.4628490.1986530.0008530.4307080.0026090.2509460.3380750.3702530.3392580.0014210.0001460.0004110.0001790.0000260.0003900.0058710.0003670.0004400.0007660.0018630.0007960.0001830.3982140.0018400.0003360.0032550.0001830.0434790.0314710.0013970.0026410.0015700.4498110.0020130.0644070.4850470.0054190.0061630.0000550.0000200.5809510.0021160.3214290.0021160.0032020.0000680.0000720.0000980.0023190.0003210.0062900.9114750.9810251.7402570.0068630.6137720.0063261.2368850.1173450.0004910.0000900.0000870.0000590.0002830.0028211.4682911.4439190.5194870.0017980.0000310.0000760.0000240.0001180.0001040.0004982.6639192.2442760.0073820.0008730.0001070.0000790.0003801.7724870.3455100.1123420.0004410.0000990.0000200.0000200.0004840.0050650.0000630.0000480.0000480.0001300.0002870.3703740.9368570.1611830.2415410.0943270.8237080.1596650.0007530.0001020.0004572.4928661.2351060.2661080.0010290.0001190.0000820.0146450.0007390.0991350.5766750.1224090.0164070.0002950.0004760.0972570.0003500.0000800.0000820.4800770.8793470.4460960.4601760.9403840.0026020.0496000.0024610.0001140.0002380.0016010.1496430.2972540.0008200.0003630.0000200.2365840.5515970.0130570.0007330.0029260.0005371.6347261.1293710.5507491.1108180.0080890.0000680.0000880.0000800.0001000.0000890.7229610.0072610.8022440.5867000.1800600.0005050.0000320.0000310.0000690.0001190.0000550.0000610.0000470.0000180.0000950.0000440.0002250.0015050.5206032.0727061.3418403.0527560.9748680.6329640.0018710.0003150.0002440.0003490.0166630.0453590.0302320.0001030.0003220.0000200.0000320.0000200.0000334.1089332.4602670.0063150.0005630.8315230.0030140.0004741.8006662.5530960.3448850.5345310.1076000.0186440.0001760.1289790.0005342.2323211.1451810.0026210.0001290.0000960.0001740.0001270.3373740.0020290.0008570.0001601.6422591.7196901.1723600.5720230.0014490.0235540.0091700.1506530.0010940.1709320.0008150.9878511.2792940.3204340.0007131.4200001.6671340.0041830.0000710.0480780.0003960.0000230.5554380.0049250.0024480.0005480.3677050.0010890.0001610.0002960.0001430.0000690.0000200.0002010.0005860.0000370.0001500.0002200.5179330.4184400.0012670.0001240.0000870.0000850.0001150.7550670.6854191.5923540.3813380.8233900.4641410.0009530.0002570.0000260.0002070.0005730.0006260.0002250.0001180.0002060.7540290.8945780.0019110.0001440.0003200.0004080.0004960.7146120.3038740.0030770.0006310.0004180.0001920.0002330.0012170.0000950.5129440.0017221.7195610.4831590.0010160.0003250.0000960.0495411.2264570.0032371.0106270.3664170.8238271.0260830.6667260.7250110.0013800.0004330.0006801.1331500.0028340.0001500.5637541.3819030.3042160.1420910.0003463.6760530.0069760.0032000.1665580.0008580.0003250.0004010.1138680.4802761.1987700.6079670.4997410.4207451.2848830.2265490.4776970.1928330.8430490.0369720.6822480.8194700.3877080.7379440.5984280.8685240.3651630.6613320.6960390.1968830.6213200.4105080.5727200.5688020.3467660.5094140.8692900.1589740.4263800.9426370.8180060.5487620.4103800.0045880.1171770.9201380.3001070.4134230.6667130.3495770.2266560.7739570.6473611.4383011.5558160.8053380.3147530.1002000.5937990.2656590.4544860.0610210.6402340.5186200.0628070.6041310.7926740.2954870.6441560.9518200.3925881.0340040.1962620.4662140.0529650.8650821.0479460.7026170.1283750.6945050.6029170.4430560.2522740.2247230.6212400.3104311.3297330.4181621.0841820.2496840.4262520.7497130.6557740.3177150.4414700.4756380.7695160.2991491.1841890.4743460.1591530.4037930.4542390.5682720.1894690.8769561.2165960.4749200.3477220.1852720.4759170.1019630.2935390.5782461.2688590.8948070.1801950.3624850.0129880.2840980.6402410.3725460.6074740.3419410.8615780.3289800.2953510.2928400.0014670.6386900.5171080.2319970.9230691.2738880.2551470.2743820.0156470.1992621.1215390.5874410.8885240.5794991.3096060.2760260.1848590.2907890.7945310.0069610.3822610.3908550.4021090.5725371.0270790.7765721.8034590.3884310.6320190.7988550.3006810.3613570.5331670.8641850.3133380.6811360.7703890.3325310.4530800.0177880.8143340.0248190.8021160.6846920.5559390.5400350.5973731.5898150.9672740.1292880.0368980.0829410.4092890.6746761.4036460.0661900.0033360.476073

*******************************************
EVALUATING PIPELINE 
Pipeline directory: /home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_7e5c3cae_2020-02-17_06-11-48706tbf3m/
With following parameter combination: {'batch_size_seq_length': 3, 'lr': 3e-05, 'lr_type': 'cosine'}
EVALUATION OF CHECKPOINT /home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_7e5c3cae_2020-02-17_06-11-48706tbf3m/outputs/checkpoint-3
-------------------------------------------------------------
|           |   agree   | disagree  |  discuss  | unrelated |
-------------------------------------------------------------
|   agree   |    800    |    73     |    146    |    13     |
-------------------------------------------------------------
| disagree  |    76     |    313    |    81     |    23     |
-------------------------------------------------------------
|  discuss  |    137    |    55     |   1496    |    76     |
-------------------------------------------------------------
| unrelated |    24     |    27     |    56     |   8502    |
-------------------------------------------------------------
Score: 8727.5 out of 9226.0	(94.59679167569911%)
Accuracy: 0.9338544293158514
F1 overall: 0.8141229384734978
F1 per class: [0.7733204446592556, 0.6514047866805411, 0.8444820773355913, 0.987284445218603]
*******************************************


*******************************************
EVALUATING PIPELINE 
{'batch_size_seq_length': 1, 'lr': 3e-05, 'lr_type': 'cosine'}
INFO:__main__:Creating features from dataset file at /home/ubuntu/fnd_implementation/data/processed
  0%|                                                 | 0/11898 [00:00<?, ?it/s]  0%|                                       | 1/11898 [00:01<4:20:07,  1.31s/it]  4%|█▌                                   | 501/11898 [00:02<2:54:32,  1.09it/s] 50%|██████████████████▏                 | 6001/11898 [00:02<1:03:13,  1.55it/s]100%|███████████████████████████████████| 11898/11898 [00:02<00:00, 5014.26it/s]
  ******************************************* 
              Running Evaluation                
  *******************************************
 
  Length dataset evaluation: 11898
  Length dataloader evaluation: 2975
  Number of epochs: 3
  Batch size: 4
  ******************************************* 
 
['/home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_79169be0_2020-02-16_21-35-29mxr4y_c3/outputs/checkpoint-3']
INFO:__main__:Evaluate the following checkpoints: ['/home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_79169be0_2020-02-16_21-35-29mxr4y_c3/outputs/checkpoint-3']
INFO:transformers.configuration_utils:loading configuration file /home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_79169be0_2020-02-16_21-35-29mxr4y_c3/outputs/checkpoint-3/config.json
INFO:transformers.configuration_utils:Model config {
  "attn_type": "bi",
  "bi_data": false,
  "clamp_len": -1,
  "d_head": 64,
  "d_inner": 3072,
  "d_model": 768,
  "dropout": 0.1,
  "end_n_top": 5,
  "ff_activation": "gelu",
  "finetuning_task": null,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "mem_len": null,
  "n_head": 12,
  "n_layer": 12,
  "num_labels": 4,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pruned_heads": {},
  "reuse_len": null,
  "same_length": false,
  "start_n_top": 5,
  "summary_activation": "tanh",
  "summary_last_dropout": 0.1,
  "summary_type": "last",
  "summary_use_proj": true,
  "torchscript": false,
  "untie_r": true,
  "use_bfloat16": false,
  "vocab_size": 32000
}

INFO:transformers.modeling_utils:loading weights file /home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_79169be0_2020-02-16_21-35-29mxr4y_c3/outputs/checkpoint-3/pytorch_model.bin
HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=2975.0, style=ProgressStyle(description_width='initial')), HTML(value='')))
0.0019450.0019580.0009920.0006310.0008840.0001910.0001150.0000310.0000180.0000140.0000660.0000921.6431030.1264070.0090430.0006170.0000530.0000171.8767030.0987880.0049540.0002510.0000260.0000150.0000150.0000860.0000182.0260000.0723700.0025090.0000980.0002432.1859910.0662550.0019610.0000690.0000342.2067700.0580870.0015030.0001200.0000150.0000130.0000900.0000130.0000120.0000120.0000120.0000870.0000130.0000120.0000120.0000120.0000120.0000120.0000120.0022640.4726630.0187402.2431580.0374700.0006320.0000404.2792030.0668800.0010460.0001332.2291692.2734760.0329630.0004860.0000210.0000150.0001450.0000160.0000340.0000372.2309011.3752730.0174221.7233552.2650620.0276372.2441902.1916112.2625260.0267610.0003220.0000950.0000162.2394610.0246240.0003850.0006350.0000210.0000150.0004650.0000160.0000120.0000120.0000120.0000120.0000120.0000140.0001750.0000130.0000120.0000960.0000130.0000120.0000141.5151031.6088871.6032783.2899630.0308820.0163100.0001950.0000150.0000140.0000150.0000160.0000130.0000160.0000130.0000230.0000860.0000150.0000190.0000140.0000140.0000130.0000140.0000130.0000180.0000140.0000820.0010581.4454090.0104112.1749790.0156770.0001240.0004850.0001562.1287880.0145930.0001120.0000200.0002470.0000140.0000120.0000510.0000130.0000850.0000850.0000190.0063430.0000642.1722100.0136050.0001060.0000500.0000190.0000190.0000190.0000950.0000250.0000200.0000720.0000230.0000260.0000310.0000690.0000220.0000230.0011050.0000270.0000230.0000360.0000200.0000220.0000190.0000270.0000220.0000240.0000220.0000240.0000230.0000960.0002730.0001040.0000200.0001030.0000880.0000532.0367740.0558390.0016581.9999040.0103030.0052060.0060120.0034690.0001000.0000190.0003310.0000150.0000150.0004060.0000880.0000150.0000140.0000630.0000680.0000160.0000150.0003341.3265410.0326831.8497541.7956671.1923610.0053580.0000350.0000120.0000110.0000110.0000110.0000240.0016500.0000190.0000120.0000110.0000120.0000110.0000120.0000110.0000120.0000112.5229510.0104800.0000550.0000140.0000130.0000130.0000140.0000140.0000130.0000130.0000130.0000130.0000130.0000220.0000130.0000130.0000130.0000130.0005630.0000160.0000130.0004450.0004620.0000130.0001530.0000122.2586020.0086120.0001810.0000970.0001760.0000240.0000160.0000150.0000150.0005910.0000150.0000130.0000130.0000130.0002770.0006280.0000161.8767181.8789910.0066070.0000370.0000140.0000141.8789361.8848870.0064920.0000370.0000840.0000120.0000830.0000830.0000360.0000830.0000120.0000830.0000900.0000120.0001010.0000130.0000120.0001540.0001600.0000830.0000830.0000130.0001530.0000830.0000130.0000120.0001660.0000130.0000130.0002660.0000160.0239640.0005930.0000170.8604250.0046990.0002840.0000130.0001710.0000850.0002300.0004310.0000880.0000130.0000130.0000130.0000120.0000130.0000130.0000130.0000130.0000130.0000130.0000120.0000120.0000130.0000130.0000130.0000130.0000130.0000130.0000130.0000160.0000130.0000420.0000130.0000130.0000880.0000130.0000120.0000130.0000130.0000140.0000140.0000130.0000130.0000130.0000150.0000130.0000130.0000130.0000130.0000860.0000130.0002120.0000140.0000140.0003450.0000150.0000130.0000130.0000150.0000240.0000260.0000130.0000140.0000130.0000130.0000150.0000130.0000160.0004940.0000150.0001660.0000890.0003280.0000880.0003330.0000140.0003130.0000140.0000130.0000130.0000130.0000130.0002320.0003480.0000860.0001550.0000710.0012850.0011060.0000890.0001060.0000120.0000850.0000850.0001650.0002520.0000130.0005020.0001590.0000250.0000130.0000120.0000980.0000130.0000130.0000130.0000130.0000130.0000130.0000130.0000131.7004620.0040040.0000220.0000130.0000130.0000130.0000320.0000130.0000130.0000140.0000130.0000131.4570841.2073750.0224790.0008120.0115730.0000410.0003000.0018650.0001980.0025512.1540830.0117410.9617960.0021120.0002570.0000132.1161210.0047070.0001380.0000130.0000470.0006331.1604710.0024920.0001701.1103890.0023700.0000170.0000120.0000121.7685380.0039880.0000200.0000820.0000120.0000120.0000120.0003430.0001590.0002160.0001220.0084280.0000470.0000420.0000390.0000340.0000360.0000330.0000290.0029890.0201360.0000660.0001640.0001070.0002150.0001570.0002400.0000150.0000150.0000140.0003910.0000191.9349220.0038240.0000230.0002820.0000150.0000150.0000150.0000150.0000150.0000160.0000160.0002940.0002920.0000140.0000130.0001560.0021100.0000240.0000350.0032830.0000220.0000180.0001440.0000200.0000210.0000500.0004770.0001860.0000140.0000850.0000120.0000110.0000120.0000110.0000900.0000860.0000830.0000120.0000110.0000120.0000110.0000120.0001560.0000120.0000110.0000860.0000130.0000150.0002840.0000181.3707451.8836800.0047242.7780412.5890810.0324800.0054480.0001360.0000170.0011830.0000171.3496231.8166280.0031990.0005210.0000840.0000130.0015250.0015250.0003850.0003071.0539150.0019140.0000160.0000130.0000850.0000140.0000120.0000830.0000130.0000120.0000120.0001610.0000840.0000130.0000130.0003330.0026090.0004310.0000850.0000130.0004340.0000160.0000150.0000150.0002690.0000160.0000160.0002690.0000160.0000130.0001610.0000120.0000110.0000871.7008570.0027880.0000161.9423500.0032390.0000890.0000120.0000111.9450710.0031440.0000890.0000120.0000110.0000960.0000120.0000110.0000110.0000900.0000850.0000120.0000122.3130330.0036610.0000182.3146310.0036462.2726980.0035690.0000190.0000852.3185090.0036180.0000180.0000120.0000120.0002600.0000130.0000120.0000130.0000820.0005760.0008600.0002910.0002860.0002810.0000150.0066350.0209802.1052723.5221901.8258780.0030505.1966610.0079733.5103200.0054190.0003201.0705681.2773302.2761340.0035390.0000181.7945560.0026710.0006190.0006750.0005510.0000130.0082780.0005090.0000131.7085800.0066990.0000220.0000120.0016091.4987580.0025300.0001900.0001100.0017830.0002210.0000270.0001540.1138710.0003970.0003010.0002930.0003030.0003020.0000850.0000260.0000140.0000140.0000150.0002680.0000150.0000150.0002660.0000150.0000140.0000150.0000140.0002670.0000150.0000140.0000290.0000110.0000120.0002620.0001260.0002941.0998310.0015290.0002220.0001970.0001000.0000150.0001930.0000120.0000221.9162770.3119013.2986400.0044950.0000191.5787692.1202820.0028782.6553550.0094350.0000960.0000150.0015750.0299200.0004360.0000170.0000150.0004530.0000160.0000160.0000150.0000170.0039290.0001680.0000150.0002910.0000150.0002750.0000150.0000150.0000140.0000140.0002660.0000160.0000140.0000140.0000210.0000140.0027000.0008560.0000150.0000130.0000380.0000300.0037740.0016430.0001040.0001050.0000890.0001110.0000150.0000141.8880910.0030170.0000970.0000140.0000140.9477790.0012120.0000950.0000140.0001130.0000944.6010916.9120460.0089740.0002020.0000830.0001560.0000850.0001770.0000840.0001900.0001070.0001610.0010200.0003460.0001390.0003020.0002240.0000950.0001540.0001590.0352630.0004170.9142190.0023204.9494910.0060400.0000190.0000110.0000120.0000151.5123620.0018401.3778691.5691450.0019020.0000141.5783001.5478541.7906130.0021562.7372414.4572344.5404260.0056800.0001820.0003290.0002210.0002710.0001370.0000140.0000140.0001740.0001040.0000130.0000130.0037180.0238200.0005510.0023280.0002940.0003080.0005690.0015370.0003000.0002280.0002970.0010270.0059780.0006030.9926350.0011600.0001553.0030271.4210610.0017303.2655600.9851240.0037490.0000190.0000141.8369981.3402530.0015400.0000160.0000140.0005640.0009061.5832290.0019780.0020351.5406131.6709340.0020671.2882930.0026331.4050640.0016633.0268580.0034760.0001030.0001100.0002431.6218490.0035930.0000931.5093330.0017680.0000131.6227900.0018050.0000850.0000120.0000110.0000110.0000110.0000110.0000111.7558293.7907870.0042990.0000160.0000821.5743501.5921210.4022400.0005250.7025571.5088470.0018110.6272470.8715260.0013970.0000890.0007860.0008620.0005870.0000850.0002660.0000140.0003150.0003830.0003730.0002680.0005340.0001710.0001240.0000170.0008800.0003760.0000140.0007960.0065060.0152970.3394540.6803520.0007410.0000150.0000140.0000170.0000130.0001950.0000140.0000830.0031260.0000160.0000130.0275790.9633750.6927410.0011680.0003110.0001680.0000980.0003010.0003070.0007020.0003040.0000120.0000110.0000120.0001130.0000340.0000130.0000130.0000130.0001360.0000200.0000130.0000130.0003660.0000130.0001330.0000130.0000850.0008120.0003860.0000430.0028230.0000160.0000130.0000140.0000260.0000130.0000150.0004140.0004010.0000710.0006010.0000140.0006000.0078680.0000280.0006430.0000220.0087150.0000320.0057510.0003160.0002330.0000210.0001300.0006620.0004900.0006890.0000150.2783740.0008920.0000582.5908232.8801361.5602082.6410820.0027910.0002260.0001520.0002220.0007440.0000820.0000920.0000160.0000220.0000150.0000990.5611070.0010550.0002940.0002920.0003760.0004561.7575641.6590220.0015961.8490661.6813960.0016130.0000283.9052144.0224211.9910250.0020092.0258930.0043500.0013740.0007080.0007240.0004070.0001630.0000850.0011650.0001580.0008581.1441610.0447350.0094350.0004930.0006660.0000141.8402610.0020290.0000150.0002980.0000840.0000130.0005731.5771070.0015530.0001090.0000120.0000111.8420111.6906490.0016770.0000131.6346960.0015903.2232213.3076530.0030400.0000170.0000150.0000130.0000850.0000130.0000140.0000130.0000140.0000140.0000152.2384430.0020390.0000150.0000130.0000140.0000140.0000140.0000140.0000140.0000140.0000850.0001280.0002660.0000130.0069580.0000910.0049681.4808490.0094910.0000210.0000920.0000120.0001520.0000130.0001520.0000840.0000130.0003220.0001530.0000830.0001550.0000830.0000830.1424730.0001390.0003520.0000140.0000130.0003750.0033920.1872750.0054850.0389900.0022053.5368421.6049470.0014070.0000993.0723401.8650341.9225411.8519420.0028520.0056043.1142591.9443640.0016890.0004010.0013560.0000141.8054470.0018040.0002780.0000140.0000130.0000120.0000130.0023392.8876721.7519100.0018101.7251681.4227920.0013710.0000130.0000870.0000900.0001720.0001280.0001620.0000120.0001770.0002320.0001590.0001590.0001620.0001180.0000120.0001600.0001060.0000130.0000140.0003160.0003860.0000880.0000880.0000130.0000130.0003080.0003320.0003252.1593872.1956042.1935300.0020500.0002392.0512033.5060102.2147410.0022840.0000150.0000140.0000140.0003840.0004750.0000140.0000130.0000130.0000130.0000190.0000130.0000430.0000130.0000680.0000130.0000140.0000140.0000150.0000130.0000130.0003910.0000140.0000140.0000140.0000130.0003740.0004300.0000140.0009300.0007120.0008735.5888781.8778203.7279845.6278703.7458620.0030110.0002770.0002750.0002740.0000140.0017920.0003273.5719360.0031654.6128520.0038210.0001580.0001540.0000830.0000120.0001550.0001560.0000840.0000830.0001550.0000130.0012090.0011580.0005140.0014890.0006430.0004060.0030860.0096280.1466291.2291180.0824910.0057990.0006360.0002380.0001150.0001790.0000130.0000140.0001920.0003150.0000130.0000140.0000130.0000160.0000110.0000110.0000120.0000120.0000120.0000110.0001600.0000121.9641422.1292900.0017890.0000130.0000120.0000110.0000860.0000860.0000120.0000120.0000130.0000120.0001730.0001090.0000130.0000120.0000120.0000860.0000130.0002970.0000140.0003730.0000140.0016550.0003150.0000140.0006904.4578740.0036490.0000182.0354600.0079450.0009060.0000140.0002730.0000130.0000130.0007580.0000130.0002480.0000130.0000120.0009800.0002980.0000120.0000130.0007260.0007450.0005450.0003680.0045530.0004790.0004130.0004410.0004470.0003610.0002290.0000831.9619430.0016660.0001550.0000830.0001030.0002240.0015663.2582423.0879494.6452024.5345115.8942654.9487440.0041350.0004300.0011220.0005320.0002290.0004760.0012180.0000860.0001570.0000130.0002300.0002340.0000840.0000850.0000120.0002280.0000840.0000860.9360640.0012960.0053200.0000200.0002340.0013880.3900640.0148441.4205130.0022260.0012431.8223631.7932813.7230820.0060911.9493810.0019130.0014630.0013770.0007260.0003510.0002160.0001640.0001560.0001580.0002390.0000870.0010130.0008490.0000880.0000130.0000830.0000130.0002350.0005040.9292160.0006700.0002950.0000180.0004680.0000310.0000140.0002980.0000210.0000150.0003030.0000150.0000140.0003020.0000261.2699100.0008931.7870581.9260960.0013450.0000140.0000130.0000130.0000131.9221040.0013371.9527810.0013630.0000140.0000131.9357010.0013411.3762170.0009560.0000140.0000130.0000130.0000130.0022400.0342350.0001080.0001600.0003860.0012230.0002390.0000920.0000860.0002270.0000890.0001740.0001590.0000370.0017620.0012600.0011870.0023703.6707340.0066210.0000171.4125490.0009620.0000142.0849090.0014110.0000140.0000120.0000120.0000130.0014030.0013550.0000120.0000960.0000120.0000110.0000120.0000110.0000120.0001910.0000120.0024640.0003220.0544851.9085072.2751840.0015170.0000132.1013260.4126430.0002840.0000120.0000120.0057480.0053760.1456540.0022140.0040830.0006790.0031070.0011660.0006570.0002971.5786291.5883901.5371100.0010151.5474101.8021880.0011860.0000120.0000120.0000113.1530050.0020611.5270890.0010021.4899840.0009780.0014710.0000140.0008750.0004570.0000140.0000930.0000180.0000140.0001540.0000830.0000980.0000830.0001510.0001120.0001000.0003940.0000820.0002440.0000130.0001970.0000130.0001530.0000860.0000862.3240634.5685052.2970590.0015450.0000842.2759522.2728452.3124164.4777472.2981502.2698994.5710000.0029064.5454980.0029622.3244144.5785510.0029000.0000130.0000110.0000110.0000940.0000120.0000120.0000110.0000110.0000840.0000110.0000110.0000110.0000820.0000110.0000820.0000920.0000120.0000110.0000110.0000120.0000120.0001010.0000120.0000130.0001620.0000120.0000110.0000960.0000120.0000820.0001060.0000120.0000110.0000110.0000110.0000120.0000110.0000110.0000970.0000140.0000110.0000120.0000110.0000110.0000110.0005150.0005140.0004090.0012410.0004500.0006620.0004530.0004280.1476960.0010810.0001610.0247761.1451005.9962533.1077740.0424651.1206181.3089040.6721940.0012460.0002930.0002940.0002912.1067003.9073430.0410620.0005040.0003340.0006970.0003150.0005830.0017100.0006760.0000120.0001730.0001200.0000120.0000120.0000140.0000120.0002350.0000130.0000130.0002360.0000120.0002290.0000120.0000830.0000120.0002350.0002120.0000130.0081700.2941620.0005390.0006500.0088030.8036190.0008080.0000140.0003330.0000840.0000110.0000120.0000110.0000841.4417460.0009500.0001000.0000120.0000110.0000110.0000110.0009920.0000120.0000110.0000110.0000120.0000120.0000110.0000120.0000110.0000110.0000120.0000823.4277985.2307191.8112225.3355742.7978720.0244220.0019580.0000920.0005860.0007360.0045200.0001010.0009190.0011300.0003330.0000261.4096950.0009040.0005170.0012450.0001910.0000460.0000160.0028940.0009750.0013340.0014390.0003110.0004630.0003860.0002953.0165910.9765860.0189831.8245930.0054560.0001720.0007431.8609170.0017080.0101682.2953530.0253550.0046530.3990960.1242230.4761731.8640390.0292010.4419210.0361630.2380140.0001530.0000130.0003000.0003050.0003011.4178060.0010990.0003040.0002970.0003610.0003990.0003032.3091482.3180300.0015924.6382463.6726031.6424270.0010940.0002610.0000120.0000110.0002450.0000120.0001600.0000860.0002400.0000880.0000120.0001620.0000130.0004070.0000130.0003350.0000130.0006290.0000130.0003390.0003080.0000140.0000130.0000130.0150990.0003520.0003660.0002950.0004300.0005530.0002740.0000490.0000250.0000930.0010740.0000160.0000250.0000162.1874471.7974371.8934350.0010510.0000152.1185262.0111652.1966121.8984432.1932280.0012090.0000142.1510510.0014430.0000170.0002760.0000160.0000160.0005292.0684470.0016520.0002413.1995871.5468703.2679311.9350631.5474530.6776270.7793140.0015240.0001840.0006960.0001620.0815720.0008820.0012230.0006902.1696540.0021470.0001040.0001260.0155730.0001060.0036120.0007670.0005850.0018660.0025250.4532782.2837820.0012300.0000120.0000120.0000122.2353220.0012020.0000120.0000110.0000110.0000872.2835405.1234230.0027280.0000130.0000120.0000115.5190800.7366870.0074750.0000180.0000150.0006110.0000150.0002460.0000120.0000860.0002800.0001070.0001410.0000360.0000110.0000880.0001850.0000130.0000120.0000120.0000250.0000130.0000130.0000122.1946450.0015460.9504860.5230710.0026481.4770591.5632671.4637452.8557420.7962270.0026430.0028340.0000150.0000140.0000140.0004240.0000130.0000830.0000840.0000840.0000130.0008390.0000140.0003110.0005910.0000140.0000130.0000130.0003210.0597260.0003330.0000140.0000130.0003750.0000140.0003020.0000140.0000110.0000120.0000150.0000370.0000110.0000110.0000121.9753830.0583760.0000410.0000120.0001420.9308570.0005610.0000140.0000130.0000120.0000120.0000851.6958500.0930341.5078430.0007760.0000121.7549920.0009003.1386051.2801820.0007312.0638420.0013030.0002951.4449820.0010900.0000140.0007340.0000140.0003510.0000130.0000830.0000140.0000130.0002230.0000860.0000820.0002240.0000130.0000920.0000820.0001730.0000830.0002230.0000900.0000130.0001541.7797961.3020430.0949090.0000630.0000150.0000150.0000751.8320294.3740020.0021860.0000171.7502350.0009570.0000161.7502341.8073880.0009090.0000160.0000150.0000441.6271141.7478280.0008780.0000150.0000150.0000880.0000140.0000312.0639920.0010280.0000150.0000140.0000140.0000140.0000140.0000210.9605960.0004840.0000151.1780330.0005900.0000140.0000141.3013490.0006490.0000140.0000130.0004350.0000140.0004070.0005990.0000140.0000130.0000130.0000970.0007540.0003870.0000141.3769030.0016210.0000141.1635470.0044180.0236010.0050211.3620350.0009110.0003050.0002630.0005860.0002120.0002010.0004370.0000360.0002700.0003270.0002830.0010371.4813160.0010790.0007120.0006710.0004440.0003610.0004680.0003061.5477610.0012520.0012560.0001580.0005140.0000120.0000850.0015310.0069250.0000230.0368820.0001150.9072240.0004530.0003610.0000190.0000200.0085320.0035570.0000380.0000340.0003080.0003100.0002940.0002950.0003230.0003160.0003970.0003340.0003460.0012160.0004000.0001080.0000880.0000130.0000200.0000850.0001990.0001502.2370030.0010640.0005500.0010660.0000140.0012581.6125460.0015600.0028150.0070150.0000170.0000130.0000130.0000130.0000130.0004760.0000130.0006330.0004940.0000140.0020070.0016870.0000150.0000130.0000130.0004300.0000140.0000130.0000130.0000130.0000131.8519913.6617820.0032020.0009220.0009500.0007483.5190181.5346550.0008000.0002161.7400190.0008980.0035850.0002343.3268100.0016210.0000880.0000131.6541860.0008460.0057183.0881111.5287710.7641430.0003631.3420601.6848320.0007831.4790970.0014320.0001020.0000910.0000130.0000880.0000920.0008320.0011260.0003100.0003040.0003040.0023470.0016420.0007680.0000120.0011762.2370140.0013040.0002220.0002910.0001590.0002230.0000820.0001520.0002220.0001570.0002920.0005350.0002910.0003530.0004780.0002910.0002220.0010150.0007660.0010172.5209720.0623590.0001131.1706830.0008020.0000140.0000840.0000140.0002344.2395632.7751184.6275853.0584320.0035160.0023500.0000200.0004170.0009300.0004090.0004180.0001550.0007020.0002250.0004220.0020290.0004230.0011310.0002920.0008440.0002850.0007120.0001550.0004250.0004970.0002250.0008720.0006880.0006340.0409130.1444740.0002470.5264710.0006462.3006930.3499380.0056102.5716501.3462630.0006132.1585860.0099900.0375490.6330720.0003330.8192571.1927501.0957400.0005210.0269070.8994960.0007781.7260672.2936540.1167841.7320790.0008290.9335280.4200840.0052550.1359851.3668200.0028061.3073611.8245750.0266180.0166400.0079400.0125330.5678372.6086480.0711270.9460060.0052060.0095020.0011940.0048480.0083220.0054650.0047241.2548440.6085800.0121350.0690591.1932772.2520800.0112390.0005961.0083670.0006010.0005071.4000040.0010472.6942640.0016260.9138991.2129041.0909461.4090441.1570200.4341230.8060051.1723360.0006470.3833820.0004480.3508870.3480130.3917101.9522570.4899830.4232240.3362610.7894870.4360870.0002150.3793980.1496801.2788780.0174330.6661860.4468850.0040080.0005821.1634710.0006020.0022981.0555031.2126531.1080280.0019580.1175920.0068021.0040811.0021730.0958220.2221940.0004493.0593010.0016441.8894780.2564093.8518461.3043590.0095090.0000970.2767610.3617110.0001770.0000140.0056190.0127071.2635980.0061231.0850720.0059580.0096510.9644581.6394542.3039311.1634770.0041210.1086962.1351270.0036480.0104940.0235681.2386960.0054220.0056180.0053540.0057720.0055500.0057291.1801280.0006541.2445150.0006160.0002141.7160530.0042730.0004051.3315730.4620660.5627140.0117810.0000440.0013300.0002090.1188591.2265480.0006260.0008700.0000281.6944130.0007990.3866930.5672770.0070160.0040610.0018150.8362981.0223931.2122400.0257402.4651760.1798530.7237743.4616002.0938410.9722371.2642121.1657180.0005070.4120402.2309320.0010400.0077550.3443732.3556400.0011110.0055910.8034651.7918620.0087090.0116020.4929660.0003240.0896881.2904650.0029150.0001370.4645620.1268160.1320370.0001440.1199800.7124440.7663680.0099310.0000471.0848280.8956030.0004650.0097780.6753360.0019851.1225800.0132770.0052570.2111400.4284471.2234660.4598280.0082370.0003050.0071360.0002051.2130370.0980650.0002781.1893810.4824320.0029890.0030250.0032630.0018671.1969110.0009390.0000171.3908631.0876561.5205111.8301640.0965241.0249851.8435860.0062740.0064700.0063520.0103560.7573211.2377440.5596930.0582911.1873750.0160050.4618680.0089990.0000951.6377710.8654180.0073411.0695451.9584030.5882222.4085391.7563080.0007611.0133610.8035060.0572871.0942742.6532880.6580931.2476760.0063071.5004510.0013200.5030831.0343710.0005080.0235911.3999020.0020701.4264770.8930041.1609450.0176670.2371840.6878102.2332430.0011200.0067580.0001400.4682410.0004440.9310210.0004970.3612291.1875720.0005591.3960570.2066701.2568660.7616660.5586220.0006500.4929530.0003121.2008792.5234221.8905691.1144851.7210480.0014020.0070700.0002012.1236052.0466830.4551670.6433740.0577570.0000570.0012550.2756720.0001920.3732521.6220380.7015300.5131251.5394640.6684660.0031501.5357040.4313240.0003392.2005890.0008660.4865330.0002530.5425260.0043120.0024690.1207561.8898790.0125940.0000331.4576180.0006601.0778021.1528841.0252780.7032740.0085470.0019020.0803810.6178721.6904481.0119290.0018961.2809050.0006720.0048381.1337400.3997730.2487600.0001380.0001620.0056750.0175780.3726020.9795270.0057470.0358171.9176340.0008510.5776701.0491441.0868240.1556300.0004781.1876540.0053800.4857130.0123160.0002151.3787700.0008400.0129831.2263132.2036971.0919860.0053360.0098260.0006522.1554090.0060091.3413680.0055570.0051001.0998591.0743010.0101280.0051660.0002580.0047621.6414190.0109830.0050520.0021221.1588831.2066790.0126180.0003810.0057360.0016960.0001160.5107371.9010052.5441030.0076430.0003871.8478232.9369981.3180330.0775070.0002983.2734971.0778831.1049171.0283590.0051540.0153210.0096910.0003060.8780670.0053230.0054150.0055100.0056110.0001010.0048962.2268640.6423450.2742240.5570790.0058750.2185750.8840380.3987970.0002251.0274402.9585281.4130652.5444750.1377540.0071771.1384780.0059650.0000180.9233440.0003891.2169171.1420120.1020510.0061250.0008811.3124590.4674240.0073471.1941390.0004490.0000240.9060690.1492931.4545821.7301311.1640650.0006210.0000350.0047291.5887870.4535390.9927841.1060440.0024550.4903790.5836430.0293800.0002070.0004910.9044251.0353780.0055001.7343840.3789351.2591501.0872830.1617210.0053142.5822650.0015981.2495820.0016360.0000290.0184250.0116680.0022300.7778420.0044850.0024480.0009700.0042740.0000771.2298420.3660610.0018570.0003570.0006420.6745421.6737520.0070760.0051551.6706731.1754370.0072640.6507710.6764150.9739330.0124610.0044750.0051371.2550132.1639070.0052883.4202000.0058410.0048520.0047150.0051870.1453941.1183630.6258021.0936620.0106860.0064680.0005690.0029540.8780040.0332970.9226341.0403712.7317650.0086070.0037150.9873500.0282450.0115101.2343760.0053161.6390781.0847071.2085180.0072840.0067452.6674840.6741440.4132440.1675820.0004691.1198800.9476120.0240051.0768580.0230661.3265021.0849302.5737760.0019190.0094581.0958550.4478583.0058410.8302062.7379212.0078600.0052502.1551990.0013311.0223401.2512690.0275050.0001822.2050171.2687700.0054200.0065570.0001240.4964600.0048100.0007170.1268480.4245631.6681081.3435570.9940280.0016010.0313891.5845290.5076890.3974792.5407560.0105980.0047400.0765321.1342270.0083340.6523301.1170150.0065370.1351283.7488990.0013580.0139560.0104160.9899260.1004400.4105231.0485360.4291790.0006710.0048731.1651180.0060520.5260600.0058270.0175130.9830820.6423301.1591262.8373050.0015450.9179050.0003440.9142652.1157260.0055420.5022020.0164211.0642071.5110641.2754390.9553342.3472160.0012390.9964320.0252320.0069240.0080041.0391030.0073220.1413860.0088690.0109532.4462751.3916861.8923150.4953882.4364761.4709652.2952380.0072121.1072072.3557270.0028920.6513561.1573970.0054310.0000900.0307130.0625450.0233350.2608441.1155740.0006050.0000970.2881420.0002060.0686301.7215911.2666550.0053330.0001590.0137522.4346111.0099120.0123490.1644950.0050120.0059110.0066020.0000450.0000200.0008460.0003631.4237091.0377191.669229

*******************************************
EVALUATING PIPELINE 
Pipeline directory: /home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_79169be0_2020-02-16_21-35-29mxr4y_c3/
With following parameter combination: {'batch_size_seq_length': 1, 'lr': 3e-05, 'lr_type': 'cosine'}
EVALUATION OF CHECKPOINT /home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_79169be0_2020-02-16_21-35-29mxr4y_c3/outputs/checkpoint-3
-------------------------------------------------------------
|           |   agree   | disagree  |  discuss  | unrelated |
-------------------------------------------------------------
|   agree   |    721    |    90     |    138    |    14     |
-------------------------------------------------------------
| disagree  |    105    |    284    |    87     |    20     |
-------------------------------------------------------------
|  discuss  |    188    |    71     |   1511    |    80     |
-------------------------------------------------------------
| unrelated |    23     |    23     |    43     |   8500    |
-------------------------------------------------------------
Score: 8700.25 out of 9226.0	(94.30143073921526%)
Accuracy: 0.9258698940998488
F1 overall: 0.7827869104628232
F1 per class: [0.721, 0.5892116182572614, 0.8327362909892533, 0.9881997326047782]
*******************************************


*******************************************
EVALUATING PIPELINE 
{'batch_size_seq_length': 2, 'lr': 3e-05, 'lr_type': 'linear'}
INFO:__main__:Creating features from dataset file at /home/ubuntu/fnd_implementation/data/processed
  0%|                                                 | 0/11898 [00:00<?, ?it/s]  0%|                                       | 1/11898 [00:01<3:35:14,  1.09s/it]  4%|█▌                                   | 501/11898 [00:03<2:24:33,  1.31it/s] 50%|███████████████████▏                  | 6001/11898 [00:03<52:21,  1.88it/s]100%|███████████████████████████████████| 11898/11898 [00:03<00:00, 3787.87it/s]
  ******************************************* 
              Running Evaluation                
  *******************************************
 
  Length dataset evaluation: 11898
  Length dataloader evaluation: 1488
  Number of epochs: 3
  Batch size: 8
  ******************************************* 
 
['/home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_710075d4_2020-02-16_14-17-18vmsbuhfn/outputs/checkpoint-3']
INFO:__main__:Evaluate the following checkpoints: ['/home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_710075d4_2020-02-16_14-17-18vmsbuhfn/outputs/checkpoint-3']
INFO:transformers.configuration_utils:loading configuration file /home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_710075d4_2020-02-16_14-17-18vmsbuhfn/outputs/checkpoint-3/config.json
INFO:transformers.configuration_utils:Model config {
  "attn_type": "bi",
  "bi_data": false,
  "clamp_len": -1,
  "d_head": 64,
  "d_inner": 3072,
  "d_model": 768,
  "dropout": 0.1,
  "end_n_top": 5,
  "ff_activation": "gelu",
  "finetuning_task": null,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "mem_len": null,
  "n_head": 12,
  "n_layer": 12,
  "num_labels": 4,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pruned_heads": {},
  "reuse_len": null,
  "same_length": false,
  "start_n_top": 5,
  "summary_activation": "tanh",
  "summary_last_dropout": 0.1,
  "summary_type": "last",
  "summary_use_proj": true,
  "torchscript": false,
  "untie_r": true,
  "use_bfloat16": false,
  "vocab_size": 32000
}

INFO:transformers.modeling_utils:loading weights file /home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_710075d4_2020-02-16_14-17-18vmsbuhfn/outputs/checkpoint-3/pytorch_model.bin
HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=1488.0, style=ProgressStyle(description_width='initial')), HTML(value='')))
0.0002640.0003340.0003300.0001490.0000470.0004531.0345040.1477940.0184821.0215210.1021600.0092950.0008140.0002880.0000280.0001050.8481130.0498971.0046790.0528870.0026810.0013550.0000690.0000110.0001030.0000120.0000090.0000080.4213861.4660340.0489160.4096120.0128080.9640961.0380550.0296690.0010490.0000371.0412141.0243211.7572221.0197800.8117620.6740150.0153971.0485390.0229430.0004990.0001410.0000110.0000080.0000080.8478920.2468020.0045780.9410311.9040012.8392760.0548390.0009370.0000240.0000090.0000080.0000430.0000090.0000080.0000080.0000080.2506230.6072170.8126400.0125121.7399810.0238430.0003320.0000120.0000190.0000730.0004751.0925730.0136650.0003250.0000120.0004040.0000170.0000080.0000800.0000090.0016710.0000260.0000080.0000080.0000080.0000080.0000100.0006410.0149190.1851101.0632751.9601380.2221881.0298170.0101470.0001650.0000790.0000420.0000170.0000110.0000730.0008592.2119150.0223540.0002070.0000090.0000080.7628720.0065850.0000640.0000090.0000081.0031020.0082980.0000760.0000100.0000080.0000080.0000100.0000080.0000080.0006500.0006120.0001030.0000681.1772790.0088360.0000760.0000090.0002840.0000100.0000080.0002231.0342490.9342570.0065411.0562620.9468170.0065250.0000880.0000370.0000390.0000900.0000080.0000080.0001290.0000610.0000670.0000350.0000800.0000080.0000900.0002060.0003700.0008240.0000830.0001150.0004320.0000110.0000080.0000080.0000080.0000080.0000080.0000080.0000080.0000080.0000080.0011860.0000150.0000440.0000080.0000080.0000080.0000080.0000090.0000080.0000370.0000310.0000080.0000640.0000080.0000080.0000080.0000080.0000080.0000080.0000520.0003620.0002950.0000730.0000760.0000080.0000080.0007360.0001150.5313960.6264100.0030530.0000880.0003870.0003080.0000930.0000080.0000420.0000080.0000080.0000080.8788560.0040970.0000260.0000090.0000080.0000080.0008440.0001810.0006270.0000500.0000320.3974671.2306980.0054151.1202550.0049360.0000320.5374370.0023320.0000900.0000080.0001500.1036800.0004720.0000100.0001240.0001230.0003190.0000090.0000080.0000090.0147620.0004400.0001210.0000810.0000080.0000640.0001420.0000080.0000610.0000080.0000080.0000090.0001390.0000080.0010320.0000130.0020590.0000380.0000110.0000690.0000100.0000410.0000140.0000420.0000730.0000080.0000080.0000750.0000080.0000440.0000390.4325490.0016011.5078490.2569870.0009200.0000410.7069950.9137270.0032290.0012130.0002050.0001720.0000080.0000380.0000400.0000080.0000730.0000390.0001760.0002420.0000430.0001130.0000080.0000870.0001310.0000080.0000710.9729031.6710310.8803450.0029280.0000170.9169620.0029880.0000480.0000090.8644320.0027811.1550020.0036521.1772321.0025540.0031711.1607890.0036130.0035090.0000190.0000390.0005420.0002400.0000840.0046812.0065450.9293240.8137140.7100290.7521843.7151620.0111240.4855080.0022960.0000900.0007712.6389701.4184160.0042110.6615160.0019960.0001250.0000880.0001950.0002950.0002850.0000420.0000080.0000830.0000080.0000820.0000080.0000780.0000090.0000080.0639441.0608580.0029390.1064600.0003340.0000410.0028180.0296270.0000880.0014960.7338930.0028340.0035960.0063220.0000320.0001390.0000110.0002660.0007600.0016050.0003240.0000090.0000900.0000080.0000180.0009360.0444850.0001230.0008380.1366800.0004260.0000471.0829910.0028560.0000170.0004560.0000410.0000745.8058030.0147700.0001390.0000980.0010710.0001250.0002410.0002330.0001770.0001450.0008820.0081792.3686920.0057710.0000220.0000640.0010320.0000100.0001280.0006970.8281940.3593360.0008650.0000840.0000460.0000940.0000810.7661980.0063750.0003590.0003870.0003280.0002120.2907980.6001080.0014510.1659070.0457602.0684260.0047410.7854280.0017970.0001300.0002960.0000920.0013100.0005630.8957880.9126470.0021060.0001310.3981370.7194130.0016041.0681410.0023950.0000140.0000081.0980851.8769170.0041352.0732550.0045471.5721110.6767311.5383030.0035820.0003430.0000730.0000420.0001100.0001280.0000920.0000760.0002110.0007340.0011880.0006190.0000100.0000090.0000930.0004410.0000120.0957930.5663020.0016960.0003190.0007350.0002920.0000080.0001790.0000080.0000080.0000080.0000720.0000460.0000490.0002310.0037760.0000150.0000080.0000080.0001420.0001250.0001260.0029850.0000160.0025340.0040950.0005010.0005150.0004520.0002440.0000860.0938930.0009840.0002170.0001900.5895940.0011790.0000130.0004710.0003620.0004080.0002910.0000690.0057560.0000190.0640360.0015190.0022000.0004720.9122730.0018130.0015070.0043290.0007610.0002770.9479140.0018790.0001190.0001550.0010150.0000390.7912250.0139550.0020590.7741480.2201850.0004110.0000520.0000080.0000080.0000081.0738440.0019500.0000120.0000080.0000090.3885060.0025000.9275102.5564030.7711930.0014120.0001140.0001470.0000130.0001600.0002490.1019890.0002500.0000080.0004250.4850720.1427522.3880000.0042120.6949270.7995020.0020762.3780930.0041690.0183280.9689990.0020970.0000110.0000092.3532770.0075750.0005110.0000450.0001210.0001160.0000950.0001130.0001200.0001160.0001150.0000080.0001910.0000680.0000080.0002191.0678851.9292980.0033862.3451160.8856860.0014671.0789620.0018730.0000110.0000080.0190890.0002730.0000080.0000080.0000080.0000910.0000080.0001130.0001120.0004792.7176832.6980953.7436010.0060660.0001630.0026170.0027560.0069100.0001460.0001100.0000740.0001050.0001050.0004170.0005511.0071860.0029570.0007050.0008210.0003770.0001490.0000790.0000810.0001460.0000090.0000080.0000130.0000080.0000240.0003341.0300710.0015850.0000390.0000390.0000080.0928420.0001930.0000080.0000410.0000670.0000640.0003740.0001701.6892571.1191620.0025880.0000660.0000080.0009070.0000600.0038040.0001370.0008530.0004440.0011110.0009580.0005290.0003220.0000420.0002260.0000840.0110292.6230001.1399561.4654890.0023940.3088890.0021400.0014030.0000850.0002250.0000760.0001120.0000740.0010590.0005380.0001570.0053710.0088130.0006010.0363080.0016100.0118230.0033640.0055570.0003020.0085680.0003340.0013370.0000360.0055540.0008300.0000770.0001040.0000130.0000710.0000800.0000250.0000700.7323592.0784400.0028820.0000121.0664641.0771910.0014901.0963860.6746840.0009320.0000090.0001252.0636300.0030220.0775640.0004950.0009200.0011780.0003100.0005280.7093460.0014870.0004660.0004390.0000080.0000080.0000080.0004910.0000380.0000080.0000080.0007020.3372730.0073170.0008100.0120450.5856350.0007800.0016800.0009740.0007610.0007310.0004642.1460271.0122252.1019540.0027480.0000111.8950521.0673021.0753200.4427030.6970430.0009460.0000090.0001150.0000700.0000790.0001110.0001430.0000790.0000820.0001170.0543120.0572670.0047851.1635810.6082720.3327370.0303990.0793270.0895350.0001210.6933080.0008800.0000090.0000420.0000080.0000460.9617890.0012080.0000090.7971620.0009990.4484710.8013900.0010350.9480190.0011790.0000090.0000080.9624900.0011920.0000090.0000930.0002700.0003080.0002810.0003110.0011090.0123204.1360600.0093140.0014210.0031730.0003564.1490920.6661960.0016870.0007190.0008840.0140700.0017650.0000100.1039390.0001360.0064020.0077090.0000530.0458110.0011190.0615890.0023990.6369990.0008500.0000410.0000080.0000860.0000700.0000080.0000080.0000400.0000080.0000080.0000080.0000080.0000384.1342284.0802423.8905330.0048720.0798290.0005340.0002310.0001970.5839460.0011040.0000940.0019800.0004970.0004030.0003882.1284201.9008781.7618190.0023051.0108841.6417890.9953581.9381711.4431740.6582180.3590240.0004140.0003910.2543200.0006520.0003710.0004032.0912982.1771922.1165010.0025420.0000100.0001010.0001020.0001300.0000680.0003230.0001380.0002220.0001680.0001070.0000081.6975420.0021610.0004640.0656780.0000800.0000830.0000082.3049741.1343351.1499442.3175972.2589320.0024711.1391110.0013080.0000100.0007140.0002360.7784690.6384450.0011880.0012330.2783890.3653240.0281460.9763120.6539530.0018250.0011910.0005680.0007582.1971040.0023520.0003350.8738450.0009370.0000362.9799860.0031680.0000112.8344830.0044490.0000770.4612030.0005270.0000500.0003940.0000680.0000550.0000080.0000080.0000081.0866121.0000100.9171431.3496202.1374530.0032290.0000110.0001430.0000490.0000890.0008760.0001450.0002210.0000080.9632030.0011620.0001560.0001710.0000080.0000080.0000080.0000080.0030940.0000110.0000890.0000690.0000080.0000370.0011330.0003810.0000810.5623660.0017650.6239580.6980960.0007720.0001380.0000680.0000480.0001350.0000810.0001100.0000850.0001180.0001670.0000861.3220130.7280020.0007320.9531931.8187140.9475030.0009471.9662120.0019520.0000101.6522710.0016390.0000480.0000090.0016720.0000110.0000120.0003530.0002060.1609830.0001660.0034880.0000130.0000680.0001120.0000990.0000080.0001510.0000760.6281280.8227670.1617601.1964640.0013380.0003330.0001780.0001150.0002380.0003050.0003670.0002490.0001690.0007031.2549891.4749001.5188050.0020640.5594550.0019620.4820770.0007080.0132790.0002470.0001640.0003100.0004110.0015100.0009280.0021940.0000810.0000080.0000451.0838050.0011920.0003300.9690850.8126230.7880510.0007440.0000080.0005190.0004770.3848780.3851490.0003650.2609690.0002520.0000083.1295120.0033940.0004151.3994810.0013830.3388270.0012521.2773090.0012100.7082691.2435870.4924340.0135370.1986450.7805510.0007830.0000390.0002380.0005270.0008620.0141410.0008381.0298560.0011600.0004460.0003900.0001680.0007460.0220090.5825360.0007620.0004740.6906950.0086960.9677430.0009040.0001315.0686423.5701090.0037020.0001230.0001560.0002230.0002400.4046130.0005800.0003030.0002910.0002120.0003290.0004100.0035230.0086130.6243950.6410111.3190810.6858610.3604670.0029790.0103820.7718180.0877790.6745100.9523310.9640970.6565560.1861220.7633940.0164330.0528250.0022990.0040871.1718300.0081530.0011910.0032770.0021551.3002040.3806731.3826180.0018630.3922300.8814301.5491690.0229600.8263880.4077561.0131660.4938030.0335081.2312301.2191480.6124671.1106400.1507420.1490741.1869561.5445910.0072690.6644670.0053011.1830970.0075260.1593530.5665770.0747090.9399150.5902152.2813690.0824420.2895840.0002520.0231240.6351810.5851190.1325722.2207101.2894251.2522450.0058670.8000560.0026610.0034171.0656850.0781540.8373241.7670210.3774990.2378660.9328480.0038750.6570161.3631850.0013100.8399380.5447370.3475510.0328861.2545941.1024940.2444262.0792650.6219361.1663751.8265040.1972071.1321020.0026040.8674470.0029470.2202261.5088350.0054980.7109070.6351030.8651260.2395380.3872520.0441470.0020200.7364760.0361820.2974740.3212810.0032760.0176361.2148520.6072690.4366290.0019810.3838680.0005681.3749641.8882680.1450240.4685770.4002780.6402511.0377050.9583100.1018270.0014080.2895020.1605500.7364552.1625660.4498670.4120101.5194590.8320280.1842200.0067960.0572650.8459710.4920210.9483020.2116571.2732190.0015770.2277100.3934710.0642650.5809511.1746681.0145380.1015270.0198661.6347690.4346640.9345320.3587271.6649600.9291090.2107250.3658590.0072300.4643561.0384540.0125310.6975861.0410610.3760150.1419270.0009350.8832310.0024711.0456191.9319970.9283900.0116840.7882571.1982371.1273660.0406711.0177520.0478640.0025330.7381700.0079241.4590770.0302880.7245720.0118430.5357690.0145890.7304980.0022020.7646240.6770410.0022590.9234730.7994660.5374390.6261440.0023181.0568260.0026750.4897850.3568840.0071970.5541430.7699400.7883640.9881421.6534050.0038402.1516481.3236720.0218020.8488700.4616240.0145500.0050040.9543770.0563650.5408650.6622160.4241650.5041021.2353610.0476380.6562400.0040890.6373531.2792620.0037480.7701930.6426850.0004790.9950740.8371950.0020410.0016200.8617271.6081720.2530780.4124370.0011810.3694721.5612250.4625700.8701001.5622610.6212340.0008080.0194000.1246060.0012630.0014250.5246960.1222460.0006611.3460110.3825131.7800790.1832101.4765390.4004660.8047191.4751281.6816450.0037391.7268920.7221680.3946340.0043980.7369940.5612631.4527600.0016010.0083300.0113160.6048390.7495030.0346141.3599810.1766010.8914190.0099840.7203390.8600161.1632790.0268671.5924631.8168080.1521230.8908691.2535000.0044950.9690430.0038690.3529870.0028190.3528230.9415430.4459070.9088660.1841520.8362730.9295130.0358390.5671040.2336420.9234040.0386980.2165330.2136700.2320580.5714830.0032370.0017630.2345091.6985850.0372490.0541490.8933980.6385951.0410130.7254081.6455800.3018420.0142280.4803970.4362000.6819782.1456902.5013511.7949550.6074550.9077920.2857980.0518820.1356320.3637800.0137070.9343650.3400081.5264470.0017491.8482890.2405760.1870530.0298860.0000300.0014670.3791370.120844

*******************************************
EVALUATING PIPELINE 
Pipeline directory: /home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_710075d4_2020-02-16_14-17-18vmsbuhfn/
With following parameter combination: {'batch_size_seq_length': 2, 'lr': 3e-05, 'lr_type': 'linear'}
EVALUATION OF CHECKPOINT /home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_710075d4_2020-02-16_14-17-18vmsbuhfn/outputs/checkpoint-3
-------------------------------------------------------------
|           |   agree   | disagree  |  discuss  | unrelated |
-------------------------------------------------------------
|   agree   |    777    |    62     |    159    |    12     |
-------------------------------------------------------------
| disagree  |    97     |    306    |    57     |    16     |
-------------------------------------------------------------
|  discuss  |    144    |    73     |   1522    |    83     |
-------------------------------------------------------------
| unrelated |    19     |    27     |    41     |   8503    |
-------------------------------------------------------------
Score: 8741.75 out of 9226.0	(94.75124647734663%)
Accuracy: 0.9336022860985039
F1 overall: 0.8103191558866342
F1 per class: [0.7591597459697118, 0.6483050847457628, 0.8453207442377118, 0.9884910485933504]
*******************************************


*******************************************
EVALUATING PIPELINE 
{'batch_size_seq_length': 4, 'lr': 3e-05, 'lr_type': 'cosine'}
INFO:__main__:Creating features from dataset file at /home/ubuntu/fnd_implementation/data/processed
  0%|                                                 | 0/11898 [00:00<?, ?it/s]  0%|                                       | 1/11898 [00:01<3:26:14,  1.04s/it]  4%|█▌                                   | 501/11898 [00:01<2:18:21,  1.37it/s]100%|███████████████████████████████████| 11898/11898 [00:01<00:00, 7658.84it/s]
  ******************************************* 
              Running Evaluation                
  *******************************************
 
  Length dataset evaluation: 11898
  Length dataloader evaluation: 372
  Number of epochs: 3
  Batch size: 32
  ******************************************* 
 
['/home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_810b96fc_2020-02-17_07-41-00fob42hg8/outputs/checkpoint-3']
INFO:__main__:Evaluate the following checkpoints: ['/home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_810b96fc_2020-02-17_07-41-00fob42hg8/outputs/checkpoint-3']
INFO:transformers.configuration_utils:loading configuration file /home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_810b96fc_2020-02-17_07-41-00fob42hg8/outputs/checkpoint-3/config.json
INFO:transformers.configuration_utils:Model config {
  "attn_type": "bi",
  "bi_data": false,
  "clamp_len": -1,
  "d_head": 64,
  "d_inner": 3072,
  "d_model": 768,
  "dropout": 0.1,
  "end_n_top": 5,
  "ff_activation": "gelu",
  "finetuning_task": null,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "mem_len": null,
  "n_head": 12,
  "n_layer": 12,
  "num_labels": 4,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pruned_heads": {},
  "reuse_len": null,
  "same_length": false,
  "start_n_top": 5,
  "summary_activation": "tanh",
  "summary_last_dropout": 0.1,
  "summary_type": "last",
  "summary_use_proj": true,
  "torchscript": false,
  "untie_r": true,
  "use_bfloat16": false,
  "vocab_size": 32000
}

INFO:transformers.modeling_utils:loading weights file /home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_810b96fc_2020-02-17_07-41-00fob42hg8/outputs/checkpoint-3/pytorch_model.bin
HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=372.0, style=ProgressStyle(description_width='initial')), HTML(value='')))
0.1498820.2590450.3515520.1201230.0300720.0060800.0010630.4574110.3153781.0496311.3514630.4060150.1163260.1942150.8567190.0571550.0036030.6180370.2711740.2469160.0192820.0009680.1093240.2422760.3740500.0153060.0009110.4730870.0169690.0006140.2661760.0087590.2354580.4427420.1850770.3670330.2234650.0061190.0003280.0000920.0005590.0002540.0000480.0000450.0000800.0000560.0001030.0000960.0012120.0026910.0002150.0518190.0019750.0000850.0645140.0500540.0880270.5254750.0092400.0193040.0004580.0021030.0003530.1914080.0030620.0008460.0001750.0000650.0000480.0655530.1970990.0390110.0142430.0002910.0024800.0000940.4687390.2597370.0434330.4561020.1732800.0025500.8620910.3222110.4278871.6042190.0189811.4531150.0165720.0002310.5948470.0075070.0012340.0038220.2019010.2919080.0043670.0044410.2287721.3678070.0186440.0501820.5476420.0072190.0962790.0014680.1657460.0413960.5489600.7361060.1911740.6926520.3061090.1465161.0208121.4160200.2028220.0018680.0025370.0357720.1938210.0032280.0005070.0001600.0320360.0011830.0081290.0197120.0023320.0173160.0006000.1534680.1444390.0048260.0510090.1071020.0016210.0000510.2981220.2417720.9626950.0094450.0298340.3447470.5942860.2911360.6195450.0224380.0003010.0899571.0205830.8708210.0057870.0000730.0001110.4670250.3200340.0648820.0006360.0037550.0071000.0001370.0001470.0002310.0000680.0003360.2926180.0049230.1933570.0465810.0182613.1510950.1086290.0007590.3881550.2817760.1546320.0329550.0029030.0001320.4656530.3681030.1472030.0099130.0004860.0433280.0088330.0017720.2098280.0698790.0020081.2716870.7738910.0381190.0004000.0001730.0790030.2339550.0052840.0000850.0719510.0286050.0021130.0439120.0166841.3457091.4898020.7105500.0036600.0001740.1978360.0126770.0001940.0000922.1888581.5607680.2425330.0454501.5939211.5551090.3978190.0020450.9953160.4540420.0021950.0001300.0335990.0002820.9434400.5504490.0036590.0017450.2545200.0560280.2785470.4072880.6933330.0031570.0011390.3010200.0389820.0012640.0238790.0004800.3812420.3195660.3749100.7262980.0031790.0004410.3140150.7741880.1312660.0095390.0005070.0081420.0128490.0002330.1714230.0011580.0006260.5525420.3663130.0061370.0003430.1085230.2895841.8511720.0086570.0017040.7111140.6145090.9306480.3987930.0017580.3188350.0014940.3437140.3345371.9151860.0077090.0969000.0006830.2301580.7868620.2547750.8073090.5550350.2866760.3924670.6285700.7360670.4508310.2421130.4988670.3538040.3550600.6155590.4013610.7340930.2062060.5236310.4550130.2659620.6520951.0216590.8228010.1979850.3003930.2792760.3311140.2081010.4453000.5199300.5093160.3394350.4926360.4962710.2554490.7273970.2981150.3620140.9130940.6586940.8629920.3949320.4901570.5830190.5721060.3453900.4894650.3760400.8276680.3423910.3159070.6388090.8456260.2029110.0811060.9038480.2938720.6056960.3344100.3150470.3928290.8767470.2213850.0975990.7237340.4324930.6681730.2225610.5223270.4346390.5038480.4733260.9250640.5793760.3992980.7285000.4101830.5082620.1434890.3787380.4938250.3277951.0268840.4631230.1056100.3621210.6165240.277809

*******************************************
EVALUATING PIPELINE 
Pipeline directory: /home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_810b96fc_2020-02-17_07-41-00fob42hg8/
With following parameter combination: {'batch_size_seq_length': 4, 'lr': 3e-05, 'lr_type': 'cosine'}
EVALUATION OF CHECKPOINT /home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_810b96fc_2020-02-17_07-41-00fob42hg8/outputs/checkpoint-3
-------------------------------------------------------------
|           |   agree   | disagree  |  discuss  | unrelated |
-------------------------------------------------------------
|   agree   |    755    |    77     |    146    |    17     |
-------------------------------------------------------------
| disagree  |    78     |    316    |    69     |    23     |
-------------------------------------------------------------
|  discuss  |    182    |    50     |   1517    |    74     |
-------------------------------------------------------------
| unrelated |    22     |    25     |    47     |   8500    |
-------------------------------------------------------------
Score: 8736.0 out of 9226.0	(94.68892261001517%)
Accuracy: 0.9319213313161876
F1 overall: 0.8089516143586006
F1 per class: [0.7431102362204725, 0.6624737945492662, 0.8423098278734037, 0.9879125987912599]
*******************************************


*******************************************
EVALUATING PIPELINE 
{'batch_size_seq_length': 3, 'lr': 3e-05, 'lr_type': 'linear'}
INFO:__main__:Creating features from dataset file at /home/ubuntu/fnd_implementation/data/processed
  0%|                                                 | 0/11898 [00:00<?, ?it/s]  0%|                                       | 1/11898 [00:01<3:35:14,  1.09s/it]  4%|█▌                                   | 501/11898 [00:01<2:24:25,  1.32it/s] 50%|███████████████████▏                  | 6001/11898 [00:02<52:18,  1.88it/s]100%|███████████████████████████████████| 11898/11898 [00:02<00:00, 5854.27it/s]
  ******************************************* 
              Running Evaluation                
  *******************************************
 
  Length dataset evaluation: 11898
  Length dataloader evaluation: 744
  Number of epochs: 3
  Batch size: 16
  ******************************************* 
 
['/home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_73ac6694_2020-02-16_18-38-09yg6rkgu9/outputs/checkpoint-3']
INFO:__main__:Evaluate the following checkpoints: ['/home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_73ac6694_2020-02-16_18-38-09yg6rkgu9/outputs/checkpoint-3']
INFO:transformers.configuration_utils:loading configuration file /home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_73ac6694_2020-02-16_18-38-09yg6rkgu9/outputs/checkpoint-3/config.json
INFO:transformers.configuration_utils:Model config {
  "attn_type": "bi",
  "bi_data": false,
  "clamp_len": -1,
  "d_head": 64,
  "d_inner": 3072,
  "d_model": 768,
  "dropout": 0.1,
  "end_n_top": 5,
  "ff_activation": "gelu",
  "finetuning_task": null,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "mem_len": null,
  "n_head": 12,
  "n_layer": 12,
  "num_labels": 4,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pruned_heads": {},
  "reuse_len": null,
  "same_length": false,
  "start_n_top": 5,
  "summary_activation": "tanh",
  "summary_last_dropout": 0.1,
  "summary_type": "last",
  "summary_use_proj": true,
  "torchscript": false,
  "untie_r": true,
  "use_bfloat16": false,
  "vocab_size": 32000
}

INFO:transformers.modeling_utils:loading weights file /home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_73ac6694_2020-02-16_18-38-09yg6rkgu9/outputs/checkpoint-3/pytorch_model.bin
HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=744.0, style=ProgressStyle(description_width='initial')), HTML(value='')))
0.0177850.0179140.008991
0.2265500.5055170.1011300.0169860.0025120.0003470.0000670.0000480.0000330.0000390.0000301.3265810.1160390.4715250.5892160.5125091.1089041.6414941.2685420.6463170.0281920.0012360.0000880.0000730.4525682.2643260.0781210.0026300.0001180.0000300.0000272.0596091.5257300.5436920.0147310.0004440.4862010.1149940.3471320.0083120.0008880.4253310.0094840.0002380.0002110.8936320.0183310.4751390.0126460.0005380.0010070.0020911.2503570.0223540.0011070.0000450.0000280.5925280.0097460.0001870.0000340.0113950.0107790.6236050.0093530.2705150.0039480.4921390.4879460.9076450.0124800.0002130.0000520.0000590.0000600.0000740.0000700.0004860.0001600.1100790.0013570.0000460.0000310.0000300.0000300.0000330.0000390.0000300.0000310.0000380.0000330.0001110.0000350.0000340.1797080.0019230.0011440.0000400.0001000.5967520.0058420.0001880.0000460.0000370.0000250.4148170.0038310.0000600.0013930.0002730.5069570.7970660.5887420.0052430.0000990.0001630.0000650.0000520.0001040.0000310.0036750.0001640.0000470.2958200.0023920.0000460.0001250.0006590.0001940.0032130.0000930.0000380.0000480.0000250.0000410.0000470.0010960.1122490.0010050.0442250.0006890.0005010.0002670.0000460.0001020.0004540.0000920.0000890.0001030.0001240.8270370.0054100.5547720.0035910.0000720.5175111.0277250.4612850.0028930.0000530.0005480.1771440.1437910.0011761.8960430.4208910.9654961.0317400.0109300.0003310.0001010.5157292.5845750.0147490.0001550.0000630.0000330.3062080.1930580.0011120.0073180.3002970.1071340.0025210.0000690.0080900.0004000.0019650.0002000.0032140.0001680.0008010.0000740.2301260.0013420.0000703.1320730.0157410.0002240.0003090.0001220.0404010.1265930.0007360.0003500.0003961.9197410.0092180.0001020.4334080.3794430.0021950.0812390.0604690.3235440.2034810.5331790.3814350.0585660.9266080.8483880.4676270.3141700.3130930.0014141.4829610.9552371.6527812.4693500.5522870.0024200.0000840.0000640.0008380.0004190.0000270.0175100.1108960.0045830.0173560.0001980.1569860.0006770.0001020.0001940.1311070.0005600.0007100.0004470.0005080.0003560.0004410.0006230.0037190.0001790.0005110.0772790.3551651.0684430.0044650.2656620.0455910.0005390.0091300.0005160.4862860.0019840.0042550.4924730.0033350.0001660.0000350.0000260.5998580.0021910.0089170.2331981.4973700.0053820.0037460.0000920.0435430.0003460.0119040.3008360.1787351.1630480.0040930.5128500.0018250.3445430.0015690.0000840.0000630.0000700.0000490.1900280.2042762.4380941.4300900.4847580.0019820.0000510.0000570.0000380.0001230.0001350.0008292.8223832.2615360.0076310.0006460.0000890.0000700.0002730.0007540.0004080.0003940.0000790.0000800.0000270.0000280.0000970.0015850.0000500.1429520.0004700.0000980.0002630.0005020.5488260.0017090.1206100.0035010.0718910.0011210.0002980.0000980.0005020.6756660.5809820.3719180.0018900.0000950.0000740.1022250.1620420.4510761.2611120.5461230.2293850.0888170.2706720.5077150.0017540.0000950.0001200.3705640.7773470.4026840.3963140.6838710.0019070.0008490.0001720.0000840.0001940.0006200.0002900.0002050.0000310.0000640.0000240.2260880.1229480.5339320.0020190.0010480.0003441.3787330.8965590.5276010.8722170.0130900.0000820.0000750.0092700.0001020.0000630.0094080.2438710.5163310.0735800.1243920.0025710.0000470.0000400.0339100.1679000.0005160.0012450.0098730.0000510.2492750.0009630.0005030.0003360.8597371.7811080.8943703.3114410.0084170.0004110.0001290.0001520.0001520.0001870.0574190.0096390.0011490.0000330.0000600.0000240.0000310.0000250.0000304.1545392.0027960.7511320.0022120.3930760.0065700.0049410.7450920.7842310.4034692.0259910.5349380.0058460.0001060.0015160.0003212.3968491.4417510.0032890.0001380.0001510.0001780.0001270.3896380.0013490.3443200.0009741.3761211.6533361.1103850.5604230.0014060.0011810.0009410.0102220.0002740.4614680.0023630.3207210.4194720.0018450.0000370.7348400.7363540.0017270.0307870.0001800.0000890.0000510.5693950.0023940.0024110.0003680.0000620.0002400.0001760.0007080.0001960.0000860.0000310.2255800.0005250.0000700.0003670.0001160.0008640.2769510.0007800.0000730.0000690.0000710.0000850.3889830.5557291.6968140.2532250.7384580.2071430.0004460.1072230.0002380.0005410.3559250.3236230.0007260.0000740.0001080.4764730.3559150.0081130.0003610.0001940.0002630.0002951.2859470.5956390.0522130.0002200.0004860.0001250.0001510.0010590.0000500.5971420.0018683.1436650.7683910.0014970.0002430.0001020.0027041.2999700.0035210.3182120.3614790.2677800.5626850.1820180.3519350.0006920.0439990.2291790.6166530.0013260.0001470.0002290.2125080.5045350.8907390.0017033.8270620.0070790.0302420.0067530.0002960.0002900.0002930.0266740.4239411.2290260.3846870.8180690.1905821.0753230.4011380.6968340.7866390.6639350.0244790.3188770.3451520.8709470.4477420.6372180.7888150.2221110.7423480.4467550.1942950.5521140.3775590.9002850.4819300.0924960.2987721.4294970.1120250.1946530.9204560.2891470.6763290.4170970.0013650.5756480.6560950.1821080.3529610.8850260.3954300.2468280.7726890.9300061.6883571.3797830.8375010.2421730.1724800.6732940.1762850.2357230.0906230.4704410.0721310.1733030.4369300.5733300.5174600.4040790.6913940.2110760.7659330.2243980.1300990.0570511.0343541.0413270.7065290.2378120.6013430.5434240.2604390.3015450.6189330.7820310.3891111.5926300.3826891.1447150.1658921.1763820.5947080.7160960.1617530.7095260.5678850.9755990.2547481.1753460.7012030.0118620.0775940.7168240.6010160.4675840.4582520.9899570.6624330.3726750.0688530.4840470.0670100.1658920.3294981.0457570.9820050.2808330.2043420.0487860.5241621.0712910.6888980.6096360.2159700.7637240.6107430.4069470.5635870.0019800.6080530.5657170.2415551.0912761.2585740.3297920.2022090.0313880.0328041.4627420.5173730.8756630.5044281.3842440.0576860.2970820.3030250.6210650.2152170.6152520.5113040.5522490.5684130.9227760.9112821.7303810.3832030.6789390.7388420.2042070.4984810.3739770.5606640.2768210.4998850.5518860.5280240.2689830.0417980.9284390.5471290.7066020.5891200.8960760.2514651.0477821.5781481.1064690.2922140.1496540.1772430.2709300.8726731.0459000.4593700.0945330.790308

*******************************************
EVALUATING PIPELINE 
Pipeline directory: /home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_73ac6694_2020-02-16_18-38-09yg6rkgu9/
With following parameter combination: {'batch_size_seq_length': 3, 'lr': 3e-05, 'lr_type': 'linear'}
EVALUATION OF CHECKPOINT /home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_73ac6694_2020-02-16_18-38-09yg6rkgu9/outputs/checkpoint-3
-------------------------------------------------------------
|           |   agree   | disagree  |  discuss  | unrelated |
-------------------------------------------------------------
|   agree   |    787    |    69     |    153    |    25     |
-------------------------------------------------------------
| disagree  |    81     |    325    |    69     |    24     |
-------------------------------------------------------------
|  discuss  |    142    |    52     |   1516    |    75     |
-------------------------------------------------------------
| unrelated |    27     |    22     |    41     |   8490    |
-------------------------------------------------------------
Score: 8743.5 out of 9226.0	(94.77021461088229%)
Accuracy: 0.9344427634896622
F1 overall: 0.8176211589445734
F1 per class: [0.7600193143408981, 0.672182006204757, 0.8507295173961841, 0.9875537978364546]
*******************************************


*******************************************
EVALUATING PIPELINE 
{'batch_size_seq_length': 2, 'lr': 3e-05, 'lr_type': 'constant'}
INFO:__main__:Creating features from dataset file at /home/ubuntu/fnd_implementation/data/processed
  0%|                                                 | 0/11898 [00:00<?, ?it/s]  0%|                                       | 1/11898 [00:01<4:02:44,  1.22s/it]  4%|█▌                                   | 501/11898 [00:02<2:42:53,  1.17it/s] 46%|████████████████▋                   | 5501/11898 [00:02<1:03:59,  1.67it/s]100%|███████████████████████████████████| 11898/11898 [00:02<00:00, 5140.89it/s]
  ******************************************* 
              Running Evaluation                
  *******************************************
 
  Length dataset evaluation: 11898
  Length dataloader evaluation: 1488
  Number of epochs: 3
  Batch size: 8
  ******************************************* 
 
['/home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_663ada68_2020-02-16_08-15-41tvoboy27/outputs/checkpoint-3']
INFO:__main__:Evaluate the following checkpoints: ['/home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_663ada68_2020-02-16_08-15-41tvoboy27/outputs/checkpoint-3']
INFO:transformers.configuration_utils:loading configuration file /home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_663ada68_2020-02-16_08-15-41tvoboy27/outputs/checkpoint-3/config.json
INFO:transformers.configuration_utils:Model config {
  "attn_type": "bi",
  "bi_data": false,
  "clamp_len": -1,
  "d_head": 64,
  "d_inner": 3072,
  "d_model": 768,
  "dropout": 0.1,
  "end_n_top": 5,
  "ff_activation": "gelu",
  "finetuning_task": null,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "mem_len": null,
  "n_head": 12,
  "n_layer": 12,
  "num_labels": 4,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pruned_heads": {},
  "reuse_len": null,
  "same_length": false,
  "start_n_top": 5,
  "summary_activation": "tanh",
  "summary_last_dropout": 0.1,
  "summary_type": "last",
  "summary_use_proj": true,
  "torchscript": false,
  "untie_r": true,
  "use_bfloat16": false,
  "vocab_size": 32000
}

INFO:transformers.modeling_utils:loading weights file /home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_663ada68_2020-02-16_08-15-41tvoboy27/outputs/checkpoint-3/pytorch_model.bin
HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=1488.0, style=ProgressStyle(description_width='initial')), HTML(value='')))
0.6317920.6324560.5117180.1718920.0430770.0103060.0053300.0008760.0002250.8210850.0823450.0076960.0020810.0013930.0002430.0037250.0003390.0001230.0001100.0005130.0013670.0011210.0001410.0002030.0011290.0001420.0001450.0001300.7790300.8403060.0293160.0011120.0001350.7358590.7539110.0218970.0009040.0003070.7353100.0192371.4476240.7693430.7463350.7590920.0185970.7299590.0169610.0006730.0023300.0001430.0000980.0008810.0090900.0036030.0001630.4540330.9148741.1753780.0221840.0004830.0001160.0001090.0001090.0011970.0001290.0001090.0001090.0001102.8394821.3278982.7751090.8734511.1959830.0164890.0003290.0001100.7355960.0119370.1361920.8435630.0607900.4210970.0053540.3343830.3990440.0050350.9294420.0112230.6186990.0073710.0005880.0002320.0014630.0014150.0006200.4968170.8519490.7725372.1846941.6438320.7444842.1825480.0233290.0023010.0030450.0016730.0015430.0010380.0025010.0097591.4361360.4542710.0041420.0001210.0000850.0030800.0001130.0000930.0000870.0000880.5820510.0049820.0012000.0003600.0002680.0002790.2363230.0020890.0002440.1998170.4603520.0060260.0023760.6803730.0068040.4453960.0033820.0008420.0001160.0001310.0021160.0085560.0076530.0001240.2564760.6193380.0056180.0018720.0014260.1668730.0043620.0001350.0001710.0052420.0026140.0026750.0013830.0037530.0001780.0013610.0020370.0116500.0152260.0021880.0038280.1908420.0012560.0001110.0001050.0001040.0001030.0001040.0001060.0001080.0001520.0001170.0002460.0001050.0014360.0001110.0001050.0001100.0001540.0001050.0001060.0013130.0001260.0002380.0008840.0002630.0002430.0004640.0006790.0003260.0002430.0302190.0031100.0047860.0009230.0007880.0002150.0001900.0055610.0040100.7341160.0115720.0021780.0027810.0030640.0030060.0030250.0001200.0013410.0001060.0000620.0000640.0011580.0009020.0000650.0000620.0000670.7613030.0062200.0013550.0039770.0011340.0198480.0276740.4299140.0027850.6397950.0081600.0003080.6682540.0043410.0050030.0001130.6289260.0044910.0009340.0000980.0025680.0043470.0123270.0001290.0000760.0000820.3367940.0036040.0036930.0026940.0002450.0029760.0726250.0005560.0006910.0002180.0001790.0005270.0012190.0001280.0158220.0003050.9559960.0038680.0002540.0011690.0013710.0013930.0001000.0011950.0024870.0001030.0000940.0023880.0001030.0011180.0015300.2067440.0037090.6169000.0386200.0005840.0015310.3660340.6930480.0037750.6893740.0051190.0023630.0001020.0010730.0012650.0000980.0021110.0011340.0007620.4124260.0029770.0019800.0001860.0006890.0007360.0001780.0026890.0018520.6529770.6528880.0048080.0001120.6544680.0034940.0014160.0001030.0015060.0014010.6354780.0021050.6365230.6137310.0033670.6327880.0020640.0007520.0001020.0013210.0027800.0018840.0008920.0159821.4369710.8309672.2383371.3555730.0271770.7116080.0042450.0165290.4804910.0101730.1501401.8102310.5299930.0033640.0154770.0032240.0037410.0025180.0050480.0114970.0101310.2554870.0010380.0009780.0003130.0008360.0002240.0008210.0002040.0000780.5611851.4338840.0040351.1940750.0043270.0011750.7709890.8458940.0023640.9165490.7025730.0207860.0091310.6774160.0019210.0008220.0001140.0030510.0028970.0012110.0008660.0001280.0007700.0001170.0001020.0123170.0042460.0001370.0104390.0043730.0026930.0014590.4713450.0032750.0001130.0102030.0015260.0028333.2805180.0163570.0039340.0038800.0037910.0040570.0075090.0049160.0053830.7378641.4863950.0087401.6556720.0044270.0004230.0009730.1130350.0007650.0014790.1520010.0143460.0045500.0003630.0023990.0011910.4348440.6733090.1228500.9155200.0119630.0070110.0070130.0092090.4551830.1660620.0025330.0035230.0027160.1218250.0006390.8822570.0021780.0024400.0053990.0051101.0556570.6582020.6952721.0913000.0042420.0033720.4510820.4529640.0011080.6261130.0028730.0001030.0000970.6413171.2842270.0041041.2835080.0073160.0173340.0052370.9587050.0047990.0061380.0029060.0019240.0028910.0057810.0041280.0028341.0316650.0366180.0582780.0007570.0001010.0000920.0025740.0114070.0002620.1607680.3152940.0026210.0015230.0042090.0034080.0001230.0035950.0000750.0000700.0000750.0008110.0014220.0012890.0042870.6095550.0012990.0000900.0000730.0012660.0013570.0016600.0011120.0002250.0014830.0084280.0039800.0040790.0039490.0089230.0022770.0376110.0263610.0075210.0062860.7378940.0031360.0000880.5315760.0103100.0157490.0111320.0009810.1474750.0003642.5959160.6232470.7254470.1308810.0102320.0034640.0047340.1221840.0250150.0027830.7077610.0019740.0082570.0015360.4342690.0023450.2063870.0032120.0022270.4598290.0046260.0001150.0012460.0001090.0001070.0001080.7376750.0014400.0001090.0001100.0001060.0025100.0038970.0021550.6022130.0038970.0009940.0024230.0037100.7268570.0050820.0040060.5862370.0022420.0001450.0110490.3842820.1364041.3635430.0032580.8345690.7906950.1209341.4332940.0038550.0019260.5558750.0044960.0001160.0001082.4593410.7325260.3327720.0018670.0036900.0039450.0023810.0036710.0051020.0012760.0038110.0000710.0716100.0025870.0000680.0036200.8250381.4477050.0094802.0477010.7984630.0014150.4865940.0020420.0000980.0003000.0006080.0005060.0001090.0002200.0001000.0013250.0011020.0013120.0055980.0066552.4902612.4845464.1012680.0079620.0022090.8505851.6299062.2238730.0086220.0040080.0027000.5390860.0048620.2285230.5912123.0974590.5732780.0184790.0207990.0179400.0052290.0032410.0026730.0052150.0001090.0000900.0000810.0000820.0000820.5508270.6700250.0011080.0012640.0010580.0000990.0012250.0009990.0000950.0011690.0014140.0014150.0182090.0106900.6181190.7101490.0129760.0006020.0000650.0025470.0008530.3821630.0017730.0032310.0044100.4511990.0097270.0118590.0088910.0013660.0062310.0024840.8297511.8550732.8441613.6354040.0099400.0079950.0052130.0388820.0019380.0053100.0018420.0027360.0020880.1483950.0140670.0051960.6019680.0142160.6587333.2641390.0070240.0026550.0063940.0072660.0050620.0059770.0038670.0036630.0013610.0038370.2672060.0011460.7765500.0013400.0008090.0008330.0002360.0008510.0184810.9583840.0015920.0002890.7232580.7219840.0066150.4523430.3192100.0010030.0004910.0018710.0040800.0053970.0052600.0026910.0058130.0053940.0115220.2724530.0885140.0282300.0333730.6268170.0009130.0000750.0001140.0043150.0012950.0000660.0000640.0014460.0012460.0283210.5005580.5462970.6534980.0009270.0659970.0318510.0249850.0078230.0074200.0289180.0010190.0475620.0001590.0001130.0060100.0020220.0010440.0014140.0044830.0009550.0018290.0042060.0028870.0030630.0029320.0057120.0030580.0028380.0020531.9635700.6875350.7749410.9994401.7262782.0674981.4018850.7204121.4045050.0018640.0023440.0000960.0000930.0013730.0082300.0014280.0038260.0000980.0001430.0021190.0001030.0028730.0021840.0013550.0029900.0000970.0000940.0000960.0025000.0001220.0000940.0022740.0091450.0101500.0082690.0080720.3533230.1880083.7199622.9635742.3132650.0142040.0101113.0786722.6602642.0596050.7838031.7668540.0060890.0015700.0000960.0048930.0001030.0046340.0037010.0014210.0067120.1648320.2844700.2249190.2085790.0012920.0013530.0000990.0044850.0028420.0001010.0001150.0014530.0001000.0000990.0001630.0000970.0014023.2173212.3506272.2166870.0521140.0271710.0056150.0039680.0031950.0047890.0248270.0034980.0028851.3561001.4501611.4818340.9904991.0859371.1116570.0063420.7426811.3021862.3421832.4221181.7264391.6219021.1192960.0014720.0091740.0099180.0100270.0097400.0097801.2497541.0549891.0600340.0080870.0001020.0041120.0041250.0053840.0027840.0007780.0008130.0013890.0007470.0008090.0001810.4961250.0069910.5187130.0018400.0003120.1835590.0006601.6236810.8549190.8935351.7491981.7573600.0019970.8854360.0015930.0001300.4435410.0071000.6072780.1158110.0116930.0180220.8630750.1254630.5751370.7069330.0064790.6381460.0377060.0259450.0068460.9236520.0010450.0763620.0645830.0001270.0009652.9756970.0032140.0000623.6601820.2616630.0020950.0008710.0009480.0013880.0009970.0009470.0011300.0001080.0000940.0001540.7732220.0264280.7119440.0041580.0052700.0888040.0001970.0013080.0015890.0027660.0140240.0006900.0012620.0001200.0158930.0007040.0006570.0006870.0001330.0001180.0001260.0001160.0041840.0001160.8189090.0019170.0001320.2522950.0697590.0120780.0018950.0255580.0037150.0278430.5656890.0017840.0018830.0013260.0013760.0038980.0027900.0039280.0027580.0041610.0053140.0026591.3130930.2802900.0003990.5927921.1575880.6568980.0008001.3023490.0014190.0002091.2341350.0014220.0013600.0003870.0022970.0002110.0002190.4248220.0097150.0019750.0002080.0007690.0002110.0014880.0020220.6883190.0007830.0023690.0049790.9956600.4021520.5626750.4463810.5204820.9109130.3905600.5879780.2449080.0560800.0182120.0046310.0028300.0068391.4261560.6801960.0046620.0038270.2361980.3247960.0026410.0017450.0022430.0036510.0059960.0117760.0106120.0099710.0091710.0102680.3512130.4800240.2753730.7407510.0151940.0158570.5958824.5570322.4889660.0024970.0002170.0039100.0046510.0102000.0087240.0001920.4445540.0007030.0002092.3313350.0139380.0082531.8816900.0047840.6989670.6299251.7172980.0028030.6920461.1900481.1242800.6425050.6853400.4946180.0023810.0009900.0028990.6281940.0320100.5296390.0142740.7482680.0084850.0067170.0047680.0058540.0066870.0077720.7591350.0084300.0043510.6255240.5844340.0835310.0014350.0035130.3912160.7438120.1532850.0016110.0026940.0041320.0066710.1082110.0737690.0026540.0043940.0052030.0071810.7815210.0614000.4305850.3325820.7605200.5685090.8412280.9746840.3501510.0448360.4400260.1905271.0081741.4544371.3337770.2810980.8541350.7195710.3007030.9455070.2921830.3651120.8162790.3536100.3118520.4652150.3417491.0747820.1089252.0086460.0438740.2879490.2638551.1678380.1984720.4684201.3343350.8648960.2339970.4138090.3322721.0327370.2363010.2985630.1023960.2589410.7110280.2785550.0497480.3065290.5566710.5223490.4051430.1885010.3663940.1987451.0840650.8492700.8953410.0120120.3954210.0007610.0276760.4926560.2512890.2941531.4445041.4422880.8239500.2780800.6981550.2177290.1641360.0768700.2301880.3151410.1503440.0006630.0710050.2479300.2275210.9352810.2483710.0193470.3800350.3031480.0826081.0715520.8019651.2144240.7336540.7077321.3972180.6757201.7430530.1242401.5657680.2126030.1326220.0776000.3121681.9393660.0020891.2499870.2775660.5908170.4651710.5251190.1297250.1323640.6185910.3721880.2561971.9818510.0927820.0586100.6512190.2496750.1824480.0061430.5449320.0025811.4487880.9394130.0142050.8895320.2584460.4483981.1038801.0015910.0180980.0082460.6327370.2576930.3746501.8127960.0464010.4372930.4693491.0792470.9254670.2175050.2097710.5278530.3516050.5296680.4260661.4926300.0205700.0482520.3097710.2535820.3657970.2877260.5992070.0908070.0038251.7519460.3428900.2224710.2443951.5158310.1187300.2383930.1315400.0666430.9121890.7943530.4760920.3016361.3348190.2117480.0830930.0794600.7855070.0303520.6664500.7511030.5966710.0397541.7478780.8020740.9733810.0202240.6477940.3301240.0557110.9133560.1659781.1823710.2356800.2714820.2621360.3673450.3905820.7450330.0136890.4947840.3426200.0479440.6083410.3692020.3112110.3347340.0271410.5323890.0731070.8632320.4206790.1265770.0553680.8092391.6556280.9955411.1236630.1994161.6377520.4169640.1066400.0530940.3724470.0501360.0248870.6658541.0476250.4596350.9533530.0571290.5702081.1021730.3432380.9396300.0900500.4527360.9012740.2686720.5246780.8340580.0008390.7736831.0971560.0580190.1630860.5171440.3539930.4329630.1230910.2150140.3215120.9085620.3963240.9433062.2811590.2951950.7160310.9915400.9222980.0437550.1292090.2527790.2509510.0025631.8935370.0749030.7966790.1064830.6578410.1585300.3563501.0958711.4787450.2210350.5439210.4334270.3341010.0736500.8459910.3083621.1161710.0687450.1717410.0520221.1155050.7668150.0582331.7337840.5256930.3792460.0586190.2296391.3733761.1594240.0669371.4406212.0864760.3493101.3215930.6822270.7947361.1127030.3272100.9849290.0460500.4452860.7607260.2435451.1662450.0952300.2615980.4983560.4930310.5298920.2189691.5480550.4237760.4666710.6419290.1061470.3770960.4634250.1450320.7732981.7016790.3040310.4064640.1158441.5696990.2395870.5498081.0928470.7588380.3362100.9578800.7386401.5065981.2754852.3191152.1701620.6232630.2282950.8142260.0836440.7220461.0380230.1593660.0599300.0580810.9597900.0265771.5781660.4032020.2891090.5498200.0009340.0416510.1283280.931330

*******************************************
EVALUATING PIPELINE 
Pipeline directory: /home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_663ada68_2020-02-16_08-15-41tvoboy27/
With following parameter combination: {'batch_size_seq_length': 2, 'lr': 3e-05, 'lr_type': 'constant'}
EVALUATION OF CHECKPOINT /home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_663ada68_2020-02-16_08-15-41tvoboy27/outputs/checkpoint-3
-------------------------------------------------------------
|           |   agree   | disagree  |  discuss  | unrelated |
-------------------------------------------------------------
|   agree   |    815    |    174    |    227    |    82     |
-------------------------------------------------------------
| disagree  |    54     |    236    |    79     |    62     |
-------------------------------------------------------------
|  discuss  |    136    |    36     |   1434    |    58     |
-------------------------------------------------------------
| unrelated |    32     |    22     |    39     |   8412    |
-------------------------------------------------------------
Score: 8563.0 out of 9226.0	(92.81378712334707%)
Accuracy: 0.9158682131450664
F1 overall: 0.7597156951001516
F1 per class: [0.6980728051391863, 0.525027808676307, 0.8329944815567819, 0.9827676850283311]
*******************************************


*******************************************
EVALUATING PIPELINE 
{'batch_size_seq_length': 1, 'lr': 3e-05, 'lr_type': 'constant'}
INFO:__main__:Creating features from dataset file at /home/ubuntu/fnd_implementation/data/processed
  0%|                                                 | 0/11898 [00:00<?, ?it/s]  0%|                                       | 1/11898 [00:01<3:43:24,  1.13s/it]  4%|█▌                                   | 501/11898 [00:01<2:29:50,  1.27it/s] 17%|██████                              | 2001/11898 [00:01<1:31:05,  1.81it/s] 38%|██████████████▍                       | 4501/11898 [00:01<47:39,  2.59it/s] 74%|████████████████████████████          | 8780/11898 [00:01<14:03,  3.70it/s]100%|███████████████████████████████████| 11898/11898 [00:01<00:00, 6138.83it/s]
  ******************************************* 
              Running Evaluation                
  *******************************************
 
  Length dataset evaluation: 11898
  Length dataloader evaluation: 2975
  Number of epochs: 3
  Batch size: 4
  ******************************************* 
 
['/home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_63040284_2020-02-16_08-15-37nps22yu4/outputs/checkpoint-3']
INFO:__main__:Evaluate the following checkpoints: ['/home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_63040284_2020-02-16_08-15-37nps22yu4/outputs/checkpoint-3']
INFO:transformers.configuration_utils:loading configuration file /home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_63040284_2020-02-16_08-15-37nps22yu4/outputs/checkpoint-3/config.json
INFO:transformers.configuration_utils:Model config {
  "attn_type": "bi",
  "bi_data": false,
  "clamp_len": -1,
  "d_head": 64,
  "d_inner": 3072,
  "d_model": 768,
  "dropout": 0.1,
  "end_n_top": 5,
  "ff_activation": "gelu",
  "finetuning_task": null,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "mem_len": null,
  "n_head": 12,
  "n_layer": 12,
  "num_labels": 4,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pruned_heads": {},
  "reuse_len": null,
  "same_length": false,
  "start_n_top": 5,
  "summary_activation": "tanh",
  "summary_last_dropout": 0.1,
  "summary_type": "last",
  "summary_use_proj": true,
  "torchscript": false,
  "untie_r": true,
  "use_bfloat16": false,
  "vocab_size": 32000
}

INFO:transformers.modeling_utils:loading weights file /home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_63040284_2020-02-16_08-15-37nps22yu4/outputs/checkpoint-3/pytorch_model.bin
HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=2975.0, style=ProgressStyle(description_width='initial')), HTML(value='')))
1.2716911.2767700.6434720.2588390.4291910.0908850.0217830.0081630.0061980.0059601.5226870.1450440.0202540.0066140.0055180.0054150.0053860.0053630.0157340.0058730.0053400.0053000.0052880.0052770.0052660.0068250.0053100.0839940.0080470.0053260.0052250.0098831.5344060.0515440.0065630.0052360.0051951.5342190.0454240.0062150.0067550.0052120.0051710.0067230.0051990.0051610.0051580.0051560.0067090.0051830.0051500.0051490.0051450.0051420.0051410.0051421.2718061.2939021.2938091.5559110.0325340.0055830.0051492.8461350.0495310.0058321.5424711.5570071.5568920.0276140.0054700.0051380.0051220.0054540.0051340.0051201.5341323.0824780.0445730.0056240.0066731.5341580.0237681.5359041.5522921.5523630.0231010.0053160.0067050.0051361.5341650.0219200.0052881.6106920.0251860.0053141.2404910.0178370.0052290.0051020.0050990.0050990.0050980.0050960.0082120.0051280.0050990.0066540.0051100.0050950.0050940.0342290.2432880.0104430.0126540.0500360.0070470.0051110.0050910.0050900.0050890.0050920.0050890.0050900.0050880.0050870.0066410.0051001.3674360.0156480.0051680.0050890.0050860.0050870.0050880.0050873.0662063.0850872.8233770.0253611.5342013.0737221.5554431.5448051.5443781.2820360.0138290.0051410.0050850.0050930.0050820.0050880.0050880.0050810.0066340.0066420.0050990.6754670.0093231.0202950.0114260.0051191.0203280.0113060.0051160.0050781.0203540.0111580.0051131.0202860.0110490.0051121.0203551.0262950.0109470.0051101.0202870.0108130.0051120.0050760.0050750.0050870.0050750.0050760.0050850.0050750.0050740.0050860.0050850.0050750.0443521.0204550.0103651.0204582.4962061.0330841.5391933.0703813.0769351.5526720.0159353.0630993.0782680.0226480.0067190.0051071.2707070.0111900.0051041.2708320.0126680.0051090.0279360.0053280.0050800.0050770.0050721.2704320.2161500.0122541.2708921.2761871.5551440.0120190.0050990.0050690.0050700.0050680.0050680.0050691.2701630.0105470.0050940.0050700.0050720.0050700.0050730.0050680.0050690.0050681.2713160.0103240.0050990.0051070.0050960.0051060.0050980.0402930.0052490.0050970.0050960.0051060.0051061.0380590.0091630.0051210.0051060.0051061.5734390.0111610.0051082.1718051.2140340.0096620.0081870.0050801.2715310.0129140.0052670.0066180.0050840.0050680.0050680.0050680.0050700.0449800.0052280.0050840.0050830.0050840.0443620.0840020.0053740.7147490.6419050.0073330.0051120.0051040.0051030.7112760.6976350.0074730.0051110.0066420.0050720.0066240.0066250.0050760.0066220.6391100.0087290.0066411.5303360.0101110.0051010.0050740.0081640.0081960.0066260.0066180.0051650.0081660.0066250.0050700.0051020.0081880.0051120.0050950.0443740.0052270.0317680.0837270.0053411.5279200.1015600.0100160.0050790.0081720.0066290.0097320.7831770.0089930.0050740.0050620.0050610.0050610.0050610.0050610.0050620.0050620.0050620.0050620.0050610.0050610.0050610.0050630.0050620.0050600.0050620.0050630.0050610.0050610.0050650.0050610.0050620.0050620.0066250.0050690.0050620.0050600.0050600.0050610.0050600.0050610.0050600.0050610.0051770.0050610.0050600.0050610.0050600.0066200.0050660.0050610.0050690.0050621.7756030.0097760.0050810.0050690.0050610.0050690.0050790.0050600.0050700.0050700.0050800.0050890.0050790.0050800.0050710.0050690.0081770.0066230.0112930.0066311.7762000.0095590.7429270.0069370.0051020.0050980.0050980.0050980.0097240.0081750.0066190.0081661.5247131.2770931.2763630.0097010.0061940.0050650.0066050.0066120.0066140.0066140.0050650.0081590.0081650.0050680.0050590.0050620.0066250.0050620.0050600.0050580.0050600.0050590.0050580.0050620.0050690.0066210.0066180.0050630.0050690.0050690.0050840.0050580.0050580.0050670.0050600.0050560.0050680.0081860.7241981.2702720.0543950.0625590.0052050.0068990.0050940.0050980.0050980.0954810.0461080.6378810.0064430.0081160.0474311.5364850.0099290.0066280.0050660.0050620.0852720.0052360.0050620.0066150.0066210.0050620.0050610.0050590.0050590.0097380.0081880.0050670.0066150.0050620.0050590.0050570.0066260.0066260.0082010.0066511.2716930.0076990.0051030.0050970.0050960.0050990.0051010.0050981.2724151.4831510.0080460.0081970.0066320.0081740.0081890.0050990.0051000.0050980.0050990.3778360.0058260.0050930.0050790.0051000.0443790.0051760.0050900.0050900.0051000.0050980.0337390.0051370.0446850.0447290.0051320.0050750.0082032.7103960.0102630.0051130.6241180.0062750.0051010.0051000.0051010.0051040.0050660.0474580.0051370.0050730.0066200.0050610.0050580.0050570.0050570.0066110.0066140.0066130.0050610.0050560.0050580.0050550.0050570.0081630.0050620.0050570.0066100.0050600.0050560.0066380.0050711.2708990.0073290.0051401.2145181.8457601.2724440.0073200.0050760.0061670.0067920.0050931.1884561.2403380.0072240.0066220.0066180.0050591.2704933.8033760.5834410.0455881.9834190.0100500.0050680.0050570.0066080.0050640.0050580.0066070.0050590.0050550.0050550.0081600.0066130.0050600.0050570.0474411.1864391.1181490.0084900.0050810.0459940.0051540.0050960.0050790.0443530.0051540.0050970.0443630.0051520.0050760.0081560.0050600.0050550.0066071.2722290.0071250.0050571.2722200.0086650.0066100.0050560.0050571.2737740.0070990.0066080.0050560.0050540.0066050.0050610.0050650.0050530.0066040.0066080.0050630.0050541.2711700.0070540.0050601.2708550.0070441.2055760.0069360.0050590.0066321.2708770.0070240.0050590.0050570.0050550.3843400.0056420.0050570.0050570.0066142.5339012.5777170.0485940.0448040.0444630.0051151.1467390.8872021.2118960.0099950.0066270.0112730.0112790.0081700.0112760.0081820.0113090.0895611.3504591.3568950.0101960.0050641.2718210.0069401.2713411.2722131.2722180.0069211.2703041.2730750.0069165.0699192.5467150.0087930.0050680.0456803.2285060.3282610.0071000.0066180.0385531.5369660.3242330.0086210.0079630.0097330.0112970.0112881.5263491.5478920.0088260.0050820.0050550.0050550.0050791.1784270.0067220.0050571.2039080.0067590.0050760.0050730.0050831.1233000.0066340.0050660.0050550.0050550.0050560.0066110.0066150.0066250.0050580.0050540.0066140.0081710.0066200.0050560.0066090.0050570.0050561.4789271.2727612.7452290.0088070.0050821.2719781.2722690.0067962.7437601.2743930.0083310.0050791.4703320.0087451.1257320.0065530.0050771.2577830.0067230.0050580.0050540.0050633.8040020.0132120.0050651.2684260.0067181.2165520.0066450.0050560.0050550.0050551.2690170.0067050.0050560.0050540.0050560.0050530.6130971.2570900.0067130.0050950.0050930.0050940.5923891.4159350.0084210.0066140.0066120.0066120.0050580.0050571.5354671.2735190.0082200.0050580.0050542.7458610.0085180.0066150.0050580.0066080.0066112.5416613.8099260.0160410.0081830.0066130.0081680.0066150.0266900.0066390.0081580.0066690.0081640.0081630.0112631.5355320.0115971.5387550.0085170.0321330.0069033.0662961.1588344.6760112.4122722.8251480.0085080.0050780.0050820.0050630.0050541.7711620.0072081.5435521.7767350.0072070.0050770.3786361.7768431.5451550.0069172.4483833.1564782.5431200.0081190.0050990.0050930.0066390.0066410.0066180.0050540.0050530.0081770.0066170.0050550.0050511.4811635.2825270.0174401.2766850.0127520.0112780.0521180.1234810.0114170.0097290.0112842.5432482.7535831.2785952.7483940.0082230.0085880.0081720.0081750.0066750.0081920.6831180.0078370.0050960.0050960.6310680.6303250.0058060.0050940.0051121.3256883.0685680.9729390.0092780.0066580.0066990.0071720.0082571.0319424.3145131.1156560.0078600.0097330.0066120.0066070.0066090.0097120.0066120.0097120.0066090.0102461.5340340.0067451.2719550.0064520.0066090.0050550.0050530.0050530.0050520.0050520.0051341.2718932.5400160.0109290.0050590.0066051.2718651.2733031.5352190.0082781.2704112.5372690.0109161.2701502.5357960.0077840.0066190.1229170.1246000.0082920.0066110.0066090.0050540.0066070.0081660.0050570.0097190.0066130.0081640.0066110.0050550.0081681.5725780.0067310.0836781.9211502.5622390.6857791.2720580.0063880.0050580.0050560.0050560.0050640.0081640.0050600.0066101.2713540.0063750.0050581.8127765.2412394.8573010.0162910.0081710.0066070.0066050.0066050.0097100.0097150.0097460.0050560.0050560.0050520.0066360.4938760.0055760.0050560.0050660.0051321.5341430.0066110.0050682.8000400.0079641.5355050.0066060.0066432.5631411.2739110.0134551.5338880.0068790.0050571.5334620.0171680.0116440.0050751.2712991.2725420.0063550.0836140.0051350.0836090.0548540.0051170.0050740.0050851.1515550.0061991.0944460.0123510.0097230.0050590.0066030.0836860.0448210.0836930.0051390.6112970.0536690.0051011.8955241.1523860.4823411.0937200.0107700.0097160.0081640.0097151.5371090.0080890.0066570.0050970.0050940.0050950.0066292.0872550.0559140.0113310.0112880.0112720.0112680.1535241.2184130.0062101.2460391.1598570.0061500.0050622.5355562.5385701.2735900.0078451.2710050.6843731.3893182.5258462.3775690.0135170.0081890.0066420.0081770.0081790.0097172.5379834.0043475.0457441.2741072.4412430.0073261.1777791.2036750.0061691.2219720.0077330.0050542.4686451.2777160.0077790.0066110.0050540.0050531.4797001.2736380.0077660.0050541.2723120.0077632.7485582.5421350.0073740.0050540.0050520.0050510.0066110.0050530.0050530.0050520.0050520.0050540.0050521.5337840.0064350.0050520.0050520.0050530.0050520.0050510.0050520.0050530.0050510.0066090.0066180.0097480.0050570.0066050.0066060.0066070.0081580.0081650.0050550.0066090.0050540.0081580.0050550.0081590.0066090.0050521.5334960.0095090.0066120.0081690.0066070.0066070.0066330.0583850.0453870.0051020.0050570.0467742.8040031.4865044.4301324.2249252.9569142.9552141.4837880.0063360.0066122.6749382.7458692.1106110.0131381.3624921.6228114.3984774.0153140.0085081.2696912.8001390.0074640.7139520.7164640.0103320.0050570.0050530.0050520.0050520.0050560.0082140.0113000.0114240.0113130.0081830.0081640.0050610.0141580.0066131.5370360.0079490.0081790.0050910.0081650.0066150.0081880.0081740.0081690.0066350.0050900.0081650.0066160.0050510.0050541.0656101.2103230.0076070.0066200.0050520.0050501.1367891.2657701.1951352.6826341.2760741.4837880.0109190.0097051.2754072.7510561.4865980.0455870.0051130.0050900.0050900.0050820.0443970.0051130.0050900.0050900.0050810.0050810.0050900.0050810.0050800.0050700.0050900.0050810.0193640.0050950.0050900.0050800.0443670.0051220.0050830.0050810.0050910.0444860.0445010.0051120.1424241.3247092.5822430.0161910.0110540.0085080.7013880.0132390.0050760.0443620.0443880.0443870.0050881.4809470.0124322.9570950.0136064.2222090.0115020.0081630.0081580.0066080.0050520.0081580.0081600.0066060.0066040.0081590.0050520.1270200.1274250.0458842.1476942.1748672.1709141.4859991.2779812.7508903.8097351.4872311.2779670.0122500.0097120.0066090.0081700.0050540.0050530.0081550.0112610.0050560.0050520.0050500.0050550.0050530.0050510.0050520.0050530.0050530.0050520.0050560.0050511.2543661.2734180.0091520.0050550.0050520.0050520.0066140.0066070.0050570.0050530.0050560.0050510.0066090.0066090.0050540.0050500.0050520.0066060.0050620.0443240.0050980.0443430.0050930.6438770.0448200.0050930.0851522.1954150.0098060.0050801.5371510.0124120.0097130.0050530.0066030.0050510.0050500.0097110.0050560.0066040.0050550.0050510.0081580.0081580.0050530.0050520.0081560.0097100.0097110.0066050.0066040.0097090.0112900.0112670.0112690.0112680.0097310.0066140.0050570.0097190.0081780.0066050.0066090.0097231.8922621.0170280.8885311.6494431.6496291.5805232.0807940.0851340.0475010.0097660.0097260.0066100.0097470.0113280.0066070.0081570.0050530.0097090.0097120.0066060.0066040.0050520.0097080.0066060.0066162.5184010.0605301.2701700.0059660.7901860.0071781.2494290.6768071.4788104.9864425.0550123.2123961.4557201.4544550.0093101.5268210.0093250.0069660.0082790.0955190.0113620.0081600.0081540.0081530.0081540.0097070.0066110.0081570.0081580.0066040.0050520.0066040.0050550.0097030.0095630.7224160.2026700.0449850.0531460.0051040.0050670.0050840.0470030.0050840.0050730.0494400.0050950.0050941.2037240.0058980.0444340.0051060.6432140.6439350.0055210.0050690.0050710.0050690.0050890.6432610.0055090.6433510.0055070.0050700.0050700.6433460.0055180.0444770.0051060.0050690.0050780.0050590.0050592.5369164.0591750.0093720.0081661.2697661.2721830.0106050.0066200.0066020.0097300.0066240.0081680.0081800.0050583.7117323.8072663.8073594.0154955.6958034.2227740.0079251.2285800.0058920.0050522.3667330.0066350.0050520.0050590.0050890.0050700.0050531.2714050.0058950.0066100.0050500.0050490.0050500.0050490.0050490.0066060.0050510.0066170.0160162.9533060.0070230.0050630.0050490.0050491.5351361.2717690.0058850.0050500.0050502.5484312.5462964.5858910.7257312.2241011.2764535.0596163.8045831.2767322.3283721.2752731.2719001.2719070.0058781.2708221.2715890.0058750.0050510.0050510.0050502.7933890.0068632.6309070.0067531.2613610.0058650.5245180.0053850.0867960.0067830.0050510.0066390.0050630.0050570.0081640.0066130.0066120.0066070.0081580.0050630.0066130.0066100.0066060.0097140.0050590.0081640.0050550.0081580.0066140.0905341.4796602.5401241.2737590.0074090.0066111.4811451.4805121.4820872.7475541.2738751.2744532.5400810.0066542.5392630.0380121.4795832.5402070.0066490.0050500.0050510.0050500.0073280.0050510.0050490.0050500.0050490.0066060.0050500.0050500.0050500.0066250.0050510.0066090.0079410.0050520.0050491.3925920.0059330.0050500.0077330.0050520.0050530.0081740.0050530.0050520.0080150.0050520.0066090.0077260.0050550.0050490.0050510.0050490.0050500.0050500.0050500.0076230.0050650.0050500.0050540.0050490.0050500.0050520.0081570.0112660.0112670.0112700.0112650.0461660.0465960.0573860.1249430.0870920.0067080.6024353.0452431.5321591.5876322.1750363.7214353.6640394.1638511.7825730.0123520.0112840.0112801.3229470.7619803.8001582.8007512.8002354.0627402.7985562.5352102.7999142.5369620.0065740.0081560.0066060.0050530.0050550.0053830.0050550.0081650.0050590.0050590.0081611.5337620.0090710.0050560.0066030.0050540.0081580.0081590.0050614.8547643.3170051.7791321.8159752.5192944.8563701.7792950.0061090.0465800.0066260.0050500.0050520.0050490.0066030.0066080.0066030.0066020.0050520.0050500.0050500.0050500.0066020.0050520.0050510.0050510.0050510.0050570.0050490.0050500.0050490.0050520.0050490.0066011.2275661.7862640.0130011.6531851.1043243.0988692.5093750.0080681.2710171.2720011.2707410.0073490.0050551.2349470.0089010.0050561.2714750.0073541.2681371.2701580.0089040.0050570.0050591.2712100.6746470.0116750.0113220.0113190.0118650.0114250.0112943.7993761.1913642.5367073.5161400.0133190.0082030.0851580.7617510.0841031.3127631.2772133.8075671.4862821.2772113.8016021.2712002.5352261.2711602.5337101.2681231.2697650.0058080.0050820.0112520.0112540.0112540.0112550.0112550.0112550.0112520.0112530.0112520.0112551.2765081.2772670.0119782.5414961.3178900.5981020.0084900.0097180.0050550.0050500.0097170.0050631.5473070.0074650.0097150.0066090.0165320.0081680.0050791.2605290.0057660.0501110.0050751.0992600.0056661.2209170.0513030.0050840.0050490.0050494.3825660.0483571.0633431.5735331.9973621.1208871.0632110.0056360.0050660.0050530.0449990.0050910.0050620.0050721.4782591.2423751.4793250.0058580.0050611.4791201.4797941.1244821.4792111.4797030.0058640.0050511.5186150.0453890.0050850.0444600.0051040.0050731.8104620.0850760.0842440.0097712.6353171.2764652.5401251.4848820.0120892.5403962.5403052.5389600.0095211.2710500.0088391.4798811.2724281.2733031.2714561.2730561.2744560.0072890.0067142.5340580.0079621.2696460.0919581.2976471.8726222.5420724.1039551.4807270.0058360.0050490.0050490.0050581.4784610.0058330.0050510.0050670.0050580.0066271.4785493.0432860.0066600.0050490.0050480.0050495.9902872.7704020.6844760.0054510.0050910.0444450.0051131.5646880.0332770.0066450.0052240.0067660.0066501.5332920.0360830.0068480.0066420.0050570.0050521.5331680.0058550.0050550.0050561.5457491.5357320.0120701.4836972.7488822.5407152.7479801.9825621.2704752.5381231.2742770.1631120.6827770.0054030.0050520.0050510.0066120.0050560.8061360.0070300.0066100.0050522.9842670.0065940.0559371.0891660.0056130.0050530.0050561.0338391.5871660.0517990.0050780.0050531.2687910.0057020.0509950.0051140.0050900.0050900.0050900.0050920.0050890.0050900.0050900.0559170.0519840.0051140.0050890.0050911.1930980.0072550.0050900.0050900.0050900.0050900.0066551.2594420.0057271.2430760.0057170.0050901.0624030.0056240.8756870.0561850.0066811.2377960.0103640.0112841.4799691.2704500.0056890.1011600.0050981.1762870.0056390.0066010.0050540.0050520.0097030.0066030.0066000.0097030.0050790.0066050.0066000.0081510.0066030.0097010.0066030.0050510.0081510.6900650.0069801.5451770.0058260.0050500.0050500.0050500.0104103.0815310.0065760.0050500.0090610.0050510.0050490.0090610.2158400.0051520.0050500.0050500.0050500.0074180.0066360.0050790.0050880.0050690.0066410.0050890.0050880.0873570.0051300.0050780.0050800.0050780.0050780.0050780.0050690.0456760.0050780.0050790.0462700.0050980.0050880.0050590.0452110.0050880.0050780.0050581.2707510.0056651.2728671.2735370.0056640.0050580.0050670.0066161.2705811.2713330.0056710.0066191.2711130.0056812.9545795.2782572.9588144.2216774.2222640.0102030.0097500.0081910.0113020.0081720.0081770.0097540.0050530.0081940.0097570.0097480.1228740.6439210.0446540.0836150.0836350.0459430.0443530.0458910.0113090.0113050.0097450.7148690.0085130.7122320.0053860.0066150.0459070.7671650.0054550.0443450.7276800.0447020.0051120.0443480.0051110.0050930.0443640.0443901.0206660.0055740.0112600.0112600.0112650.0112640.0112710.0112640.0112680.0112650.0112672.0773450.0123030.0066100.0066070.0050520.0050570.0066060.0050550.0066081.5369500.0057700.0836350.1622810.0051243.2038520.0134923.7999685.2724171.3902480.0057050.0050670.0050470.0050670.0050580.0504810.0050800.0891050.2814150.0051850.6596380.6167710.0053610.0050660.0050670.0911630.0050960.0050590.0050690.0050670.0050570.0066340.0116350.8064790.0839800.1228940.0836870.0174380.0081580.0066030.0081500.0066060.0066050.0066040.0081520.0097070.0066090.0066070.0050550.0066050.0066100.0050560.0097110.0081600.0244470.0050610.0081510.0081670.0050530.0081560.0081590.0066050.0066020.0050610.0066080.0066043.7911645.0672150.0135770.0112760.0112790.0081880.0081850.0081910.0050500.0081871.5370480.0119570.0097120.0112661.5325070.0104030.0066140.0081590.0097113.0660760.0126450.0098150.0112650.0081630.0097220.0112660.0097140.1622080.1229870.1622390.0867890.0067080.0165511.5367560.0103910.0059440.0066051.1822400.0102632.6826932.8230851.5527041.3784591.4621640.0994380.0051310.0485990.0484640.0560880.0462760.0081750.6293320.0099840.0669450.2228540.0627132.6591500.0673300.2139380.0587600.9550530.0085750.0696180.0498340.0097400.1135320.1029490.0725850.0489680.0464960.0051082.4498720.0061722.2904841.5444230.6016021.5437641.9959330.0059571.5826110.6113660.6015730.5884890.0053480.0575410.6054851.7713270.0058660.5778891.5434491.5438551.7724093.0809571.5431161.7709940.0058640.6255772.1770260.0060401.4631713.3125471.7756453.3130351.5448000.4135761.1183310.3447060.2447121.5430511.5434641.2809711.2772011.5433183.0811910.0064251.5427161.5436271.5433861.5433481.5425751.9053710.3707430.3641723.5404401.5441380.0969580.0051310.6802700.0053790.0050950.6437160.0446801.5824040.0057730.2755351.5429120.6930481.5436331.5439530.3100342.2226360.6702860.0053772.1797380.0060231.0514090.7185890.0446561.5390770.0451050.0444960.6379820.0844240.0450040.0051090.0445400.7237143.1969351.7703071.7744381.7732200.0467990.0051140.3188080.0052280.0474340.6313550.6433311.8479070.0058710.7056311.3245580.0456620.7189870.5974161.4776820.0057143.1303890.0063991.5434070.2618292.8069080.9543510.0447710.0051110.6351690.0839140.0051290.0050920.0443620.0836480.7276520.5995860.5524890.6004861.5788140.7980790.0465831.5866591.2780890.0056241.5416652.0827450.0492000.3605711.1250880.6352540.5912400.5911580.5702540.5881330.5863170.5687201.5433870.0057320.6334810.0053550.0050943.0805202.0736910.0059491.7741130.0518831.5427460.0450170.0050920.0050930.0050931.5434081.0647990.0055290.0445480.0051341.8598090.0058581.8139640.3295870.0456570.0447000.0051121.5427690.7678040.6441780.0053571.7556620.7678970.3606710.8064940.1000981.2810030.0056451.6301200.0057580.0555132.1236560.0059620.5347440.5896271.1717790.0055680.5968451.7715501.7766910.5761301.1689351.8921690.0058591.5412363.3093551.0425170.0055141.5430201.5436690.3869440.0052471.4934402.4971790.0460990.0445340.0051081.5427831.7726770.0058061.1826081.6475751.0348890.0553141.1860870.5905080.6377700.0494541.5420191.8142710.6967480.0053711.7731680.0058032.1664891.5438720.0057070.6058571.8128000.0454960.0465180.0443900.0051081.5820320.0450190.0051102.5597920.6365203.3124490.6774630.0053621.8155401.7751230.6143060.5918920.6213511.3934141.0779030.9149350.0054550.3653382.0873860.0477050.0875140.0500320.0051110.0050930.6431440.0482501.5425080.7492250.0909940.7043632.1718300.0059470.0457600.7256250.6354980.0452371.5426340.7579941.2742530.6069143.1037290.5071491.5437640.6130860.0053310.3521971.4267730.0056420.0050961.5858400.6519921.7354420.5472950.7756081.5431040.0056930.6275260.0053361.0879750.0055190.0531310.0051120.6419980.7757640.0053931.0389210.2761751.8138210.5087381.7713850.0450351.7551390.0057730.6831322.6668180.0866860.6430011.5829220.0057040.0445210.3469821.8893732.3055560.3616450.0515400.6469330.0053400.0445260.6391820.0053370.0454831.8158640.4024800.0476182.4268701.0395990.0054953.3114631.7751870.0057754.1155380.0066711.5435340.0056830.0478000.0443990.0051101.5429011.4788170.0842190.0051240.6437800.0053280.6798130.7615440.3608801.0626870.4731130.0052731.5422972.3866891.7770220.3217780.0052143.1651861.0399340.6288600.6536100.7232411.3615240.0056110.0050930.6401120.6675791.5409050.6384301.5430230.6443931.5435300.0056781.5432680.4740520.0485403.0821540.0062550.8524220.5975571.5434731.1787740.0055361.8648740.0057931.8110960.6586731.1883250.0511380.6019711.1966620.0055410.1022640.6003440.6043850.6034350.6010690.6521120.0537451.1969390.6013540.0053150.6038441.0390551.1996920.6028571.0387610.6309680.6238081.2128700.0055341.4213060.0448900.0051061.5458280.0490260.3694410.5328900.0052901.5426910.0056700.0900001.5406000.0056632.1703991.7645111.7674700.0592870.6012921.7837582.2235900.0059193.3119120.6009660.6016100.5979070.5838660.0053060.6012760.1008511.0442720.6311530.9050600.0457810.0450480.7254230.0589980.0051120.6774981.3662590.6440821.6259720.2788881.5436540.9515011.1105360.0054981.7971840.0057491.5412394.1202731.5439730.0449990.0468340.5635380.6365690.0462250.6755270.0053370.0050900.5933910.6752442.2440641.7728230.6324820.0053190.0050920.5986512.1960831.7749361.5436733.5428820.4826781.5429921.7736731.1704390.0055150.0050931.7721321.5372391.5433731.5441271.5439441.5441241.5465533.3037810.0540571.8153170.0057520.9991880.0451510.0051090.0890470.0787560.0051171.5826480.0483190.0051080.0455060.0478040.0051060.6582851.0624200.0456760.0051100.0452300.4945640.5981870.3216200.6036180.2908460.7280481.5433100.0056440.6259433.0834440.9770560.5708520.5936880.6316591.5434880.5938001.5428820.6082720.5821690.5728300.6181951.8348270.6367580.6479820.6461570.5898030.5920740.0053020.0050920.0549680.5857120.0619361.2564600.7184360.0466150.0051072.5765590.6415080.6357000.6247110.0053142.5655401.0862571.0430171.0824280.6155883.0416221.0284401.2146790.3503770.0052140.7039160.0489430.0515170.0461150.6385001.8106660.6856811.5428580.0449640.0450720.0832211.5430191.5432581.5434861.5431833.3064640.0536531.0694850.0054551.5865642.7765941.7374210.0056991.0389742.2058180.5596190.5902540.0052970.0445750.0454810.0446020.7401130.0515462.1673560.7212780.2529390.0051861.7630301.4825420.2935780.3608491.5429240.3959140.3632073.0456631.5440350.5542580.0052830.0546380.6305050.0446152.2647640.0058730.6149350.6259520.4143270.2790612.1592001.7745171.5457510.0056240.6711661.5435911.5446281.5449981.5432491.5439020.0466951.5383690.6380271.8134960.1038080.0446770.0051050.7668160.1350850.6115543.3138721.5447090.6815650.0484601.2168080.0450264.1156040.0065020.0581181.1537440.5760870.5552272.3364890.6025753.0809351.5440110.5628031.4804372.3896661.3075012.0191261.7749652.2276241.5442450.0448800.6837151.5431520.0056160.0880460.6884480.0859690.0051200.6346571.0207111.2787110.6342390.7309330.0053370.0050920.0528610.0051001.1873450.6103390.5930230.5767970.0052860.5850961.5430221.1922030.9883811.5120180.5987260.5962380.5843200.0052880.0050920.0460410.0486470.1116560.0731211.180917

*******************************************
EVALUATING PIPELINE 
Pipeline directory: /home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_63040284_2020-02-16_08-15-37nps22yu4/
With following parameter combination: {'batch_size_seq_length': 1, 'lr': 3e-05, 'lr_type': 'constant'}
EVALUATION OF CHECKPOINT /home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_63040284_2020-02-16_08-15-37nps22yu4/outputs/checkpoint-3
-------------------------------------------------------------
|           |   agree   | disagree  |  discuss  | unrelated |
-------------------------------------------------------------
|   agree   |    481    |    256    |    135    |    52     |
-------------------------------------------------------------
| disagree  |     8     |     8     |     3     |     2     |
-------------------------------------------------------------
|  discuss  |    444    |    101    |   1532    |    109    |
-------------------------------------------------------------
| unrelated |    104    |    103    |    109    |   8451    |
-------------------------------------------------------------
Score: 8355.5 out of 9226.0	(90.56470843269022%)
Accuracy: 0.8801479240208439
F1 overall: 0.5671221775239154
F1 per class: [0.49056603773584906, 0.032719836400818, 0.7727616645649432, 0.972441171394051]
*******************************************


*******************************************
EVALUATING PIPELINE 
{'batch_size_seq_length': 4, 'lr': 3e-05, 'lr_type': 'constant'}
INFO:__main__:Creating features from dataset file at /home/ubuntu/fnd_implementation/data/processed
  0%|                                                 | 0/11898 [00:00<?, ?it/s]  0%|                                       | 1/11898 [00:01<3:47:37,  1.15s/it]  4%|█▌                                   | 501/11898 [00:01<2:32:40,  1.24it/s] 50%|███████████████████▏                  | 6001/11898 [00:02<55:18,  1.78it/s]100%|███████████████████████████████████| 11898/11898 [00:02<00:00, 5094.16it/s]
  ******************************************* 
              Running Evaluation                
  *******************************************
 
  Length dataset evaluation: 11898
  Length dataloader evaluation: 372
  Number of epochs: 3
  Batch size: 32
  ******************************************* 
 
['/home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_6b999b2a_2020-02-16_12-48-43s6vcnc_d/outputs/checkpoint-3']
INFO:__main__:Evaluate the following checkpoints: ['/home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_6b999b2a_2020-02-16_12-48-43s6vcnc_d/outputs/checkpoint-3']
INFO:transformers.configuration_utils:loading configuration file /home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_6b999b2a_2020-02-16_12-48-43s6vcnc_d/outputs/checkpoint-3/config.json
INFO:transformers.configuration_utils:Model config {
  "attn_type": "bi",
  "bi_data": false,
  "clamp_len": -1,
  "d_head": 64,
  "d_inner": 3072,
  "d_model": 768,
  "dropout": 0.1,
  "end_n_top": 5,
  "ff_activation": "gelu",
  "finetuning_task": null,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "mem_len": null,
  "n_head": 12,
  "n_layer": 12,
  "num_labels": 4,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pruned_heads": {},
  "reuse_len": null,
  "same_length": false,
  "start_n_top": 5,
  "summary_activation": "tanh",
  "summary_last_dropout": 0.1,
  "summary_type": "last",
  "summary_use_proj": true,
  "torchscript": false,
  "untie_r": true,
  "use_bfloat16": false,
  "vocab_size": 32000
}

INFO:transformers.modeling_utils:loading weights file /home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_6b999b2a_2020-02-16_12-48-43s6vcnc_d/outputs/checkpoint-3/pytorch_model.bin
HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=372.0, style=ProgressStyle(description_width='initial')), HTML(value='')))
0.1861250.5249770.4559610.1527470.0382670.1666500.0290561.1297790.4627150.4210631.3003040.3850320.1013820.1939350.9007340.0601050.0037851.5789620.5056110.2629970.0132320.0006680.0001510.0002110.0004020.0005060.0004270.4814020.0476920.0016710.1442280.0046820.0005580.2223130.1724480.3922950.3922230.0107330.0047020.0206720.0019870.0027150.0000930.0000310.0000710.0000380.0002100.0001390.0002030.0006400.0003220.1153680.0030290.0001520.1923070.0051770.0027400.3942610.0072630.0007770.0004380.0011180.0047610.2429640.0040530.0045780.0002270.0001230.0000770.0058430.0464710.0952610.0018340.0001540.0012790.0002070.0035000.0014300.0001200.2715960.0798580.0020260.0863890.4937990.2274930.2426780.0129191.1445440.0131820.0002530.6959990.0276870.0788330.0014860.0008900.0006020.0009010.0014180.0019191.3292740.0138220.0486020.1782350.4032350.7580900.0122870.1949980.0046570.1624750.5414030.2869010.5667000.5174550.0638850.3642441.1327040.2720720.0026900.0052530.0024680.7554770.0855800.4930210.0047930.0061760.0436690.0859460.0341900.0226770.0477360.0012710.0055100.0112031.1460480.0410720.1685450.0027770.0000720.2796780.1923900.7556120.0433870.0034890.2925820.2280000.4070060.1981100.0139440.0004800.0006050.6399980.8446980.0057920.0000800.0005991.0622600.8130300.1908120.0019240.1489330.3459210.0023240.1000730.0441220.0006360.0017390.2774690.0018820.0060500.0439640.0022463.4768040.0225000.0004840.6482891.0509520.1839990.0021780.0252850.0003960.4907310.5556880.3003630.0063540.0017870.0085380.0025990.0003240.0202690.0066820.0034191.0652500.6243970.4045130.0024330.0019540.9277261.2045960.2937750.0016110.0004400.0003760.0001590.0002340.0015711.1563860.6378800.0042950.0012250.0009010.2188000.0110640.0001900.0000581.7032681.5122460.1723430.5666800.6586320.3795140.0038760.0006470.9312410.4070660.0022170.0006020.1669170.0039461.0376130.3498760.0044550.1647490.0201370.0393140.0082660.4528290.5282510.2028500.0170600.7434140.0089960.0316560.0017320.0004170.0002890.0001800.0052390.1734610.0013450.0003880.5141161.0496820.4836560.2192800.0012680.0032330.0518110.0022550.4714160.0027480.0018820.0036410.1027230.0092350.0009220.0123760.2682781.4935720.0506890.0006820.5716050.7284460.8810510.7000030.0035790.3624200.1171300.2282070.5187042.1299910.0102670.0017640.0017370.3262850.8019880.1821360.3648870.6114880.5877500.4460830.6610140.8129240.6443460.4363200.6149700.4312190.3827550.8852070.2055460.6563410.1687860.8371720.2997680.3050330.4080060.6439721.1963250.2059500.4810590.2466510.2834680.4300080.5856380.4642290.5417310.3195970.4845510.8885400.2106630.8471710.2090430.2976171.3625170.8445440.7573760.2823160.3958360.6186460.8395490.3473260.5439870.2238690.3537280.4552980.5234210.4778380.9438330.1245000.4672190.4900100.6736910.7645460.2918850.4763800.2744931.1601340.2024510.1295730.3930690.3735040.7112420.2316430.4403460.4404290.5512500.5906711.0275830.5202700.2480390.6617730.5073990.4224570.2520430.4252290.4121690.2666131.1578280.7741490.1902860.4281400.5211890.183638

*******************************************
EVALUATING PIPELINE 
Pipeline directory: /home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_6b999b2a_2020-02-16_12-48-43s6vcnc_d/
With following parameter combination: {'batch_size_seq_length': 4, 'lr': 3e-05, 'lr_type': 'constant'}
EVALUATION OF CHECKPOINT /home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_6b999b2a_2020-02-16_12-48-43s6vcnc_d/outputs/checkpoint-3
-------------------------------------------------------------
|           |   agree   | disagree  |  discuss  | unrelated |
-------------------------------------------------------------
|   agree   |    813    |    98     |    196    |    28     |
-------------------------------------------------------------
| disagree  |    86     |    317    |    85     |    31     |
-------------------------------------------------------------
|  discuss  |    107    |    21     |   1434    |    56     |
-------------------------------------------------------------
| unrelated |    31     |    32     |    64     |   8499    |
-------------------------------------------------------------
Score: 8680.0 out of 9226.0	(94.08194233687405%)
Accuracy: 0.9298201378382922
F1 overall: 0.805301644633474
F1 per class: [0.7486187845303868, 0.6423505572441742, 0.8442743597291728, 0.9859628770301624]
*******************************************


*******************************************
EVALUATING PIPELINE 
{'batch_size_seq_length': 2, 'lr': 3e-05, 'lr_type': 'cosine'}
INFO:__main__:Creating features from dataset file at /home/ubuntu/fnd_implementation/data/processed
  0%|                                                 | 0/11898 [00:00<?, ?it/s]  0%|                                       | 1/11898 [00:01<3:48:33,  1.15s/it]  4%|█▌                                   | 501/11898 [00:01<2:33:18,  1.24it/s] 46%|████████████████▋                   | 5501/11898 [00:01<1:00:14,  1.77it/s] 56%|█████████████████████▏                | 6645/11898 [00:01<34:37,  2.53it/s]100%|███████████████████████████████████| 11898/11898 [00:01<00:00, 6405.07it/s]
  ******************************************* 
              Running Evaluation                
  *******************************************
 
  Length dataset evaluation: 11898
  Length dataloader evaluation: 1488
  Number of epochs: 3
  Batch size: 8
  ******************************************* 
 
['/home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_7bc0aac0_2020-02-17_01-56-25yz5s3qgz/outputs/checkpoint-3']
INFO:__main__:Evaluate the following checkpoints: ['/home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_7bc0aac0_2020-02-17_01-56-25yz5s3qgz/outputs/checkpoint-3']
INFO:transformers.configuration_utils:loading configuration file /home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_7bc0aac0_2020-02-17_01-56-25yz5s3qgz/outputs/checkpoint-3/config.json
INFO:transformers.configuration_utils:Model config {
  "attn_type": "bi",
  "bi_data": false,
  "clamp_len": -1,
  "d_head": 64,
  "d_inner": 3072,
  "d_model": 768,
  "dropout": 0.1,
  "end_n_top": 5,
  "ff_activation": "gelu",
  "finetuning_task": null,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "mem_len": null,
  "n_head": 12,
  "n_layer": 12,
  "num_labels": 4,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pruned_heads": {},
  "reuse_len": null,
  "same_length": false,
  "start_n_top": 5,
  "summary_activation": "tanh",
  "summary_last_dropout": 0.1,
  "summary_type": "last",
  "summary_use_proj": true,
  "torchscript": false,
  "untie_r": true,
  "use_bfloat16": false,
  "vocab_size": 32000
}

INFO:transformers.modeling_utils:loading weights file /home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_7bc0aac0_2020-02-17_01-56-25yz5s3qgz/outputs/checkpoint-3/pytorch_model.bin
HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=1488.0, style=ProgressStyle(description_width='initial')), HTML(value='')))
0.0003780.0005240.0006190.0002550.0000770.0000790.8990030.1284420.0160690.9402860.0940410.0085620.0007620.0004790.0000480.0001151.1066700.0651111.0345720.0544750.0027660.0001830.0000210.0000150.0000560.0000160.0000130.0000141.2572021.4583950.0488150.7855510.0245620.0072451.0922510.0312270.0011640.0000541.1367620.0292781.4505521.1643512.2412701.1924020.0271731.1520440.0253790.0005560.0002590.0000180.0000130.0000130.0000850.0000550.0000140.9034741.8085072.6224510.0453610.0007810.0000260.0000140.0000130.0000470.0000130.0000130.0000130.0000130.5483401.6608052.0617560.0292900.4309310.0059160.0000930.0000140.0000240.0000750.0005631.1179600.0139981.0893630.0132980.0821370.0013490.0000290.0550990.0006471.0519780.0118330.0001440.0000140.0000130.0000130.0032331.0096281.1244482.0088360.3384771.3903250.7481140.7963550.0078670.0002490.0001640.0000560.0001350.0000150.0001740.0006642.1056030.8857720.0079220.0000830.0000140.0004490.0000170.0000130.0000140.0000131.0724350.0088760.0000860.0000160.0000140.0000140.0000490.0000140.0000140.0001510.0002060.0002250.0000761.0816380.0081620.0031380.0000390.0005180.0000170.0000140.0005020.9394950.9339140.0065440.9373840.9472420.0065300.0000850.0000430.0000410.0000950.0000140.0000130.0001290.0000720.0000710.0000420.0000790.0000130.0001480.0068530.0005120.0005070.0000840.0001300.0013530.0000220.0000140.0000130.0000140.0000130.0000130.0000140.0000140.0000140.0000140.0000150.0000130.0000520.0000140.0000140.0000140.0000140.0000140.0000140.0000480.0000160.0000130.0002100.0000140.0000140.0000140.0000150.0000140.0000140.0007480.0001240.0003250.0002540.0002080.0000140.0000140.0001970.0001151.7793280.9627560.0046880.0001010.0000900.0000840.0000810.0000130.0001140.0000130.0000130.0000140.0012200.0000500.0000130.0000140.0000130.0000150.0007160.0036560.0013310.0000700.0000560.4619571.3750990.0060651.2479080.0055170.0000370.0003420.0000480.0000970.0000140.0001810.0000990.0000420.0000130.0002810.0001520.0002510.0000150.0000140.0000151.0473740.0084030.0001610.9515880.0038040.0000290.0000470.0000130.0001460.0000130.0000130.0000160.0003070.0000150.0005760.0000260.0003510.0000170.0004750.0001680.0000200.0000440.0000130.0000430.0000730.0000130.0000130.0000750.0000130.0000500.0000510.0082310.1059821.3776950.0054140.0000600.0000540.0197800.0001230.0000530.0008020.0003730.0003840.0000140.0000570.0000420.0000130.0000760.0000430.6212280.7014230.0025050.0002600.0000140.0001580.0001560.0000140.0000710.0002021.7841121.0158440.0033700.0000230.9755660.0031800.0000520.0000130.0001030.0000431.0822420.0034271.0875681.0885080.0034481.0860640.0033850.0001310.0000130.0000440.0008860.0003720.0003260.0044610.0081050.0021210.0002470.0002841.3524253.4058980.0102200.6435250.6249760.0022930.0740260.2364410.7179580.0022410.0006910.0000760.0001000.0000740.0001510.0003210.0004790.0000670.0000140.0001480.0000150.0001510.0000140.0001490.0001430.0000160.0028470.0012310.0000180.0469810.0001890.0000461.1449583.1076070.0084582.0378931.9737130.9764090.0028370.0010470.0000170.0001510.0000152.1799780.0058500.0007490.0003440.0000140.0001940.0000140.0000150.0003270.0003150.0000150.0002980.0018420.0001060.0000700.2679130.0008770.0000300.0003720.0000540.0000965.5810920.0141830.0001390.0001010.0001930.0001120.0013520.0004250.0001460.0003540.1457180.0015891.2803750.0031290.0000210.0002770.0161100.0000520.0037910.0005732.0062021.9328500.0046160.0001070.0000430.0000990.0000631.2334941.0752970.0031240.0004080.0006860.0002380.4623931.2136920.0029730.0001850.0001431.7010160.0039120.8748100.0020100.0006940.0034270.0001270.0034510.0076740.7959051.7171330.0039290.0001540.8286630.8919400.0019911.1003750.0024750.0000190.0000131.0986842.2083140.0048682.1947710.0049622.7344350.9534501.8093300.0043940.0005640.0000810.0000530.0000830.0001470.0001100.0001030.0003880.0009070.0012000.0021690.0000200.0000130.0000760.6921650.0014590.0020700.0094680.0002280.0001050.0007870.0002490.0000140.0237500.0000620.0043070.0001670.0002190.0000470.0000450.0007540.7496880.0015230.0000180.0000160.0006940.8151090.0019310.0010120.0000180.0013990.0006960.0001140.0005740.0005440.0001800.0002730.0011380.0005770.0002150.0001770.7254430.0014510.0000170.0007930.0003690.0003050.0004400.0003170.4841800.0009371.8168120.5245300.4566270.0019680.0722140.0002390.0005480.0007680.0015990.0007040.8833030.0018850.0002690.0003650.0007620.0000581.2374420.0025570.0006280.5813270.0015180.0000150.0000460.0000130.0000120.0000131.1327080.0020610.0000160.0000120.0000120.3127710.0008800.0005950.0003390.0004040.0000430.0000790.0001160.0000200.0001170.0001190.0041950.0001490.0000140.0006210.0017090.0010383.1430200.0055122.0130250.6374510.0034181.1800140.0021990.0001680.9246400.0017070.0000150.0004240.0011030.0004900.0002360.0000660.0002330.0001140.0000760.0001090.0001320.0000470.0001070.0000140.0037920.0000830.0000130.0038131.1373891.8835890.0033212.9222181.1164410.0018560.0061990.0002320.0000140.0000180.0000440.0007540.0000260.0001960.0000140.0002030.0006580.0002430.0003630.0008892.2300722.4298843.4714700.0057180.0003070.4822690.0016220.0008810.0001440.0001030.0000760.0001050.0001040.0006770.0007962.1540350.4107570.1648581.2615120.0032500.0001510.0000820.0000800.0001470.0000140.0000130.0000130.0000130.0000900.0018521.0822880.0016700.0000520.0000520.0000130.0000720.0000610.0000140.0000500.0001750.0001850.0006500.0004050.7001921.1712980.0020950.0000820.0000130.0001910.0001000.0001590.0001090.0004790.0003650.0002180.0002720.0002730.0002390.0007250.0001760.0000781.3564693.7576895.4659255.4589300.0084801.2453450.0106160.1631310.0003130.0001890.0000730.0001250.0000830.0253880.0005810.0002140.4413850.3971350.0014860.0003310.0430580.0001960.0005930.0013110.0002740.0003670.0001940.0028800.0000560.0001690.0026910.0001820.0001550.0000180.0001750.0001760.0000240.0001750.0050461.6161940.0022490.0000160.8072910.8525590.0011890.8560930.6821660.0009480.0000150.0007130.7382120.0026850.0008390.0001120.0001890.0001950.0003530.0012070.0060390.0005600.0004860.0006900.0000150.0000140.0000160.0002440.0000530.0000130.0000130.0000601.5728080.0637670.0003380.2679220.0009930.0000140.0014490.0013170.0008270.0011810.0003952.1806451.1233222.2457260.0029400.0000161.9709841.1257711.1204640.0023800.0081270.0000590.0000140.0001170.0000870.0000810.0001020.0001760.0001140.0000850.0001512.4173890.8899500.9167681.3861662.5179042.4677421.7868090.8949411.7297370.0021940.0022950.0000160.0000130.0000560.0000130.0000520.0071300.0000220.0000130.0326920.0000540.0002860.0103420.0000570.0080920.0000230.0000130.0000130.0958540.0001310.0000130.0000830.0002690.0002690.0005820.0009280.0005640.0014184.0601873.0158753.1055470.0042850.0002716.0232090.0079610.0005130.0005890.0004840.0000920.0000590.0000140.0001040.0000160.0001110.0001060.0000450.0001920.0018210.0012081.0222350.0084330.0002680.0000450.0000130.0001020.0000850.0000130.0000150.0000510.0000130.0000140.0000130.0000140.0000454.6939543.7248343.2865780.7900581.2696350.0656620.5350300.0011450.8309911.1867280.0017480.6050480.0012970.0003270.0003143.2053243.2486803.2329780.0041750.9219961.0435060.8794100.0029590.0007930.0006460.0004310.0000380.0002410.0002450.0002420.0002420.0002442.0730132.1567621.8940770.0023190.0000150.0001220.0001290.0001570.0000860.0003590.0002670.0004990.0002760.0002260.0000130.8549470.0013590.0005750.0002710.0000630.0002930.0000160.6847790.0692580.0004750.0006850.0009700.0000150.0005840.0001600.0000142.0946120.0027150.8804550.0019370.0005740.0007020.0003290.0003470.0004091.0387130.1310600.0021760.0006020.0011350.0026911.3230200.0014240.0000150.5272020.0005730.0000572.2235750.0023710.0000153.9975970.0047210.0001980.0001150.0000500.0002020.0000570.0000520.0033850.0000190.0000160.0005081.1266980.0020240.0058450.1712270.0115850.0016340.0000140.0000590.0000480.0000800.7664330.0010820.0005500.0000140.0021290.0002640.0005250.0002620.0000140.0000140.0000130.0000120.2334410.0002510.0035270.0000600.0000130.0000480.4962300.8271980.0010960.8758930.9251050.5198631.0966690.0012710.0003000.0001650.0000440.0001060.0000760.0001050.0000760.0001050.0001470.0000791.2949130.0143520.0000270.5482511.4731890.8465170.0008521.7046650.0016990.0000141.6327090.0016250.0000590.0000150.0004730.0000150.0000140.0004390.0002520.0002540.0000140.0003550.0000160.0001630.0002100.0002130.0000140.0002270.0001691.1393590.0016300.0012970.0013740.0002110.0002700.0001490.0001240.0002130.0005470.0003340.0006010.0003850.0005861.4739610.0516630.3323900.0007110.0222450.0005900.0172120.0003740.2582580.0006430.0001570.0002850.0007450.0071630.0039260.1884060.000284
0.0000130.0000531.0624300.0013360.0006670.8297241.0955160.4752920.0004580.0000230.0002890.0004030.0004000.0002270.0000140.8894270.0008460.0000142.7310160.0038240.0011412.5592600.0024850.8677610.0012231.7712930.0016730.8450141.8414371.7534910.5002090.8600820.8230120.0009220.0000690.0005010.0008090.0003550.0002580.0001331.9102100.0019730.9485230.0010410.0001830.0004621.0973251.2521850.0013680.0010270.5175970.0236440.6975780.0006900.0001425.0339763.0985040.0033510.0001490.0002790.0004900.0019380.0011930.0009660.0006110.0005490.0002820.0003510.0006830.0103220.0042150.5319510.6300301.0697090.7336520.4719160.0038760.0447640.7445520.6085150.4134751.7999900.9937380.8268660.5257090.9417730.0828350.5967780.1485500.6537511.8065560.0112690.0172430.3758130.0028041.4110900.0152441.5778010.7972380.0362910.8311090.7352790.0083911.3508610.6465260.4090770.0774120.2597380.5884860.7686280.3041450.3679090.0781980.3006131.0720770.9727820.0053110.8024900.2378940.8369620.0162450.2449920.4883440.0772120.3722970.3314971.8762710.0083990.9994420.0008530.0111430.6330610.7964890.1402911.6057281.0823101.3175770.1044480.6447630.0044750.0276690.0213690.2744060.6220401.4627681.2637240.3489290.5157430.0009530.4779960.6467330.0028310.6788910.3572010.7611331.1874291.6863531.1659911.0235731.6101390.3852121.0002561.5316850.0564332.3392180.0070610.6985950.0035840.8393130.9328320.0012950.7713540.3218660.6021700.0080020.1128250.1696370.3610010.8080850.3080230.2804530.5996960.0024670.0032711.8163490.5835120.9021740.0041510.2056550.0019070.2142570.8760510.4262191.0070700.0225500.4304540.3817440.7306340.5044290.0379730.9331120.3372840.2485271.4524770.0079330.6474290.9964750.4811720.1654960.2251070.1267850.5566320.7071280.4498170.2524240.6158390.0055230.3009600.3528050.0097400.3523770.3683550.7239660.1226210.0868741.9384820.7929770.6697300.0233541.7085350.5075070.0400090.2425340.1548310.7428170.1889880.0978550.9326000.8649230.1633040.0662730.0045570.5594690.0126950.7504871.1554230.6112450.0071720.5960280.4509621.4061670.0019690.8304040.0285040.0087570.4753340.1892520.7662740.3284180.2923870.0689730.0822280.0076170.0619470.1399731.3466400.4239510.2853240.5097550.0327140.2825710.5485980.0028801.0270570.0114860.5624720.4772660.0722760.0575790.6091310.6903471.4715120.8210960.3862771.8476890.9792550.0185830.0188870.2270910.0500480.0012221.3846980.3354250.3672020.6393720.0946760.6296921.2666930.0132910.4193600.0615990.7069460.4684540.0179560.7798610.3861420.0002990.3335680.5776030.0077940.0020730.8008640.7662470.7569540.4393220.0014200.3997661.1197290.9127221.5991701.0733210.5908670.0026620.0072530.0118790.3617840.0406480.0032590.0669640.0003151.0736490.0088751.2957140.4003770.8804850.0247800.7956581.3013041.4120320.0068850.0396140.5285350.4323400.0087750.5282030.2647411.4266650.0027530.0052330.0134840.5632860.7176050.0508020.8556490.2032540.7867610.0095070.6325180.7394991.1089800.3454191.6359461.7700680.2305600.9904791.2836450.0061481.6705280.0047740.1917060.0609690.3321050.7620570.3347050.2133040.4190241.0055760.4260940.1587740.4059900.0073660.9824810.0164160.3873250.3988890.0059130.7061210.0037030.0036040.5337181.2966440.0056590.2279140.5055060.4871951.0120340.8739800.8193070.4972100.0289090.4425210.5001070.4750201.8298891.1820891.4837970.4844280.0616330.2417880.0088690.0554260.1366270.3441460.3656800.2318581.4759940.0014201.4481520.3657030.5195230.0145000.0000370.0068210.3706200.423569

*******************************************
EVALUATING PIPELINE 
Pipeline directory: /home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_7bc0aac0_2020-02-17_01-56-25yz5s3qgz/
With following parameter combination: {'batch_size_seq_length': 2, 'lr': 3e-05, 'lr_type': 'cosine'}
EVALUATION OF CHECKPOINT /home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_7bc0aac0_2020-02-17_01-56-25yz5s3qgz/outputs/checkpoint-3
-------------------------------------------------------------
|           |   agree   | disagree  |  discuss  | unrelated |
-------------------------------------------------------------
|   agree   |    764    |    79     |    134    |    20     |
-------------------------------------------------------------
| disagree  |    84     |    315    |    75     |    17     |
-------------------------------------------------------------
|  discuss  |    167    |    52     |   1536    |    81     |
-------------------------------------------------------------
| unrelated |    22     |    22     |    34     |   8496    |
-------------------------------------------------------------
Score: 8752.75 out of 9226.0	(94.87047474528507%)
Accuracy: 0.9338544293158514
F1 overall: 0.8116381595674858
F1 per class: [0.7512291052114061, 0.656934306569343, 0.8497925311203319, 0.988596695368862]
*******************************************


*******************************************
EVALUATING PIPELINE 
{'batch_size_seq_length': 4, 'lr': 3e-05, 'lr_type': 'linear'}
INFO:__main__:Creating features from dataset file at /home/ubuntu/fnd_implementation/data/processed
  0%|                                                 | 0/11898 [00:00<?, ?it/s]  0%|                                       | 1/11898 [00:01<3:20:41,  1.01s/it]  4%|█▌                                   | 501/11898 [00:01<2:14:35,  1.41it/s] 38%|█████████████▌                      | 4501/11898 [00:01<1:01:09,  2.02it/s] 48%|██████████████████▏                   | 5714/11898 [00:01<35:47,  2.88it/s] 57%|█████████████████████▋                | 6790/11898 [00:01<20:41,  4.11it/s]100%|███████████████████████████████████| 11898/11898 [00:01<00:00, 7253.38it/s]
  ******************************************* 
              Running Evaluation                
  *******************************************
 
  Length dataset evaluation: 11898
  Length dataloader evaluation: 372
  Number of epochs: 3
  Batch size: 32
  ******************************************* 
 
['/home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_76763a6c_2020-02-16_20-07-53xalizeni/outputs/checkpoint-3']
INFO:__main__:Evaluate the following checkpoints: ['/home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_76763a6c_2020-02-16_20-07-53xalizeni/outputs/checkpoint-3']
INFO:transformers.configuration_utils:loading configuration file /home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_76763a6c_2020-02-16_20-07-53xalizeni/outputs/checkpoint-3/config.json
INFO:transformers.configuration_utils:Model config {
  "attn_type": "bi",
  "bi_data": false,
  "clamp_len": -1,
  "d_head": 64,
  "d_inner": 3072,
  "d_model": 768,
  "dropout": 0.1,
  "end_n_top": 5,
  "ff_activation": "gelu",
  "finetuning_task": null,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "mem_len": null,
  "n_head": 12,
  "n_layer": 12,
  "num_labels": 4,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pruned_heads": {},
  "reuse_len": null,
  "same_length": false,
  "start_n_top": 5,
  "summary_activation": "tanh",
  "summary_last_dropout": 0.1,
  "summary_type": "last",
  "summary_use_proj": true,
  "torchscript": false,
  "untie_r": true,
  "use_bfloat16": false,
  "vocab_size": 32000
}

INFO:transformers.modeling_utils:loading weights file /home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_76763a6c_2020-02-16_20-07-53xalizeni/outputs/checkpoint-3/pytorch_model.bin
HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=372.0, style=ProgressStyle(description_width='initial')), HTML(value='')))
0.1495590.3088060.3566710.1195390.0299150.0060250.0010370.5162350.2244590.5506770.6010600.3246700.0271250.2308691.1061300.0737810.0046351.1643750.2869290.2298430.0116920.0005910.0118490.0006090.3127490.0630640.0024960.6468480.0231980.0008240.2571810.0083230.0007140.2837500.1794790.4776800.4693400.0127490.0004220.0000920.0006390.1300620.0031230.0000990.0000420.0000280.0000370.0000590.2452390.0067780.0002480.5140440.0101240.0002300.1853430.0825750.0172840.4030500.0070720.0104630.0004210.1134120.0020060.2714470.0042960.0003290.0001730.0000630.0000440.0867240.0586730.1025160.0019040.0001060.0001640.0000830.5136090.2809460.0036510.4531880.2125820.0035040.8118711.0635700.5247930.3055300.0038411.9739130.0225050.0004020.0945050.0029510.0232660.0074670.3579130.3042990.0040250.0167020.0085571.3641060.0138030.0008690.4678610.0673500.4255010.0041590.3610190.1416560.5778820.6158440.2274570.7568620.4470380.0049020.0614591.6146910.2413190.0022020.0200340.0016600.5610810.0048940.0013240.0045570.0002740.0096750.0025200.0006650.0111990.0719370.0009470.2761010.1540750.1204510.1753520.3123400.0136040.0001370.2723250.3638310.8528520.0062140.0153940.3119660.9535480.2540300.0713960.0339670.0003520.1628261.3145731.0119080.0067080.0000690.0000940.7327530.4599800.0045940.0002790.0731970.1014480.0007330.0001750.0014350.0001870.0004680.4551980.0028570.0008560.0004120.0007442.5435250.0266730.0002780.9851930.0144730.1310380.3908390.4025110.0023270.3273430.3278760.2655140.0219780.0004020.0044410.0119060.0002370.2337450.1675520.0016351.1403560.7301510.0727450.2538560.0014480.2143990.3213450.0023630.0000670.0005090.0006900.0001190.0003220.0148101.9191601.3660530.5595090.0029000.0003570.6438270.2732560.0014100.0000481.7750271.2287860.1194030.0145212.1371240.3926940.0042670.0003381.1810680.4391520.0038000.0024550.1386440.0855871.5607430.7122510.0035350.2993510.2015450.0467890.7477850.6257650.7887420.0046990.0000870.3995090.0039640.0416170.0145770.0024480.2124260.0086020.3010660.9749110.0041630.0001600.4100340.9619680.2662870.0100350.0003950.0584540.0006630.0005260.2364560.0171840.0004090.6648180.3316580.0183120.0005020.0064860.2408210.6832190.0027300.0009210.5612270.8592280.9911070.6590580.0026880.2527480.0012510.0006540.2889201.0967890.0044510.0009480.0003720.2453720.6988350.2318000.4543970.4301110.2180820.6545030.6096910.7369730.4997700.5207060.6346570.4379610.6138890.6513050.4292660.4871230.2131810.5739380.1650880.3242450.5426720.9906370.9429280.1810110.5325520.3462660.2415630.2983090.4091110.4883360.5571170.4140250.4469040.7227370.2531220.4979560.1794490.2383670.6285530.7694380.7454530.4063280.3581280.5198960.6997280.1445590.5494240.1628850.5489470.2656230.2854150.3024381.2864390.2339430.0595110.6358950.3684710.5555920.3803410.4444580.4073700.9664350.3852890.1248930.5302140.3809580.6843700.2582260.5149570.4306660.5062590.4101051.0331800.4920310.3530100.5114770.4015710.6013140.1331190.5008730.5242320.4014141.1847820.4898250.0809050.3549480.5605140.137535

*******************************************
EVALUATING PIPELINE 
Pipeline directory: /home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_76763a6c_2020-02-16_20-07-53xalizeni/
With following parameter combination: {'batch_size_seq_length': 4, 'lr': 3e-05, 'lr_type': 'linear'}
EVALUATION OF CHECKPOINT /home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_76763a6c_2020-02-16_20-07-53xalizeni/outputs/checkpoint-3
-------------------------------------------------------------
|           |   agree   | disagree  |  discuss  | unrelated |
-------------------------------------------------------------
|   agree   |    745    |    70     |    125    |    18     |
-------------------------------------------------------------
| disagree  |    82     |    309    |    82     |    20     |
-------------------------------------------------------------
|  discuss  |    187    |    65     |   1511    |    67     |
-------------------------------------------------------------
| unrelated |    23     |    24     |    61     |   8509    |
-------------------------------------------------------------
Score: 8727.0 out of 9226.0	(94.59137220897463%)
Accuracy: 0.9307446629685662
F1 overall: 0.8037342294948479
F1 per class: [0.7468671679197995, 0.6430801248699272, 0.8373510667775007, 0.9876385584121641]
*******************************************


*******************************************
EVALUATING PIPELINE 
{'batch_size_seq_length': 1, 'lr': 3e-05, 'lr_type': 'linear'}
INFO:__main__:Creating features from dataset file at /home/ubuntu/fnd_implementation/data/processed
  0%|                                                 | 0/11898 [00:00<?, ?it/s]  0%|                                       | 1/11898 [00:01<3:55:44,  1.19s/it]  4%|█▌                                   | 501/11898 [00:01<2:38:07,  1.20it/s] 46%|████████████████▋                   | 5501/11898 [00:01<1:02:07,  1.72it/s]100%|███████████████████████████████████| 11898/11898 [00:01<00:00, 5976.94it/s]
  ******************************************* 
              Running Evaluation                
  *******************************************
 
  Length dataset evaluation: 11898
  Length dataloader evaluation: 2975
  Number of epochs: 3
  Batch size: 4
  ******************************************* 
 
['/home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_6e514002_2020-02-16_14-09-10gzjh09ia/outputs/checkpoint-3']
INFO:__main__:Evaluate the following checkpoints: ['/home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_6e514002_2020-02-16_14-09-10gzjh09ia/outputs/checkpoint-3']
INFO:transformers.configuration_utils:loading configuration file /home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_6e514002_2020-02-16_14-09-10gzjh09ia/outputs/checkpoint-3/config.json
INFO:transformers.configuration_utils:Model config {
  "attn_type": "bi",
  "bi_data": false,
  "clamp_len": -1,
  "d_head": 64,
  "d_inner": 3072,
  "d_model": 768,
  "dropout": 0.1,
  "end_n_top": 5,
  "ff_activation": "gelu",
  "finetuning_task": null,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "mem_len": null,
  "n_head": 12,
  "n_layer": 12,
  "num_labels": 4,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pruned_heads": {},
  "reuse_len": null,
  "same_length": false,
  "start_n_top": 5,
  "summary_activation": "tanh",
  "summary_last_dropout": 0.1,
  "summary_type": "last",
  "summary_use_proj": true,
  "torchscript": false,
  "untie_r": true,
  "use_bfloat16": false,
  "vocab_size": 32000
}

INFO:transformers.modeling_utils:loading weights file /home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_6e514002_2020-02-16_14-09-10gzjh09ia/outputs/checkpoint-3/pytorch_model.bin
HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=2975.0, style=ProgressStyle(description_width='initial')), HTML(value='')))
2.0530032.0530171.0265230.3423450.0859480.0172050.0029390.0004320.0001040.0000230.0000520.0000760.0003540.0000380.0000130.0000110.0000110.0000111.9554630.1029300.0051570.0002560.0000230.0000110.0000110.0000690.0000130.0003610.0000240.0000120.0000130.0001862.2084331.9647400.0577990.0016650.0000602.2040180.0580150.0015070.0001070.0000160.0000120.0000740.0000120.0000110.0000110.0000110.0000720.0000120.0000110.0000110.0000110.0000110.0000110.0000131.2869850.5977300.2081402.2267340.0371830.0006292.1855374.3624400.0681780.0010620.0158862.2142542.2521960.0326560.0004840.0000220.0000152.2197780.0300110.0004762.2140342.2471042.2175810.0280850.0331382.2230330.0271242.2230052.2405752.2419832.0876650.0240102.2145240.0248992.2162920.0243690.0002850.0126660.0001580.0000140.0002640.0000140.0000120.0000120.0000120.0000120.0000120.0000370.0001440.0000130.0000120.0000700.0000120.0000150.0000161.7524451.7795501.7407003.6290811.6267670.0151090.0001420.0000140.0000130.0000130.0000130.0000130.0000140.0000130.0000140.0000710.0000130.0000160.0000130.0000130.0000130.0000130.0000130.0000130.0000131.9769730.0146304.1951550.0301932.1571253.7620940.0265060.0002132.1130362.3910610.0163880.0001220.0000180.0000120.0000110.0000110.0000120.0000130.0000730.0000720.0000110.0014820.0000232.3844000.0153340.0001080.0000320.0000130.0000120.0000130.0000170.0000130.0000120.0000180.0000140.0000130.0000300.5974080.0034470.0000340.0000850.0000130.0000140.0000120.0000120.0000130.0000130.0000130.0000130.0000120.0000120.0000130.0000120.0000130.0002070.3486860.0018290.0000291.0649570.0069452.2044395.0057644.3762432.2264702.1753462.2015584.4230530.0218610.0002060.0000270.0001830.0000130.0000640.0002050.0000930.0000980.0000140.0000510.0006430.0000700.0000350.0002000.0006570.0002731.1966731.4474880.0071590.0000430.0000110.0000110.0000110.0000110.0000110.0000111.5941550.0069120.0000400.0000110.0000110.0000110.0000110.0000110.0000110.0000111.9979530.0083010.0000450.0000130.0000130.0000130.0000130.0000130.0000130.0000130.0000130.0000130.0000130.0000190.0000130.0000130.0000130.0000120.0001840.0000140.0000130.0004290.0002960.0000130.0001230.0000132.4259370.0092090.0000930.0000700.0000200.0000140.0000130.0000140.0000150.0004150.0000120.0000110.0000110.0000120.0002290.0003940.0000131.9750961.9727980.0069610.0000360.0000120.0000111.9675841.9737200.0067940.0000350.0000700.0000120.0000690.0000690.0000120.0000700.0000120.0000680.0000740.0000120.0000160.0000120.0000120.0001260.0001290.0000690.0000680.0000160.0001240.0000690.0000130.0000120.0001260.0000120.0001030.0001440.0000250.0004020.0002800.0000180.0006240.0004470.0002540.0000120.0001290.0000700.0001860.0014980.0000750.0000120.0000110.0000110.0000110.0000110.0000110.0000110.0000120.0000110.0000110.0000110.0000110.0000110.0000110.0000110.0000110.0000110.0000120.0000110.0000110.0000110.0000120.0000110.0000110.0000720.0000120.0000110.0000110.0000110.0000110.0000120.0000120.0000110.0000110.0000120.0000110.0000110.0000110.0000110.0000720.0000120.0000180.0000120.0000120.0002190.0000120.0000110.0000110.0000110.0000140.0000120.0000120.0000130.0000110.0000110.0000120.0000110.0000121.3191910.0033850.0001390.0000690.0002530.0000680.0002260.0000120.0002230.0000120.0000120.0000120.0000110.0000120.0002040.0002352.1207430.0053362.1044531.8267011.6450060.0040720.0000280.0000130.0000700.0000700.0000810.0000730.0000130.0001370.0001300.0000130.0000110.0000110.0000930.0000110.0000110.0000110.0000110.0000110.0000110.0000110.0000110.0001300.0000710.0000120.0000110.0000110.0000120.0000110.0000110.0000120.0000120.0000110.0000110.0001641.2777880.0031180.0008380.0006930.0001100.0000770.0005270.0018880.0000223.8120951.7249541.7331820.0037960.0000770.0000113.2028570.0070020.0000870.0000120.0000110.0003920.0000650.0000110.0000700.0000880.0000110.0000110.0000110.0000110.0017970.0005430.0000130.0000680.0000120.0000120.0000110.0002490.0000900.0001350.0000720.0005500.0000190.0000180.0000160.0000290.0000160.0000190.0000200.0002550.2403670.0004970.0001470.0002230.0001260.0001260.0000130.0000110.0000110.0000110.3596100.0007220.0246650.0000600.0000110.0001580.0000110.0000110.0000110.0000110.0000110.0000110.0000110.0001540.0001580.0000130.0000130.0001300.4050360.0008010.0000180.0009050.0000160.0000140.0000340.0000460.0000160.0001040.0003351.7553470.0032940.0000760.0000120.0000110.0000120.0000110.0000700.0000700.0000710.0000120.0000110.0000120.0000120.0000120.0001280.0000120.0000120.0000720.0000130.0000110.0001140.0000111.0212590.7792760.0014051.7997691.6014250.0031620.0000180.0000110.0000200.0000760.0000110.0095620.0318260.0000660.0000770.0000730.0000110.0037730.0027070.0002180.0001960.0051080.0001040.0000140.0000120.0000710.0000160.0000130.0000700.0000130.0000120.0000120.0001280.0000700.0000110.0000110.0002940.0003640.0002470.0000680.0000120.0002320.0000130.0000120.0000130.0001590.0000130.0000120.0001580.0000130.0000130.0001220.0000130.0000130.0000672.4126670.0039500.0000202.4133970.0039860.0000740.0000130.0000132.4106060.0038950.0000750.0000130.0000130.0000680.0000130.0000130.0000130.0000680.0000680.0000130.0000111.8132760.0028710.0000161.6666710.0026270.0002120.0000110.0000110.0000691.6772180.0026190.0000150.0000110.0000110.0000110.0000110.0000110.0000110.0000680.0013450.0017540.0004480.0004660.0003980.0000130.0027550.0005940.0009930.0010210.0532590.0003220.0008360.0001260.0007720.0001340.0004032.2416955.1442493.2029190.0048930.0000182.0102160.0029892.2270491.7681811.7949270.0026541.9842101.5275620.0022516.6935701.8756150.0027520.0000180.0001680.0004390.0000870.0000720.0000700.0000720.0001280.0000140.0001260.0008280.0001890.0002440.0002440.0002380.0002410.0000690.0000280.0000140.0000150.0000170.0001480.0000140.0000150.0001530.0000140.0000130.0000140.0000140.0001450.0000180.0000180.0024710.0000140.0000110.0006661.7060631.9656530.0027300.0000571.6304821.5461120.0021940.0538120.0001450.0000110.0000181.6289381.0755752.3760100.0032390.0000161.4257381.6195800.0022003.0512541.4249830.0019860.0000150.0003970.0004640.0001770.0000130.0000120.0001920.0000130.0000130.0000120.0000124.7127760.0063630.0000200.0009110.0000120.0009430.0000120.0000120.0000120.0000130.0002610.0000140.0000110.0000120.0000130.0000121.6209980.0023640.0000170.0000140.0000160.0000341.2258040.0057270.0000850.0000750.0000710.0000730.0000190.0000140.6960440.0010550.0000780.0000150.0000140.0017220.0000180.0000710.0000140.0000740.0000724.8349317.2633780.0093420.0001320.0000700.0001270.0000710.0001280.0000740.0001280.0000700.0001260.0001580.0002470.0000730.0001880.0001830.0000740.0001260.0006612.2080450.0029290.0006350.0006405.3768470.0065610.0000190.0000110.0000110.0000120.0002710.0000120.0028300.0002570.0000120.0000110.0005120.0002040.0011770.0000130.0006856.5329394.3752580.0052290.0002330.0000140.0000730.0000790.0000690.0000120.0000120.0001260.0000790.0000120.0000110.0031890.0023031.2158920.0019830.0002410.0002430.0003290.0004470.0002430.0001850.0002420.0005581.4297050.0019680.0039470.0000170.0004530.0001330.0011480.0000700.0030641.8828750.0037520.0000170.0000132.0280971.7582210.0020140.0000140.0006480.0003120.0005260.0002160.0001230.0000730.0001800.0010160.0001241.8728310.0032451.8364180.0021273.6825560.0041880.0000750.0000700.0001891.9217410.0023310.0000721.6750840.0018690.0000142.2823630.0025380.0000720.0000120.0000120.0000120.0000120.0000120.0000122.4246894.8451410.0054200.0000170.0000692.3622592.3830330.0028880.0000790.0023980.0146650.0001530.0066760.0069210.1174310.0001970.0004520.0005200.0001370.0000690.0000770.0000120.0000760.0001330.0000160.0001840.0000770.0001260.0000700.0000120.0001310.0001990.0000140.0003830.0038750.0013031.3106730.0018420.0000180.0000120.0000140.0000120.0000130.0001400.0000120.0000700.0003740.0000120.0000120.0005510.0034470.0102140.0002480.0001270.0000690.0000680.0000700.0001810.0001860.0001860.0000110.0000110.0000110.0321020.0000450.0000100.0000100.0000100.0000110.0000110.0000110.0000100.0002530.0000110.0000690.0000100.0000700.0004610.0002160.0000102.0676910.0020900.0000140.0000110.0000110.0000100.0000110.0002490.0002070.0000110.0002930.0000150.0002880.0026640.0000180.0000290.0000190.2192390.0002360.0056810.0003590.0002040.0000110.0002060.0009050.0003950.0008980.0000130.0003530.0001980.0000130.0008320.0007880.0002950.0007920.0001820.0001840.0001250.0001821.4563370.0014790.0000710.0000150.0000150.0000150.0000720.0005850.0003430.0002440.0002440.0002460.0002480.0001680.0001810.0000140.0015000.0004450.0000170.0000140.8510471.3255240.0135530.0000890.0322231.0313570.0016380.0004130.0004501.9756560.0019840.0000710.0004260.0001240.0002300.0016440.0008160.0013710.0002051.2811950.0012061.0882150.0062640.0000160.0026410.0000750.0000110.0072591.5288640.0014830.0000720.0000120.0000121.6482871.4669060.0014250.0000131.4243810.0013751.8201531.7745730.0016360.0000140.0000130.0000120.0000700.0000130.0000120.0000120.0000120.0000120.0000122.2013860.0020050.0000140.0000120.0000120.0000130.0000130.0000120.0000120.0000120.0000720.0000810.0001920.0000110.0000970.0000690.0002100.0001770.0001460.0000110.0000680.0000110.0001300.0000120.0001330.0000720.0000122.0714250.0019650.0000780.0001560.0000810.0000711.0362250.0009500.0001860.0000190.0000280.0002080.0007300.0009820.0016780.0010310.0007403.3280150.8880080.0007820.0000700.0019601.8952160.0040140.0002470.0019280.0012083.1554372.1493030.0018650.0001810.0001890.0000121.5760680.0015910.0001970.0000130.0000130.0000130.0000130.0000152.6731451.8685560.0018220.0525450.0679430.0001880.0000120.0000720.0000710.0001320.0000730.0001240.0000130.0001250.0000710.0001240.0001250.0001240.0000720.0000130.0001240.0000720.0000110.0000141.7117551.4571160.0012840.0000690.0000110.0000101.6219611.5735561.6723504.2299902.4169242.5193860.0022700.0001872.4043594.9403642.5262430.0023540.0000140.0000110.0000120.0000410.0002210.0000120.0000110.0000110.0000110.0002520.0000120.0000150.0000110.0000150.0000110.0000120.0000120.0000120.0000110.0000110.0002460.0000120.0000120.0000140.0000120.0002850.0002350.0000120.0005040.0003920.0004695.3241101.9012101.6786904.9491511.9641660.0015880.0001550.0001560.0001580.0000131.2760790.0012540.0339590.0002701.2218910.0010950.0001290.0001270.0000690.0000110.0001300.0001280.0000700.0000700.0001280.0000120.0015410.0011530.0003413.3961586.1178231.7454310.0020240.0003890.0006990.0006190.0005990.0003680.0005250.0001860.0000730.0001610.0000130.0000130.0001280.0002450.0000130.0000130.0000120.0000130.0000110.0000100.0000110.0000100.0000100.0000100.0000140.0000111.1935352.3973020.0020140.0000120.0000100.0000100.0000700.0000740.0000210.0000110.0000110.0000110.0002640.0000900.0000110.0000100.0000110.0000720.0000120.0001810.0000140.0001760.0000130.0006510.0001650.0000130.0003580.0110590.0001340.0026852.2150420.0018950.0001830.0000130.0000680.0000130.0000120.0001810.0000130.0000680.0000120.0000120.0003480.0001230.0000120.0000120.0001260.0001800.0001780.0000680.0000730.0001800.0006920.0006720.0006750.0003040.0001840.0001210.0000290.0003280.0002380.0000680.0000910.0002930.0050183.6908153.6778245.4349185.2744377.0529585.3894940.0042180.0002840.0022250.7236020.0198951.2371430.0019650.0000710.0001270.0000110.0001850.0001860.0000690.0000690.0000110.0001850.0000700.0000680.0134300.0003090.0003860.0000120.0001810.0000700.0007430.0007311.2571730.0015310.0006460.0012500.0016020.0022330.0002350.0263700.0002270.0004760.0003110.0064750.0027410.0001320.0001260.0001270.0001270.0005260.0000760.0001260.0001920.0000730.0000120.0000680.0000130.0001790.0000721.5049110.0010720.0002850.0000150.0143330.0000410.0000160.0001770.0000160.0000160.0001790.0000340.0000150.0001880.0000170.0040940.0000152.0879982.0955930.0014610.0000130.0000120.0000120.0000122.0899160.0014512.0998440.0014860.0000130.0000112.1579140.0014921.7934650.0012410.0000130.0000120.0000130.0000120.0004020.0005110.0000720.0001340.0001950.0002180.0001900.0000710.0000690.0001870.0000710.0001290.0001290.0000120.0005980.0006570.0006480.0008650.0013570.0009630.0000130.0009000.0000120.0000112.0492630.0013870.0000130.0000120.0000120.0000120.0000120.0003460.0000110.0000780.0000110.0000100.0000110.0000110.0000110.0000810.0000110.0013450.0001361.5739650.0010560.1758870.0001270.0000110.0023020.6166310.0004180.0000110.0000110.0015910.0014510.0010460.0007951.9559570.0016550.0007430.0006240.0003890.0002412.1130542.1707922.2946150.0015112.2702171.2272420.0008120.0000140.0000130.0000122.3041580.0015152.1535120.0014102.1599010.0014110.1448750.0001040.7232300.2621580.0001800.0000710.0000130.0000130.0001310.0000700.0000750.0000700.0001300.0000130.0000770.0000730.0000700.0001950.0000130.0001430.0000120.0001290.0000670.0000681.8908514.5497672.2638470.0015080.0000681.6279382.3400931.6934504.4104272.3658782.2532794.4882010.0028534.5695890.0029571.4365543.9622850.0025100.0000120.0000100.0000100.0004390.0000110.0000100.0000100.0000100.0000740.0000110.0000100.0000100.0000740.0000110.0000720.0003360.0000110.0000100.0000100.0000110.0000100.0005310.0000110.0000100.0002300.0000110.0000100.0003740.0000110.0000710.0003210.0000110.0000100.0000100.0000100.0000100.0000100.0000100.0003530.0000110.0000100.0000100.0000100.0000100.0000100.0001770.0002500.0002530.0003710.0002790.0004360.0050881.1288050.0269420.2740450.0002350.0002991.1864796.7803624.0323842.0068690.0021780.0014430.0006190.0003640.0002710.0002890.0002483.3566661.7014580.0024060.0002680.0475860.0004750.0002000.0002810.0001960.0015150.0000130.0001390.0000930.0000120.0000120.0000120.0000120.0002000.0000130.0000120.0001970.0000120.0001680.0000120.0000680.0000120.0002770.0001480.0000120.2942621.2381280.0014090.0032922.0231540.3043500.0020230.0000140.0010670.0000690.0000120.0000120.0000120.0000690.0000790.0000740.0000690.0000120.0000120.0000120.0000140.0000750.0000120.0000120.0000130.0000120.0000120.0000120.0000170.0000120.0000130.0000120.0000693.8473473.8826771.9215645.9267321.9993672.3361571.8253770.0011331.2239651.1110830.6170420.0004290.0002420.0006620.0003030.0000141.0282300.0006660.6769631.4387560.0009630.0000150.0000120.6645911.9373731.8584113.7389370.0030181.9367271.4376290.0010685.8325642.2981743.9147924.1956871.3326350.0009260.0006371.9767480.0017011.2037282.3616931.6729421.6027911.5080144.7107191.4315972.9405211.4495343.2497291.4142271.4451240.0008290.0000120.0002340.0002330.0002360.0002470.0002370.0002380.0002360.0002370.0002340.0002332.4105092.4233280.0016144.4616264.8173611.6332630.0010420.0001850.0000120.0000110.0001890.0000120.0001260.0000710.0001880.0000690.0000110.0001270.0000110.0002470.0000120.0002350.0000110.0003810.0000110.0002360.0001530.0000110.0000110.0000112.7042970.0020522.4711710.0016250.0004350.0006460.0004020.0008590.0000250.0000550.0002810.0000140.0000230.0000142.2680252.0858042.2939340.0012710.0000192.4149542.3440712.4693002.3336592.4612490.0013560.0000132.5059960.0015890.0000210.0002240.0000170.0000160.0004422.0895920.0015860.0001950.2874820.0005450.0005470.6954810.0006280.0005640.0004510.0007200.0001290.0041320.0001310.0009460.0008140.0010710.0004352.1649480.0017470.0000730.0000900.0064920.0000750.0004630.0003930.0003440.0013900.0199550.2347471.2350550.0006700.0000120.0000110.0000111.3472260.0007290.0000120.0000110.0000110.0000681.2349294.5105610.0024030.0000130.0000110.0000115.0222890.0035120.0020860.0000180.0000180.0001790.0000170.0001130.0000110.0000700.0000120.0000690.0000920.0000110.0000110.0000690.0000750.0000120.0000110.0000120.0000220.0000120.0000120.0000123.8760043.7492237.4709542.9083181.2166020.0514100.0008361.3746330.0016880.0003000.0009300.0005160.0000120.0000120.0000120.0000740.0000120.0000740.0000720.0000710.0000110.0057970.0000140.0003870.0005220.0000110.0000110.0000100.0004481.2310200.0008860.0000110.0000110.0007040.0000110.0002530.0000210.0000110.0000120.0000120.0000120.0000110.0000110.0000110.8771680.0009150.0000120.0000110.0000121.7196790.0013100.0000130.0000200.0000140.0000140.0000680.0151340.0000271.4996850.0007720.0000120.0002230.0000120.0118810.2402420.0001901.6176090.0010060.0002462.8500930.0016070.0000170.0003130.0000140.0001700.0000130.0000710.0000120.0000120.0001880.0000710.0000700.0001940.0000150.0000740.0000690.0001320.0000750.0001920.0000730.0000120.0001291.7398331.4895591.0923840.0005560.0000130.0000140.0000131.5170072.2555840.0011320.0000131.6700510.0008410.0000131.6700511.8816750.0009440.0000130.0000130.0000131.4467191.7232070.0008630.0000130.0000150.0000750.0000130.0000130.0022250.0000150.0000150.0000140.0000140.0000170.0000130.0004810.0061210.0000180.0000140.0068690.0000170.0000160.0000140.0035190.0000170.0000150.0000140.0001890.0000140.0002620.0002460.0000140.0000160.0000140.0000740.0001890.0001870.0000141.7110300.0014820.0000140.0022970.0013180.0013751.6046260.0027590.0002560.0001880.0001340.0002450.0001290.0001260.0001890.0000130.0001290.0001850.0001860.0004521.6347530.0009560.0003160.0003100.0002180.0001700.0002380.0002790.0010911.2637521.1351280.0006751.4002450.0006780.0000900.0023511.1631780.0005690.0033260.4047220.0070720.0000190.0005950.0000140.0000140.0086180.0428770.4066470.0002120.0002420.0002440.0002470.0002540.0002770.0002700.0250910.0002710.0002600.0024860.0002930.0000750.0000720.0000120.0000120.0000720.0000150.0000722.1853620.0010370.0003720.0006410.0000110.0007451.5213144.3878490.4984511.9505120.0009250.0000130.0000140.0000120.0000130.0003460.0000140.0002900.0002620.0000130.0005870.0004310.0000140.0000130.0000130.0002900.0000130.0000130.0000130.0000130.0000121.5361123.8096890.0023300.0003550.0004540.0003593.5391551.5995250.0008050.0001291.8771130.0009330.0000740.0001293.3664990.0016150.0000700.0000111.8487860.0009230.0000203.1522951.6234571.7045950.0007900.0016631.7371940.0008041.7865230.0009480.0000690.0000690.0000110.0000690.0000710.0004120.0005760.0014500.0003640.0015693.1570373.0271963.0139770.0013772.4397902.1754710.0012270.0001850.0002430.0001290.0001850.0000700.0001270.0001830.0001270.0002420.0001870.0002412.2105402.2069400.0012350.0001860.0005840.0004480.0005580.0154680.0030630.0000691.8435090.0016610.0000110.0000690.0000110.0001966.3495913.3733654.3774533.4372060.0022090.2180500.0001160.0001820.0001720.0001800.0002140.0001290.0003520.0001840.0002730.0008310.0002710.0001610.0001620.0004780.0001560.0004430.0001260.0002820.0003630.0001840.0003640.0004090.0003930.1193402.5432810.0014011.1742340.0006480.1774640.0197680.0053503.0203481.2125300.0005731.6120840.0089710.0054480.7392020.0003691.0261510.1782280.7521630.0003750.0083550.0073291.8339321.3720042.4284300.4536161.0975680.0005261.6375541.1894920.0041960.2412921.5834630.0017581.1842581.7383990.2187470.0097590.0085720.0669000.3259491.7828842.1129440.2144700.0051390.0083980.0001550.0039560.5185040.0098610.0047631.4975220.4356520.0079680.0103530.6428631.6799950.0059541.8412370.9934200.0005780.0002731.9006440.0014452.5394270.0012920.0111171.0312181.0518801.8963742.2565280.3672410.1766492.0068360.0010160.4180630.0002890.4441741.0540910.9519150.1227010.7659880.2544200.3668931.1527370.6440450.0003000.6878950.3395320.4839780.0552330.3841280.9188160.0194690.0000651.1508640.0005180.0078480.8525261.5731691.2281300.0006041.3183570.0088420.9714991.1124220.0089950.1656490.0002880.2985530.0001950.1184470.2635541.9144471.2571420.2948500.0001550.0490940.0119140.0000190.0000150.0065800.0098291.1375130.0080540.5377790.0094580.0127870.0241960.7854502.2654882.6379050.0017270.0348582.8054360.0084170.5652740.0148311.1734650.0069850.0056480.0068820.0073660.0075630.0087170.1996420.0002131.0828160.0005730.0003592.0052430.0010390.0001620.4646610.1066710.3141890.2109170.0001861.9288010.0009100.9130121.1755860.0005650.0006960.0026071.6335900.0007160.0115370.5519611.1590930.0009760.0028152.6017561.2198671.2985450.7390841.1973352.2386190.0018141.5379831.6671651.9595370.7186352.2546640.0009410.9413973.3676920.0013920.4370501.6904872.8212410.0012300.0084611.0144820.4101590.3157350.0068140.4971780.0003280.1030852.6008390.5650000.0004140.3909140.2018360.2389240.0003110.4758111.1466641.1897200.0079290.0000460.2335910.9239090.0005020.0065610.3980850.9588011.2455130.0124552.3116970.0118930.3135180.1181520.9900580.0082030.0001650.5286620.0004871.8961600.7548070.0003870.9806081.2958960.0009790.0004490.0008040.8328270.4956420.0005790.0000493.0401701.6429011.9699281.0877600.5460190.1700712.5297290.0095380.6050350.0074870.0098670.8750632.0543500.0013600.4964201.0962020.0815610.0621020.0076900.0000560.0016770.3441330.0077501.3317571.5056300.4202951.5764742.9788370.0012080.0097311.1469850.6627310.4058382.5164260.3029842.1079460.0092252.5017450.0028380.8304221.0319740.0005170.0112421.0476160.0006540.0011530.4108270.6227950.1505760.1147941.6298121.0733150.0005250.0050110.0000300.5544340.0002991.0188380.0004600.1919081.0730430.0004710.9415280.0753060.4243660.4904280.8301260.0011190.2683410.0001511.3775140.8833690.1339331.0219070.3699820.0003460.0239250.0001092.8079421.7381710.9256870.3825020.1456280.0000780.0010530.4197020.0002281.0284731.4660882.0589991.0118900.3588130.7540111.3950051.7277250.3967780.0002620.8918950.0003620.3137900.0001710.1887960.0018540.0000500.1817351.4555720.0133610.0004841.4953820.0006781.4919571.1500121.0170420.9275080.0115150.0001012.1110330.4216822.3696840.4104300.7439611.9574150.0009180.0064601.1287191.0836541.2546650.0005330.0001040.0430500.0697190.1026890.0933650.4514590.6471401.9450980.0009120.2682530.5602330.3600752.1005160.0009950.1330540.0070780.0038010.0088800.0070321.6006710.0007290.0082281.2450141.0358851.1551720.0044000.0117380.0000332.3446320.0041761.6440710.0040620.0035460.4689791.2491250.0073630.0035520.0001490.0033591.9970480.0072910.0037770.0000850.9573190.9665140.4437990.0002020.0089400.0014070.0002610.4402890.8102990.5691030.0125500.0001102.5701090.4675290.9003241.1569190.0006483.3942390.8129550.9933270.7665320.0038970.0135950.0123370.0002251.1535090.0036100.0046850.0052210.0054600.0000400.0048652.3670760.0018580.1980000.4839000.0784510.3474900.7189850.4255750.0001910.5625762.4606081.2530672.7850420.1942490.0088611.0859640.0081120.0000310.0060640.4911141.1762011.5955330.1818730.0031940.0076940.8694501.5510150.0068411.2380570.0004700.0000191.0139281.6306470.4673520.3715340.0050720.0000430.0000180.0044931.8385330.3632260.1356540.8007930.3051811.4197090.4130710.0144900.0001050.0000750.4114610.2683750.0050411.3771560.6592730.1923992.5301710.7949850.0026862.2916970.0010181.4828260.0018670.0000170.0081660.0060240.0003680.4802150.0022670.0967900.0008010.0045790.0000731.0361430.5758000.0007510.0000150.0015080.6626343.6401920.0098020.0078591.2456100.8425950.0758320.5669151.1493480.1019420.9899690.0050990.0044921.1778972.2521170.0047933.6935370.0063540.0043100.0050920.0064580.3875191.1329450.3457270.1677600.0041260.0062250.0003560.0293041.1364990.3793841.1266501.0386131.7107860.0062000.0003390.5790860.0076450.0080490.0104530.0011741.3764451.0001681.0341010.0090040.0081021.3991520.8316540.1723070.0281480.0037411.2095590.2144150.0128530.5837570.0155221.1737831.0127662.0213200.2615820.0127390.3188530.3978312.8161040.8064952.6311430.7710300.0068601.9284380.5288021.0254881.1916170.8756490.0003592.1385521.1352070.0062990.0066020.0000490.9773990.1867300.0002680.0088891.0850620.8774851.2140431.1107610.5323060.1281221.1230840.3813100.4308721.3138200.1203950.0054691.4311791.0530850.0070540.5352241.0327920.0078940.0078913.5132640.0012670.0083340.0088681.4398290.4515750.4855410.9551870.0084140.0000690.0053731.0772300.0067630.0097230.0069320.0086401.5900260.9900691.3191452.7642410.0063920.5439500.0002050.2071450.7959660.0066991.0203800.0073180.2814380.2092711.2009560.9517182.2471040.0023821.0373630.0133820.0050340.0072541.0832000.0061950.2113550.0084350.0053621.9663911.9260453.2480351.6163362.6464081.4344102.6014470.0032670.9547730.3243650.0004680.0166071.0692770.1010930.0001310.0620300.0003130.5575920.0776760.4254620.0001740.0000250.3570370.3276880.0097140.2313451.2283990.0059170.0001030.0109834.0733951.6944950.0168111.0533620.0062270.0052550.0055210.0000220.0000200.0013630.0026031.9892450.6059180.853784

*******************************************
EVALUATING PIPELINE 
Pipeline directory: /home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_6e514002_2020-02-16_14-09-10gzjh09ia/
With following parameter combination: {'batch_size_seq_length': 1, 'lr': 3e-05, 'lr_type': 'linear'}
EVALUATION OF CHECKPOINT /home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_6e514002_2020-02-16_14-09-10gzjh09ia/outputs/checkpoint-3
-------------------------------------------------------------
|           |   agree   | disagree  |  discuss  | unrelated |
-------------------------------------------------------------
|   agree   |    734    |    78     |    156    |    26     |
-------------------------------------------------------------
| disagree  |    95     |    301    |    74     |    22     |
-------------------------------------------------------------
|  discuss  |    188    |    66     |   1511    |    105    |
-------------------------------------------------------------
| unrelated |    20     |    23     |    38     |   8461    |
-------------------------------------------------------------
Score: 8689.0 out of 9226.0	(94.17949273791459%)
Accuracy: 0.9251134644478064
F1 overall: 0.7911031360394174
F1 per class: [0.7227966518956179, 0.6270833333333333, 0.8281721019457385, 0.9863604569829797]
*******************************************


real	64m15.446s
user	215m7.149s
sys	22m25.541s
ubuntu@run-gpu-mg:~/fnd_implementation$ 
ubuntu@run-gpu-mg:~/fnd_implementation$ 
ubuntu@run-gpu-mg:~/fnd_implementation$ exit
exit

Script done on 2020-02-17 11:13:16+0000
