Script started on 2020-02-22 13:06:10+0000
ubuntu@run-gpu-mg:~/fnd_implementation$ time python3 model_grid_search.py --modell=xlnet --model_type=xlnet-base-cased --dataset_name=fnc_arcMscript output_xlnet_grid_search_lr_4_fnc_arc.txt[KM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Ctime python3 model_grid_search.py --model=xlnet --model_type=xlnet-base-cased --dataset_name=fnc_arcM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C.py --model=[1PM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C.py --model=x[1PM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C.py --model=xl[1PM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C.py --model=xln[1PM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C.py --model=xlne[1PM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C.py --model=xlnet[1PM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C.py --model=xlnet [1PM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C.py --model=xlnet -[C[1PM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C.py --model=xlnet --[1PM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C.py --model=xlnet --m[1PM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C.py --model=xlnet --mo[1PM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C.py --model=xlnet --mod[1PM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C.py --model=xlnet --mode[1PM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C.py --model=xlnet --model[1PM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C.py --model=xlnet --model_[1PM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C.py --model=xlnet --model_t[1PM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C.py --model=xlnet --model_ty[1PM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Ce.py --model=xlnet --model_t[1@yM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Cv.py --model=xlnet --model_[1@tM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Ca.py --model=xlnet --model[1@_M[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Cl.py --model=xlnet --mode[1@lM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C_.py --model=xlnet --mod[1@eM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Cs.py --model=xlnet --mo[1@dM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Cea.py --model=xlnet --[2@moM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Cr.py --model=xlnet -[1@-M[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C.py --model=xlnet --[1PM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C.py --model=xlnet --m[1PM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Cp.py --model=xlnet --[1@mM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Ca.py --model=xlnet -[1@-M[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Cr.py --model=xlnet [C[1@-M[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Ca.py --model=xlnet[1@ M[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Ct.py --model=xlne[1@tM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Ce.py --model=xln[1@eM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C

/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/home/ubuntu/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/ubuntu/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/ubuntu/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/ubuntu/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/ubuntu/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/ubuntu/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
There are 2 GPU(s) available.
The following GPU is used:  Tesla V100-PCIE-16GB
INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/xlnet-base-cased-config.json from cache at /home/ubuntu/.cache/torch/transformers/c9cc6e53904f7f3679a31ec4af244f4419e25ebc8e71ebf8c558a31cbcf07fc8.8df552e150a401a37ae808caf2a2c86fb6fedaa1f6963d1f21fbf3d0085c9e74
INFO:transformers.configuration_utils:Model config {
  "architectures": [
    "XLNetLMHeadModel"
  ],
  "attn_type": "bi",
  "bi_data": false,
  "clamp_len": -1,
  "d_head": 64,
  "d_inner": 3072,
  "d_model": 768,
  "dropout": 0.1,
  "end_n_top": 5,
  "ff_activation": "gelu",
  "finetuning_task": "multi",
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "mem_len": null,
  "n_head": 12,
  "n_layer": 12,
  "num_labels": 4,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pruned_heads": {},
  "reuse_len": null,
  "same_length": false,
  "start_n_top": 5,
  "summary_activation": "tanh",
  "summary_last_dropout": 0.1,
  "summary_type": "last",
  "summary_use_proj": true,
  "torchscript": false,
  "untie_r": true,
  "use_bfloat16": false,
  "vocab_size": 32000
}

INFO:transformers.tokenization_utils:loading file https://s3.amazonaws.com/models.huggingface.co/bert/xlnet-base-cased-spiece.model from cache at /home/ubuntu/.cache/torch/transformers/dad589d582573df0293448af5109cb6981ca77239ed314e15ca63b7b8a318ddd.8b10bd978b5d01c21303cc761fc9ecd464419b3bf921864a355ba807cfbfafa8
INFO:transformers.configuration_utils:loading configuration file /home/ubuntu/fnd_implementation/xlnet/model_pretrained/config.json
INFO:transformers.configuration_utils:Model config {
  "attn_type": "bi",
  "bi_data": false,
  "clamp_len": -1,
  "d_head": 64,
  "d_inner": 3072,
  "d_model": 768,
  "dropout": 0.1,
  "end_n_top": 5,
  "ff_activation": "gelu",
  "finetuning_task": null,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "mem_len": null,
  "n_head": 12,
  "n_layer": 12,
  "num_labels": 4,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pruned_heads": {},
  "reuse_len": null,
  "same_length": false,
  "start_n_top": 5,
  "summary_activation": "tanh",
  "summary_last_dropout": 0.1,
  "summary_type": "last",
  "summary_use_proj": true,
  "torchscript": false,
  "untie_r": true,
  "use_bfloat16": false,
  "vocab_size": 32000
}

INFO:transformers.modeling_utils:loading weights file /home/ubuntu/fnd_implementation/xlnet/model_pretrained/pytorch_model.bin
INFO:__main__:Loading initialized pretrained model from /home/ubuntu/fnd_implementation/xlnet/model_pretrained
  ******************************************* 
           Freezing Embedding Layers          
  *******************************************
 
name:  transformer.mask_emb
param.requires_grad:  False
=====
name:  transformer.word_embedding.weight
param.requires_grad:  False
=====
name:  transformer.layer.0.rel_attn.q
param.requires_grad:  True
=====
name:  transformer.layer.0.rel_attn.k
param.requires_grad:  True
=====
name:  transformer.layer.0.rel_attn.v
param.requires_grad:  True
=====
name:  transformer.layer.0.rel_attn.o
param.requires_grad:  True
=====
name:  transformer.layer.0.rel_attn.r
param.requires_grad:  True
=====
name:  transformer.layer.0.rel_attn.r_r_bias
param.requires_grad:  True
=====
name:  transformer.layer.0.rel_attn.r_s_bias
param.requires_grad:  True
=====
name:  transformer.layer.0.rel_attn.r_w_bias
param.requires_grad:  True
=====
name:  transformer.layer.0.rel_attn.seg_embed
param.requires_grad:  True
=====
name:  transformer.layer.0.rel_attn.layer_norm.weight
param.requires_grad:  True
=====
name:  transformer.layer.0.rel_attn.layer_norm.bias
param.requires_grad:  True
=====
name:  transformer.layer.0.ff.layer_norm.weight
param.requires_grad:  True
=====
name:  transformer.layer.0.ff.layer_norm.bias
param.requires_grad:  True
=====
name:  transformer.layer.0.ff.layer_1.weight
param.requires_grad:  True
=====
name:  transformer.layer.0.ff.layer_1.bias
param.requires_grad:  True
=====
name:  transformer.layer.0.ff.layer_2.weight
param.requires_grad:  True
=====
name:  transformer.layer.0.ff.layer_2.bias
param.requires_grad:  True
=====
name:  transformer.layer.1.rel_attn.q
param.requires_grad:  True
=====
name:  transformer.layer.1.rel_attn.k
param.requires_grad:  True
=====
name:  transformer.layer.1.rel_attn.v
param.requires_grad:  True
=====
name:  transformer.layer.1.rel_attn.o
param.requires_grad:  True
=====
name:  transformer.layer.1.rel_attn.r
param.requires_grad:  True
=====
name:  transformer.layer.1.rel_attn.r_r_bias
param.requires_grad:  True
=====
name:  transformer.layer.1.rel_attn.r_s_bias
param.requires_grad:  True
=====
name:  transformer.layer.1.rel_attn.r_w_bias
param.requires_grad:  True
=====
name:  transformer.layer.1.rel_attn.seg_embed
param.requires_grad:  True
=====
name:  transformer.layer.1.rel_attn.layer_norm.weight
param.requires_grad:  True
=====
name:  transformer.layer.1.rel_attn.layer_norm.bias
param.requires_grad:  True
=====
name:  transformer.layer.1.ff.layer_norm.weight
param.requires_grad:  True
=====
name:  transformer.layer.1.ff.layer_norm.bias
param.requires_grad:  True
=====
name:  transformer.layer.1.ff.layer_1.weight
param.requires_grad:  True
=====
name:  transformer.layer.1.ff.layer_1.bias
param.requires_grad:  True
=====
name:  transformer.layer.1.ff.layer_2.weight
param.requires_grad:  True
=====
name:  transformer.layer.1.ff.layer_2.bias
param.requires_grad:  True
=====
name:  transformer.layer.2.rel_attn.q
param.requires_grad:  True
=====
name:  transformer.layer.2.rel_attn.k
param.requires_grad:  True
=====
name:  transformer.layer.2.rel_attn.v
param.requires_grad:  True
=====
name:  transformer.layer.2.rel_attn.o
param.requires_grad:  True
=====
name:  transformer.layer.2.rel_attn.r
param.requires_grad:  True
=====
name:  transformer.layer.2.rel_attn.r_r_bias
param.requires_grad:  True
=====
name:  transformer.layer.2.rel_attn.r_s_bias
param.requires_grad:  True
=====
name:  transformer.layer.2.rel_attn.r_w_bias
param.requires_grad:  True
=====
name:  transformer.layer.2.rel_attn.seg_embed
param.requires_grad:  True
=====
name:  transformer.layer.2.rel_attn.layer_norm.weight
param.requires_grad:  True
=====
name:  transformer.layer.2.rel_attn.layer_norm.bias
param.requires_grad:  True
=====
name:  transformer.layer.2.ff.layer_norm.weight
param.requires_grad:  True
=====
name:  transformer.layer.2.ff.layer_norm.bias
param.requires_grad:  True
=====
name:  transformer.layer.2.ff.layer_1.weight
param.requires_grad:  True
=====
name:  transformer.layer.2.ff.layer_1.bias
param.requires_grad:  True
=====
name:  transformer.layer.2.ff.layer_2.weight
param.requires_grad:  True
=====
name:  transformer.layer.2.ff.layer_2.bias
param.requires_grad:  True
=====
name:  transformer.layer.3.rel_attn.q
param.requires_grad:  True
=====
name:  transformer.layer.3.rel_attn.k
param.requires_grad:  True
=====
name:  transformer.layer.3.rel_attn.v
param.requires_grad:  True
=====
name:  transformer.layer.3.rel_attn.o
param.requires_grad:  True
=====
name:  transformer.layer.3.rel_attn.r
param.requires_grad:  True
=====
name:  transformer.layer.3.rel_attn.r_r_bias
param.requires_grad:  True
=====
name:  transformer.layer.3.rel_attn.r_s_bias
param.requires_grad:  True
=====
name:  transformer.layer.3.rel_attn.r_w_bias
param.requires_grad:  True
=====
name:  transformer.layer.3.rel_attn.seg_embed
param.requires_grad:  True
=====
name:  transformer.layer.3.rel_attn.layer_norm.weight
param.requires_grad:  True
=====
name:  transformer.layer.3.rel_attn.layer_norm.bias
param.requires_grad:  True
=====
name:  transformer.layer.3.ff.layer_norm.weight
param.requires_grad:  True
=====
name:  transformer.layer.3.ff.layer_norm.bias
param.requires_grad:  True
=====
name:  transformer.layer.3.ff.layer_1.weight
param.requires_grad:  True
=====
name:  transformer.layer.3.ff.layer_1.bias
param.requires_grad:  True
=====
name:  transformer.layer.3.ff.layer_2.weight
param.requires_grad:  True
=====
name:  transformer.layer.3.ff.layer_2.bias
param.requires_grad:  True
=====
name:  transformer.layer.4.rel_attn.q
param.requires_grad:  True
=====
name:  transformer.layer.4.rel_attn.k
param.requires_grad:  True
=====
name:  transformer.layer.4.rel_attn.v
param.requires_grad:  True
=====
name:  transformer.layer.4.rel_attn.o
param.requires_grad:  True
=====
name:  transformer.layer.4.rel_attn.r
param.requires_grad:  True
=====
name:  transformer.layer.4.rel_attn.r_r_bias
param.requires_grad:  True
=====
name:  transformer.layer.4.rel_attn.r_s_bias
param.requires_grad:  True
=====
name:  transformer.layer.4.rel_attn.r_w_bias
param.requires_grad:  True
=====
name:  transformer.layer.4.rel_attn.seg_embed
param.requires_grad:  True
=====
name:  transformer.layer.4.rel_attn.layer_norm.weight
param.requires_grad:  True
=====
name:  transformer.layer.4.rel_attn.layer_norm.bias
param.requires_grad:  True
=====
name:  transformer.layer.4.ff.layer_norm.weight
param.requires_grad:  True
=====
name:  transformer.layer.4.ff.layer_norm.bias
param.requires_grad:  True
=====
name:  transformer.layer.4.ff.layer_1.weight
param.requires_grad:  True
=====
name:  transformer.layer.4.ff.layer_1.bias
param.requires_grad:  True
=====
name:  transformer.layer.4.ff.layer_2.weight
param.requires_grad:  True
=====
name:  transformer.layer.4.ff.layer_2.bias
param.requires_grad:  True
=====
name:  transformer.layer.5.rel_attn.q
param.requires_grad:  True
=====
name:  transformer.layer.5.rel_attn.k
param.requires_grad:  True
=====
name:  transformer.layer.5.rel_attn.v
param.requires_grad:  True
=====
name:  transformer.layer.5.rel_attn.o
param.requires_grad:  True
=====
name:  transformer.layer.5.rel_attn.r
param.requires_grad:  True
=====
name:  transformer.layer.5.rel_attn.r_r_bias
param.requires_grad:  True
=====
name:  transformer.layer.5.rel_attn.r_s_bias
param.requires_grad:  True
=====
name:  transformer.layer.5.rel_attn.r_w_bias
param.requires_grad:  True
=====
name:  transformer.layer.5.rel_attn.seg_embed
param.requires_grad:  True
=====
name:  transformer.layer.5.rel_attn.layer_norm.weight
param.requires_grad:  True
=====
name:  transformer.layer.5.rel_attn.layer_norm.bias
param.requires_grad:  True
=====
name:  transformer.layer.5.ff.layer_norm.weight
param.requires_grad:  True
=====
name:  transformer.layer.5.ff.layer_norm.bias
param.requires_grad:  True
=====
name:  transformer.layer.5.ff.layer_1.weight
param.requires_grad:  True
=====
name:  transformer.layer.5.ff.layer_1.bias
param.requires_grad:  True
=====
name:  transformer.layer.5.ff.layer_2.weight
param.requires_grad:  True
=====
name:  transformer.layer.5.ff.layer_2.bias
param.requires_grad:  True
=====
name:  transformer.layer.6.rel_attn.q
param.requires_grad:  True
=====
name:  transformer.layer.6.rel_attn.k
param.requires_grad:  True
=====
name:  transformer.layer.6.rel_attn.v
param.requires_grad:  True
=====
name:  transformer.layer.6.rel_attn.o
param.requires_grad:  True
=====
name:  transformer.layer.6.rel_attn.r
param.requires_grad:  True
=====
name:  transformer.layer.6.rel_attn.r_r_bias
param.requires_grad:  True
=====
name:  transformer.layer.6.rel_attn.r_s_bias
param.requires_grad:  True
=====
name:  transformer.layer.6.rel_attn.r_w_bias
param.requires_grad:  True
=====
name:  transformer.layer.6.rel_attn.seg_embed
param.requires_grad:  True
=====
name:  transformer.layer.6.rel_attn.layer_norm.weight
param.requires_grad:  True
=====
name:  transformer.layer.6.rel_attn.layer_norm.bias
param.requires_grad:  True
=====
name:  transformer.layer.6.ff.layer_norm.weight
param.requires_grad:  True
=====
name:  transformer.layer.6.ff.layer_norm.bias
param.requires_grad:  True
=====
name:  transformer.layer.6.ff.layer_1.weight
param.requires_grad:  True
=====
name:  transformer.layer.6.ff.layer_1.bias
param.requires_grad:  True
=====
name:  transformer.layer.6.ff.layer_2.weight
param.requires_grad:  True
=====
name:  transformer.layer.6.ff.layer_2.bias
param.requires_grad:  True
=====
name:  transformer.layer.7.rel_attn.q
param.requires_grad:  True
=====
name:  transformer.layer.7.rel_attn.k
param.requires_grad:  True
=====
name:  transformer.layer.7.rel_attn.v
param.requires_grad:  True
=====
name:  transformer.layer.7.rel_attn.o
param.requires_grad:  True
=====
name:  transformer.layer.7.rel_attn.r
param.requires_grad:  True
=====
name:  transformer.layer.7.rel_attn.r_r_bias
param.requires_grad:  True
=====
name:  transformer.layer.7.rel_attn.r_s_bias
param.requires_grad:  True
=====
name:  transformer.layer.7.rel_attn.r_w_bias
param.requires_grad:  True
=====
name:  transformer.layer.7.rel_attn.seg_embed
param.requires_grad:  True
=====
name:  transformer.layer.7.rel_attn.layer_norm.weight
param.requires_grad:  True
=====
name:  transformer.layer.7.rel_attn.layer_norm.bias
param.requires_grad:  True
=====
name:  transformer.layer.7.ff.layer_norm.weight
param.requires_grad:  True
=====
name:  transformer.layer.7.ff.layer_norm.bias
param.requires_grad:  True
=====
name:  transformer.layer.7.ff.layer_1.weight
param.requires_grad:  True
=====
name:  transformer.layer.7.ff.layer_1.bias
param.requires_grad:  True
=====
name:  transformer.layer.7.ff.layer_2.weight
param.requires_grad:  True
=====
name:  transformer.layer.7.ff.layer_2.bias
param.requires_grad:  True
=====
name:  transformer.layer.8.rel_attn.q
param.requires_grad:  True
=====
name:  transformer.layer.8.rel_attn.k
param.requires_grad:  True
=====
name:  transformer.layer.8.rel_attn.v
param.requires_grad:  True
=====
name:  transformer.layer.8.rel_attn.o
param.requires_grad:  True
=====
name:  transformer.layer.8.rel_attn.r
param.requires_grad:  True
=====
name:  transformer.layer.8.rel_attn.r_r_bias
param.requires_grad:  True
=====
name:  transformer.layer.8.rel_attn.r_s_bias
param.requires_grad:  True
=====
name:  transformer.layer.8.rel_attn.r_w_bias
param.requires_grad:  True
=====
name:  transformer.layer.8.rel_attn.seg_embed
param.requires_grad:  True
=====
name:  transformer.layer.8.rel_attn.layer_norm.weight
param.requires_grad:  True
=====
name:  transformer.layer.8.rel_attn.layer_norm.bias
param.requires_grad:  True
=====
name:  transformer.layer.8.ff.layer_norm.weight
param.requires_grad:  True
=====
name:  transformer.layer.8.ff.layer_norm.bias
param.requires_grad:  True
=====
name:  transformer.layer.8.ff.layer_1.weight
param.requires_grad:  True
=====
name:  transformer.layer.8.ff.layer_1.bias
param.requires_grad:  True
=====
name:  transformer.layer.8.ff.layer_2.weight
param.requires_grad:  True
=====
name:  transformer.layer.8.ff.layer_2.bias
param.requires_grad:  True
=====
name:  transformer.layer.9.rel_attn.q
param.requires_grad:  True
=====
name:  transformer.layer.9.rel_attn.k
param.requires_grad:  True
=====
name:  transformer.layer.9.rel_attn.v
param.requires_grad:  True
=====
name:  transformer.layer.9.rel_attn.o
param.requires_grad:  True
=====
name:  transformer.layer.9.rel_attn.r
param.requires_grad:  True
=====
name:  transformer.layer.9.rel_attn.r_r_bias
param.requires_grad:  True
=====
name:  transformer.layer.9.rel_attn.r_s_bias
param.requires_grad:  True
=====
name:  transformer.layer.9.rel_attn.r_w_bias
param.requires_grad:  True
=====
name:  transformer.layer.9.rel_attn.seg_embed
param.requires_grad:  True
=====
name:  transformer.layer.9.rel_attn.layer_norm.weight
param.requires_grad:  True
=====
name:  transformer.layer.9.rel_attn.layer_norm.bias
param.requires_grad:  True
=====
name:  transformer.layer.9.ff.layer_norm.weight
param.requires_grad:  True
=====
name:  transformer.layer.9.ff.layer_norm.bias
param.requires_grad:  True
=====
name:  transformer.layer.9.ff.layer_1.weight
param.requires_grad:  True
=====
name:  transformer.layer.9.ff.layer_1.bias
param.requires_grad:  True
=====
name:  transformer.layer.9.ff.layer_2.weight
param.requires_grad:  True
=====
name:  transformer.layer.9.ff.layer_2.bias
param.requires_grad:  True
=====
name:  transformer.layer.10.rel_attn.q
param.requires_grad:  True
=====
name:  transformer.layer.10.rel_attn.k
param.requires_grad:  True
=====
name:  transformer.layer.10.rel_attn.v
param.requires_grad:  True
=====
name:  transformer.layer.10.rel_attn.o
param.requires_grad:  True
=====
name:  transformer.layer.10.rel_attn.r
param.requires_grad:  True
=====
name:  transformer.layer.10.rel_attn.r_r_bias
param.requires_grad:  True
=====
name:  transformer.layer.10.rel_attn.r_s_bias
param.requires_grad:  True
=====
name:  transformer.layer.10.rel_attn.r_w_bias
param.requires_grad:  True
=====
name:  transformer.layer.10.rel_attn.seg_embed
param.requires_grad:  True
=====
name:  transformer.layer.10.rel_attn.layer_norm.weight
param.requires_grad:  True
=====
name:  transformer.layer.10.rel_attn.layer_norm.bias
param.requires_grad:  True
=====
name:  transformer.layer.10.ff.layer_norm.weight
param.requires_grad:  True
=====
name:  transformer.layer.10.ff.layer_norm.bias
param.requires_grad:  True
=====
name:  transformer.layer.10.ff.layer_1.weight
param.requires_grad:  True
=====
name:  transformer.layer.10.ff.layer_1.bias
param.requires_grad:  True
=====
name:  transformer.layer.10.ff.layer_2.weight
param.requires_grad:  True
=====
name:  transformer.layer.10.ff.layer_2.bias
param.requires_grad:  True
=====
name:  transformer.layer.11.rel_attn.q
param.requires_grad:  True
=====
name:  transformer.layer.11.rel_attn.k
param.requires_grad:  True
=====
name:  transformer.layer.11.rel_attn.v
param.requires_grad:  True
=====
name:  transformer.layer.11.rel_attn.o
param.requires_grad:  True
=====
name:  transformer.layer.11.rel_attn.r
param.requires_grad:  True
=====
name:  transformer.layer.11.rel_attn.r_r_bias
param.requires_grad:  True
=====
name:  transformer.layer.11.rel_attn.r_s_bias
param.requires_grad:  True
=====
name:  transformer.layer.11.rel_attn.r_w_bias
param.requires_grad:  True
=====
name:  transformer.layer.11.rel_attn.seg_embed
param.requires_grad:  True
=====
name:  transformer.layer.11.rel_attn.layer_norm.weight
param.requires_grad:  True
=====
name:  transformer.layer.11.rel_attn.layer_norm.bias
param.requires_grad:  True
=====
name:  transformer.layer.11.ff.layer_norm.weight
param.requires_grad:  True
=====
name:  transformer.layer.11.ff.layer_norm.bias
param.requires_grad:  True
=====
name:  transformer.layer.11.ff.layer_1.weight
param.requires_grad:  True
=====
name:  transformer.layer.11.ff.layer_1.bias
param.requires_grad:  True
=====
name:  transformer.layer.11.ff.layer_2.weight
param.requires_grad:  True
=====
name:  transformer.layer.11.ff.layer_2.bias
param.requires_grad:  True
=====
name:  sequence_summary.summary.weight
param.requires_grad:  True
=====
name:  sequence_summary.summary.bias
param.requires_grad:  True
=====
name:  logits_proj.weight
param.requires_grad:  True
=====
name:  logits_proj.bias
param.requires_grad:  True
=====

*******************************************
Evaluating the following pipelines 
['/home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_0b6f043a_2020-02-22_05-19-52dp1bti1v/', '/home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_fdc25af8_2020-02-21_21-58-59lddp9zml/', '/home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_08c35524_2020-02-22_03-51-04fe3xt7cu/', '/home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_10defd44_2020-02-22_09-42-54g18jnqvq/', '/home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_0e24bd14_2020-02-22_05-21-33av2k0c1z/', '/home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_fafe8b34_2020-02-21_21-46-551cd49x8c/', '/home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_f4eee8f6_2020-02-21_17-24-58rcg23wm1/', '/home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_00815366_2020-02-21_23-19-0260ddp99c/', '/home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_f84154f8_2020-02-21_17-25-03z_o5g3ci/', '/home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_06047886_2020-02-22_03-49-267r_7tlv1/', '/home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_138386e6_2020-02-22_11-13-14ri6mtlpc/', '/home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_0341f7ae_2020-02-21_23-27-42ea6x5_w3/']

*******************************************

*******************************************
EVALUATING PIPELINE 
{'batch_size_seq_length': 1, 'lr': 4e-05, 'lr_type': 'cosine'}
INFO:__main__:Creating features from dataset file at /home/ubuntu/fnd_implementation/data/processed
  0%|                                                 | 0/11898 [00:00<?, ?it/s]  0%|                                       | 1/11898 [00:01<3:24:37,  1.03s/it]  4%|â–ˆâ–Œ                                   | 501/11898 [00:02<2:17:22,  1.38it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                    | 5501/11898 [00:02<53:58,  1.98it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11898/11898 [00:02<00:00, 4551.74it/s]
  ******************************************* 
              Running Evaluation                
  *******************************************
 
  Length dataset evaluation: 11898
  Length dataloader evaluation: 2975
  Number of epochs: 3
  Batch size: 4
  ******************************************* 
 
['/home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_0b6f043a_2020-02-22_05-19-52dp1bti1v/outputs/checkpoint-3']
INFO:__main__:Evaluate the following checkpoints: ['/home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_0b6f043a_2020-02-22_05-19-52dp1bti1v/outputs/checkpoint-3']
INFO:transformers.configuration_utils:loading configuration file /home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_0b6f043a_2020-02-22_05-19-52dp1bti1v/outputs/checkpoint-3/config.json
INFO:transformers.configuration_utils:Model config {
  "attn_type": "bi",
  "bi_data": false,
  "clamp_len": -1,
  "d_head": 64,
  "d_inner": 3072,
  "d_model": 768,
  "dropout": 0.1,
  "end_n_top": 5,
  "ff_activation": "gelu",
  "finetuning_task": null,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "mem_len": null,
  "n_head": 12,
  "n_layer": 12,
  "num_labels": 4,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pruned_heads": {},
  "reuse_len": null,
  "same_length": false,
  "start_n_top": 5,
  "summary_activation": "tanh",
  "summary_last_dropout": 0.1,
  "summary_type": "last",
  "summary_use_proj": true,
  "torchscript": false,
  "untie_r": true,
  "use_bfloat16": false,
  "vocab_size": 32000
}

INFO:transformers.modeling_utils:loading weights file /home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_0b6f043a_2020-02-22_05-19-52dp1bti1v/outputs/checkpoint-3/pytorch_model.bin
eval_separate.py:214: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0
Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`
  for batch in tqdm_notebook(eval_dataloader, desc="Evaluating"):
HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=2975.0, style=ProgressStyle(description_width='initial')), HTML(value='')))
1.5601861.5610030.7813690.2627130.9015360.1808080.0309600.0044920.0006260.0001320.0005240.0008230.0036100.0004400.0002050.0002210.0002080.0001571.4009070.0738840.0038690.0003660.0001850.0001690.0001760.0008080.0002000.0039210.0002770.0001460.0001500.0027422.0246350.0614330.0018790.0001240.0000762.0263840.0533982.0156250.0511050.0013170.0000970.0007230.0000770.0000650.0000640.0000630.0007240.0000770.0000630.0000690.0000630.0000630.0000620.0000631.5359951.5595011.4113172.0298800.0346820.0008790.0002180.0076580.0003000.0001860.0003310.0157452.0068180.0292720.0008600.0002040.0001830.0026530.0002120.0003650.0007140.1646480.0029280.0002381.9695582.0302130.0249262.0068040.0242011.5446881.7387080.0201350.0011130.0005461.9946590.0222440.0005950.0036050.0005430.0004740.0457460.0005340.0000690.0000670.0000620.0000630.0000610.0003090.0014390.0000760.0000700.0007430.0000710.0000940.0000621.1250731.1369741.1217921.9939590.0256831.4137370.0121630.0001840.0000790.0000740.0000750.0000730.0000940.0000730.0000800.0007010.0000820.0000990.0000760.0000770.0000780.0000830.0000740.0000790.0000733.0395501.8892903.0004630.0216702.0033733.8234860.0272620.0003982.0029461.5065200.0103980.0002640.0000930.0001560.0000730.0000800.0001200.0001570.0007260.0007200.0001471.8016630.0115441.9808470.0125640.0002361.9310850.0120010.0002470.0001611.8533220.0112670.0002241.8642440.0111330.0002430.0006381.8668910.0108970.0002280.5375010.0031940.0002020.0001600.0001500.0001840.0001660.0001760.0001770.0001800.0001690.0001620.0001590.0001760.0017701.9271330.0102021.1804920.0064151.9271360.0109260.0001450.0003170.0083870.0013810.0001570.0002390.1335520.0014930.0004551.2392510.0061770.0001511.3159940.0071080.0001910.0048300.0008740.0005420.0074160.0002191.2458061.4896340.0094831.5635211.5677170.5994790.0028250.0001510.0001360.0001570.0001230.0001380.0001360.0133850.0002530.0002340.0001860.0002410.0002340.0001700.0002060.0002070.0002280.1251120.0007370.0002390.0002100.0001960.0002210.0003000.0003280.0002570.0002050.0002680.0002150.0002161.6398560.0066530.0002290.0002100.0002130.0024550.0002800.0005240.0081310.0050130.0000840.0013590.0000671.5631440.0072180.0086600.0008300.0003100.0001260.0001170.0001350.0002340.0029500.0002060.0002090.0002080.0001970.0019520.0035300.0001341.4101021.4100891.9017670.0067810.0001570.0001381.4105181.4169990.0050080.0001550.0007590.0007080.0013030.0011220.0008370.0012720.0008010.0012270.0013110.0006500.0007230.0008590.0007740.0013530.0013750.0007140.0007130.0000990.0013570.0007160.0000730.0000770.0032940.0000990.0001010.0017200.0003170.0003890.0033250.0001880.0286890.0699490.0022190.0001010.0013680.0007200.0020070.1990630.0013290.0001590.0001100.0001160.0001050.0001460.0001570.0001230.0001020.0001040.0001670.0001190.0001390.0001320.0001270.0001500.0001180.0001770.0001020.0001490.0001080.0001260.0001680.0001270.0001310.0007930.0001280.0001240.0001060.0001310.0001260.0001110.0001010.0001620.0001100.0001140.0001180.0001120.0001260.0001600.0007680.0001141.4126400.0039880.0005860.0053580.0004170.0001900.0001840.0003710.0016880.5066450.0238070.0017960.0002000.0001940.0004850.0001970.2906550.0272930.0023030.0013800.0007310.0026860.0007360.0066010.0002030.0025810.0002150.0001920.0003130.0002110.0002020.0023231.0992070.0034340.0013740.9160421.5525341.2730390.0038060.0000980.0000820.0007100.0007160.0007400.0007190.0000780.0017280.0013520.0000840.0000790.0000790.0007550.0000810.0000810.0000830.0000820.0000790.0001000.0000790.0000800.0007690.0007670.0000880.0000800.0000840.0000880.0000810.0000850.0000920.0143130.0001100.0001110.0016360.1354020.9622850.0092320.0119710.0003240.6714811.2631520.0031320.0003020.0049280.0021761.4138510.0031750.0007580.0000992.0144380.0051050.0007710.0000900.0001240.0038280.0001270.0000690.0007030.0007190.0000690.0000680.0000840.0000670.0023450.0016090.0000730.0007110.0000700.0000720.0000700.0027110.0011350.0015390.0009091.5318420.0033250.0001870.0001490.0001990.0002500.0001820.0002190.0070291.9181950.0040540.0124180.0010310.0014060.0015300.0003940.0001940.0001840.0001691.9128880.0039940.0002270.0002270.0001840.0018440.0002150.0002450.0001890.0002020.0002050.0003570.0001930.0063980.0902580.0003580.0002110.0014400.5871520.0013040.0001941.1399520.0023470.0002180.0003100.0003340.0001830.0002420.0022630.0004960.0002250.0007570.0000980.0000950.0000940.0000900.0007270.0007330.0007370.0000950.0000960.0000990.0000930.0000940.0013680.0000920.0000940.0007450.0001010.0000780.0007830.0000971.5537510.0030470.0000981.6315792.2333231.5568930.0028570.0001010.0000880.0007430.0000881.5476901.5545340.0028110.0009170.0007400.0000871.5503254.1384240.0096630.0018950.0043010.0007890.0001010.0000900.0007050.0001280.0000870.0007110.0000880.0000890.0000850.0013320.0007100.0001020.0000990.0061280.0033100.0073080.0007470.0000900.2638270.0005770.0001390.0001450.0016660.0001450.0001390.0016730.0001420.0001070.0013780.0000760.0000670.0007721.5609500.0026300.0000781.4590940.0030920.0007260.0000720.0000701.5593990.0025800.0007230.0000690.0000670.0007380.0000740.0000760.0000660.0007380.0007310.0000690.0000911.5712950.0026370.0001311.5697250.0025651.5704540.0025580.0001000.0007401.5712190.0025440.0001000.0001010.0000990.0001150.0000940.0000970.0001010.0007300.0035420.0051910.0069310.2684550.0066300.0001710.1766740.2616080.1686670.1177380.5687330.0034920.0101800.0013671.3565920.0033820.0026770.0087822.0501442.5630440.0051910.0000941.5316440.0023611.1885680.7760951.1196940.0017351.1948601.5632510.0023785.7162752.7644130.0042510.0002650.0080730.0762700.0008800.0007680.0009090.0008960.0014070.0000960.0013470.0008620.0022320.0026330.1015700.2554420.0031380.0008080.0001570.0001250.0001310.0001260.0017070.0001300.0001270.0017130.0001250.0001440.0001230.0001210.0016810.0001240.0001080.0001540.0001130.0001010.0027720.0380910.0020230.0001370.0001220.0125080.0038120.0010220.0001390.0007650.0000890.0001011.9068551.5641672.3142930.0032110.0000721.5627411.5678340.0021882.1930351.5692910.0028230.0003790.2747700.3211810.0044090.0004100.0004260.0075430.0004610.0004800.0004250.0004150.0204060.0014320.0001250.0017870.0001360.0017900.0001310.0001860.0001340.0001410.0017480.0001290.0001260.0001350.0001320.0001420.0077490.0055020.0004820.0004030.0004170.0052440.0081340.0493780.0011990.0010280.0013010.0010270.0005240.0005090.8661540.0036800.0012960.0005410.0004460.3006420.0008160.0011500.0004560.0010470.0010273.1512634.7347450.0088520.0015200.0007240.0013540.0007580.0013480.0007280.0013490.0007410.0013590.0013590.0026120.0007540.0022730.0019860.0050400.0013570.0007580.0222130.0025660.0064240.0084843.9828680.0053350.0006100.0002350.0005370.0019890.0078040.0003611.0104820.0088230.0004240.0002570.2257020.0197220.6299480.0010291.0793342.3727022.7151410.0034230.0005460.0002920.0008540.0009100.0007690.0000740.0000710.0013910.0008310.0000730.0000701.9201164.4297320.0087961.2173080.0040350.0026300.0071010.0199160.0026630.0020430.0026361.4910693.8352980.0534324.2845370.0050970.0017542.5568191.1458470.0022372.4461311.2165010.0117980.0002510.0002520.7819841.1905920.0016110.0001770.0035460.0034660.0058110.0341030.0016330.0008790.0021290.0010860.0014910.0107530.0065110.0038350.0007220.0044130.0007190.0007210.0007080.0020260.0015670.0033000.0007110.0014930.0001380.0000931.2650210.0014900.0007400.0000890.0000970.0001160.0000960.0001090.0001081.5527802.9482530.0045840.0000850.0007461.3134971.3134941.4621560.0044131.0600572.3294950.0039461.0005392.0774451.7318800.0027180.0048200.0054390.0029790.0007500.0013270.0001200.0007680.0040820.0001420.0020190.0007620.0013830.0007530.0001250.0014010.0022780.0003010.0052481.8194103.0051131.4048820.0088320.0001890.0001530.0001600.0001530.0001400.0014230.0001490.0007610.9647810.0011510.0001780.0085091.0089960.6202460.0033831.8856850.0026800.0007320.0025190.0025950.0044060.0027300.0000760.0000770.0000760.0011650.0006920.0000970.0000990.0000960.0001060.0002860.0000970.0000961.4885530.0016090.0009600.0001020.0007332.4167571.4277750.1210600.0004750.0001030.0000920.0001170.0028290.0001000.0001771.3065951.2333640.0113840.0035190.0001230.0034040.0171040.0003130.0002630.0003140.0724690.0003450.0106900.0027280.0020640.0001670.0019350.0038540.0019410.0037080.0002730.3754210.0232490.0004101.0314721.4506251.0606441.0972700.0030490.0019870.0013760.0019992.0076110.0027120.0008790.0002890.0002820.0003120.0009713.1023030.0065950.0026390.0026300.0038780.0067581.2161051.1997440.0012241.2893080.9641160.0010070.0000953.1397883.1457141.5695340.0022521.5717500.1822630.5567311.8408241.1843511.1830880.0025930.0007910.0016130.0013800.0021120.0088921.2562370.0077140.0018090.0102350.0001651.4072000.0035700.0001780.0041420.0007810.0001540.0035641.2145870.0018770.0007260.0000880.0000901.9304581.5457910.0021450.0000951.5557940.0021462.9170981.9099480.0018250.0000820.0000810.0000810.0007140.0000800.0000780.0000780.0000810.0000820.0000802.0166380.0019050.0000760.0000780.0000780.0000870.0000800.0000820.0000840.0000810.0087940.0007260.0020160.0001391.3072370.0019701.3528302.6548081.2624360.0012450.0007490.0001340.0013690.0000840.0013620.0007240.0000861.8432300.0029910.0007230.0013650.0007290.0007141.2110610.0014170.0020640.0001820.0003250.0031251.3693071.8741524.7411965.0493282.2692943.6439821.1447240.0010600.0007183.0711614.9043154.6917240.0067593.5533821.8005013.8772701.4890020.0015600.0031960.0024880.0002621.3789160.0033610.0029630.0001850.0002350.0003860.0003310.0005460.0046680.0044980.0026460.0026410.0014240.0013790.0001150.0007540.0007430.0013850.0007210.0013580.0000910.0013400.0007230.0013510.0013540.0013530.0007200.0000880.0013400.0007330.0001200.0001120.0020160.0032630.0007520.0007970.0001190.0001090.0023920.0035250.0070751.2639381.3327300.9411660.0027680.0032501.0623942.0159911.8129920.0032270.0001360.0001610.0001700.0138700.0017450.0001630.0001580.0001490.0001680.0002050.0001530.0001770.0001500.0002530.0001500.0001670.0001950.0001690.0001790.0001580.0017630.0001610.0001720.0001810.0001660.0020860.0017730.0001710.0048800.0046681.6848054.2297901.4160832.7514174.2371702.8094250.0023950.0016640.0016470.0016460.0001161.7916490.0041093.7869860.0056845.3394840.0056790.0013820.0013770.0007720.0002150.0013980.0013850.0008210.0008110.0014110.0001790.0063400.0065940.0021140.0063890.0378470.0078871.3037550.0201352.0009211.2591091.1921060.7709710.0340470.0019980.0007250.0013510.0000960.0001070.0013540.0026260.0000930.0001160.0000980.0001100.0000890.0000820.0000890.0000900.0000960.0000910.0002410.0000851.3270561.4426460.0025310.0000900.0000870.0000850.0008360.0007320.0001000.0000840.0000880.0000850.0007580.0007210.0000900.0000820.0000870.0007340.0001410.0018910.0001390.0018770.0001410.0080110.0018990.0001590.0096520.0069950.0013600.0001522.0191310.0041850.0020730.0000680.0007230.0000640.0000650.0044990.0000670.0007580.0000660.0000630.0014200.0013810.0000640.0000640.0053340.0020550.0020270.0007310.5982280.0024500.0029030.0027070.0027980.0050500.0020070.0007910.0544190.0020590.0013830.0009060.0008380.0020081.9959051.8424361.4083933.3796551.6591882.7145013.5539460.0058450.0029530.0029160.0497990.0008040.0024530.0941230.0007950.0013710.0001180.0020130.0020250.0007290.0007210.0000800.0021420.0007300.0007271.4872780.0087691.1857580.0009270.0020230.0007221.4775981.1138881.5838890.0109380.0082200.0060790.0327260.0063011.5779411.3111440.0028890.0080620.0065112.0690380.0092320.0934520.0014330.0013710.0013740.0020500.0007240.0133750.0016770.0007480.0000780.0007140.0000830.0020090.0026321.0647860.0010340.0025950.0002830.0004970.0004370.0003650.0021670.0003150.0002830.0022240.0002740.0003750.0020110.5486340.2428520.0004750.4426980.0191440.0003090.0002740.0003020.0002980.0002910.8187140.0008650.3200920.0005710.0003020.0002960.6612130.0008470.0856520.0003750.0003160.0002960.0002760.0003030.0093900.6390950.0013520.0015710.3581020.0023540.0021070.0007650.0007550.0020510.0011080.0014570.0014090.0001370.0291080.1261220.4593450.7954731.3237930.8531460.0010010.5884330.0008270.0005171.1734240.0011560.0003690.0004570.0004620.0004820.0003081.5212560.0010900.0007360.0000730.0000660.0000750.0000700.0000711.9070700.0013400.0007381.9413283.7600030.0025700.0003060.0000750.0000740.8071711.5617080.0011000.0000780.0000750.0293350.0301760.4570640.2659970.8647050.0082751.4561170.0162860.0072151.2770121.5269831.5519931.5343770.0010861.5388751.4400740.0010170.0000850.0000820.0000833.4931300.0023611.5520470.0010861.5478630.0010890.0071390.0000990.0247210.0018290.0000880.0007320.0000960.0001060.0013630.0007310.0007580.0007350.0013550.0001000.0007500.0009960.0007390.0020160.0000990.0014960.0000970.0098740.0008120.0007571.3730673.0646091.5309150.0017000.0007291.7540320.4795851.3063462.0823901.5507221.4833503.0518540.0020063.0543170.0027781.6689453.0510850.0019880.0000710.0000640.0000630.0007400.0000630.0000630.0000630.0000620.0006990.0000610.0000630.0000610.0007110.0000660.0006990.0008410.0000630.0000600.0000630.0002250.0000630.0007830.0000640.0001150.0013410.0000640.0000620.0007450.0000620.0006980.0017790.0000650.0000610.0000640.0000630.0000630.0000620.0000620.0009160.0177560.0000710.0000610.0000620.0000620.0000620.0048420.0028130.0026840.0031830.0027191.5250401.1655301.2657012.8067662.8495670.0025670.0100450.4971054.0234573.8089060.0698461.9622451.3218160.6037690.2642410.0028500.0026760.0026281.1690800.5622170.0421910.0034520.9174060.0047921.3979170.7955700.0262051.1645920.0007660.2110300.0009250.0000620.0000670.0000640.0000630.0015910.0000800.0000680.0014480.0000700.0014220.0000670.0007080.0000610.0014130.0014000.0001460.3420191.2053320.0060500.0102442.0365972.0462030.0146620.0003580.0156090.0007520.0000960.0000930.0000920.0007570.0166390.0008290.0007820.0000910.0000980.0000900.0000960.0017270.0000980.0000950.0001010.0000910.0001150.0000970.0001320.0000920.0000990.0000900.0007472.6265873.6283661.2721244.1014212.8408910.7876560.6599820.0011591.4334840.2688270.5631720.0011320.0002860.0034400.0015150.0001801.3288300.0015660.6302640.0114490.0025310.0001730.0001380.1654520.0024730.0065310.0075460.0028460.0328850.0100400.0027304.3341041.5544203.0370974.6496080.0053120.0013900.0038611.4984080.0041260.9862911.5169534.2659503.3319791.5384651.4500431.3031961.3336220.8133022.0035940.2932691.3021120.0008340.0000930.0026470.0026450.0026480.0027940.0026510.0026420.0026650.0026490.0026520.0026491.5645791.5705560.0035263.1322781.5749750.5066600.0016200.0019950.0000740.0000690.0019930.0000700.0013760.0007210.0020240.0007090.0000670.0013540.0001190.0028290.0002050.0045190.0002460.0053480.0002410.0024730.0021420.0002270.0002080.0002090.2712230.0025370.0026570.0019180.0030620.0034800.0018091.4571240.0012530.0005170.0027090.0003410.0033100.2580460.5176771.0233030.7979520.0005600.0001240.5781390.3737060.3259400.2995790.3134270.0003000.0001290.5551640.0022970.0002010.0017710.0002010.0001981.9543192.5306050.0050200.0025421.8569720.1435592.1666151.6019860.0040531.3183251.2097242.8553530.0029912.8560030.0029601.1832661.4673681.2380350.7949041.5403381.3829980.0015010.0008420.8025530.0011830.1326810.0104800.0035850.0130970.0205171.5595070.4704290.0004740.0002470.0002340.0001950.3718430.0004680.0002010.0002200.0002300.0008670.4695942.6466250.0016360.0002370.0002090.0002133.9178210.7411160.9732480.0009190.0004070.0041720.0003670.0010770.0000820.0007210.0001140.0007480.0007730.0000890.0000800.0007370.0007260.0001210.0000730.0000750.0000840.0000750.0000810.0000952.0224100.0038931.8805483.3402501.6206761.9142721.2021161.0011761.4995980.0064470.0075880.2308020.0001890.0000730.0000730.0008770.0000740.0007200.0007130.0007100.0001872.1550580.0013350.0052020.0072730.0002040.0002180.0002430.0024261.8502260.0046000.0002410.000224
0.0029120.0002570.0039450.0001040.0000920.0000910.0000940.0000840.0000880.0000880.0000891.5326530.0112710.0001150.0000870.0000841.2499660.0013790.0000870.0000960.0000860.0000900.0007441.2549670.0007310.2166010.0001910.0001051.3600630.0007772.7524131.0226090.0012511.5371810.0027460.0026071.6684970.0034400.0002560.0039210.0002710.0060010.0001710.0007470.0001260.0001110.0019930.0007780.0007370.0020050.0001380.0007850.0007300.0013711.8551370.0029190.0007550.0001500.0013942.5664340.5398140.4968750.0003920.0001290.0001440.0001541.1953931.3296100.0008260.0001431.0079410.0006490.0001471.0079611.1437530.0007120.0001220.0001240.0001570.4855930.9593490.0009700.0004160.0004040.0009490.0003650.0004020.0086890.0004320.0004190.0004020.0004260.0004290.0004300.6212490.5824900.0006630.0003560.0040810.0003760.0003650.0003310.0076470.0004150.0004010.0001550.0825130.0001201.2179751.3455040.0007360.0000990.0000830.0009051.4503461.0938530.0006160.0010621.4712980.0007953.1957210.6998943.1283272.1979303.5504730.0085780.0020351.9383620.0062850.0013900.0013800.0021181.2913100.0036310.2442700.0031250.0056011.2876050.0025980.0043020.0038270.0045130.0021830.0031570.0026361.7485290.1524011.5438420.0021151.9053370.0010390.0012020.0030001.3944650.0009320.0018671.3525210.0025870.0002710.0019450.0002510.0002210.0030730.0021160.0002100.0002630.0026560.0026740.0026910.0027210.0028710.0027320.0027160.0026670.0041680.9231050.6226440.0010470.0007370.0001010.0001080.0007360.0001240.0007382.0046920.0010440.0032490.0063530.0000963.4177010.0044380.0118110.0130440.0107660.0001340.0001700.0001130.0001840.0001760.0198810.0001770.0053010.0173460.0001680.4675660.4650500.0006500.0001730.0002080.0049020.0002430.0001460.0002060.0001440.0001411.4055234.2093870.2114080.0053390.0058220.0043490.0037810.0085700.0007170.0013680.0007530.0007230.0018920.0013680.0113780.0007240.0007050.0000760.0090180.0007512.0038660.0103180.0026660.0008100.0000770.0085400.0014450.0000800.0014780.0039880.0007370.0007250.0000760.0007180.0007220.0055980.0074190.0066911.1656480.9881372.5273882.5463441.8580580.0009902.3268833.2400920.0040680.0020000.0026000.0016740.0020020.0007430.0013680.0019800.0015770.0025980.9521320.0030330.5734490.0022780.0026040.0020180.0065640.0052400.0064900.0118490.0030770.0007730.0028310.0024780.0001980.0030320.0001240.0021273.3124711.0047182.6732261.6616450.8972071.1265540.0010270.2796430.0223370.1525200.1759170.0015840.0038940.0022170.0031890.0496410.0032480.0023470.0022710.0087370.0021110.0055530.0015520.0032530.0037920.0020560.0068710.0049200.0027620.0947010.6474320.0044560.8347250.7854742.9253150.6022030.0079072.4634050.1864790.0007332.6868400.1106830.4095470.3543710.0008770.0790801.0916210.7892440.0007350.3994920.1046511.2175371.5381191.9187791.6531191.5527720.0013700.4899972.4140351.1543940.1907181.6483340.1072941.1089722.2543910.2960440.3902190.0109880.0081612.5025630.5945510.0169930.0160440.0085410.0142350.0008000.0080250.0120940.0080640.0077241.0885122.3224060.2989270.2414601.9109091.9627550.5336880.0019140.4801230.0011240.0006761.3709910.0029492.1897750.0020190.0083390.4891200.4321331.7791560.1860610.2808920.1977651.7946610.0016110.2363500.0005740.3301640.4265180.8296632.0351141.2798860.3273810.3612201.2196580.3374990.0005980.6187730.2582451.9488741.0328281.9622630.3060520.0562130.0005000.7562830.0012900.0801520.0021551.2588181.2553550.0010591.3229810.0643540.9547261.0993670.0086260.0076950.0025262.0216970.0017930.3718850.8094481.8906711.2958870.0080920.0003540.4457070.0109400.0003820.0003270.0082290.0124071.0248970.0077581.0592940.0209600.3425320.0440530.9603172.8810991.4664360.0019600.4698842.4722140.0028500.1970290.0708421.1235670.0081760.0074830.0077670.0077710.0108840.0082830.2367990.0013081.0861060.0018600.0009690.9945980.0015260.0009140.4072670.2339911.3729951.0529040.0016450.0021140.0007090.5488940.9648440.0012450.0467000.0006180.6987910.0009770.1455740.3078191.1634430.0071770.0011721.6395251.0317310.4258330.6951061.8495511.8445640.8443881.4927120.5042570.1312630.0008602.5947180.0012691.0209582.0065470.0013691.3687130.1807601.5075470.0016521.0940860.5992601.8159170.0083580.0905470.4938060.0010890.1976873.8085690.0019390.0007841.6754031.9178990.1924800.0007530.1892900.8916360.0979580.7520750.0007700.2132750.3350110.0007770.0140260.0846660.0456331.0578440.3479800.5400080.2767630.2810421.4521761.1106320.3203620.0013490.3215600.0012520.4608790.1955850.0007770.2748271.3036630.0082810.0216630.0075670.0003881.0010610.0087000.0004841.9511811.4098481.3732881.1600680.0020140.0092732.4103740.0085290.1823360.0076100.1906901.1947250.5491590.0018470.7169190.4138660.1652061.1330020.0826310.0006270.4420290.1869820.8275581.5806560.9402180.5807462.5379651.8234410.0012850.4406080.8078110.0826161.0433851.8966450.5059100.4215620.0083590.7484540.0013320.6694940.6272340.0021600.2131710.9162850.0009350.0003481.7511220.2610031.0643531.0366591.2321752.1326080.0016650.0079660.0008470.0148610.0006521.5988900.0014200.0200511.1286930.0009930.8767100.0080510.0085630.9634310.2710470.0020000.0192990.0004561.4662321.5587210.6065110.3021182.2950670.0018650.1332360.0012162.0801591.7653410.3181160.2893350.2718060.0006270.0025110.2866180.0007650.0968911.9956282.1581340.8760462.0080201.5245630.0036770.3685140.2434760.0010491.6964650.0012930.3662330.0010600.0307020.0077160.0019640.2503390.9932660.0268820.0007571.2143520.0012480.9450910.8597760.3188201.5106640.0094400.0002711.8522050.6008432.1106710.3149510.7734023.2747020.0063980.0077500.1102871.0875350.2579480.0003700.0004830.4705190.3706810.3360660.4531290.3986781.4231252.0490490.0027421.5189340.6354560.1455771.5888460.0014640.3790490.0078670.0083500.0145760.0052450.5099610.0008640.2049211.0979591.7167671.0166420.0079060.0161620.0006031.2843040.0079061.0945440.0077360.0082180.3207030.6790030.0150500.0075030.0009720.0164621.6385820.0154680.0077700.0070711.0338770.5405781.4020730.0014440.1713830.0222910.0010070.5357520.4252511.9541650.0117080.0009751.9601761.0066520.8763810.9040250.0010873.6430440.3216320.9532240.9428220.0077550.0207030.0144350.0035341.9864610.0084130.0075440.0076040.0075330.0008620.0074522.1065820.4497620.0622080.9765871.0124590.4252341.1986810.1934630.0009910.4464820.5391290.0963712.1463940.8940850.2590700.3445430.0086920.0008090.1138450.5872981.1192671.3347160.1920580.6934130.0771200.5268510.0178491.6570730.6390160.0011070.0005232.0450510.6698101.7620720.2187990.3489180.0009810.0007500.0074572.0851350.8960851.1207401.1206820.0012890.0129411.0306571.7566470.0010130.0009471.3220180.2053130.0076341.2244530.6621720.1984950.2156681.2050780.0173732.2237590.0016371.4357920.0422100.0009700.0079650.0163300.0012090.6614220.0030100.0141000.6392830.0084960.0008260.5937380.2160110.0021130.0008440.0033350.8260952.8324222.0821060.2062742.0477840.9996680.0079730.0084370.2306471.8357320.9749801.4163590.0078281.1274722.0570880.0084792.2269950.0083490.0075700.0077090.0079400.2210980.9232141.1209201.1261750.0078650.0087360.0006080.0003461.0568380.0096551.0545750.3413362.1579710.0715710.0008881.3053420.0080630.0083420.0090730.5278611.8319111.0407881.0601420.2109150.0627923.2323160.6053961.1175400.1113780.0014010.6945140.2180410.0951561.0316490.0083641.5439821.3936451.9266010.0057230.0087010.2117110.3623931.6144610.8729721.9868641.7587970.9849533.1940280.0020030.3373010.6729520.5487210.0010231.1525551.1263020.0080740.0074310.0005320.3156340.0982340.0065200.0975180.7144371.6827971.1699710.4498220.0020040.1888411.7665840.2990720.3142321.8305210.0294020.0056862.7507240.2731660.0081571.0920480.3316650.7491031.4878951.9951670.0012090.0081390.0079611.3170570.1235471.4377440.9954610.2105940.0008010.0081670.7952870.0080700.6091930.0080790.2137181.0404220.3998381.0302562.0903500.5316240.0323250.0005940.4275160.2834420.0074880.5440910.0160111.1112430.3320311.1085041.0495662.9742310.0018641.3464090.0159440.0077370.0080341.0591260.0079230.9907410.0081360.0076921.8250090.3255441.9097832.3100352.2422540.5616372.1077230.0045311.2128721.1035300.0013470.0667640.5908530.0402850.0004550.0096980.3111580.9183040.3142740.1584790.0011010.0005910.2757220.0013440.3410780.2968881.2890140.0079990.0008302.0084891.5946310.3692410.4536561.7190970.0095890.5468640.5950330.0014460.0007790.0590960.2187951.6900900.9678090.911351

*******************************************
EVALUATING PIPELINE 
Pipeline directory: /home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_0b6f043a_2020-02-22_05-19-52dp1bti1v/
With following parameter combination: {'batch_size_seq_length': 1, 'lr': 4e-05, 'lr_type': 'cosine'}
EVALUATION OF CHECKPOINT /home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_0b6f043a_2020-02-22_05-19-52dp1bti1v/outputs/checkpoint-3
-------------------------------------------------------------
|           |   agree   | disagree  |  discuss  | unrelated |
-------------------------------------------------------------
|   agree   |    623    |    122    |    135    |    27     |
-------------------------------------------------------------
| disagree  |    105    |    217    |    79     |    24     |
-------------------------------------------------------------
|  discuss  |    277    |    97     |   1512    |    99     |
-------------------------------------------------------------
| unrelated |    32     |    32     |    53     |   8464    |
-------------------------------------------------------------
Score: 8592.25 out of 9226.0	(93.1308259267288%)
Accuracy: 0.9090603462766852
F1 overall: 0.7287054024045825
F1 per class: [0.6409465020576132, 0.48600223964165734, 0.8034006376195537, 0.9844722302995057]
*******************************************


*******************************************
EVALUATING PIPELINE 
{'batch_size_seq_length': 4, 'lr': 4e-05, 'lr_type': 'constant'}
INFO:__main__:Creating features from dataset file at /home/ubuntu/fnd_implementation/data/processed
  0%|                                                 | 0/11898 [00:00<?, ?it/s]  0%|                                       | 1/11898 [00:00<3:10:55,  1.04it/s]  4%|â–ˆâ–Œ                                   | 501/11898 [00:01<2:08:07,  1.48it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                  | 6001/11898 [00:01<46:24,  2.12it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11898/11898 [00:01<00:00, 6326.95it/s]
  ******************************************* 
              Running Evaluation                
  *******************************************
 
  Length dataset evaluation: 11898
  Length dataloader evaluation: 372
  Number of epochs: 3
  Batch size: 32
  ******************************************* 
 
['/home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_fdc25af8_2020-02-21_21-58-59lddp9zml/outputs/checkpoint-3']
INFO:__main__:Evaluate the following checkpoints: ['/home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_fdc25af8_2020-02-21_21-58-59lddp9zml/outputs/checkpoint-3']
INFO:transformers.configuration_utils:loading configuration file /home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_fdc25af8_2020-02-21_21-58-59lddp9zml/outputs/checkpoint-3/config.json
INFO:transformers.configuration_utils:Model config {
  "attn_type": "bi",
  "bi_data": false,
  "clamp_len": -1,
  "d_head": 64,
  "d_inner": 3072,
  "d_model": 768,
  "dropout": 0.1,
  "end_n_top": 5,
  "ff_activation": "gelu",
  "finetuning_task": null,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "mem_len": null,
  "n_head": 12,
  "n_layer": 12,
  "num_labels": 4,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pruned_heads": {},
  "reuse_len": null,
  "same_length": false,
  "start_n_top": 5,
  "summary_activation": "tanh",
  "summary_last_dropout": 0.1,
  "summary_type": "last",
  "summary_use_proj": true,
  "torchscript": false,
  "untie_r": true,
  "use_bfloat16": false,
  "vocab_size": 32000
}

INFO:transformers.modeling_utils:loading weights file /home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_fdc25af8_2020-02-21_21-58-59lddp9zml/outputs/checkpoint-3/pytorch_model.bin
HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=372.0, style=ProgressStyle(description_width='initial')), HTML(value='')))
0.0012080.1531760.2374360.0804340.0201820.0042950.1282420.2088000.4076940.4172140.7985250.3058320.0258260.2880630.7951500.0531650.0033921.7921470.5254780.2724580.2513280.2272390.1951650.0097870.6028140.1573240.0063560.6572390.0237390.0008990.1294910.0042410.0010500.2350130.0179910.3485550.3659540.0103180.0009740.0004060.0015910.0008800.0000910.0000780.0001920.0000940.0003390.0001770.0001260.0022490.0008360.1515270.0034560.0002580.0002280.1006080.2222890.5883310.0112080.0012500.0020500.0672150.0021130.0005620.0020220.1849230.1374210.0023270.0002140.2035230.9193200.5490750.0239120.0008080.0144210.0005310.4551300.2373930.0034640.5607720.3840480.0061770.9787672.2064650.8311220.6575760.0105700.8362840.0097890.0010350.0832640.7368440.9683980.0110830.2714860.0037200.1078050.0022860.0008471.1322200.0125340.0026450.5384000.0436860.7040020.0072290.2428740.0108900.4389870.6390720.6417530.6708870.3391990.1603930.6787161.4440490.2697450.0032060.2364730.1083070.0369990.0029940.0006440.2106790.0183790.0023450.0363930.0021540.0027680.1681570.0033250.1863440.0733920.1604810.3914970.2599200.0056420.0002250.1881450.0034030.1418880.0180210.0014260.4452371.8386610.1943490.6390880.1719400.0022860.0008140.4818380.9080390.0062610.0001500.0003521.1119940.8324300.0079480.0010890.1615680.0042350.0009400.0004740.0012590.0002800.0010320.4790390.0197450.0966080.1294970.0023432.0374440.1105620.0015890.0034810.5769290.0966300.0014550.0070230.0005950.6362500.4406620.4328400.3899790.0033760.2151630.0024350.0919600.1302400.2170680.0049790.9128740.5178560.0685070.0011550.0007731.6942041.5825180.4184800.0022920.0947140.0464270.0081120.2304720.0038970.9280991.3446380.4881980.0027600.0004920.0881070.2030860.0085100.0002521.4893081.3274150.0905380.0689171.3915830.3382030.6884140.0050980.8801890.3499830.0738130.0031840.0054550.0006290.5950050.1577140.0029640.0244580.1823840.0939520.5037160.6326360.6334940.1771990.0034240.4605320.2974400.2029110.0121020.0011530.0004500.0006760.0008030.0020970.0008850.0009270.4194560.8617910.2728340.3477060.0018190.0077500.0017610.0006940.5594510.0041510.0042300.0437990.0364670.0013670.0029960.0019460.1991921.3101690.0061650.1962460.5541150.3669560.6599240.3092290.0032210.1808290.0026360.0039050.2698240.6569340.0051640.4108240.0038350.4132370.6836050.4231760.4745340.3367840.9234390.8224790.7822470.6978460.3413780.3211020.4822960.4476850.4292080.9994740.3422670.9387500.3736170.5983020.5447450.3583430.6680941.4669830.8540010.3324230.3859760.5167890.3535360.2743540.5233320.4978290.4153770.4089160.7875780.6733110.2417670.6646910.2800561.0336831.0574380.7706971.2069850.6999310.4671420.4206610.7485440.4203030.5522660.4095580.7057190.3995260.3643260.6909171.1678130.4810120.4428551.0437010.3454210.7491350.5692030.4161730.3712580.7358760.1937910.1773351.1844560.5047340.7169270.3723530.6259970.4850740.8499400.8266211.0564900.6057870.3424540.6419820.4892781.0134910.1573960.6580520.9776760.6095411.1034610.4869980.2236710.4653680.7913160.300782

*******************************************
EVALUATING PIPELINE 
Pipeline directory: /home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_fdc25af8_2020-02-21_21-58-59lddp9zml/
With following parameter combination: {'batch_size_seq_length': 4, 'lr': 4e-05, 'lr_type': 'constant'}
EVALUATION OF CHECKPOINT /home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_fdc25af8_2020-02-21_21-58-59lddp9zml/outputs/checkpoint-3
-------------------------------------------------------------
|           |   agree   | disagree  |  discuss  | unrelated |
-------------------------------------------------------------
|   agree   |    709    |    76     |    128    |    35     |
-------------------------------------------------------------
| disagree  |    122    |    296    |    89     |    43     |
-------------------------------------------------------------
|  discuss  |    177    |    60     |   1492    |    76     |
-------------------------------------------------------------
| unrelated |    29     |    36     |    70     |   8460    |
-------------------------------------------------------------
Score: 8650.5 out of 9226.0	(93.76219380013006%)
Accuracy: 0.9209110774920155
F1 overall: 0.7779214616430047
F1 per class: [0.7143576826196474, 0.581532416502947, 0.8325892857142857, 0.9832064617351386]
*******************************************


*******************************************
EVALUATING PIPELINE 
{'batch_size_seq_length': 4, 'lr': 4e-05, 'lr_type': 'linear'}
INFO:__main__:Creating features from dataset file at /home/ubuntu/fnd_implementation/data/processed
  0%|                                                 | 0/11898 [00:00<?, ?it/s]  0%|                                       | 1/11898 [00:01<3:36:09,  1.09s/it]  4%|â–ˆâ–Œ                                   | 501/11898 [00:01<2:25:01,  1.31it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                  | 6231/11898 [00:01<50:28,  1.87it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11898/11898 [00:01<00:00, 6336.72it/s]
  ******************************************* 
              Running Evaluation                
  *******************************************
 
  Length dataset evaluation: 11898
  Length dataloader evaluation: 372
  Number of epochs: 3
  Batch size: 32
  ******************************************* 
 
['/home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_08c35524_2020-02-22_03-51-04fe3xt7cu/outputs/checkpoint-3']
INFO:__main__:Evaluate the following checkpoints: ['/home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_08c35524_2020-02-22_03-51-04fe3xt7cu/outputs/checkpoint-3']
INFO:transformers.configuration_utils:loading configuration file /home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_08c35524_2020-02-22_03-51-04fe3xt7cu/outputs/checkpoint-3/config.json
INFO:transformers.configuration_utils:Model config {
  "attn_type": "bi",
  "bi_data": false,
  "clamp_len": -1,
  "d_head": 64,
  "d_inner": 3072,
  "d_model": 768,
  "dropout": 0.1,
  "end_n_top": 5,
  "ff_activation": "gelu",
  "finetuning_task": null,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "mem_len": null,
  "n_head": 12,
  "n_layer": 12,
  "num_labels": 4,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pruned_heads": {},
  "reuse_len": null,
  "same_length": false,
  "start_n_top": 5,
  "summary_activation": "tanh",
  "summary_last_dropout": 0.1,
  "summary_type": "last",
  "summary_use_proj": true,
  "torchscript": false,
  "untie_r": true,
  "use_bfloat16": false,
  "vocab_size": 32000
}

INFO:transformers.modeling_utils:loading weights file /home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_08c35524_2020-02-22_03-51-04fe3xt7cu/outputs/checkpoint-3/pytorch_model.bin
HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=372.0, style=ProgressStyle(description_width='initial')), HTML(value='')))
0.0005790.2013150.2980860.0996210.0249270.0050600.0008840.0948130.2528830.3034431.1304690.3782180.0316150.2404521.0341570.0689820.0043331.0044510.1635960.2379350.0780750.1098360.0297890.0075790.1853480.0095210.0004670.3561830.0128430.0004650.2214640.0071870.0006400.2490060.0163960.4859440.4857060.0132210.0004740.0001060.0004110.0013150.0000530.0000240.0000390.0000230.0000390.0000640.0000280.0137520.0004820.2330760.0046780.0001300.1112260.0022570.0015510.6870320.0120010.0004500.0001920.0004100.0001920.0005470.0000790.0003350.0000800.0000840.0000530.0829540.0132920.0067030.0002930.0000960.0015370.0001070.2484580.2257270.0038850.2992970.1168270.0110800.6851380.7416040.5847470.3211330.0039271.7615360.0201020.0004100.8162280.0120220.0037930.0361100.0155530.0005190.0002800.0032780.0037771.2739150.0129700.0014020.2336310.0280740.0266170.0003900.2820140.0036831.0542260.9354070.1406840.7306010.3979300.1178040.5636551.7060970.1552230.0015180.0010510.0003190.2542790.0050270.0001770.0003280.0009320.0006580.0018650.1291980.0498340.0011830.0004700.0020000.0011590.1013430.0030400.2837270.0053870.0000770.2948510.0024720.0099090.0004140.0625450.1231491.6578740.3998470.4978760.0068640.0002440.0002200.7675870.9701800.0067270.0000680.0001211.3188501.1345000.0078550.0003330.0141020.0021080.0001220.0001740.0006040.0003650.0004800.7567960.2228250.2547420.1182630.1343563.1046200.3518530.0022340.2487210.0196250.1310420.0012160.0137580.0001550.4305540.3099380.2751950.0150170.0004530.0008160.0007270.0529600.3494270.1562630.0018241.0559980.6320410.3998250.0166970.0002760.2262300.0488450.0015500.0000780.0010800.0011780.0004040.0033490.0005182.9124922.3256741.5342460.0085220.0007230.5391430.2979860.0029540.0000561.7774531.2229770.5139660.1224840.7642100.9728270.3141050.0018570.9547470.5037710.0026310.0001780.1976300.0012241.0346050.4159870.0023650.0317580.3858060.0070410.1138410.3786230.3858090.1502940.0009440.2655160.0023620.0036870.0003030.0001180.0000800.0000800.0001490.1210190.0006630.0001810.1739000.6438040.1894390.0505250.0002860.1024170.0006160.0002280.2282200.0012710.0004620.2314050.0062100.0045020.0014030.0299530.2793300.5526860.0023160.0096340.5727410.7733821.0355190.9391350.0038020.2003070.0011510.1545190.1012711.9044970.0079700.1315760.0009810.1512550.5787800.3181300.5046440.5027800.3218650.6464990.4522880.5705660.2829030.5393240.5238470.4391800.3417540.5114060.5081620.5931090.1633400.5782940.4055670.4317610.5743811.0779711.1395800.2536120.3738760.2075390.1941620.5106640.4894210.6036750.4200260.5685010.4427430.6283130.3437040.4518950.2422200.4910020.7909930.8160230.6719940.4977880.4920510.4394030.6971030.2503210.4444010.2370260.5511910.2525880.3984420.4853670.8119010.1740360.1183810.5971680.2352980.6075300.4554000.3882010.2198291.1326200.3187590.0504920.7053600.4046650.5435080.2653310.6418500.5194920.4031850.6524731.0938010.7586750.3374750.3963600.3765980.4675370.1720170.3960680.5292300.2814731.0619600.5423390.1295150.2648020.6180750.418327

*******************************************
EVALUATING PIPELINE 
Pipeline directory: /home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_08c35524_2020-02-22_03-51-04fe3xt7cu/
With following parameter combination: {'batch_size_seq_length': 4, 'lr': 4e-05, 'lr_type': 'linear'}
EVALUATION OF CHECKPOINT /home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_08c35524_2020-02-22_03-51-04fe3xt7cu/outputs/checkpoint-3
-------------------------------------------------------------
|           |   agree   | disagree  |  discuss  | unrelated |
-------------------------------------------------------------
|   agree   |    785    |    76     |    146    |    16     |
-------------------------------------------------------------
| disagree  |    84     |    314    |    75     |    24     |
-------------------------------------------------------------
|  discuss  |    146    |    54     |   1510    |    73     |
-------------------------------------------------------------
| unrelated |    22     |    24     |    48     |   8501    |
-------------------------------------------------------------
Score: 8737.5 out of 9226.0	(94.7051810101886%)
Accuracy: 0.9337703815767355
F1 overall: 0.8121807069512408
F1 per class: [0.7621359223300971, 0.6507772020725389, 0.8478382930937676, 0.9879714103085595]
*******************************************


*******************************************
EVALUATING PIPELINE 
{'batch_size_seq_length': 3, 'lr': 4e-05, 'lr_type': 'cosine'}
INFO:__main__:Creating features from dataset file at /home/ubuntu/fnd_implementation/data/processed
  0%|                                                 | 0/11898 [00:00<?, ?it/s]  0%|                                       | 1/11898 [00:01<3:27:04,  1.04s/it] 13%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ                               | 1501/11898 [00:01<2:06:41,  1.37it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                  | 6001/11898 [00:01<50:18,  1.95it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11898/11898 [00:01<00:00, 7443.76it/s]
  ******************************************* 
              Running Evaluation                
  *******************************************
 
  Length dataset evaluation: 11898
  Length dataloader evaluation: 744
  Number of epochs: 3
  Batch size: 16
  ******************************************* 
 
['/home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_10defd44_2020-02-22_09-42-54g18jnqvq/outputs/checkpoint-3']
INFO:__main__:Evaluate the following checkpoints: ['/home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_10defd44_2020-02-22_09-42-54g18jnqvq/outputs/checkpoint-3']
INFO:transformers.configuration_utils:loading configuration file /home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_10defd44_2020-02-22_09-42-54g18jnqvq/outputs/checkpoint-3/config.json
INFO:transformers.configuration_utils:Model config {
  "attn_type": "bi",
  "bi_data": false,
  "clamp_len": -1,
  "d_head": 64,
  "d_inner": 3072,
  "d_model": 768,
  "dropout": 0.1,
  "end_n_top": 5,
  "ff_activation": "gelu",
  "finetuning_task": null,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "mem_len": null,
  "n_head": 12,
  "n_layer": 12,
  "num_labels": 4,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pruned_heads": {},
  "reuse_len": null,
  "same_length": false,
  "start_n_top": 5,
  "summary_activation": "tanh",
  "summary_last_dropout": 0.1,
  "summary_type": "last",
  "summary_use_proj": true,
  "torchscript": false,
  "untie_r": true,
  "use_bfloat16": false,
  "vocab_size": 32000
}

INFO:transformers.modeling_utils:loading weights file /home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_10defd44_2020-02-22_09-42-54g18jnqvq/outputs/checkpoint-3/pytorch_model.bin
HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=744.0, style=ProgressStyle(description_width='initial')), HTML(value='')))
0.2093920.2095810.1048650.3367150.4601550.0920670.0155370.0022850.0003110.0000810.0000500.0000270.0000330.0000240.5775540.0385400.3290440.6085410.0349380.5869101.8782700.2532910.6481650.0283700.0013830.0001730.2541790.4819922.1990120.0759060.0025620.0001150.0000270.0000250.5225730.1651000.4510050.0122120.0003660.5166290.0133760.0032100.0001280.1686720.3781630.0084350.0002120.0084850.5265100.9205330.4641920.0093030.0003290.0000900.2215310.9434310.0168700.0006830.0000340.0000230.5311280.0087390.0001700.0000400.0001330.0006250.5675550.0085070.0967670.0015050.4314310.4322620.8494110.0116830.0002100.0078170.0001650.0001070.0000530.0000990.0006660.0002680.0008950.0000370.0000250.0000250.0000250.0000270.0000760.0000710.0000260.0000260.0000350.0001690.0004150.0001030.2205070.1554100.0462030.0020620.0000630.0002520.5975660.0058450.0002230.0000500.0000360.0000330.3288860.0030540.0000610.0018050.0004550.7415860.6467190.5787960.0052260.0001690.0002340.0000980.0000500.0002630.0000600.0526200.0005680.0000550.4566420.0036990.0000540.0002170.0026400.0004020.0001620.0002420.0000360.0000500.0000230.0000400.0000470.0034220.1848250.0020620.3822080.0034210.0006520.0000470.0000330.0000590.2066240.0015330.0001270.0001150.0000690.4734760.0031160.5082420.0032970.0000650.4613280.4146690.3461970.0022030.0000450.0141340.0018641.3894000.5239942.2831660.4284651.0362280.9003170.0109950.0003620.0000820.6735042.9344770.0167770.0002070.0000960.0000420.3185650.2647690.0014970.0035300.0006970.0011900.3567000.0020080.0005140.1305200.0023580.0004610.0004920.0001750.2294030.0012380.2220420.0019130.0000702.9485790.0148260.0001680.0001310.0011190.2074780.4322090.0036040.0010520.0050720.2270820.0011320.0000570.5714970.0069350.0005900.0028400.0053600.0669310.0006010.4525080.0030520.4704090.5797080.5260150.4476800.3354450.3330350.0014901.3067890.8538990.5002841.9750420.1865680.0008560.0001080.0000710.0008130.0009930.0000300.0004880.0025620.0016680.0006200.2873730.3571610.0015020.0009600.0005710.3161440.0013210.0008020.0004290.0005860.0005870.0024200.0005150.0024380.0001280.0803810.0019260.0007250.0016530.0002550.1300760.0536640.4079730.0071110.0109280.3399250.0019820.3635700.4906940.0111720.1376550.0005350.0000270.6275580.0022900.0000710.0010980.2706520.0010090.3959950.0014690.3079150.0015140.0013270.5525290.3263861.0818630.0041140.3626320.0012661.3052530.2043860.0551510.0002580.0000710.0000700.0006480.0008141.6817131.6302230.5413260.0021360.0000450.0000460.0000400.0002880.0003290.0012780.8244881.1176970.1701710.7240050.0023850.0000730.0011180.0019950.0008400.3345110.0011140.0000760.0000250.0001070.0020150.3901520.0012340.0000600.0000360.0003570.0004360.3841830.6519430.0020090.0002410.0001300.0003320.0001860.0001610.0001140.0075814.6290193.2600220.0208720.0024850.0001030.0000730.0053150.1201040.7268472.3274380.1818590.0013740.0003850.0053120.4659770.0024160.0003250.0007590.1857400.9464650.4431070.4651650.7185770.0020350.0348800.0010730.0000900.0002270.4055910.0018340.0007310.0000690.0001900.0000230.0026860.0003080.0132510.0008670.0009830.0007381.3778780.9038440.4103560.9011920.0284050.0001070.0001900.0141120.0001230.0000850.0123820.3837950.0230290.1955490.0007570.1188630.0003320.0000580.2550240.2642400.0911810.2490350.1540680.0004030.2894720.0007770.0002160.0010450.5397872.1779420.1851902.2383820.0059820.0005240.0055040.0095820.0070950.0522900.2679200.0727110.0796380.0002190.0001150.0000220.0000350.0000220.0000322.9969882.3749431.4481410.4453411.4093610.4021080.0011531.4431502.9934220.3925900.5762430.0159750.0332690.0001660.1459850.0005132.1099420.7423150.0017090.0000980.0001620.0002920.0002030.1030680.3251240.0011860.0003171.2507181.4324400.9087650.5318040.0016680.0012670.0013170.0609010.0007090.7309520.0033060.9840701.3101860.0035960.0000391.2406350.9773130.0030000.0002860.0004520.0001090.0000270.4032090.0023750.0110280.0013670.0413010.0007460.0003040.2222850.0007180.0001240.0000300.0003020.0001710.0000680.0002430.0002520.0004650.1094340.0005240.0017280.0001430.0001630.0003070.7555280.4045821.6538570.3297840.6984000.1393300.0003430.1568150.0003420.0164030.0017990.2452220.0006900.0001600.0002620.6011970.0039830.0005350.0002100.0004640.0007360.0006610.9119210.5744740.0062200.0052700.0077510.0003900.0004150.0006410.0000590.5759560.0022903.0063720.4388320.0009340.0003350.0001310.0001241.0789290.0037981.1002450.7137370.9939631.1481211.0502880.8751880.0016520.0008240.0003820.3539080.0007990.0002340.0005470.6423720.3700070.7370410.0014283.2335040.0809120.0009330.1387850.0009830.0005150.0005510.1604490.2433861.1114390.3004960.4406250.6154391.0654210.5825170.6682370.5133740.3746810.0098530.0324480.5780400.5299130.6425200.2538170.8269980.4807350.6620660.3254350.2922310.6614990.3839570.3599960.4849170.2956300.7143511.0328970.2283390.0021670.6736690.9938340.4983110.4229480.0056490.4041070.7417220.2163410.1589460.6454650.3085770.2186981.0566710.6357281.0425531.2263110.2313180.4327540.1366431.0985350.2111970.3804220.1080960.4402990.2820800.0908240.6175600.4914310.2898460.5998520.7149330.1354370.3987810.2407620.4661170.3252930.8518930.6365090.5142020.1650110.6513270.6918080.6324100.4793070.2674070.5319970.4157921.4606440.3422631.1624900.3529140.8072600.6875250.9533330.3476850.6136130.4074210.9330290.2189540.9154740.3922170.0565710.3423790.6186520.3739820.0367760.3965690.6769190.4435030.5664360.2193370.4295170.5483520.0400820.3206910.9190290.6762910.1156350.2475690.0315950.6164490.7019620.4622440.8123730.1509970.4081760.4482680.2553760.6857810.0468571.3995070.8706630.3387240.8922161.1113560.3404800.1364350.0025390.2082840.5081890.6743490.7831520.5018831.0822150.0720210.2111980.2081010.8751730.0296580.3849980.4552621.0274980.3965330.1590200.6812391.8107440.5543600.6542870.7710500.3196750.6032440.8488190.4484740.2923520.5592240.9595190.4390120.3254750.0614940.8198280.1956920.3520650.6110820.9077660.1909600.7275851.5457340.7787590.3697320.0222570.4395180.4100480.4124670.9003270.3167850.0029370.270605

*******************************************
EVALUATING PIPELINE 
Pipeline directory: /home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_10defd44_2020-02-22_09-42-54g18jnqvq/
With following parameter combination: {'batch_size_seq_length': 3, 'lr': 4e-05, 'lr_type': 'cosine'}
EVALUATION OF CHECKPOINT /home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_10defd44_2020-02-22_09-42-54g18jnqvq/outputs/checkpoint-3
-------------------------------------------------------------
|           |   agree   | disagree  |  discuss  | unrelated |
-------------------------------------------------------------
|   agree   |    794    |    68     |    161    |    20     |
-------------------------------------------------------------
| disagree  |    83     |    316    |    77     |    21     |
-------------------------------------------------------------
|  discuss  |    134    |    60     |   1485    |    73     |
-------------------------------------------------------------
| unrelated |    26     |    24     |    56     |   8500    |
-------------------------------------------------------------
Score: 8718.75 out of 9226.0	(94.50195100802081%)
Accuracy: 0.9325096654899984
F1 overall: 0.8116823678843131
F1 per class: [0.7634615384615384, 0.6549222797927461, 0.8411214953271028, 0.9872241579558653]
*******************************************


*******************************************
EVALUATING PIPELINE 
{'batch_size_seq_length': 2, 'lr': 4e-05, 'lr_type': 'cosine'}
INFO:__main__:Creating features from dataset file at /home/ubuntu/fnd_implementation/data/processed
  0%|                                                 | 0/11898 [00:00<?, ?it/s]  0%|                                       | 1/11898 [00:01<3:28:53,  1.05s/it]  4%|â–ˆâ–Œ                                   | 501/11898 [00:01<2:20:09,  1.36it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                    | 5501/11898 [00:01<55:03,  1.94it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11898/11898 [00:01<00:00, 6365.93it/s]
  ******************************************* 
              Running Evaluation                
  *******************************************
 
  Length dataset evaluation: 11898
  Length dataloader evaluation: 1488
  Number of epochs: 3
  Batch size: 8
  ******************************************* 
 
['/home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_0e24bd14_2020-02-22_05-21-33av2k0c1z/outputs/checkpoint-3']
INFO:__main__:Evaluate the following checkpoints: ['/home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_0e24bd14_2020-02-22_05-21-33av2k0c1z/outputs/checkpoint-3']
INFO:transformers.configuration_utils:loading configuration file /home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_0e24bd14_2020-02-22_05-21-33av2k0c1z/outputs/checkpoint-3/config.json
INFO:transformers.configuration_utils:Model config {
  "attn_type": "bi",
  "bi_data": false,
  "clamp_len": -1,
  "d_head": 64,
  "d_inner": 3072,
  "d_model": 768,
  "dropout": 0.1,
  "end_n_top": 5,
  "ff_activation": "gelu",
  "finetuning_task": null,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "mem_len": null,
  "n_head": 12,
  "n_layer": 12,
  "num_labels": 4,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pruned_heads": {},
  "reuse_len": null,
  "same_length": false,
  "start_n_top": 5,
  "summary_activation": "tanh",
  "summary_last_dropout": 0.1,
  "summary_type": "last",
  "summary_use_proj": true,
  "torchscript": false,
  "untie_r": true,
  "use_bfloat16": false,
  "vocab_size": 32000
}

INFO:transformers.modeling_utils:loading weights file /home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_0e24bd14_2020-02-22_05-21-33av2k0c1z/outputs/checkpoint-3/pytorch_model.bin
HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=1488.0, style=ProgressStyle(description_width='initial')), HTML(value='')))
1.0474951.0480380.5266480.1756780.0439360.0089000.0093600.0013550.0001870.6712400.0671420.0061220.0006210.0022780.0002190.0003360.9813610.0577450.9575110.0504140.0026300.0002430.0000270.0000180.0001150.0000210.0000170.0000171.5734491.0332290.0345520.0018090.0000750.0020400.9670320.0276500.0008690.0000450.9586500.0246971.9382031.0202730.9951510.9601600.0219340.9697220.0224790.0004970.0005670.0000280.0000170.0000170.0002090.0001180.0000190.7012291.3816211.4598850.5666800.0096230.0001780.0000260.0000200.0001140.0000190.0000180.0000180.0000182.3959852.0283471.8123430.9914562.0086450.0275330.0003940.0000220.0002140.0002090.0061521.1215700.0141410.0002740.0000540.0001390.0000720.0000631.0887490.0125631.1130590.0125690.0002210.0000580.0000580.0000540.0000670.0015561.1062430.0122562.9179903.0371011.7195651.9697300.0194220.0007370.0006140.0001220.0000180.0000170.0005690.0021362.0031790.0186800.0001830.0000180.0000160.0007420.0000240.0000170.0000180.0000170.8342660.0069130.0000760.0000210.0000190.0000190.0000230.0000190.0000190.0010420.0017010.0014320.0002221.0372100.0078510.0000760.0000180.0012400.0000360.0000370.0019890.6359680.6289330.0045980.6607690.6744070.0049210.0001430.0001100.0001120.0002280.0000300.0000180.0003870.0002040.0002050.0001110.0002030.0000250.0011480.0189600.0027080.0017410.0002120.0003881.0989970.0066380.0000570.0000180.0000170.0000170.0000170.0000170.0000170.0000170.0000170.0000190.0000170.0001140.0000180.0000170.0000170.0000170.0000170.0000170.0001120.0000180.0000520.0023650.0000650.0000700.0000640.0000610.0000560.0000550.0002800.0002950.0004790.0027230.0025910.0000840.0000730.0006720.0003521.6372090.9175140.0044720.0002220.0002090.0002020.0002020.0000180.0001150.0000180.0000180.0000190.2965780.0014770.0000240.0000240.0000180.0000190.0003110.2792810.0058090.0001750.0001560.7515090.8463020.0038680.9706260.0044170.0002590.0022870.0001260.0002960.0000240.0004510.0002310.0001100.0000180.0002150.0003010.0072920.0000500.0000210.0000220.5101030.0022840.0003090.0002720.0001050.0001940.0001350.0000950.0013570.0001110.0000930.0001020.0025690.0000320.0031740.0000920.0013720.0007920.0003280.0014250.0014980.0001230.0000190.0001150.0002120.0000190.0000190.0002180.0000190.0001220.0001100.4397310.2602311.1964080.0370470.0001780.0001120.8052360.0350750.0002310.0605860.0021250.0037700.0000300.0001100.0001100.0000170.0002050.0001100.0010410.0023100.0001170.0013120.0000590.0009950.0012020.0000520.0002010.0001100.9025650.7630710.0026800.0000250.9024240.0030120.0001180.0000180.0001080.0001091.0429770.0033071.0393321.0365790.0033501.0426270.0032550.0000270.0000170.0001090.0054600.0013770.0011330.0057920.6984150.5937390.3899430.4343070.7953602.0801340.0063920.5319890.0051770.0400610.8653562.1086300.9744080.0037040.0024900.0002080.0002920.0001990.0023900.0007750.0015640.0001630.0000600.0011260.0000600.0010790.0000600.0010010.0000490.0000170.0005170.2189690.0006210.0009490.0001120.0001100.0030410.0985900.0002840.7886950.0098620.0045310.0059540.7350460.0019970.0005580.0000340.0049180.0002470.0023350.0015510.0000630.0014510.0000540.0001270.0014260.0012660.0000430.0024120.0041860.0002250.0001280.0114240.0006290.0000260.0020900.0001230.0002145.2598670.0137560.0003330.3024840.0010810.0003020.0007320.0004630.0003950.0003070.0042760.0104491.5366640.0037920.0000600.0035500.5992520.0014920.0050140.0139192.0169251.8305380.0043900.0002300.0001130.0003730.0002430.7193600.2113660.0028780.0015500.0033200.0006840.2432680.2192000.0007180.5234470.5245990.0035110.0001050.9688250.0023070.0014140.0034970.0003600.9667120.0388670.0085630.0088890.0002280.0003920.0079210.0152420.0000521.0221970.0023670.0000220.0000171.0331102.0800390.0046512.0476860.8801821.5180230.4837481.6344270.0069130.0034950.0002260.0001190.0002200.0004350.0003030.0002140.0007040.0067460.2973670.5428020.0011600.0000190.0003180.4996040.0010580.1567860.4252340.0014660.0003250.0013960.0003300.0000170.3669900.0007670.0000180.0000170.0006830.0010610.0001130.0024591.1381610.0023070.0000640.0000170.0016870.0023570.0023190.0012730.0001220.0024070.0022760.0003040.0056380.0057490.6096330.0022101.3034070.7068100.0019510.0004890.9712210.0019970.0000420.1653970.0022030.0008030.0016570.0012400.0011420.0000200.8751950.0187210.4753920.0099560.0022350.0003020.9360200.0053550.8074451.2942710.5773730.5527720.5932851.1844020.2439280.0005990.8531400.6230380.4829590.9572110.7360190.0013630.0001160.0000180.0000180.0000180.9633950.0017600.0000210.0000170.0000170.0002280.0003090.0005950.0056270.0003650.0001120.0002090.0003030.0027130.0003080.0003050.6369040.0018030.0000280.0401860.0076040.0305573.2243840.0057203.0683250.6844020.4926202.2487330.0043550.0007240.6417310.0014090.0000240.0010261.8199460.6296310.5149310.0009880.9059340.0018300.0002090.0003070.0003920.0001120.0002990.0000471.9073710.0033870.0000231.8689112.9515042.0174140.0039782.9421241.0594260.0018240.0005170.0013050.0000760.0001110.0008850.0003710.0000760.0000920.0000840.0012220.0001010.0014890.0013310.0215421.8079591.9088713.0265230.0061420.0024221.0186072.0640992.5433150.0044360.0003170.0002130.0003090.0003080.0047090.0079130.0007170.0171520.5310800.4543720.3989460.0010140.0002070.0002050.0003910.0000180.0000170.0000160.0000160.0001200.8212000.5399990.0008430.0001130.0001130.0000190.0001140.0001170.0000180.0001330.0014150.0016450.0073990.0034540.0021050.9972280.0023830.0001320.0000170.0004400.0001780.0003270.0002170.0003770.0006600.0005150.0006960.0007920.0006750.0001150.0004880.0002080.4785012.7299683.7187014.8152440.0098820.9601750.3329420.0010100.0002110.0005940.0002100.0003060.0002081.1692100.0540550.0006370.6882690.6344250.5307092.2993621.0255300.5241610.0194800.0006820.0004150.0005410.9737140.9472250.0014470.0003091.0162460.0034340.0002160.0001040.0013500.0019110.0003950.0015610.0042121.2508570.0017660.0000380.6709040.5240960.0010910.5798110.3652100.0005390.0000350.0025700.0044260.0027490.0016560.0002050.0003860.0003860.0014220.0267041.6512860.1114000.2404940.4488860.0006250.0000240.0000240.0028200.0001140.0000170.0000170.0001100.0099041.6970410.0022740.1309741.0303580.0013760.0150180.0078830.8229330.0048090.0011920.2292890.0258710.4690630.0006280.0000170.4193800.0029680.1864780.0003640.0003430.0001120.0000200.0008890.0002050.0004820.0002050.0003920.0002080.0002040.0003122.4351000.7987410.7159561.7133162.4275892.3304811.5056970.8786051.5810730.0020100.0001330.0000170.0000160.0001110.0000160.0001110.0002230.0000160.0000170.0001310.0000170.0002210.0001300.0001090.0001280.0000160.0000160.0000160.0001300.0000170.0000160.0002370.0009290.0008530.5698800.0169750.0647320.0299934.1632971.4309611.6227890.0080260.0007740.6905863.3475961.8932190.8546662.2058370.0029130.0002040.0000170.0003020.0000180.0002770.0003220.0001100.0005540.4277950.3003910.7794280.0600010.0022660.0001150.0000180.0002460.0002380.0000180.0000180.0001140.0000180.0000170.0000180.0000180.0001103.1534222.5615131.1598800.6617330.8226780.0556960.0008980.0002330.7161640.0074030.0002420.0427430.2901210.2746700.0011092.4613822.6165092.3015430.0055610.7245971.6217721.2537660.4853740.0063690.0044820.0033770.0000420.0007550.0007640.0007580.0007570.0007562.0326062.0635401.5832390.0022520.0000200.0002940.0002950.0003870.0002040.0008290.0008700.0016480.0008220.0008490.0000350.6767080.0037580.0033620.0007890.0001740.0016790.0001862.0108030.9947241.0355442.0022172.0181900.0022191.0269570.0018100.0000362.5918380.0044460.7167440.5176830.0138750.1136400.0018950.0504900.0054030.8881890.0023150.0116280.0039310.0048080.0115011.7054660.0018380.0000190.9471900.0010250.0001123.5934320.0038280.0000213.5189630.0058870.0005660.0001630.0001190.0005050.0001440.0001230.0001200.0000190.0000200.0000220.9900590.0206871.8402170.5767640.0092240.1638040.0001870.0001230.0001150.0002060.0022050.0012840.0026250.0000800.5369530.0017970.0015490.0012410.0000190.0000170.0000170.0000170.0304460.0000480.9658130.0240080.0000410.0001140.0013270.0009690.0027230.0073380.0031110.0042821.2465160.0021250.0016700.0006570.0001120.0002970.0002040.0003120.0002030.0002980.0003960.0002071.2935220.6018060.0006230.5776411.2234660.6114730.0006321.2543960.0012660.0000271.2953400.0013860.0001850.0000990.0080470.0001190.0001140.0064890.0057460.0027950.0001000.0060920.0000990.0009160.0007990.0007060.0000590.0007980.0006821.3066260.0033100.0059730.6788000.0011560.0006180.0004500.0003150.0005120.0019630.0015220.0029710.0017210.0012491.8486900.8563020.5364450.0013370.1294250.0026140.0018820.0011220.0033600.0028380.0003950.0007680.1281800.2501180.6330850.0042380.0174120.0000350.0001190.9491780.0032590.0041450.6554153.1693340.8198470.0007840.0000200.0008950.0027500.0040660.0032450.0000210.8613640.0008220.0000182.0384240.0078010.0056931.6681280.0018260.5907680.5790971.2705190.0012740.5959650.6361071.0948980.4945060.3515180.9548960.0010700.0001090.0030450.0046080.0007610.0050710.0036400.8662470.0014590.0005850.0003960.0004870.0005940.0009400.0043040.0006790.0072870.0316580.0028420.2289160.0003490.0003453.6331043.3500830.5285250.0010090.0013680.0014790.4222970.0524780.0029420.0116600.0259360.0012210.0013120.0112660.1576390.1217580.3208020.3417251.0396110.9358601.2843620.2054050.0603010.3115810.2428690.6092941.5910891.3206400.5188831.1614340.5366240.2303790.2546610.0261950.5470470.5479160.0287720.0129380.3772250.1728600.7257590.1999950.9891600.0120370.2744620.6938911.1350390.1034080.8782600.7763820.7228920.4921420.0808101.2466931.2065860.4868510.6899310.3574950.4356431.3632240.8912620.1470680.4175090.5453091.1216530.0853650.4604080.6225750.2409760.8140320.5456371.2419290.0254670.2586330.0002820.0127860.3366280.4712510.1616871.2527871.6995730.8464150.0467830.4902730.2275590.0221860.0402070.8519430.4296461.2047330.0012700.5725290.1745970.0022150.0927760.7779400.0039760.6197870.3266760.0223710.2659581.3971770.6917991.2080710.9612620.9889070.5936891.0968520.0148230.8529650.5317740.5725190.0247270.3596851.1509310.0017240.9834100.0756841.1189000.4374530.2323110.2758770.0145580.8497010.2507780.3477440.3768600.0782880.0998460.7524560.2556440.5236950.0034620.1378410.0021391.2888491.7766830.9950510.9017950.0263270.4910620.6079460.6675860.2362800.0049070.4784320.4620790.7481971.4825980.3747070.4815141.4794060.6408540.2718260.0166000.1100840.4921340.6148880.4437530.4655721.3276080.0147400.2985670.2709790.1714560.3715080.5451181.0758191.0740680.0248362.3803171.4701740.6998860.0232881.7116470.4188260.1009710.1997450.2212762.0589720.4206810.7113780.4617261.1030980.0836640.1454240.0037901.2302500.0101430.7298731.0799230.6011120.0092710.4830311.3531671.6170180.0072990.6489780.0804540.0065320.2543460.5585351.3144460.0263750.7428241.0684420.4905170.0312060.6444630.1581991.2181120.5187130.0122211.0865400.0313310.7481210.5354110.0039450.8255300.0134550.3210410.1710790.0059800.0021360.4231491.3013731.2440531.0145770.4953431.6779140.8455740.0281000.0146080.4102950.0176510.0077630.9128430.3652300.7316121.4097240.1381701.1803981.7019690.1272560.5523960.0273870.4788060.2016920.0055070.7740110.2815510.0002860.7183200.6523630.0105090.0072470.2852350.5178570.3335410.3070420.0005080.2817761.1749950.1935311.0809821.0825730.5842580.0025980.0182630.0449860.0028940.0047000.3368140.0374840.0010530.9702700.0498690.9488730.3995790.6484500.1008040.5192861.1248581.1421530.0196780.4975010.9019420.3275280.0096250.4215340.4190180.5582520.0030550.0380480.0700470.8527310.7147710.0250851.2291400.0907160.3303960.2136770.3880060.8782050.9886640.3990771.2040151.3926340.2531421.0780930.7719620.2640231.2862620.0154090.4538780.1538531.7326631.2185790.2678140.9018780.9585270.7840050.3450680.1907320.5142970.2825591.7343700.0274330.6468130.3134820.5417280.4133590.0185170.0109890.1204881.1393640.0088700.2222500.1609510.3105200.3347730.4622490.9150020.8240720.0144040.4420520.4541200.9244341.7442312.6080001.7371880.5405170.9486460.2575860.0151000.3073640.3024910.0782480.2786090.2257491.6040820.0061061.4997150.4445350.1905140.8016470.0009450.0310430.5447940.996770

*******************************************
EVALUATING PIPELINE 
Pipeline directory: /home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_0e24bd14_2020-02-22_05-21-33av2k0c1z/
With following parameter combination: {'batch_size_seq_length': 2, 'lr': 4e-05, 'lr_type': 'cosine'}
EVALUATION OF CHECKPOINT /home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_0e24bd14_2020-02-22_05-21-33av2k0c1z/outputs/checkpoint-3
-------------------------------------------------------------
|           |   agree   | disagree  |  discuss  | unrelated |
-------------------------------------------------------------
|   agree   |    734    |    96     |    149    |    16     |
-------------------------------------------------------------
| disagree  |    76     |    272    |    67     |    13     |
-------------------------------------------------------------
|  discuss  |    196    |    73     |   1516    |    96     |
-------------------------------------------------------------
| unrelated |    31     |    27     |    47     |   8489    |
-------------------------------------------------------------
Score: 8686.0 out of 9226.0	(94.14697593756775%)
Accuracy: 0.9254496554042696
F1 overall: 0.7861583065586518
F1 per class: [0.7224409448818898, 0.6071428571428571, 0.8284153005464481, 0.9866341236634124]
*******************************************


*******************************************
EVALUATING PIPELINE 
{'batch_size_seq_length': 3, 'lr': 4e-05, 'lr_type': 'constant'}
INFO:__main__:Creating features from dataset file at /home/ubuntu/fnd_implementation/data/processed
  0%|                                                 | 0/11898 [00:00<?, ?it/s]  0%|                                       | 1/11898 [00:00<3:15:01,  1.02it/s]  4%|â–ˆâ–Œ                                   | 501/11898 [00:01<2:10:49,  1.45it/s] 17%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                              | 2001/11898 [00:02<1:19:33,  2.07it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                    | 5501/11898 [00:02<35:59,  2.96it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11898/11898 [00:02<00:00, 5011.87it/s]
  ******************************************* 
              Running Evaluation                
  *******************************************
 
  Length dataset evaluation: 11898
  Length dataloader evaluation: 744
  Number of epochs: 3
  Batch size: 16
  ******************************************* 
 
['/home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_fafe8b34_2020-02-21_21-46-551cd49x8c/outputs/checkpoint-3']
INFO:__main__:Evaluate the following checkpoints: ['/home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_fafe8b34_2020-02-21_21-46-551cd49x8c/outputs/checkpoint-3']
INFO:transformers.configuration_utils:loading configuration file /home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_fafe8b34_2020-02-21_21-46-551cd49x8c/outputs/checkpoint-3/config.json
INFO:transformers.configuration_utils:Model config {
  "attn_type": "bi",
  "bi_data": false,
  "clamp_len": -1,
  "d_head": 64,
  "d_inner": 3072,
  "d_model": 768,
  "dropout": 0.1,
  "end_n_top": 5,
  "ff_activation": "gelu",
  "finetuning_task": null,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "mem_len": null,
  "n_head": 12,
  "n_layer": 12,
  "num_labels": 4,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pruned_heads": {},
  "reuse_len": null,
  "same_length": false,
  "start_n_top": 5,
  "summary_activation": "tanh",
  "summary_last_dropout": 0.1,
  "summary_type": "last",
  "summary_use_proj": true,
  "torchscript": false,
  "untie_r": true,
  "use_bfloat16": false,
  "vocab_size": 32000
}

INFO:transformers.modeling_utils:loading weights file /home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_fafe8b34_2020-02-21_21-46-551cd49x8c/outputs/checkpoint-3/pytorch_model.bin
HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=744.0, style=ProgressStyle(description_width='initial')), HTML(value='')))
0.4159370.4195900.2100180.0704800.3043610.0609730.2579240.0375690.0047800.0006160.0003880.0001140.0002110.0000970.4444541.0207980.9330100.4897030.1138030.8737470.9137591.3464500.9267720.4338600.0199720.0008780.0004860.2133670.9273500.2681800.0090310.0005020.0001050.0000911.7781871.4961630.4251040.0115840.0006340.4084650.0103210.0003560.0001160.0001100.0069740.0002600.0001110.0014490.0025651.7156620.7894610.0172950.0023020.0001490.8918101.0265420.0184410.0021700.0001340.0313080.2555930.0042890.0001750.0143220.0019470.0042740.4580920.0070390.3701430.0054490.3877440.6183270.5867480.0083690.0004380.0003780.0005700.0005720.0004470.0014000.0097230.0044480.2573130.0031820.0001190.0000830.0000820.0000820.0000830.0002070.0000840.0000820.0002070.0001340.0014370.0026770.0003450.0049450.0011800.0028550.0001270.0010720.3688880.0039110.0009890.0003370.0002090.0000850.0312590.0003720.0000880.0031470.0030710.2221790.4856140.4318900.0066280.0003790.0006810.0090480.0004030.0029740.0001390.2009730.0023480.0003670.0001160.0015460.0001220.0027880.0057910.2537810.0020630.0016780.0002150.0004460.0000840.0003270.0003330.7614830.1015850.0012510.3336860.0099600.0060010.0002910.0002080.0004950.0044180.0017200.0014790.0014530.0004710.0036330.0003550.0022020.0002230.0003500.0594220.1006550.0226010.0002480.0002010.8550930.0112670.6451790.1975901.3636910.4287331.1411361.5905510.4301830.0070100.0008340.0022370.4921960.0042170.0014430.0014200.0001000.0014650.0006660.0003430.0278400.0042650.0251240.0308630.0020410.4513380.0041460.0015540.0014700.2406190.0028080.4553600.0028070.1564960.0180730.0005652.2721230.0121670.3191230.5897820.7925660.8886230.4522520.0040170.0048490.0066761.7180300.0086070.0004940.3530510.0897710.0073760.0114020.3750530.0031850.4413810.3245540.0105270.4423960.2092050.5019700.2874000.5155490.4251470.0019561.3290900.8733940.9126332.5566980.6066010.0030500.0008200.0006900.0154970.0229660.0002580.0023450.0195820.0133980.0205210.0008430.0002920.0001040.0017380.0045540.0004850.0001080.0059280.4318650.4142300.4247940.0093310.0089020.1742600.0021020.4291060.0090850.0057420.5518290.0053151.4909261.6771021.1339170.1960080.0168460.2937520.0055480.4527710.9499851.4008150.9075970.0035160.0000960.4319580.0016440.0004560.0007360.0008950.0004750.0004560.0008780.0108330.0101720.0436390.7270750.4781690.7934290.0059890.6557510.0023380.0026220.0007040.0008970.0007210.0006950.0004660.0035640.0029111.4501981.4125770.5029220.0032690.0001130.0001020.0001030.0016660.0016310.0086421.7005561.4205210.5014982.2518550.0080750.0007110.0051291.3684180.3168200.1011890.0011930.0009210.0000850.0000820.4249700.4533820.0017110.3300260.0012080.0015440.0064770.2901980.4379480.0015570.0007720.0553890.0023230.2362670.0026900.0399270.0988742.4633991.6513560.2885050.0097120.0010750.0007800.2235370.2359690.2960310.0869860.5796890.2595330.0624810.0015480.1903320.2674230.0022180.0015330.0038930.4486150.2791860.2850340.3921210.0011790.0068860.0037310.0014750.0054990.5167590.3406640.2426950.0007500.3342500.0009840.0363090.7492910.2233120.0258950.2634270.2902770.0065350.0031720.0015890.4427180.0018310.0002940.0006950.0006080.0008080.0006050.0169740.3226110.1449740.1853640.0040550.2900750.0009610.0002290.2867900.2766060.2489810.2907400.2802450.0007870.2858780.1320320.0048040.0102440.5586972.5134551.1091100.8341160.0134170.0090110.5221480.5510100.3072690.3615320.5261710.3319740.0855780.0004090.0407730.0001770.0002040.0000810.0002031.4477082.0504941.0099320.0053490.8175630.5713070.0036301.1593642.2578710.2877580.0807680.0138280.0077720.0010880.3798310.0028881.7956090.7198420.0020480.2344860.0021820.0040980.0027860.1221430.0079360.0018130.0015730.7311590.6459770.3187600.9250870.5052130.9038370.5994400.0115870.0698960.2926960.2071061.9910101.8036460.4307810.0011211.6033571.1177680.0102580.0003600.0004510.0003280.0000990.0015331.4123480.2996810.0159200.0003730.3197980.0048920.4843060.0041140.0656210.0002160.0081070.0017250.5401820.0043910.0031870.0051180.3557940.0055710.0018960.0078590.0045760.0039660.7880700.5908351.2830730.0658120.1909220.3874700.0009980.0031680.0001110.0017540.0016230.0016120.0032620.0017480.2816460.4962130.7761910.0029830.0009320.0057110.0682250.0056520.5985460.2631420.0859250.0046620.0037350.0016000.0020320.0097330.0003490.4361860.0097461.5377520.3836070.0024630.3543590.3501460.0156280.8589600.0151380.8641250.5717930.7655730.6684480.7882600.5719950.0015080.0104031.0357391.1727310.0037600.0011650.0016480.0015440.9175310.5729010.0016271.1107610.0587570.0060170.2661650.0089350.0062200.0079390.1792430.9016800.7714240.5523440.2531300.6949931.4885530.2158700.8999210.8596221.2268650.1149171.4533111.0809371.0317250.4803500.6778530.6887670.4605400.2895600.9447850.3597000.6122690.3128920.5338300.3594800.2441420.6017610.7074930.2268350.1464890.4825930.9732880.4648070.2511100.0859121.0397081.5277470.6389700.7120130.3314960.3970421.0992210.7274790.3132810.6431161.0012710.7699320.3333920.6563231.2014621.2158550.3871350.3254350.3589050.1696530.3398020.2719610.3846170.5009960.3651081.2683091.0062220.3811500.4325400.1269290.5398580.7646500.7405890.3806390.2464940.1807260.5233610.8989460.2103150.1824520.3924360.2545041.0713350.2747101.8496790.0887321.3738490.6001301.8323500.2111520.5905360.2854430.8437600.4177270.9325100.3355470.1648950.9014970.8715971.4226670.4239670.6722960.9194830.3153590.8628630.1878230.3225440.4886540.0829520.5557821.0032150.7386630.0583990.2419040.0137420.6392570.7569660.6725870.9039740.2238690.6411060.2603680.3363120.6601510.3964542.0684201.0529140.2240650.7417421.2794900.2776090.2613880.0057940.1286070.2612580.5911150.3327270.6583791.2290750.1178010.4550490.2551360.9776460.1363580.8005870.4336840.8645520.1941260.9029660.7504991.5514731.2828541.0347310.3182920.0959120.2997320.2980241.7403230.7607380.3157990.8938960.7546640.6114790.7087651.1183730.1688030.9867151.0159110.3782700.2090860.7059141.5115240.7207580.8433490.1158730.1269430.2185470.2865540.8392570.1256280.0145420.477425

*******************************************
EVALUATING PIPELINE 
Pipeline directory: /home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_fafe8b34_2020-02-21_21-46-551cd49x8c/
With following parameter combination: {'batch_size_seq_length': 3, 'lr': 4e-05, 'lr_type': 'constant'}
EVALUATION OF CHECKPOINT /home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_fafe8b34_2020-02-21_21-46-551cd49x8c/outputs/checkpoint-3
-------------------------------------------------------------
|           |   agree   | disagree  |  discuss  | unrelated |
-------------------------------------------------------------
|   agree   |    721    |    71     |    141    |    22     |
-------------------------------------------------------------
| disagree  |    80     |    267    |    63     |    21     |
-------------------------------------------------------------
|  discuss  |    170    |    74     |   1495    |    60     |
-------------------------------------------------------------
| unrelated |    66     |    56     |    80     |   8511    |
-------------------------------------------------------------
Score: 8655.5 out of 9226.0	(93.81638846737481%)
Accuracy: 0.9240208438393007
F1 overall: 0.7839871759763632
F1 per class: [0.7238955823293173, 0.5939933259176863, 0.8356623812185578, 0.9823974144398915]
*******************************************


*******************************************
EVALUATING PIPELINE 
{'batch_size_seq_length': 1, 'lr': 4e-05, 'lr_type': 'constant'}
INFO:__main__:Creating features from dataset file at /home/ubuntu/fnd_implementation/data/processed
  0%|                                                 | 0/11898 [00:00<?, ?it/s]  0%|                                       | 1/11898 [00:01<3:27:27,  1.05s/it]  4%|â–ˆâ–Œ                                   | 501/11898 [00:02<2:19:13,  1.36it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                  | 6001/11898 [00:02<50:25,  1.95it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11898/11898 [00:02<00:00, 5429.84it/s]
  ******************************************* 
              Running Evaluation                
  *******************************************
 
  Length dataset evaluation: 11898
  Length dataloader evaluation: 2975
  Number of epochs: 3
  Batch size: 4
  ******************************************* 
 
['/home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_f4eee8f6_2020-02-21_17-24-58rcg23wm1/outputs/checkpoint-3']
INFO:__main__:Evaluate the following checkpoints: ['/home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_f4eee8f6_2020-02-21_17-24-58rcg23wm1/outputs/checkpoint-3']
INFO:transformers.configuration_utils:loading configuration file /home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_f4eee8f6_2020-02-21_17-24-58rcg23wm1/outputs/checkpoint-3/config.json
INFO:transformers.configuration_utils:Model config {
  "attn_type": "bi",
  "bi_data": false,
  "clamp_len": -1,
  "d_head": 64,
  "d_inner": 3072,
  "d_model": 768,
  "dropout": 0.1,
  "end_n_top": 5,
  "ff_activation": "gelu",
  "finetuning_task": null,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "mem_len": null,
  "n_head": 12,
  "n_layer": 12,
  "num_labels": 4,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pruned_heads": {},
  "reuse_len": null,
  "same_length": false,
  "start_n_top": 5,
  "summary_activation": "tanh",
  "summary_last_dropout": 0.1,
  "summary_type": "last",
  "summary_use_proj": true,
  "torchscript": false,
  "untie_r": true,
  "use_bfloat16": false,
  "vocab_size": 32000
}

INFO:transformers.modeling_utils:loading weights file /home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_f4eee8f6_2020-02-21_17-24-58rcg23wm1/outputs/checkpoint-3/pytorch_model.bin
HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=2975.0, style=ProgressStyle(description_width='initial')), HTML(value='')))
0.8512361.0810050.7702711.1079931.7497020.5797090.8022530.3443760.2728160.2600820.2557770.7288871.2422410.3253260.2530060.2466360.2451830.2441910.7192010.2676210.2431500.2413470.2407390.2402360.2397790.7152260.2572771.4822320.2827060.2395170.2377531.6650360.2818010.2383080.2367780.2365340.2363390.2361560.2359830.2358200.7115300.2471230.2356530.7111150.2459300.2352340.2348830.2347660.7105260.2442690.2346540.2343700.2342760.2341890.2341060.2340250.8554150.8662430.8661710.2444500.7097090.2414030.2336620.2334780.2334170.2333600.2333050.2332510.2331990.2331480.2330990.2330520.2330060.2329610.2329170.2328740.2328330.2327930.2327530.2327150.7085440.2385160.2326770.7084380.2382030.2325710.2324730.2324410.7082760.2377270.2324100.2323230.2322941.4752010.2454620.2323531.3295220.2434750.2322530.2321150.2320900.2320670.2320440.2320221.1837320.2410420.2320430.7078030.2363220.2319370.2318771.1835900.7162020.7119731.1877460.8615640.7130620.2358630.2317680.2317160.2317000.2316840.2316680.2316520.2316370.2316220.7074730.2353390.2316070.2315640.2315500.2315360.2315230.2315100.2314960.2314840.2314710.2314580.8529130.2359050.2314540.2314100.2313980.2313870.2313760.8528320.2356100.2313720.2313320.2313210.2313110.2313010.2312900.2312800.7071370.7101970.2343212.7168310.2469640.2313220.2312150.2312050.2311960.2311870.2311780.2311700.2311610.2311530.2311450.2311360.2311280.2311200.2311120.2311050.2310970.2310890.2310820.2310740.2310670.2310600.2310520.2310450.2310380.2310310.2310240.2310180.2310110.2310040.2309970.2309910.8524520.2342320.2309890.2309660.2309590.2309530.2309470.2309410.2309351.1826611.1874140.2356760.2309350.7067720.7090990.2332280.8523680.2338860.2308930.8523410.7096930.2331320.2308680.2308530.2308480.2308420.2308370.8523002.0980802.1428130.8609760.8551321.6612190.2372180.2308280.2307950.2307900.2307850.2307810.2307770.8522390.2334580.2307750.2307590.2307550.2307510.2307470.2307420.2307380.2307340.8521970.2333050.2307330.2307180.2307140.2307100.2307070.2307030.2306990.2306950.2306920.2306880.2306840.2306810.2306770.2306730.2306700.2306660.8521300.2330590.2306650.8521201.3303540.2348271.1823900.2342310.8521171.1846920.2341890.7065050.2323850.2306260.2306170.2306140.2306100.8520750.2328560.2306090.2305980.2305950.8520601.4757360.2350020.7064650.7081220.2322530.2305810.2305720.2305690.7064330.7080710.2322020.2305640.7064220.2321720.7064220.7080210.2321530.7064140.2321310.7064080.7079820.2321130.2305350.2305270.2305251.1822541.1853520.7094830.7079310.2320521.1822470.7094240.2320350.2305081.1822320.2335100.2305050.8519610.2324390.2304951.4734220.2343452.3857992.4317991.6648490.2348761.1822190.7092391.6595221.1865300.7092190.2319050.2304650.2304590.2304570.2304550.2304530.2304510.2304490.2304470.2304450.2304430.2304410.2304390.2304370.2304350.2304330.2304310.2304290.2304270.2304250.2304230.2304220.2304200.2304180.7062820.2317470.2304160.2304110.2304090.2304070.2304050.2304030.2304020.2304000.2303980.2303970.2303950.2303930.2303910.7062560.2316670.2303900.2303850.2303830.8518490.2320280.2303830.2303770.2303750.2303730.2303720.2303700.2303690.2303670.2303660.2303640.2303620.2303610.2303590.2303581.1820880.7086432.1350310.7110400.8530320.2319170.8518190.2319040.2303490.2303430.2303420.2303401.6579371.1855940.7085551.1832420.2326691.3276711.3303400.7088720.2314890.2303290.7061910.7073360.7073350.7073310.2314611.1820531.1843150.2325820.2303200.2303130.7061780.2314300.2303120.2303080.2303070.2303060.2303040.2303030.2303020.7061670.7072620.2313950.2302990.2302960.2302950.2302930.2302920.2302910.2302900.2302890.2302871.1820180.8538860.8531460.8531400.8531360.2316650.7061480.2313310.2302790.2302761.4732100.8544671.6198750.2333060.7061430.2313040.7061360.7071630.7071620.2312930.2302661.9490640.2339420.2302690.7061260.7071370.2312700.2302590.2302560.2302551.6578511.1849840.2322530.7061210.2312430.2302510.2302470.7061120.7070971.1829620.7080740.8526930.2315200.2302430.2302400.2302390.2302380.2302370.2302360.8517021.6197260.2330341.1819700.7080081.1829201.1838670.2321320.2302310.2302260.2302260.2302250.2302240.2302230.2302220.2302210.8516880.2314350.2302210.2302180.2302170.2302160.2302150.2302140.8516810.8528770.2314090.2302131.1819422.7175980.2349550.2302161.1425770.2319370.2302080.2302040.2302030.2302020.2302010.8516680.2313640.2302010.7060640.2310840.2301980.2301960.2301950.7060600.7069370.7069370.2310680.2301930.2301900.2301900.2301891.1819200.2319180.2301900.7060520.2310460.2301860.7060490.2310391.3275170.2321480.2301840.8516471.7651250.8543770.2312860.2301790.2301760.7060410.2310140.8516430.8527330.2312650.7060400.7068690.2310021.3275052.5723461.3315680.8535441.4741800.7081810.2309900.2301660.7060300.2309800.2301640.7060280.2309740.2301620.2301601.1818910.7076380.2309660.2301590.8516240.8526701.3285350.7078640.2309541.3274880.2319850.2301550.2301520.8516180.2311810.2301520.8516170.2311740.2301501.1818790.2317090.2301490.7060110.8523900.2311590.2301450.8516100.7070170.7067810.2309120.2301421.3274730.2319060.7060080.2309020.2301390.7060030.2308970.2301370.2301350.7060010.7067550.2308890.2301340.8516000.2311120.2301330.8515980.2311060.8515980.2311010.2301300.7059940.8523360.2310940.2301280.2301260.2301250.2301240.2301240.2301230.2301230.7059881.4737862.0964280.8544420.8525410.8525360.2310660.8515872.4257281.9522451.1844540.7074242.1343002.1364471.1847132.1350111.1847022.1350062.4276273.3010672.5749571.1853320.2315300.8515800.2310301.3274440.8531970.8524950.2310240.8515760.8524870.2310192.7159761.9525400.2326190.2301080.8515711.4739410.7077740.7066600.7066570.7066561.1825200.2314731.1818340.7073331.6583812.1356082.1362882.1362842.1362800.7086780.2307770.2300970.2300950.2300950.8515620.2309720.2300950.8515600.2309660.2300930.2300910.2300910.8515580.2309580.2300910.2300890.2300890.2300880.7059540.7066120.7066120.2307450.2300870.7059521.1824720.7072590.2307390.7059510.2307340.2300841.1424530.8527931.7647670.2321670.2300841.3274140.8530320.2309211.7639180.8536130.7067840.2307191.1424490.7071660.8521830.2309080.2300770.8515430.2309030.2300760.2300740.2300742.5703421.1849010.2313340.8515410.2308910.8515400.2308880.2300720.2300700.2300700.8515370.2308800.2300700.2300680.2300680.2300681.1424370.8527160.2308720.2300670.2300660.2300651.6183012.7177180.7091230.7065440.7065390.7065380.2306710.2300630.7059280.8521340.7067170.2306660.2300611.7638980.2319990.7059280.2306590.7059250.7065232.4253232.5730802.1364571.1841750.7071151.1823830.7071091.1823810.7071051.1823790.7071021.1823771.1829642.1346950.7082701.6582401.6594090.7076761.1823700.7070851.1823671.3285492.7172622.7189562.5336910.2328550.2300520.2300480.2300480.2300480.8515150.2307981.1424180.8526140.2307960.2300460.8515130.8522581.1431610.2311381.3273793.0081272.4280250.2326630.2300460.2300420.7059080.7064720.7064720.2306050.2300411.1817720.7070280.2306020.2300401.6182753.0084402.1367592.2813362.1359012.1357282.2813262.0968302.1356741.6598502.1351602.4269122.7181501.8061141.7656940.2318081.1817681.1828621.1828620.7069941.1823122.1345880.7080800.2305790.2300321.1424021.1434420.2310710.2300320.2300301.4729652.5717071.3300151.1830050.7069710.7064330.7064311.1822961.3284322.7171311.8060180.7076591.6581590.7074890.7064250.7064231.6581540.7074811.6581540.7074771.1822860.2310790.2300250.8514910.2307100.7058890.2305470.2300230.2300220.2300220.2300210.2300210.8514881.4736351.1831110.2310600.7058870.8520050.8521630.2306950.7058850.8520021.4736271.1830960.8525151.4736240.2313580.7058842.0949312.5722901.1842640.7069050.7063920.2305250.7058811.1822550.2310301.6576130.7074001.1822530.7068910.2305191.1817450.8524880.2306711.4729472.9684353.8823811.7676970.8530970.2306660.2300110.2300100.2300100.2300101.1817410.2310040.7058760.8519720.2306560.2300091.4729433.0080713.1549632.1365021.1837120.7068590.7063650.7063641.6580951.6590741.6590730.2314740.2300060.2300050.7058700.2304910.2300040.2300040.2300030.2300030.2300030.2300030.2300020.8514700.2306320.7058680.2304830.7058681.9492820.8532030.2306290.2300010.2300000.2300000.2300000.2299990.2299990.2299990.8514660.8520870.2306191.4729330.2312361.4729340.8527000.2306160.2299980.2299970.8514640.2306111.3273302.1345431.6594720.2314040.7058621.4733980.8526831.4735400.2312131.1423660.8523540.2306022.0547352.5323801.1446072.5314901.6598291.6589801.1831111.6585141.1831080.7067800.7063180.2304510.2299910.2299910.7058562.0551892.2808102.1354242.1352822.1352802.1352780.8532790.8520520.2305830.8514560.8520480.2305800.2299881.4729221.4741021.3285010.7068941.3277712.2407292.7177562.4270022.4267252.1355201.1835120.7067481.1821651.1826111.6584762.4259902.8632112.7183170.8537771.9493670.2315871.3273180.8524720.2305620.8514500.7064250.2304241.4729171.8043320.7073040.7062880.2304210.2299811.1423510.8522880.7064190.2304180.8514480.7064162.2401201.4747550.2311180.2299800.2299790.2299790.7058440.2304120.2299780.2299780.2299780.2299770.2299770.2299770.2299770.2299770.2299770.2299760.2299760.2299760.2299760.2299760.2299750.7058410.7062681.6579990.2312530.7058420.7062650.7062651.1821311.1825540.2308220.7058400.2303961.1817050.2308171.1817050.7066810.2303940.2299721.1817040.7066781.1821240.7066760.7062570.7062560.2303890.8514380.2305160.2299710.8514372.3858192.5718223.4449923.1548492.7180892.0568772.0956610.2315910.7058361.9491822.3867642.5721052.1354602.5718843.0087642.8635382.3875440.2318270.8514360.8519690.2305011.1816991.6583811.6587890.2311900.2299670.2299650.2299650.2299651.1816972.1342402.1350512.1350501.1833161.1825060.2307730.7058300.7062331.1820990.7066351.1820980.2307671.1816950.7066311.1820961.1824961.1824950.7066280.2303621.1816940.7066250.2303610.2299620.8514281.3278130.7067430.7062240.2303570.2299610.8514270.8519440.8519442.2401791.3289602.0949721.6591011.6587391.8043392.7168282.5719790.8533560.2304720.2299580.2299580.2299580.8514250.2304670.2299580.2299570.2299570.2299570.2299570.2299560.2299560.2299560.2299560.2299560.2299560.2299560.2299550.2299550.8514220.2304580.2299550.2299550.2299540.8514220.8519230.2304552.0943562.4261202.5719872.1352980.7073481.1820681.6583141.1828280.2307150.8514210.8519160.8519160.2304481.6181892.1345213.0079392.1356243.1535391.1840031.1824401.1824380.7065710.2303281.1816831.1824340.7065680.7061921.1820570.2307002.0943522.0958170.8528821.6580362.1345332.1349052.5714092.2808462.7171222.5721602.5717452.2808402.1350101.6590290.7069261.1820500.2306870.2299481.1816792.1341490.2314220.2299480.2299470.2299460.2299460.2299460.2299460.2299460.2299460.2299460.2299450.2299451.3272791.3281201.1825180.2306740.2299450.2299450.7058100.7061730.2303070.2299440.2299440.2299440.7058100.7061710.2303050.2299430.2299430.7058090.2303030.8514100.2304120.8514100.2304111.1423130.8520970.2304101.9487431.6588321.1827470.2306571.1816742.1341181.6589650.2310100.7058070.2302960.2299411.6575380.2310050.7058070.2302940.2299401.1816721.1823790.2306470.2299401.1816711.6582421.6585940.7068610.7061571.6578882.1344562.1348072.1348062.1348051.6589370.7068550.2302881.6575361.1827170.7065020.7061521.6578842.7168512.4264212.1350052.1347912.1347902.1347892.1347871.4742571.8040401.6586781.6585710.7068381.6578792.1344340.7071801.1820120.2306231.6575331.6585630.7068310.7061440.2302781.6575320.7068270.7061431.4732111.3281601.8039210.2310621.6575320.7068211.3276081.8039171.6192942.7167942.7175762.4263722.1349612.1347521.1830190.7064761.1820020.7064741.1820022.1340702.1347441.1830111.1823371.1823361.1823361.6582010.7068041.1819991.1823330.7064670.2302660.7057970.2302641.6575280.7067972.3855690.2314390.8513980.2303640.2299300.2299290.2299290.8513960.2303620.2299290.8513960.2303610.2299290.8513960.2303600.8513960.2303591.1422991.1429300.2305590.2299280.2299280.2299270.2299271.1422980.2305551.1422980.2305540.2299270.2299271.1422970.2305520.8513940.2303520.2299260.2299260.2299260.2299261.4728601.4737080.7066391.1819820.8520410.8518161.6579460.7067610.7061151.6578460.7067591.1819801.1823010.2305691.7637622.5712292.5717732.8626753.5902782.6783960.2315721.1422950.2305370.2299241.7637610.2309520.2299240.2299230.2299230.2299230.2299230.8513900.2303370.7057880.2302400.2299220.2299220.2299220.2299220.7057880.2302380.7057880.2302372.0546620.2311300.2299220.2299210.2299210.7057870.8517020.2303310.2299210.2299203.8794023.8818043.1543962.8630133.1537242.2809052.7171352.5718192.2805192.1347261.8043650.8524160.8517930.2303250.8513860.8517910.2303240.2299190.2299180.2299180.8513860.2303220.8513860.2303210.8513850.2303210.7057840.2302261.1816500.7063990.2302250.7057830.2302240.2299171.1816490.7063960.7060890.7060891.1819540.2305280.7057830.7060870.7060871.6578190.2308301.1816480.2305241.1816480.7063890.7060861.1425891.4734320.8521750.7061770.7060841.6184541.1431671.6187311.7646340.8523551.3276421.4735440.2307011.4728490.7065661.1425851.4734250.2306980.2299140.2299140.2299140.7057790.2302130.2299130.2299130.2299130.7057790.2302110.2299130.2299130.7057790.2302100.7057790.7060760.2302090.2299120.2299120.2299120.2299120.7057780.2302080.2299121.1816430.2305020.2299120.7057770.2302060.7057770.7060710.2302050.2299110.2299110.2299110.2299110.2299100.2299100.7057760.2302030.2299100.2299100.2299100.2299100.2299101.1816422.1339572.1345392.1345392.1345381.3284071.3279140.8520472.0946911.9498470.7068231.1425703.2981402.1352392.7166362.3867242.9683292.5321772.2410081.8043262.1343252.1345252.1345243.1531333.0084462.0959880.8525010.8517501.4732170.8521241.4732160.8521231.4732160.2306541.1816390.7063440.2301920.2299070.2299070.2299061.1816380.2304750.2299071.1816380.2304741.1816380.2304730.7057720.2301891.1816381.1822040.2304722.2396091.7649360.8522841.4732092.2403462.6773040.8528210.2302730.8513720.7061380.2301860.2299050.2299040.7057700.7060510.7060510.7060500.2301840.2299040.2299040.2299040.7057700.2301830.2299040.2299030.2299030.2299030.2299030.2299030.2299030.2299030.2299030.7057691.1819122.1339212.1344752.1344743.0074823.1535901.4745350.7064910.8516461.3275960.8520050.7061280.2301771.3272351.1822680.2304520.8513690.7061260.8516430.8517271.1819910.2304490.2299011.3272341.1822632.1339122.1344582.1344572.1344562.1344562.1344552.5712592.2803052.4257392.5714232.1347011.1827191.9492443.0076521.4744171.9494092.2799432.5713342.5711992.2802952.0954660.8524251.4731870.8520711.4731860.8520700.8517180.2302500.2298992.1333622.1344372.1344372.1344362.1344362.1344352.1344342.1344342.1344332.1344322.2800332.2801142.1345122.4256332.4257951.6193641.1824071.6580280.2306960.2298981.6574950.2306941.1816290.7062941.6577600.7065580.2301621.1816290.2304260.8513640.2302420.8513640.2302411.4728310.2305850.8513640.8517080.2302400.2298960.2298962.3852011.3284191.3278350.8519691.8034381.4736970.8520480.2302380.2298950.2298950.8513620.2302360.2298950.2298951.1422650.8518621.1426060.2303940.2298951.1422651.1427631.1427631.1427631.1427630.2303920.2298941.7637320.8521960.2302320.8513610.2302310.2298941.4728281.4735031.4735031.6581652.7162372.2803042.4256692.5710492.1346222.4255891.9498791.9496221.1825521.3277401.1822161.6186421.3279731.3278160.8519501.3275601.8036810.7066030.7060141.4730820.7064241.3274801.3278131.4734142.7164262.7170903.0079921.1437450.2303790.2298920.2298910.2298911.1422610.2303770.2298910.2298910.2298910.7057571.1425141.4733100.2305500.2298910.2298910.2298903.2975662.8626841.7651190.2307010.2298910.8513570.2302180.7057560.2301410.7057560.2301400.7057560.7060060.2301400.2298900.7057550.7060050.2301390.2298890.2298890.2298890.2298890.2298890.2298890.7057552.1336012.5708512.7166802.4258522.2407371.9497360.8522511.4731471.3278682.7163281.7650180.2306850.2298880.2298880.7057540.2301340.7057540.7060000.7060000.2301341.4728220.2305300.8513551.4731430.2305280.2298880.2298870.8513541.7640450.8521440.2302070.2298870.8513540.2302060.8513540.2302050.2298870.2298870.2298860.2298860.2298860.2298860.2298860.8513540.8516710.2302030.2298860.2298860.8513530.7060680.2301280.2298860.2298860.2298860.7057511.3274600.2304420.8513530.2302000.2298850.8513530.2302001.4728200.8519810.7060650.8515931.6577972.1340692.0949470.8522920.2301981.4728190.2305100.8513520.2301970.7057500.2301230.2298841.6574820.7064660.7059891.6577200.2305990.7057500.7059881.1818540.7062251.6577190.7064620.2301211.1816151.1820900.7062240.7059860.2301200.2298830.2298830.2298830.7057491.6577170.2305910.2298830.7057490.2301180.2298830.7057490.7059840.2301180.2298830.2298820.2298820.7057480.7059830.2301170.2298820.2298820.7057480.2301160.2298821.4728160.2304920.2298820.2298820.2298820.2298810.2298810.2298810.8513490.2301850.2298810.8513490.2301850.2298810.2298810.8513480.2301840.2298810.2298810.8513480.2301831.3272141.3277480.2304140.2298810.2298800.7057460.8515790.8516490.2301820.7057460.8515780.2301812.5304873.0077653.0076953.1532963.1533651.1830231.6579371.1823002.1338021.1825291.1820701.6579350.2305661.1816121.6579341.6581632.0949671.1431440.8517841.4731121.4734091.3278080.8518721.3275102.1338672.1342531.6583862.1340251.1825191.1820650.2303320.7057441.3274381.3277340.2304010.8513460.7060400.8515720.2301730.8513450.2301730.2298780.8513450.8516400.2301720.2298782.1333412.1342422.1342422.1342412.1342412.1342402.1342402.1342392.1342392.1342382.1342380.7066400.7059670.2301010.2298770.7057430.2301000.7057431.1818320.2303231.4728112.7163280.2310412.0942791.6583472.0949463.0075202.7170440.2310380.2298770.2298760.2298760.2298761.3272090.2303870.8513430.8516320.2301651.7637131.1429590.2303000.2298760.2298750.8513430.2301630.2298750.2298750.2298750.2298750.7057412.1335591.9495551.4736042.0948511.4736701.6580461.1822650.7061801.1818260.7061790.7059600.7059591.1818251.6579100.7063960.7059590.2300930.7057400.7059580.2300921.6574721.1822600.7061760.2300921.1816061.1820410.2303091.1816061.1820400.7061740.7059570.2300910.7057400.7059562.0944922.7165912.1344682.1342032.1342021.1824701.1820371.1820370.2303051.1816051.1820362.1337681.6583332.1339831.1824661.6579010.7063841.1818201.6579001.1822492.1337661.6583292.1339801.1824621.6578992.1339791.6583272.7163842.0953922.7165792.4256550.7067230.7059521.1818171.6578960.2305120.7057380.2300851.6574702.1339742.1341872.1341861.1824541.7641341.4734910.2304260.8513390.8516150.8516151.3274811.1820911.4732291.6580221.8037052.7164391.8041740.8520370.8516142.0945480.8521652.4248131.1825751.8034922.2796321.6583751.9493032.4252971.3281730.8518220.8516120.2301441.3272040.2303541.8030701.1429331.1426420.7061370.7059450.2300791.3272031.1427221.1426411.1426400.2302700.8513370.7060080.8515450.2301421.1422401.1426390.7061340.8515451.6183770.7063410.8515440.2301401.1422391.6185030.2304740.7057351.3274090.8518141.3274730.7062121.1424461.1426351.1426351.1426351.1426350.7061302.0548151.6188951.1428402.0550040.2306581.1422391.1426331.1426331.1426330.7061281.7639110.8519970.8516041.4730711.1427741.4731960.2304031.7637060.2305270.2298681.1422380.8517271.7639720.2305261.1422380.7061250.7059370.7059370.7059371.1424410.7061240.7059370.2300711.6181030.2304600.8513350.7059980.8515370.7059980.8515370.8515991.1425021.4731900.8518630.2301310.8513340.7059971.7639060.8519850.8515980.8515970.8515970.2301301.3272000.2303310.8513340.7059951.1424381.3275850.2303300.7057321.4730010.8518580.7059941.1424371.1426210.2302501.8030650.2305280.7057320.7059320.8515331.3274600.8517940.2301261.1422361.4731830.2303870.2298650.8513321.4730600.7062521.1424351.7640841.1428771.1426171.7640840.8519731.3274580.7061890.2300630.7057312.0548040.8520920.8515912.0548640.7064901.1424331.1426141.1426141.1426141.1426141.1426130.7061090.2300620.7057300.2300610.2298642.0546050.2306190.2298640.8513310.8515881.1424910.8517080.2301200.2298640.2298640.7057300.7059260.2300600.8513310.2301191.3271970.2303151.4727981.1427440.8517060.8515860.2301180.7057291.3273921.1426830.2302370.7057291.3273910.2303121.9486641.4735001.1427410.2302361.1422330.2302350.8513301.6183520.2304291.1422331.1426052.0549750.2306051.1422330.8517010.8515821.1424852.0549741.3279370.2303080.7057281.3273880.2303070.2298620.7057280.7059210.7059210.2300540.7057281.3273870.8517730.8515800.2301130.7057280.8515210.2301122.0546021.1429670.2302290.8513292.0548521.1429661.1425990.8516960.7059771.4729870.8518280.2301110.8513280.2301101.6180970.7062830.2300521.1422311.4731610.8518260.8515770.8515770.2301091.7636980.8519400.2301090.7057271.1424211.3275581.7641360.2304721.4727950.8518221.1424781.1425941.1425930.8516901.3274401.6185320.2304110.8513281.7639440.8519361.4730410.8518200.2301060.2298601.1422300.8516880.7059711.3273811.4732280.7062171.6182840.2304070.8513270.7059701.1424170.8516861.1424751.3275522.0550321.1429482.0549590.2305771.1422300.7060830.2300461.1422290.8516840.2301030.2298591.7636960.7063261.4729800.7062111.6182811.1427720.2302151.1422290.2302152.0545990.2305710.8513260.2301011.1422291.6184500.2303990.2298581.1422291.4731480.8518090.8515670.8515670.8515670.2300991.7636961.7642911.4733881.1427101.7640490.2304520.8513250.2300981.3271911.8034810.8519340.8515650.7059640.2300410.8513251.1424680.2302100.8513251.4730321.4732710.8518040.8515640.2300970.2298571.3271900.8517460.2300962.0545980.2305581.1422280.2302070.8513240.8515630.2300950.7057230.2300391.4727920.2303321.1422270.2302061.7636941.3277760.8517430.2300941.1422270.2302050.7057231.7638750.8519080.8515610.2300932.0545970.2305511.1422271.7640410.7063051.6182730.2303830.2298561.1422261.1425720.7060681.1424071.1425721.1425720.7060670.2300360.7057220.8515030.8515581.6183270.2303801.6180921.1427501.1425702.0549400.2305441.6180920.2303781.4727900.7061892.0547750.8520091.1424602.0549390.2305411.4727901.1426921.1425681.1425681.1425681.7640350.8518972.0548291.1429090.2301971.1422250.2301962.0545951.1429070.2301961.1422251.1425660.8516630.2300870.8513220.8515540.2300861.1422250.8516620.8515531.1424560.2301941.1422250.2301931.4727890.7061820.2300312.0545950.8519980.8515520.8515521.1424552.9673032.0556080.2305301.7636921.1427921.1425621.1425611.1425610.2301911.1422241.4731250.2303121.1422241.6184260.8518330.8515501.3274160.8517250.2300821.7636911.6186541.1427341.1425590.7060541.1423981.6184241.1427330.2301881.7636910.2304150.7057192.0547680.7063870.8514950.8515480.7059461.1423970.8516541.7639180.2304130.2298530.7057190.7058921.1817580.8516671.7639170.2304110.2298531.1422230.8516520.8515460.7059441.4729600.2303041.1422230.8516512.0548190.2305140.2298520.8513190.7059431.1423950.7060480.7058900.7058900.7058901.3273570.8517161.4730110.2303011.7636900.8518730.2300761.4727860.8517670.2300761.7636890.8518710.2300760.8513190.8515420.2300750.7057170.7058880.8514900.2300750.8513190.8515421.1424451.1425491.1425491.4731130.7061631.1423920.2301780.7057172.0547621.7643411.1427701.1425480.7060430.7058871.1423911.1425471.1425471.1425471.1425461.1425462.0549160.7063670.7058860.7058861.1423901.1425450.2301750.2298510.8513181.1424410.8516421.6183070.7062090.8514870.2300711.1422211.1425441.1425441.1425440.2301730.7057160.8514860.2300701.1422201.1425431.4731070.2302891.6180860.8518070.2300690.7057160.8514850.8515360.8515361.1424391.1819031.7640221.1427590.8516380.8515350.8515351.1424381.1425400.7060361.1423871.3275030.8517010.8515350.2300671.7636872.2400902.0552930.2304880.2298491.6180851.1427041.1425380.2301680.8513160.8515330.8515331.7639030.8518511.6183020.7061981.1423850.2301660.8513160.7059310.8514820.8515321.1424350.8516330.8515321.6183010.7061961.1423840.2301650.8513161.1424340.8516321.1817960.2301781.1422191.1425341.4730991.1426482.0549040.8519461.1424330.2301631.1422180.7060291.1423831.1425331.1425331.1425330.8516300.7059281.1423821.4730960.2302750.8513150.2300611.3271811.4731591.1426451.7639991.1427440.7060270.8514781.6182970.8517911.6182970.2303230.8513152.0548011.1428421.1425301.7639971.1427421.6183951.1426921.1425290.7060251.7638470.7062361.3273430.8516881.1817910.7060370.8514761.7638961.1427390.2301571.4727820.7061351.4729430.2302691.1422170.2301562.0545871.1428361.1425260.2301560.2298470.8513140.2300570.8513140.7059230.7058731.1423780.2301551.1422171.1425251.6183912.0550560.7063281.1423771.1425241.1425240.2301540.2298460.8513130.8515231.4729900.8517321.181787

*******************************************
EVALUATING PIPELINE 
Pipeline directory: /home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_f4eee8f6_2020-02-21_17-24-58rcg23wm1/
With following parameter combination: {'batch_size_seq_length': 1, 'lr': 4e-05, 'lr_type': 'constant'}
EVALUATION OF CHECKPOINT /home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_f4eee8f6_2020-02-21_17-24-58rcg23wm1/outputs/checkpoint-3
-------------------------------------------------------------
|           |   agree   | disagree  |  discuss  | unrelated |
-------------------------------------------------------------
|   agree   |     0     |     0     |     0     |     0     |
-------------------------------------------------------------
| disagree  |     0     |     0     |     0     |     0     |
-------------------------------------------------------------
|  discuss  |     0     |     0     |     0     |     0     |
-------------------------------------------------------------
| unrelated |   1037    |    468    |   1779    |   8614    |
-------------------------------------------------------------
Score: 6460.5 out of 9226.0	(70.02492954693258%)
Accuracy: 0.7239872247436544
F1 overall: 0.20997464898595944
F1 per class: [0.0, 0.0, 0.0, 0.8398985959438378]
*******************************************


*******************************************
EVALUATING PIPELINE 
{'batch_size_seq_length': 1, 'lr': 4e-05, 'lr_type': 'linear'}
INFO:__main__:Creating features from dataset file at /home/ubuntu/fnd_implementation/data/processed
  0%|                                                 | 0/11898 [00:00<?, ?it/s]  0%|                                       | 1/11898 [00:01<3:48:48,  1.15s/it]  4%|â–ˆâ–Œ                                   | 501/11898 [00:01<2:33:30,  1.24it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                  | 6001/11898 [00:01<55:35,  1.77it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11898/11898 [00:01<00:00, 6319.90it/s]
  ******************************************* 
              Running Evaluation                
  *******************************************
 
  Length dataset evaluation: 11898
  Length dataloader evaluation: 2975
  Number of epochs: 3
  Batch size: 4
  ******************************************* 
 
['/home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_00815366_2020-02-21_23-19-0260ddp99c/outputs/checkpoint-3']
INFO:__main__:Evaluate the following checkpoints: ['/home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_00815366_2020-02-21_23-19-0260ddp99c/outputs/checkpoint-3']
INFO:transformers.configuration_utils:loading configuration file /home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_00815366_2020-02-21_23-19-0260ddp99c/outputs/checkpoint-3/config.json
INFO:transformers.configuration_utils:Model config {
  "attn_type": "bi",
  "bi_data": false,
  "clamp_len": -1,
  "d_head": 64,
  "d_inner": 3072,
  "d_model": 768,
  "dropout": 0.1,
  "end_n_top": 5,
  "ff_activation": "gelu",
  "finetuning_task": null,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "mem_len": null,
  "n_head": 12,
  "n_layer": 12,
  "num_labels": 4,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pruned_heads": {},
  "reuse_len": null,
  "same_length": false,
  "start_n_top": 5,
  "summary_activation": "tanh",
  "summary_last_dropout": 0.1,
  "summary_type": "last",
  "summary_use_proj": true,
  "torchscript": false,
  "untie_r": true,
  "use_bfloat16": false,
  "vocab_size": 32000
}

INFO:transformers.modeling_utils:loading weights file /home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_00815366_2020-02-21_23-19-0260ddp99c/outputs/checkpoint-3/pytorch_model.bin
HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=2975.0, style=ProgressStyle(description_width='initial')), HTML(value='')))
1.6870081.6870630.8435860.2818740.0718660.0144020.0050240.0007590.0001460.0000570.0003810.0014461.4732120.1133540.0081270.0005720.0000690.0000351.6152670.0850440.0042820.0002360.0000420.0000330.0000320.0012260.0000771.1708190.0418470.0014740.0000820.0230841.9650660.0595960.0018000.0001140.0000671.8021170.0474780.0019850.0006940.0000660.0000400.0004170.0000390.0000320.0000350.0000310.0003310.0000390.0000320.0000340.0000300.0000300.0000320.0000391.6301731.7225371.3931681.9659260.0331000.0006100.0000731.8221970.0285310.0004940.0002011.9062812.0131000.0292630.0004860.0022690.0001160.0006810.0000860.0047410.0002561.8715830.1947320.0025241.8554731.9775560.0241871.9552930.0260501.9028841.9805100.0228341.3554650.0153341.8954650.0208960.0003040.0013230.0000460.0000320.0534130.0006000.0000760.0000710.0000740.0000510.0000470.0000510.0050500.0000990.0000720.0010220.0000790.0000860.0000521.1492381.1589031.1634762.2868071.1252961.1573760.0099390.0001310.0000490.0000460.0000480.0000470.0000470.0000470.0000450.0005910.0000500.0000470.0000500.0000490.0000490.0000480.0000470.0000490.0000454.8702653.9785013.6722870.0264491.9920913.9334780.0280791.9311812.0618011.3236540.0091110.0001080.0000460.0000690.0000460.0000470.0000460.0000590.0003550.0126880.0001250.0093270.0001212.1248800.0145300.0001240.0000550.0000330.0000330.0000320.0000850.0000360.0000310.0000530.0000360.0000340.0000440.0005240.0000360.0000370.3329590.0019150.0000450.0000340.0000320.0000380.0000320.0000370.0000320.0000450.0000320.0000310.0000370.0000370.0007150.0009200.0000372.0893830.0186870.0001911.7776133.5488705.1556321.8688441.5094833.6246353.5778530.2552250.0028250.0000470.0019760.0000370.0000290.0013950.0003160.0000300.0000290.0000370.0000290.0000300.0000300.0007340.0025440.0022421.5140231.5157110.1964930.0009590.0000750.0000710.0000700.0000810.0000780.0000821.6085580.0069950.0000580.0000280.0000290.0000280.0000280.0000290.0000280.0000280.5480640.0023020.0000390.0000290.0000290.0000290.0000290.0000300.0000300.0000290.0000290.0000290.0000290.0000310.0000290.0000290.0000300.0000290.0006880.0000320.0000300.0045970.0048620.0000510.0016670.0000441.6978700.0085081.7847490.0081310.1104490.0173730.0064320.0000770.9083350.0115480.0000720.0000320.0000300.0000320.0007780.0015290.0000381.6559831.6509810.0058930.0000530.0000320.0000331.6576621.6609930.0057400.0000530.0006680.0000490.0007930.0028230.0000640.0008240.0000660.0012220.0003360.0000500.0000600.0000560.0000480.0017300.0024970.0309030.0005280.0000520.0042960.0004620.0000440.0000600.0013590.0000620.0000670.0006560.0000390.0001110.0012860.0000450.0089580.0038160.0011690.0000610.0230200.0013870.0051670.0023300.0622470.0002300.0000440.0000450.0000430.0000420.0000390.0000440.0000420.0000430.0000430.0000430.0000420.0000420.0000430.0000420.0000440.0000430.0000460.0000430.0000450.0000430.0000420.0000440.0000430.0088920.0000680.0000420.0000430.0000420.0000450.0000440.0000430.0000430.0000440.0006030.0000450.0000420.0000440.0000430.0491440.0001760.0001790.0000350.0000350.0032860.0000430.0000340.0000330.0000370.0000420.0004430.0000360.0000371.6008740.0041800.0000460.0000330.0000351.0203460.0026460.0007960.0007190.0018030.0003740.0013810.0000390.0007450.0000700.0000360.0000390.0000340.0000340.0015940.0041390.0024580.0010591.8204711.1002160.2272230.0009340.0000390.0000340.0003750.0004990.0004840.0002990.0000360.0011550.0006270.0000450.0001490.0000830.0012140.0001470.0000710.0000630.0000300.0000300.0000310.0000310.0000300.5337870.0016540.0000350.0000310.0000310.0000300.0000310.0000300.0000310.0000300.0000300.0000310.0233870.7204750.0994300.0030890.0327770.0001100.0079880.0009620.0000460.0000391.3841130.0298641.4750120.0032640.0099200.0000681.9734260.0077350.0032450.0000540.0000500.0045550.0000520.0000300.0013780.0102760.0000510.0000310.0000290.0000290.0703710.0011480.0000490.0011880.0000450.0000450.0000470.0005330.0004500.0008520.0012411.3062280.0027150.0000390.0000330.0000310.0000330.0000350.0000370.0069102.2325540.0047060.0030440.0015070.0011250.0019270.0000380.0000330.0000330.0000331.9866820.0039600.2582700.0005480.0000340.0007990.0000350.0000330.0000340.0000340.0000330.0000370.0000330.0007940.0011160.0000310.0000300.0099351.1206400.0021730.0000380.0972980.0002180.0000360.0000350.0000580.0000350.0000360.0012940.0000860.0000300.0014240.0000430.0000410.0000400.0000410.0003270.0002890.0012490.0000440.0000390.0000420.0000510.0000520.0058140.0000510.0000390.0002990.0000530.0000280.0003570.0000321.0256810.8380970.0015432.3856391.6433540.0055240.0011940.0000380.0000290.0003210.0000300.8800161.2146460.0021720.0006930.0012050.0000511.3861600.0158530.0012600.0007810.3393970.0578890.0001550.0000580.0004270.0000450.0000500.0003660.0000550.0000520.0000540.0008490.0004130.0000330.0000290.0037680.0043850.0016780.0006480.0000320.0011140.0000330.0000320.0000320.0006620.0000330.0000310.0006650.0000340.0000370.0158790.0000710.0000390.0306090.9903080.0452770.0001141.2360020.0041320.0079730.0000520.0000681.2357420.0020300.0021950.0000450.0000390.0031220.0002360.0000480.0000380.0170160.0019760.0000410.0000431.7297410.0027720.0000501.8118040.0028911.8299290.0029100.0000520.0008881.7050510.0026950.0000510.0000460.0000470.0000560.0000430.0000450.0000440.0007100.0015060.0022600.0007990.0007710.0008120.0000330.9613130.0059840.0996371.7819851.4858100.0059233.4200290.0127551.5999770.0037590.0448390.0188751.6436961.5514990.0030860.0000331.7141290.0025680.0079050.0483660.0012020.0000290.0017010.0027210.0000313.5377450.9411280.0014020.0000300.0007130.0020540.0041490.0016370.0021170.0008300.0012480.0004070.0013030.0016560.0592470.0995410.0604940.0030230.0027580.0003840.0009730.0000350.0000310.0000320.0006780.0000320.0000330.0006770.0000310.0000300.0000320.0000310.0006770.0000320.0000340.0000350.0000330.0000330.0018340.0005160.0009281.1633510.0016420.0003630.0009490.0005420.0000760.0007440.0000330.0015591.5927260.6069312.5345780.0034800.0000440.3723631.2258970.0016951.3022670.6700530.0200530.0000600.0065851.4078290.0025280.0000320.0000300.0006850.0000330.0000290.0000290.0000304.3674050.4216040.0005870.0007200.0000340.0014510.0000320.0000400.0000310.0000310.0006900.0000340.0000300.0000310.0002710.0000320.0083310.0017680.0203270.0000570.0006680.0000880.0337450.2134220.0005860.0004220.0002980.0002940.0000320.0000311.6600210.0028060.0004040.0000310.0000310.0082950.0000410.0003790.0000310.0003000.0003193.4534905.2044740.0085900.0333770.0011740.0012640.0016420.0038960.0010180.0015050.0006910.0021090.0025070.0029360.0003800.0027300.0023690.0009460.0023810.0011380.0019200.0027300.0027170.0030233.1861980.0039140.0000370.0000320.0000320.0000330.0012810.0000360.1629180.0010330.0000330.0000330.0013050.0027580.0196740.0000570.0023333.1771493.0791790.0037110.0013350.0000470.0004700.0003850.0003130.0000340.0000320.0007300.0005810.0000340.0000332.1885756.0883130.0086471.2547330.0040080.0115150.9084190.0039250.0147560.0016300.0025380.0072380.1325230.0014081.6937620.0069641.1899240.0019400.0008660.0005010.0006452.5524740.0476650.0000860.0000421.0180371.4488800.0016800.0000370.0001080.0013470.0029130.0013490.0031440.0957610.0234871.6591370.0187920.0515990.0031030.7900250.0017640.6565670.0009990.0003170.0004870.0008450.0854720.0048300.0002860.0355630.0003190.0000501.6825450.0019170.0007040.0000410.0000410.0000420.0000410.0000450.0000501.6472473.2103030.0048230.0000460.0005651.6426951.5232900.0017100.0003521.7983823.3801480.0046151.3520763.2615361.9348510.0024260.0020800.0389350.0013610.0333240.0004640.0000500.0004870.0264860.0000830.0627530.0005250.0251020.0032530.0000500.0583200.0011410.0001050.0016600.0199800.0341461.4966440.0032461.4227180.0015260.0000310.0000290.0000290.0114150.0000420.0248010.5589620.0006110.0000300.0017060.0179030.4741830.0015390.0006510.0003670.0002970.0003740.0008260.0008450.0012090.0001020.0001110.0001180.0018540.0001300.0003880.0007830.0001021.8384890.0025930.0004330.0000560.4830090.0005230.2459000.0028000.0003500.0748850.0706881.8992291.9512860.0024160.0007290.0014971.0699070.0011330.0001880.7668350.1832430.0073000.0017830.0000330.0017901.1256950.0011590.0000390.0000440.6730480.0007061.1730540.0050610.0028020.0000370.0003430.0021640.0016150.0028740.0000380.0067840.0008460.0001670.0137930.2325210.0067790.0163410.0033500.0031480.0017300.0027631.3804670.0022610.0003120.0000300.0000290.0000311.6484162.9949430.0053200.0027240.0028520.0137790.0080020.0007860.0044330.0000330.0451850.8968560.0008830.0000340.0125060.0572560.0091040.0008130.0052090.0677120.0055110.0413560.0093501.3667360.0019130.0037460.0159970.0006860.0053600.7531241.5636070.0169780.0122270.0046980.0000351.4455920.0057890.0000340.0017070.0004460.0000290.0028911.4734680.0016760.0004090.0000360.0000392.1455781.8131010.0019370.0000421.4766990.0018233.8539143.2841730.0030580.0000550.0000510.0000500.0011190.0000510.0000510.0000510.0000500.0000520.0000511.7493430.0016330.0000530.0000510.0000530.0000540.0000490.0000510.0000520.0000520.0011260.0012060.0063520.0000370.0005770.0006640.0008850.0014790.0009800.0000300.0003940.0000300.0039160.0000420.0025270.0015320.0000411.8354560.0033600.0008150.0018580.0002780.0012791.6032140.0014750.0006770.0000450.0000390.0006850.0080750.0103150.0351820.6094260.0106494.1071162.2373870.0019800.0009843.6461704.2421412.8445680.0040410.0088320.4167751.4530611.6406050.0014440.0006960.0007950.0000302.3676900.0186020.0294250.0000750.0000490.0000490.0000500.0000740.3460741.4080490.0033691.6223850.0472400.0011410.0000520.0003290.0008220.0021350.0008470.1083890.0001540.0365110.0779270.1205340.0911950.1483220.0004230.0000530.1143780.0266880.0000550.0000340.0006750.0016860.0008790.1091430.0001240.0000320.0006980.0007110.0007592.1910371.6714681.9690140.0030570.0014821.7560493.5665912.0709830.0026300.0000330.0000300.0000310.0004180.0008850.0000330.0000310.0000300.0000360.0000530.0000310.0024090.0000320.0000330.0000310.0000430.0000320.0001410.0000300.0000310.0008570.0000330.0000340.0006890.0000310.0008530.0012710.0000320.0022630.0298910.0685930.0268910.0012620.0044130.0091730.0044690.0000350.0007120.0007190.0006940.0000322.0954310.0027074.4021080.0045554.3071910.0039940.0006140.0007730.0003700.0000760.0005910.0008730.0003380.0003510.0005990.0000580.0100530.0038660.0012782.7631384.3352492.1625551.3958200.4001653.0829394.4171361.7229881.3062100.0028970.0017530.0006910.0008570.0000400.0000400.0008080.0024190.0000420.0000390.0000390.0000420.0000310.0000300.0000370.0000330.0000320.0000290.0017560.0000301.7660781.7312140.0019370.0000330.0000290.0000300.0004260.0013600.0000480.0000460.0000730.0000470.0016470.0010210.0000480.0000470.0000480.0013230.0000300.0008160.0000300.0008300.0000290.0275340.0008560.0000310.0022173.2665100.0060640.0000581.9659670.0399490.0029500.0000360.0002600.0000320.0000350.0010990.0000350.0002630.0000350.0000350.0005840.0004940.0000340.0000320.0006350.0007570.0008520.0002600.0003280.0009310.0011240.0012840.0015020.0014710.0061400.0003840.0138560.0011020.0008370.0006630.0004100.0014460.0201952.8067942.7991903.9934243.9131204.2138553.4583600.0039330.0372460.0399510.0598980.1584520.0021630.0041090.0011690.0014980.0000590.0026890.0021310.0009050.0008790.0000510.0019970.0011880.0011542.0565570.0028160.0029960.0000310.0023300.0012570.0014980.0084131.1925570.0034490.0026080.1977612.7259780.5685510.0069580.1078410.0013000.0031820.0012910.0014730.0030590.0018980.0053890.0485410.0028750.0299840.0012290.0360330.0063750.0014180.0000600.0393220.0000830.0496200.0007610.3295210.0002640.0014970.0000340.0000400.0000360.0000330.0007120.0000330.0000510.0007480.0000340.0000330.0012260.0006360.0081770.0000351.5658511.4969020.0010640.0000340.0000300.0000300.0000291.5915160.0011261.5911750.0011480.0000320.0000291.5404570.0010860.3000530.0002360.0000290.0000310.0000750.0000290.0037100.0102800.0008550.0005580.0056900.0017800.0041870.0006390.0073860.0385670.0005410.0011900.0051610.0000630.0074090.0235110.0023090.0102360.0204680.0261600.0000700.2234220.0001850.0000362.1975960.0015090.0000370.0000330.0000360.0000350.0000320.0007360.0000290.0004120.0000290.0000290.0000290.0000280.0000280.0003230.0000290.0003220.0002320.0278640.0000470.0001980.0000280.0000300.1740031.8242970.0012330.0000290.0000290.0284540.0281270.1849030.0090860.0155760.0014630.0028580.0022970.0015250.0550860.6753840.8488930.7908770.0005810.6698701.1917620.0008580.0000480.0000590.0000881.2930840.0009790.5829990.0004270.6405200.0004860.0003570.0000300.0006320.0011170.0000300.0004750.0001220.0003850.0007460.0003650.0004590.0004020.0007430.0005840.0004340.4549320.0006750.0011260.0000420.0009170.0000390.0088440.0006130.0004411.7152542.9880481.6068410.0016030.0007101.2802640.9664751.1334232.7586801.5342311.5495473.1061980.0020512.9565660.0024970.2640023.1917510.0020420.0000310.0000280.0000281.0882390.0007120.0000280.0000280.0000280.0009110.0000290.0000280.0000280.0006920.0000290.0005500.3876040.0002700.0000280.0000280.0000300.0000291.6229980.0010380.0002540.1944030.0001490.0000281.3004490.0008340.0011330.3499630.0002450.0000280.0000280.0000280.0000280.0000280.0000281.4083360.0009000.0000290.0000300.0000280.0000280.0000290.0009720.0302730.0045500.0073660.0024050.0015250.1608091.4132363.1486041.3479050.0037440.0072160.0183285.6382193.5006071.0797700.6354000.9265780.1676770.0036180.0032700.0019200.0018912.2442901.4334223.9369601.0887611.3831571.4387131.2102592.7615880.7992751.5728540.0009810.0212380.0005220.0000360.0000440.0000960.0000390.0012410.0007080.0002040.0010480.0000410.0011740.0000410.0075350.0000420.0008640.0059820.0000430.0417980.0167360.0030850.0067340.7211230.7161050.0017880.0000370.0008910.0018560.0000440.0000420.0000400.0006360.0003070.0003970.0004720.0000410.0000420.0000420.0000430.0006840.0000420.0000420.0000420.0000440.0000630.0000400.0000400.0000390.0001570.0000410.0015923.1627003.1520271.6263704.8513193.8039350.1388643.4297510.0024091.5927061.4191531.4910900.0015120.0001251.3473340.0016560.0003151.7877050.0024331.5966823.1085040.0025780.0000410.0000341.6627330.0017180.0011950.0028610.0013060.0024560.0028780.0011924.3394951.5554752.7273424.1968620.0047220.0005950.0018081.6385950.0024251.3555421.7059251.5575231.8710011.7659430.0422680.0015860.0029160.0012050.0023630.0014180.0014500.0000450.0000430.0116650.0197260.0482560.0192980.0052050.0056720.0248060.0089180.0069160.0141351.7834301.7095970.0270513.4678011.7412551.2706880.0029570.0023810.0000510.0000420.0109430.0000520.0015890.0007120.0025630.0046700.0000530.0011940.0000340.0011900.0000300.0013720.0000300.0022160.0000310.0011910.0011520.0000310.0000300.0000300.3063670.0514900.0029450.0009260.0057500.0015290.0007500.0010350.0012970.0003100.0016470.0000310.0008911.7149881.8277001.1680421.7369600.0009810.0000371.9150911.8598501.9071721.7455801.9317130.0010830.0000381.8126890.0016740.0000350.0006950.0000330.0000332.9552392.7549020.0028940.0015553.1576151.3725551.7665551.9524650.0029982.6876162.6491620.3444370.0008050.4050650.0008211.1637860.4648380.0013250.0108951.0685680.0077040.0004410.0014500.0040450.0005230.0099940.0026640.0024350.5951770.0072331.3923952.0824510.0011420.0000340.0000310.0000352.0839610.0011410.0000330.0000310.0000320.0006152.0817074.7510010.0025490.0000340.0000320.0000337.8199251.7174641.5532510.0008540.0000340.0006570.0000330.0029740.0000371.8443500.9839730.0009850.0007420.0000390.0000330.0004750.0005301.1087140.0006130.0017590.0001340.0000470.0000351.3815082.9999880.0543610.0257990.0087771.8211470.6757850.9335431.1850182.0411850.9643090.0101541.6130750.0008850.0000480.0000480.0008320.0000460.0022610.0011370.0009710.0000350.0233960.0000430.0013420.0020240.0000320.0000310.0000320.0012711.8377090.0018750.0000310.0000470.0043890.0000330.0009360.0000420.0000410.0000420.0000430.0000390.0000400.0000390.0000411.5246210.0015860.0000430.0000420.0002351.5628760.0019990.0000540.0000410.0000500.0000380.0020351.7129630.0009171.2754950.0006870.0000410.9829540.0005381.6604161.4529610.0850411.6292980.0063590.0015461.2503490.0013220.0000390.0014310.0000290.0007160.0000600.0087790.0000900.0001010.0210950.0295160.0011190.0032150.0001390.0010400.0010170.0158950.0009870.0213180.0088230.0000870.0406930.9303750.8972081.6572040.0008570.0000320.0000320.0000330.5353294.8105020.0024210.0000341.0939480.0005740.0000321.0939491.2854570.0006670.0000310.0000320.0000321.0574631.1710800.0006140.0000360.0000360.0432520.0000580.0000360.2486040.0001600.0000400.0000360.0000510.0000370.0000350.0004830.9704970.0005410.0000380.8287910.0004400.0000350.0000360.9400630.0004960.0000350.0000380.0007030.0000310.0009980.0010400.0000310.0000310.0000300.0003150.0007250.0007170.0000311.6655080.0016570.0000310.0677030.0092250.5497000.4374302.0226730.0020810.0009660.0035950.0019220.0008940.0006400.0017620.0001780.0006040.0011190.0015340.0020561.5360720.0014150.0013500.0013470.0012340.0006840.0009690.0010990.0865590.8219292.0394640.0017522.3940560.0011710.0003650.0032061.0616900.0005380.0060941.0412750.0026070.0000350.0023090.0000350.0000330.0048370.0028720.0000400.0000340.0028180.0025980.0010870.0012810.0018200.0027750.0039930.0030490.0032300.0139670.0022060.0005890.0006180.0000630.0000710.0006420.0001820.0011022.0899020.0010500.0016020.0030540.0000392.6413410.0088284.2833364.1920802.1691470.0011360.0000290.0000300.0000300.0000320.0015090.0000330.0024440.0007400.0000290.0106770.0106460.0000590.0000310.0000460.2492940.0001450.0000360.0000330.0000300.0000291.4545633.6672090.0071570.0019920.0030890.0021892.5043621.2756860.0008770.0006581.2868360.0009091.1740890.0011152.0045620.0033750.0002500.0000411.2638370.0009121.9029842.2374080.6242131.2636020.0006141.3091450.8957840.0004370.0188970.0021390.0048400.0003030.0000340.0005120.0002730.0021690.0029310.0311080.0081060.0030010.0025280.0022540.0017480.0000390.0022741.3047500.0229780.0043010.0348680.0185200.0103600.0008930.0118560.0066710.0043370.0329171.2325990.0215260.0157830.0187690.0079590.0035260.0026560.0019520.0025730.0020290.0006320.0007130.0014900.0008190.0000360.0003290.0007790.0011424.4335152.8160763.6040661.5566170.0087180.0016710.0000360.0007560.0007960.0007351.8998770.0029980.0231650.0017760.0028010.0035480.0019740.0009010.0008280.0023150.0007620.0030490.0018600.0039660.0043190.0025280.0037420.0028630.0014980.3364660.2346860.0009880.4608800.0457790.3734010.2400570.0087793.4887051.4498370.0006721.5161870.0086420.0077360.0077390.0000480.9936301.1274641.0090400.0004990.0078460.0091501.1568730.3332670.4614940.0440420.2497710.0004201.0474240.7738710.0082770.1167271.5693030.0027820.1014731.5978970.0081340.0080230.0078850.0088942.1941122.5627170.3281550.2539080.0080400.0154500.0004550.0113390.0097770.0076750.0077151.1271331.6765580.1917390.0066472.2212592.0812410.0036980.5298301.1508100.0006800.0000502.1409950.0018232.6682010.0017650.0190190.7136330.9775331.8285970.0528240.7352140.1334261.8457750.0009850.4747880.0002780.5396130.5039990.0841042.6468310.4172980.2624930.2181650.7549030.3063670.0001690.7488470.4411553.2664480.6705321.7586930.4503550.0028050.0003420.5763600.0004600.0037210.9778841.5942201.4969450.0010801.2697400.0058900.4265720.9031440.0097760.0199220.0004883.0293890.0016190.0807530.4225052.2741562.0753220.0069210.0000400.1651760.2757020.0001540.0000390.0234740.0111020.8413620.0100500.9644350.0108700.0083260.7746890.6870191.8422800.8432110.2228960.0732392.6675320.0026180.6847190.0647501.1319790.0088780.0083690.0170370.0078720.3372280.0436281.7479800.0008310.9281790.0060550.6357113.3616780.0015860.0024310.0189480.3631332.5263590.3978660.0023100.0016770.0001481.7011711.3860080.0007960.0015350.0006822.1252470.0010231.8750480.3463301.9067540.0031160.0000970.0322951.1779121.1945920.0016512.1645650.0571110.0039471.6158371.9950792.1047780.0097901.9032570.0008220.4696562.0764660.0009720.0090950.6676981.8100230.0241530.0085450.6861371.4282060.0087930.0150520.4804390.0004620.0468954.0343700.7112010.0003760.1505690.2791340.0693780.0001840.1371001.1463000.7231240.0058670.0000360.1761690.4699610.0008070.0150830.7675570.0019821.0077930.0170000.0121811.1523220.2296410.0494830.0156250.0059000.0002440.0238550.0002731.8516700.9764280.0004460.9477861.2298460.0013030.0020300.0010990.0000650.8761600.0012340.0000400.1334941.3270703.0834671.1795290.0026430.0056930.7392840.0087640.0102290.0089020.0059630.9127742.3061310.0025060.5576690.4446130.0082650.0950980.0022980.0000630.1725530.3523760.2257001.8790652.1640411.3097611.1378191.7875650.0007680.9676360.8987220.1955451.5250682.1754670.4234481.2707430.0087091.1261160.0005350.9787140.0676450.0005260.1897282.4345950.0030030.0014661.1634340.1316171.1628550.0934090.8310312.1042560.0009080.0089240.0000520.3822330.0003030.4336750.0002670.2882371.6942600.0007410.7036160.0174131.8140070.8720500.5648960.0027500.1877710.0001511.4991642.4574830.6768700.8794201.8515790.0007620.0043550.0000402.4343601.2701120.3671180.3273530.0950690.0000800.0013781.3857610.0006710.5176601.2488240.6776980.9878140.2982960.2119070.0018710.4515330.4376980.0002660.6106880.0002950.4710820.0002440.3614400.0476720.0001250.0820940.9006100.0098240.0001211.2404690.0009181.0507611.1876140.7099360.9361930.0083080.0000920.4420591.4659911.8985230.9824960.8426193.1299640.0012650.0077150.9804761.1064700.3599560.0001850.0017110.3758060.4796580.0379560.6859750.7099901.1088382.5089140.0010711.0223370.5268650.1234491.8194410.0008600.0552110.0085480.0082730.0369430.0011041.4763540.0009890.0068661.1346170.6317101.0062850.0080340.0170290.0000652.0029530.0083240.0083220.0077560.0079200.6146021.0050780.0156690.0078740.0001950.0079561.6379270.0159390.0078210.0024791.1593701.1140310.2287470.0002710.0089850.0012320.0002201.9648660.9800451.0204720.0096890.0001192.8915280.5197221.9898200.4439090.0003423.0552770.9760291.0013900.0485720.0074430.0223520.0162480.0038491.0111600.0084830.0074420.0074160.0074470.0000440.0075292.0236631.9242670.0133411.1878570.8837410.8783621.4586760.2734240.0001961.0048251.4293590.0117281.8148560.2283640.0100551.4352250.0093020.0002620.0675910.0000671.0989360.9023040.2063440.0035940.6123421.1179430.6971940.7255731.0383400.0004320.0000530.5550501.1868421.5349970.6607870.0334160.0001280.0000570.0081051.0315750.6154710.4825831.0129480.1035200.7554770.4076400.0179230.0000890.0001110.7058010.0596460.0077992.4604930.6713500.0507142.0443980.2015360.0082592.1646050.0010491.1631820.0018030.0000350.0071550.0031860.0011630.1470690.0022770.0000600.0015890.0027120.0000650.0004490.0531250.0007460.0000410.0007900.6176423.7699210.0141490.0075361.7415241.3736700.0314040.0031640.3255162.5193130.0234560.0079630.0075291.1389152.6013220.0086392.9045790.0085610.0078430.0090101.1924002.2999880.2599980.1408140.2873240.0518230.0080600.0043360.0188710.8612800.2200590.8174961.3268812.8177150.0039360.0005550.5185250.0110020.0082620.3593100.0009102.4653600.2633480.9295670.1245240.3996792.8091720.8256970.6553420.2658200.0001941.2732720.2795610.0080920.2021250.3342371.8173480.6558262.5840340.0271000.1675040.3443830.3138502.8606600.3997712.3603651.2231460.0077103.5147760.0015361.0763201.1480170.0203440.0002401.8549821.0949760.0080820.0084630.0000482.0842330.1074400.0020800.0091130.9900181.1947021.2109631.0989070.0100230.2731880.6025250.6107990.4805540.6944110.0098760.0063473.0885000.8534970.0098090.9242280.8230400.0079770.0227994.1191130.0015690.0088250.0088942.1133480.0857252.0197270.7361790.0082160.0000770.0083951.1378150.0080520.0090200.0075580.0075780.9463060.3073290.8738493.1091240.0021540.9861850.0003922.2364211.3792720.0081642.0441070.0099971.1384290.7535181.1474940.9974931.3943610.0009011.0029760.5877370.0079920.0076720.9889230.0081830.4882760.0248100.0076801.4202640.7076331.7373093.0796002.8905692.3661040.1242220.0008812.1603082.0621020.0014180.0268600.1406880.0171710.0001330.0075010.0393200.0195540.0079030.3045280.0073170.0000570.4625290.0074800.4655871.0720961.7077230.0094810.0003140.5058953.1020590.2286300.2214080.3812510.0079220.0111710.6777330.0002950.0000490.0041440.0077121.1808390.6523470.703692

*******************************************
EVALUATING PIPELINE 
Pipeline directory: /home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_00815366_2020-02-21_23-19-0260ddp99c/
With following parameter combination: {'batch_size_seq_length': 1, 'lr': 4e-05, 'lr_type': 'linear'}
EVALUATION OF CHECKPOINT /home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_00815366_2020-02-21_23-19-0260ddp99c/outputs/checkpoint-3
-------------------------------------------------------------
|           |   agree   | disagree  |  discuss  | unrelated |
-------------------------------------------------------------
|   agree   |    667    |    83     |    131    |    22     |
-------------------------------------------------------------
| disagree  |    101    |    275    |    80     |    13     |
-------------------------------------------------------------
|  discuss  |    239    |    81     |   1523    |    108    |
-------------------------------------------------------------
| unrelated |    30     |    29     |    45     |   8471    |
-------------------------------------------------------------
Score: 8663.5 out of 9226.0	(93.9030999349664%)
Accuracy: 0.9191460749705833
F1 overall: 0.7692152293500852
F1 per class: [0.6876288659793814, 0.5869797225186766, 0.8166219839142091, 0.9856303449880738]
*******************************************


*******************************************
EVALUATING PIPELINE 
{'batch_size_seq_length': 2, 'lr': 4e-05, 'lr_type': 'constant'}
INFO:__main__:Creating features from dataset file at /home/ubuntu/fnd_implementation/data/processed
  0%|                                                 | 0/11898 [00:00<?, ?it/s]  0%|                                       | 1/11898 [00:01<3:58:46,  1.20s/it]  4%|â–ˆâ–Œ                                   | 501/11898 [00:01<2:40:08,  1.19it/s] 21%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                            | 2501/11898 [00:01<1:32:25,  1.69it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                    | 5501/11898 [00:01<44:02,  2.42it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                 | 6576/11898 [00:02<25:40,  3.45it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11898/11898 [00:02<00:00, 4452.06it/s]
  ******************************************* 
              Running Evaluation                
  *******************************************
 
  Length dataset evaluation: 11898
  Length dataloader evaluation: 1488
  Number of epochs: 3
  Batch size: 8
  ******************************************* 
 
['/home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_f84154f8_2020-02-21_17-25-03z_o5g3ci/outputs/checkpoint-3']
INFO:__main__:Evaluate the following checkpoints: ['/home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_f84154f8_2020-02-21_17-25-03z_o5g3ci/outputs/checkpoint-3']
INFO:transformers.configuration_utils:loading configuration file /home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_f84154f8_2020-02-21_17-25-03z_o5g3ci/outputs/checkpoint-3/config.json
INFO:transformers.configuration_utils:Model config {
  "attn_type": "bi",
  "bi_data": false,
  "clamp_len": -1,
  "d_head": 64,
  "d_inner": 3072,
  "d_model": 768,
  "dropout": 0.1,
  "end_n_top": 5,
  "ff_activation": "gelu",
  "finetuning_task": null,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "mem_len": null,
  "n_head": 12,
  "n_layer": 12,
  "num_labels": 4,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pruned_heads": {},
  "reuse_len": null,
  "same_length": false,
  "start_n_top": 5,
  "summary_activation": "tanh",
  "summary_last_dropout": 0.1,
  "summary_type": "last",
  "summary_use_proj": true,
  "torchscript": false,
  "untie_r": true,
  "use_bfloat16": false,
  "vocab_size": 32000
}

INFO:transformers.modeling_utils:loading weights file /home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_f84154f8_2020-02-21_17-25-03z_o5g3ci/outputs/checkpoint-3/pytorch_model.bin
HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=1488.0, style=ProgressStyle(description_width='initial')), HTML(value='')))
0.6179450.6263900.5523220.1863770.0474370.0118750.4733710.0684740.0094290.4649080.0473640.0051740.4629711.0592450.0766130.0100800.6989820.0419190.6981320.0375470.0040450.0023990.0010100.0011360.0023770.0009490.0011760.0008811.2695371.3620330.0475641.3603090.0433160.6604810.7121310.0212900.0015970.0010231.9829620.7141410.7170570.7167031.4010490.0339340.6486560.7123290.6484400.0148320.0104810.0010460.0008850.0009340.0035380.0022440.0008490.0036390.6657611.2811810.4134950.0078120.0010420.0008250.0009380.0021870.0008620.0008170.0008800.0008811.3562981.3511701.3436070.1242941.3257260.0189450.0011750.0008140.0008010.0035030.7542090.6717160.0101180.0018580.0016710.5277600.0080010.0014900.0027880.0015920.0025410.0013510.0015950.0018860.0014950.0015980.0020410.0098970.0425160.0035150.0013760.0419380.0045510.0027320.0022530.6247470.6379280.0082930.0009470.0008550.6334621.3008611.2931900.4813820.0051320.0008600.0009250.6369210.0063110.0008870.0008510.0008261.0177100.0097280.0015830.0020690.0015430.0016700.0016440.0013890.0018880.6534380.0166320.0117180.0037050.6262110.0092010.0018570.0014940.0090580.0009170.0008630.5297440.4539070.4592570.0045790.4597480.4578010.0056980.0025680.0024470.0026330.0037540.0011760.0010980.3992060.0060880.0035230.0021630.0037920.0010280.0088500.6958710.9162670.1246960.0043020.0062760.5222200.0043580.0013420.0012150.0011890.0011980.0011890.0010840.0012910.0012070.0012730.0012820.0012270.0026330.0012170.0012170.0012040.0012210.0014020.0011280.0025670.0012240.0015070.0099540.0011801.3964590.2437600.0029240.0011290.0011730.2990080.0065120.0076300.0111110.0096940.0010860.0010760.0078780.0050671.3328030.6449990.0043160.0037870.0037490.0036540.0036740.0010780.0024090.0011050.0009370.0011340.4622070.0044270.0009510.0009580.0009740.0041360.0036901.2372150.3025000.0041170.0020240.8366290.5509930.0048310.7020930.0069700.0010670.0176960.0028850.0025300.0012960.0052500.0035720.0021740.0009290.0035660.0051580.1449150.0015340.0008880.0009311.3388080.0093550.0050770.6645340.0035110.6697200.0073560.0010200.0084000.0009080.0008500.0011010.0160220.0009341.6842120.0074830.0371210.0011400.0010600.0103100.0019410.0021850.0008030.0021520.0034930.0008030.0008770.0034830.0008060.0021470.0021690.6329610.0033542.0423040.6186090.0030280.0021701.2633220.0068110.0021701.8705820.0250250.0189200.0008560.0021440.0021470.0008000.0034920.0022040.0085940.0177300.0022850.0100960.0009290.0082180.0082700.0010920.0034870.0587620.6446160.6446260.0055820.0008060.6463000.0042290.0021640.0008310.0022590.0021640.6408730.0035330.6362230.6398590.0041590.6412300.0027830.0008310.0007930.0021610.6651380.0180370.0087101.2192801.5439170.4724641.3705080.9237090.0276611.5147600.0080300.6430451.2897770.6284461.2770512.5423111.2796940.0310150.1215410.0039690.0054360.0037470.0064180.0118880.0124610.0025430.0009680.0090580.0008780.5194080.0024960.0092600.0008550.0008130.0021760.0035820.0008180.0048990.0021700.0021740.7689611.4238090.0046811.2814061.4228110.6444330.7824051.2654450.0042230.6091950.0024610.0265440.0041370.6400910.6444140.0032330.6430870.0030340.0015110.0321450.0115120.0012850.0341600.0355000.0039050.0025960.6906380.0124730.0012330.4201470.0035350.0036953.2026920.0169400.0049020.0048780.0049380.0060140.0091560.0064400.0066140.0052120.4659430.9522540.8571710.0032150.7041670.0108950.4276840.0020200.0177130.7840730.2770390.0205740.0008630.0035200.0021580.0035340.0021740.7905512.6786460.6389230.8362600.0339130.0103971.2868211.9002150.0081041.3873830.4735600.0088210.0011580.0713500.0011230.0160110.0339160.0073710.0055130.0140510.6646890.2342460.0041320.0062560.3071540.0056440.0008280.5983540.0034860.0008220.0008100.5927381.2730850.0049380.8775981.1458070.0331140.0122681.2035060.0277390.0278110.0035780.0021660.0035810.0062170.0050990.0035210.0102721.7390751.6768820.6223220.0024680.0012270.0037450.6446920.0024260.9663870.8190810.0066280.0035530.0090960.0049050.0008250.4636720.0018340.0008780.0010770.5659840.0034390.0022170.0263530.6998530.0022850.0010330.0009040.0170900.0203140.0179120.2100060.0023600.2209700.0168800.0050870.8086930.0276870.1238550.1244031.1650781.4463890.0117290.0078241.5670480.0055380.6709941.2088030.0206220.7688680.7688090.0097870.0199580.0008602.5572760.6458421.3026281.8879960.4821670.0060280.0065380.9317651.7836330.6007470.4847780.0095360.0098660.0160960.3936900.0029900.7880970.6340810.0110560.8000910.6015340.0019820.0021950.0009320.0008360.0008780.6769320.0021180.0010660.0008580.0008960.0036260.0048530.0035680.0049340.0035550.0021760.0039840.0053490.5783240.0062870.0053450.4189500.0102410.0011700.3639962.1464632.6065672.3676590.0062602.0737291.2004830.2548374.2666410.0162510.0091130.9323550.0064400.0008550.0010600.0097770.0116300.0062730.0021540.0048260.0050230.0035300.0049160.0061790.0021520.0048320.0008280.5828210.0045160.0008280.7718790.9066991.4306630.0113152.0628850.8038800.0036931.3248020.0109540.0010340.7007600.0021340.3661890.0809450.0018750.0010190.0087280.0055380.0087210.3536890.4496562.3123541.4040852.3366480.0122130.0157400.7905671.5837872.2269110.0099170.0050820.0037560.0051020.0050840.0248630.0325330.0103740.7952772.0485692.6814060.6454020.0073100.0035910.0035150.0062430.0008220.0008100.0008030.0008050.0008880.6440890.6485250.0018040.0021730.0022820.0009610.0023510.0023660.0009340.0023810.0101610.0104220.0454080.0229180.4263970.8356110.0142890.0022920.0008740.0050040.0021800.0035990.0035330.0036260.0090380.0037800.0102740.0115880.0102310.0021870.0075210.0035132.5646621.9694480.6237610.5574720.0266690.0089900.3261370.0080160.0035590.0088780.0034920.0050100.0036692.3152480.6271890.1749850.0252010.8070460.5227183.2189321.3783050.7973651.3305690.0118660.0062910.0077360.0049140.0050530.0022820.0048970.4219730.0096700.0012360.0010740.0099170.0099420.0010930.0098360.1998970.4018560.0017530.0011900.2033090.3806200.0017410.2386080.2121140.0014110.0011561.2647261.2758460.6457540.6425200.0048420.0065520.0063301.6371730.0781523.2267502.0183380.3042231.0259370.0022140.0008470.0009570.6396860.0033140.0009200.0012120.0023640.0045881.5766490.6740850.6755400.6404490.0018700.2521841.0209560.6682561.3610641.5266960.9383520.0103750.0173550.0008630.0008810.0090360.0089990.0092990.0024880.0050430.0024800.0008080.0048660.0035900.0035160.0035770.0062730.0035710.0034940.0035432.0285200.6403450.7875161.4959822.0380671.9093991.2716350.7869071.2703350.0023990.0021660.0008010.0007970.0021550.0008000.0021560.0035060.0007990.0008090.0021800.0008030.0035060.0021650.0021500.0021640.0008010.0007950.0007980.0022110.0008030.0007950.7880900.0125510.0115901.2860052.5719961.2844013.6387821.8512191.6890742.3580230.3096760.0120263.8352151.8849630.0407780.0252581.2642550.0051620.0022920.0008970.0035720.0008180.0035850.0035930.0022160.0062830.4250290.0602451.4315940.8397840.0101190.0021640.0008060.0035580.0035320.0008050.0008070.0021670.0008120.0008350.0009410.0008040.0021641.8860971.4232242.1242180.0560691.2885650.0146850.0119480.5320900.6452130.1909160.0040140.6275420.0096950.0116480.0116541.9234031.9238301.9154550.0225341.0892860.0317961.8130991.7143171.1385500.1121370.5365860.0014310.0115490.0132230.0115720.5379840.0121611.2746571.2841601.0631240.0087210.0008030.0048330.0048260.0061770.0034910.0107630.0110560.0210120.0110760.0117520.0011361.7660840.7074521.1253160.0104120.7027290.0108610.0013751.4308910.7876860.7872141.5731301.5736220.0026610.8033720.0098850.0013180.9064840.0215581.3918482.0266680.6520771.9282290.6562070.7944371.2676921.2744831.4478421.2668271.4517500.6630011.0853151.8328220.0028080.0008220.7869800.0016790.0023102.4737600.0035030.0008641.9994220.4234340.0104550.8122380.0029930.0025450.0022970.0021400.0021820.0008070.0008080.0008680.6917972.2242102.0748321.7429681.7406910.4140860.0014580.0025020.0023380.0038220.0177010.0090830.0176160.0011050.8058480.0100960.0093580.0092410.0013180.0015470.0014340.0014381.2790430.0029291.2977000.0041050.0013010.0027370.6514420.6404400.6452931.3117390.6451420.6491140.4346710.0091460.0163460.0088860.0021530.0048560.0035720.0049460.0035030.0050360.0063440.0035750.0067140.0022210.0008470.0022900.0229000.0035350.0008760.0050750.0008460.0010260.0043280.0018230.0031390.0017790.0180910.0018300.0019160.0019760.0094920.0103280.0020150.0105360.0018460.6335200.6400150.6423930.0014500.6348310.6193910.6401521.5610273.5957534.9338200.0123870.0090380.0062230.0049170.0077650.0282760.4339580.0325700.0180770.0153080.0102340.0089890.0035660.7257400.4798000.4790230.0090650.0085700.0085900.0085750.0063290.0117451.5277431.9735191.1345620.7509890.0045290.0012290.0024350.6956070.0177080.0379790.8658164.6062430.6647620.0014770.0009160.6224961.2529291.3742050.7734230.0017840.6340210.0014950.0009371.8375930.8019000.0473860.0103990.0051500.4629110.4043850.4540620.0027870.4588150.8916980.0060700.2639630.0045900.0065560.0035770.0024000.0279230.0403710.0116681.7023580.6976730.8649540.0111930.6710520.0069260.0076960.0092090.0102610.6974890.0109640.0529250.4576530.0040410.0077450.0022400.0051272.7654312.4439090.2799070.1329100.0317720.0128470.0210770.0430160.0199130.0326110.0276230.0143180.0168850.0370730.2521550.2425540.8754431.8290161.2630480.4351050.7976320.0649710.2532550.5565640.0334880.3728861.4434620.5965010.3763500.8065770.9256870.8255900.7091900.0688690.4800860.5061760.4314640.6619830.0728210.2946281.7401790.5258160.4362040.0194840.2842171.0998561.0469810.0343390.6855791.3254980.8013280.8315640.3894531.0910661.1672950.5224530.5919670.2628900.5867901.4578541.1161130.2289480.6711090.4306400.6235120.3349720.7023450.3685480.0642751.7177621.0820201.9317780.2557100.5123920.0016570.6598910.4075010.4636610.3173761.3465380.7232080.7753060.1997790.4179090.0641970.1248890.0693850.6609390.3336900.0846330.0021040.9524771.2798780.1895130.6856870.7250770.2507220.7986671.0288021.0247060.8039960.7009160.3363160.6708621.4427840.5929450.5234091.0425920.0569651.1129280.0341341.0338640.0965240.5970101.8808400.0037031.4529510.3111500.8131300.3736620.3520180.2407840.4202710.4262040.1063440.2792632.4886430.7364320.2628381.4698780.0355891.3366580.4919090.2400410.1921280.7845810.8602060.4527390.8647210.0702080.5126260.7738160.9830400.2480620.0128970.0329980.5142821.4916981.1297340.2591820.3678341.3122150.6361941.0280111.4189690.3494750.2825780.4619261.2104791.4443401.8268600.0400370.8602350.2559360.0343030.3788620.5927491.7730610.9162410.9293892.3151331.1658921.2773300.2582392.3851161.0355600.2868131.1500550.2384842.3860680.8215400.4497211.3338461.0753560.0337540.2528200.2280551.2166500.4838590.0379430.8243410.9210470.0342740.6404740.9794651.0993640.0333640.6272771.0138490.1835740.4335890.9214290.7935590.7007861.0776971.1263490.8210840.1483160.4924980.9160641.2946241.8799601.0875911.9495152.0097522.9154681.9814470.9486621.4274712.9467980.0410980.6499380.2346980.2194921.8245511.4610771.0560400.9790630.3442011.2836350.5141300.1290270.0650180.3111020.0656620.0568430.5200100.5985620.4957110.7636410.2531650.5308870.6452240.4577050.4005500.2627820.3525310.8297940.4664530.3905560.4857210.0017000.6841311.0299770.7960810.0338492.1123312.3661090.8363180.8427600.0025400.8034170.9085311.0959171.4327611.2842590.2667470.2359990.7006670.2781530.3298050.4694380.3252980.3442040.0096911.0523770.0651670.8129130.0535310.9585240.3119880.3832240.8655351.0533920.0653381.4007600.6592470.3244420.4421110.2583530.2853530.7281730.0654261.4397990.0657160.8366400.6660700.0657041.5947800.6286610.3580470.4647470.2743221.2482920.9427770.5002431.2483621.6589400.9829981.3642660.8840601.4251030.7653890.1111890.2220910.4788110.5249400.7916130.0335851.4086191.7750441.5179802.5216320.3496260.4147140.2895021.3620790.0658070.5554490.3304520.0451400.3861060.0673440.0921390.5569301.2279140.2571160.9715530.5098051.7728770.5584670.6190740.8115000.3641230.0640970.3176580.8276720.7825991.1063292.2268471.8157360.3927721.0612810.7738990.4455900.4597330.4848560.6764400.2615310.4924520.7935980.0348291.2728400.4198090.7299110.0681500.0015240.3126561.3804541.365821

*******************************************
EVALUATING PIPELINE 
Pipeline directory: /home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_f84154f8_2020-02-21_17-25-03z_o5g3ci/
With following parameter combination: {'batch_size_seq_length': 2, 'lr': 4e-05, 'lr_type': 'constant'}
EVALUATION OF CHECKPOINT /home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_f84154f8_2020-02-21_17-25-03z_o5g3ci/outputs/checkpoint-3
-------------------------------------------------------------
|           |   agree   | disagree  |  discuss  | unrelated |
-------------------------------------------------------------
|   agree   |    478    |    65     |    103    |    14     |
-------------------------------------------------------------
| disagree  |    218    |    245    |    122    |    59     |
-------------------------------------------------------------
|  discuss  |    275    |    96     |   1455    |    50     |
-------------------------------------------------------------
| unrelated |    66     |    62     |    99     |   8491    |
-------------------------------------------------------------
Score: 8527.0 out of 9226.0	(92.42358551918491%)
Accuracy: 0.89670532862666
F1 overall: 0.6949925836697274
F1 per class: [0.563347083087802, 0.44064748201438847, 0.7961696306429549, 0.9798061389337641]
*******************************************


*******************************************
EVALUATING PIPELINE 
{'batch_size_seq_length': 3, 'lr': 4e-05, 'lr_type': 'linear'}
INFO:__main__:Creating features from dataset file at /home/ubuntu/fnd_implementation/data/processed
  0%|                                                 | 0/11898 [00:00<?, ?it/s]  0%|                                       | 1/11898 [00:00<3:12:00,  1.03it/s]  4%|â–ˆâ–Œ                                   | 501/11898 [00:01<2:08:47,  1.47it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                    | 5501/11898 [00:01<50:36,  2.11it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                  | 6132/11898 [00:01<31:56,  3.01it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11898/11898 [00:01<00:00, 7489.80it/s]
  ******************************************* 
              Running Evaluation                
  *******************************************
 
  Length dataset evaluation: 11898
  Length dataloader evaluation: 744
  Number of epochs: 3
  Batch size: 16
  ******************************************* 
 
['/home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_06047886_2020-02-22_03-49-267r_7tlv1/outputs/checkpoint-3']
INFO:__main__:Evaluate the following checkpoints: ['/home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_06047886_2020-02-22_03-49-267r_7tlv1/outputs/checkpoint-3']
INFO:transformers.configuration_utils:loading configuration file /home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_06047886_2020-02-22_03-49-267r_7tlv1/outputs/checkpoint-3/config.json
INFO:transformers.configuration_utils:Model config {
  "attn_type": "bi",
  "bi_data": false,
  "clamp_len": -1,
  "d_head": 64,
  "d_inner": 3072,
  "d_model": 768,
  "dropout": 0.1,
  "end_n_top": 5,
  "ff_activation": "gelu",
  "finetuning_task": null,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "mem_len": null,
  "n_head": 12,
  "n_layer": 12,
  "num_labels": 4,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pruned_heads": {},
  "reuse_len": null,
  "same_length": false,
  "start_n_top": 5,
  "summary_activation": "tanh",
  "summary_last_dropout": 0.1,
  "summary_type": "last",
  "summary_use_proj": true,
  "torchscript": false,
  "untie_r": true,
  "use_bfloat16": false,
  "vocab_size": 32000
}

INFO:transformers.modeling_utils:loading weights file /home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_06047886_2020-02-22_03-49-267r_7tlv1/outputs/checkpoint-3/pytorch_model.bin
HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=744.0, style=ProgressStyle(description_width='initial')), HTML(value='')))
0.3609310.3611350.1806440.0604460.3971170.0794390.0141380.0021310.0002830.0000480.0001130.0000260.0000740.0000210.5002600.0334120.0023780.4160600.4026050.5711190.9678520.9415470.5556710.0242640.0011030.0000610.0001440.4457422.2452090.1255830.0042010.0001830.0000210.0000160.3939750.5154730.3346590.0090630.0003140.4208730.0107180.0002820.0000240.0000230.0001270.0000200.0000180.0000890.0149520.0366670.0014610.0001420.0001100.0000210.0004040.8436360.0150810.0003410.0000220.0000170.4367190.0075070.0001380.0000200.0001800.0002450.5437710.0081670.0004500.0000230.4478770.4038480.8493240.0117050.0002330.0000800.0001290.0001290.0001170.0000760.0003940.0003200.0003970.0000200.0000160.0000160.0000150.0000160.0000290.0000660.0000160.0000160.0000520.0000170.0001500.0000180.0000170.0025440.0004530.0753160.0007690.0002831.1373040.0111190.0002860.0000760.0001180.0000180.3564660.0032870.0000460.2624170.0040830.0636690.0253380.4395760.0040230.0594010.1113420.0010500.0001200.0190830.0001730.3515910.0030320.0001040.0423540.0004140.0000200.0001510.0004620.0002060.0000840.0000860.0000460.0000990.0000170.0000750.0000850.2369460.4513280.0033120.3110100.0026400.0006220.0000560.0000460.0001240.0006450.0001570.0000740.0000760.0001100.5020220.0033350.3703750.0024170.0001930.5153090.7662060.5269190.2091490.0013360.0017460.1044011.2926390.0084630.7602000.4082661.1570090.9557700.0960660.0007630.0001570.0021622.1550920.0123150.0001380.0000690.0000160.0261870.0473550.0003390.0022100.0001870.0008460.0098430.0001150.0096700.1052020.0354720.0002880.0057750.0001110.0016080.0002370.0091160.0003700.0001642.7592870.0139820.0003020.0004200.0002570.4271840.6505380.0033560.0020660.0056380.1788500.0010360.0001240.5749280.0049970.0005670.0009410.5556980.0585981.3591010.5165780.0033810.0700090.5714690.3281630.1226220.1358700.3712680.0016511.3550880.8108191.3562291.9429540.0088340.0001600.0002110.0001690.0008960.0044550.0000350.2141530.0545701.4360720.8675890.3526670.3587300.0014840.1880360.0010880.4219110.0019180.0004000.0039620.0336980.0031860.0010280.0003800.0056370.0003810.4581320.0024490.0005750.0004560.0009060.1227020.0027860.7373400.1328150.0017400.3532950.0019810.0627410.5971270.0072290.0423400.0002060.0000170.5067990.0018460.2920220.0013580.0006200.0001050.0001130.0002040.0287300.0004190.0652040.7885130.4273131.7151470.0062760.4871700.0017671.0866600.0058430.0002660.0002170.0002330.0001690.2586160.5847552.4317871.5729110.5451060.0022630.0001530.0001670.0000180.0002860.0001400.0017872.1812821.5528800.0053750.0045530.0002220.0001530.0069090.0033800.0010610.0012230.0002090.0002060.0000170.0000320.0083480.0135680.0001210.0001280.0000490.0000970.0002870.7494620.5050410.0016050.0005690.0009140.0006700.0012410.0358460.0004210.0058654.6169563.6398460.2282820.0011020.0002240.0001540.0010560.1436190.0037960.1145850.2623530.0011670.0002820.0001570.1460340.0006310.0000920.0001090.3398290.9694960.5057740.4735550.8670150.0023940.3742460.0053900.0003820.0004530.0036830.0156620.1258220.0003540.0439850.0001320.0001180.3602110.5619660.0026380.0028680.0007171.5657881.0568170.5252671.0392310.0316280.0001560.0002090.0001380.0001790.0951571.7475511.0963342.6304761.1978030.8156760.0021400.0000560.0000540.0001370.0000990.0001690.0001530.0000970.0000160.0001930.0000930.3997790.0017170.1561343.0184330.5267402.3183100.0794670.0066430.0066980.0076860.0060560.0028570.2163750.5713960.5538450.0013610.0002230.0000170.0001030.0000160.0000443.4773551.5588750.7486570.2002020.3311500.0131441.6037292.5283682.7734440.2935582.8941351.0396330.5860440.0015580.0004690.0004611.9653900.8231850.0019620.0002570.0001380.0001850.0001350.0035320.0026900.0005100.0006311.5039601.3739320.8624020.5226530.0014610.0008420.0007730.1833230.0608140.8223440.0030480.4322610.5228840.2257390.0005280.9520531.8103770.0061710.0001170.0000910.0002880.0000170.2126701.0464230.0064840.0010600.0002380.0003200.0001920.0003750.0001520.0000680.0000160.0011080.0302790.0001270.0001960.0006430.0037670.3734460.0008920.0000930.0001810.0001920.0002531.3356940.7163841.6686480.1174220.4598130.1227230.0002940.0906680.0001940.0002070.0061950.1726900.0005740.0001160.0002410.2904840.7679230.0020420.0002750.0004530.0003940.0003830.4333310.0993720.0016170.0342140.0005190.0004370.0313570.1403220.0003740.4842900.0018172.1937710.5034370.0010330.0003900.0001520.0048851.1729810.0031271.1941010.4637570.8250691.1848410.9432290.8677640.0016920.0005370.0006981.0109480.4796840.0011920.9613470.5072350.1640380.5103850.0011293.1636760.0060210.0019060.0008640.0008010.0005180.0007110.1292180.2050651.1016150.7886930.0618170.1858560.8629310.5609870.6397410.2436450.6250900.0690440.2172680.7075860.9829850.2799570.3891271.3272320.3741320.3868511.0366510.4089400.9511810.5428900.3972780.3821000.1912560.4841411.5884880.2845530.0538170.7013750.7514690.9319330.3619370.0429800.8225880.8137010.1700840.2279580.7885060.3121130.2589470.6605120.5431570.8412361.3198710.4874240.4047680.2473450.2409360.0506770.4013220.1050120.2727280.4149250.1074980.5005640.7646650.1346830.4577710.6183660.5525080.7751850.2752660.1818050.4032550.8954171.1491890.9102690.2042630.7804600.5784380.6396730.3125390.3234650.3927130.4602731.2505560.3855481.2810660.0557901.1686070.7081320.7132370.2783670.8568800.2724040.7116920.6427910.9783560.4536090.0120630.6709500.8995360.3654270.2931590.3926700.8022360.3829360.7960640.2381510.4791380.5988600.2957690.9886510.5927920.8783980.2413820.2140410.0160810.6252221.0499740.6543130.8054400.3775720.5656980.4881400.2006230.5639350.0032410.6105910.2247600.1818841.2609141.6080110.3130130.1242460.0020800.2491900.6002530.5946770.5790190.4096921.4497440.2210840.2818390.3206460.9883600.0328090.4612470.3485650.6654780.3753190.4755040.3265971.4698970.5519460.5559220.8334230.2458680.4527190.6195810.9670660.6149120.2362820.7911170.4360970.3398390.0054530.9001860.1069540.6225310.7553100.5441900.2271380.5096191.6827580.2808970.5609570.0353350.0595810.5059940.5273861.1085890.0424360.1923780.687285

*******************************************
EVALUATING PIPELINE 
Pipeline directory: /home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_06047886_2020-02-22_03-49-267r_7tlv1/
With following parameter combination: {'batch_size_seq_length': 3, 'lr': 4e-05, 'lr_type': 'linear'}
EVALUATION OF CHECKPOINT /home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_06047886_2020-02-22_03-49-267r_7tlv1/outputs/checkpoint-3
-------------------------------------------------------------
|           |   agree   | disagree  |  discuss  | unrelated |
-------------------------------------------------------------
|   agree   |    757    |    83     |    141    |     9     |
-------------------------------------------------------------
| disagree  |    85     |    317    |    78     |    23     |
-------------------------------------------------------------
|  discuss  |    172    |    40     |   1506    |    66     |
-------------------------------------------------------------
| unrelated |    23     |    28     |    54     |   8516    |
-------------------------------------------------------------
Score: 8738.25 out of 9226.0	(94.71331021027531%)
Accuracy: 0.9325937132291141
F1 overall: 0.8083571059716432
F1 per class: [0.7469166255550074, 0.6529351184346035, 0.845355037889419, 0.9882216420075428]
*******************************************


*******************************************
EVALUATING PIPELINE 
{'batch_size_seq_length': 4, 'lr': 4e-05, 'lr_type': 'cosine'}
INFO:__main__:Creating features from dataset file at /home/ubuntu/fnd_implementation/data/processed
  0%|                                                 | 0/11898 [00:00<?, ?it/s]  0%|                                       | 1/11898 [00:01<3:19:46,  1.01s/it]  4%|â–ˆâ–Œ                                   | 501/11898 [00:01<2:13:58,  1.42it/s] 38%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                      | 4501/11898 [00:01<1:00:52,  2.03it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                   | 5716/11898 [00:01<35:36,  2.89it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                | 6913/11898 [00:01<20:06,  4.13it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11898/11898 [00:01<00:00, 7783.64it/s]
  ******************************************* 
              Running Evaluation                
  *******************************************
 
  Length dataset evaluation: 11898
  Length dataloader evaluation: 372
  Number of epochs: 3
  Batch size: 32
  ******************************************* 
 
['/home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_138386e6_2020-02-22_11-13-14ri6mtlpc/outputs/checkpoint-3']
INFO:__main__:Evaluate the following checkpoints: ['/home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_138386e6_2020-02-22_11-13-14ri6mtlpc/outputs/checkpoint-3']
INFO:transformers.configuration_utils:loading configuration file /home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_138386e6_2020-02-22_11-13-14ri6mtlpc/outputs/checkpoint-3/config.json
INFO:transformers.configuration_utils:Model config {
  "attn_type": "bi",
  "bi_data": false,
  "clamp_len": -1,
  "d_head": 64,
  "d_inner": 3072,
  "d_model": 768,
  "dropout": 0.1,
  "end_n_top": 5,
  "ff_activation": "gelu",
  "finetuning_task": null,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "mem_len": null,
  "n_head": 12,
  "n_layer": 12,
  "num_labels": 4,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pruned_heads": {},
  "reuse_len": null,
  "same_length": false,
  "start_n_top": 5,
  "summary_activation": "tanh",
  "summary_last_dropout": 0.1,
  "summary_type": "last",
  "summary_use_proj": true,
  "torchscript": false,
  "untie_r": true,
  "use_bfloat16": false,
  "vocab_size": 32000
}

INFO:transformers.modeling_utils:loading weights file /home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_138386e6_2020-02-22_11-13-14ri6mtlpc/outputs/checkpoint-3/pytorch_model.bin
HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=372.0, style=ProgressStyle(description_width='initial')), HTML(value='')))
0.0028480.0029570.1847510.1780200.0445350.0089460.0015250.7843160.3525030.5462021.3639580.4027150.0336290.1965100.8629620.0575830.0036292.1423290.5465850.0635970.0063250.0003900.0039790.0002740.1197990.3453070.0133560.3864800.0138680.0005120.2575550.0083360.0007030.2998580.0256130.4227090.4248590.0115440.0003920.0000940.0003250.0001810.0000330.0000300.0000520.0000330.0000420.0000830.0013880.0011600.0001260.3501920.0068460.0001670.2030120.0056000.1124400.3752470.1174650.1976430.0063670.0483810.0009260.0000790.0000890.0004850.0001660.0000570.0000470.0743170.2024440.1385410.0023620.0000920.0007670.0000920.1447050.1273370.0016870.3917140.0815550.0036600.0274020.4316380.4250620.3108970.0037981.0282790.0117840.0002080.2754990.0715570.1349580.0515560.2759830.2213480.0075510.0009650.1095771.5094340.0160990.1509930.3994140.0056190.5641510.0058040.0066510.0030260.1072810.5289320.0150590.5106260.3288060.0039770.1277331.7908700.0166650.0002560.0016930.0207240.0200090.0003550.0000470.0010240.0004760.0015940.0012630.0034000.0013620.0009250.0143610.5565580.2161730.1196710.1503800.0263320.0180790.0001710.2567320.3071970.8974610.0912510.0309110.3372321.0051110.2477440.1658510.0012830.0001690.2163470.9140850.3595680.0024330.0000460.0001421.0857630.9200890.0069740.0002530.5719420.0044500.0001000.0003080.0055010.0023210.0002390.2862460.0017890.0330120.0013330.3645413.3559040.0292390.0003020.3184020.9225500.0643190.0625160.1373900.0010030.6163810.4866210.3940670.0547630.0058340.2205040.0054790.0004150.2052730.1929950.0019531.3774090.8227110.0273950.2092900.0031590.9929321.4093460.2243460.0011730.0001490.0002740.0000460.0001290.0004120.6580251.2635890.1085310.0006090.0000870.0737600.0949850.0007180.0000401.8472711.4878980.4075960.2191841.7455870.3255660.0021970.0005341.0989720.6152440.0036880.0016050.0899730.0006341.8154990.8797770.0046370.0014580.3584210.1097370.4330010.5682330.3292390.0036200.0001410.2850230.0076790.0846040.0023350.0012140.3137130.1861180.5039840.9148330.0038940.0002590.4019171.0100340.4690080.0596320.0003700.0013080.0002490.0001900.3404290.0035170.0007350.1370660.0070680.0012050.0002540.0116360.2528260.4249410.0019880.0337130.5128010.6714540.7958220.7231440.0031170.2778570.0013720.3854260.5968012.3873080.0098540.3439380.0016620.1703160.7295780.3080860.8806960.3971710.3534770.4288910.3668470.8778230.5347730.3957390.6160490.4513130.4549200.5735350.5007400.7976080.2219530.3675360.4087950.2162390.5272111.0592030.9448100.2750970.2737080.3810900.2589860.2977040.2811170.6222540.7066110.2737110.4892310.6857760.3513630.6603100.2541330.4010590.7824880.7816010.5696150.3088080.5071210.5592590.7440600.2163930.4367120.2048480.4772790.1542930.2757240.2587790.7467740.1160230.3132300.4974350.6674490.6383410.4556400.3363010.3118170.9766550.2405800.0997000.6113030.4721590.7802520.3095890.3663830.6678290.5207930.4639680.9999650.7226010.3156570.5214320.2657180.4686370.2222280.5677930.7068640.4955831.3914530.7289390.0412570.3583940.5328260.291102

*******************************************
EVALUATING PIPELINE 
Pipeline directory: /home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_138386e6_2020-02-22_11-13-14ri6mtlpc/
With following parameter combination: {'batch_size_seq_length': 4, 'lr': 4e-05, 'lr_type': 'cosine'}
EVALUATION OF CHECKPOINT /home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_138386e6_2020-02-22_11-13-14ri6mtlpc/outputs/checkpoint-3
-------------------------------------------------------------
|           |   agree   | disagree  |  discuss  | unrelated |
-------------------------------------------------------------
|   agree   |    770    |    70     |    143    |    15     |
-------------------------------------------------------------
| disagree  |    66     |    324    |    72     |    16     |
-------------------------------------------------------------
|  discuss  |    178    |    47     |   1515    |    91     |
-------------------------------------------------------------
| unrelated |    23     |    27     |    49     |   8492    |
-------------------------------------------------------------
Score: 8737.0 out of 9226.0	(94.69976154346412%)
Accuracy: 0.9330139519246933
F1 overall: 0.8170590657049875
F1 per class: [0.7567567567567568, 0.6849894291754757, 0.8393351800554016, 0.9871548968323162]
*******************************************


*******************************************
EVALUATING PIPELINE 
{'batch_size_seq_length': 2, 'lr': 4e-05, 'lr_type': 'linear'}
INFO:__main__:Creating features from dataset file at /home/ubuntu/fnd_implementation/data/processed
  0%|                                                 | 0/11898 [00:00<?, ?it/s]  0%|                                       | 1/11898 [00:01<3:38:32,  1.10s/it]  4%|â–ˆâ–Œ                                   | 501/11898 [00:01<2:26:35,  1.30it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                    | 5501/11898 [00:01<57:36,  1.85it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11898/11898 [00:01<00:00, 5987.65it/s]
  ******************************************* 
              Running Evaluation                
  *******************************************
 
  Length dataset evaluation: 11898
  Length dataloader evaluation: 1488
  Number of epochs: 3
  Batch size: 8
  ******************************************* 
 
['/home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_0341f7ae_2020-02-21_23-27-42ea6x5_w3/outputs/checkpoint-3']
INFO:__main__:Evaluate the following checkpoints: ['/home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_0341f7ae_2020-02-21_23-27-42ea6x5_w3/outputs/checkpoint-3']
INFO:transformers.configuration_utils:loading configuration file /home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_0341f7ae_2020-02-21_23-27-42ea6x5_w3/outputs/checkpoint-3/config.json
INFO:transformers.configuration_utils:Model config {
  "attn_type": "bi",
  "bi_data": false,
  "clamp_len": -1,
  "d_head": 64,
  "d_inner": 3072,
  "d_model": 768,
  "dropout": 0.1,
  "end_n_top": 5,
  "ff_activation": "gelu",
  "finetuning_task": null,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "mem_len": null,
  "n_head": 12,
  "n_layer": 12,
  "num_labels": 4,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pruned_heads": {},
  "reuse_len": null,
  "same_length": false,
  "start_n_top": 5,
  "summary_activation": "tanh",
  "summary_last_dropout": 0.1,
  "summary_type": "last",
  "summary_use_proj": true,
  "torchscript": false,
  "untie_r": true,
  "use_bfloat16": false,
  "vocab_size": 32000
}

INFO:transformers.modeling_utils:loading weights file /home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_0341f7ae_2020-02-21_23-27-42ea6x5_w3/outputs/checkpoint-3/pytorch_model.bin
HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=1488.0, style=ProgressStyle(description_width='initial')), HTML(value='')))
0.9875830.9879020.4951730.1651040.0412870.0083760.1946150.0278130.0034870.7635940.0763710.0069540.0006330.0007790.0000670.0001271.0997660.0647041.1942720.0628680.0031910.0004010.0000290.0000120.0000820.0000150.0000120.0000120.3303791.1284060.0376700.6504860.0203420.0032621.1610050.0331860.0009440.0000411.0875670.0279041.1409721.1681002.1122330.0532530.0012661.1776590.0262700.0005720.0012530.0000370.0000120.0000110.0000960.0000940.0000140.7310141.4805831.8002950.0312320.0005430.0000230.0000180.0000140.0000470.0000150.0000150.0000140.0000141.3977661.5582521.9284590.8458581.7595960.0241150.0003380.0000160.0000120.0000770.0027981.0756960.0134650.0001880.0000190.9792390.0116890.0001570.0000290.0000180.5044860.0056850.0000800.0000180.0000170.0000170.0124080.9187350.0096370.0002090.0000180.0001980.0000980.0006630.0000930.0003980.0004460.0003490.1435230.0014310.0004520.5086011.3776010.0126400.0001230.0000120.0000110.4416780.0038190.0000520.0000120.0000121.0625520.0087940.0000850.0000140.0000130.0000130.0001880.0000140.0000130.0004880.0007560.0006170.0000831.1081770.0115570.0001030.0000140.0003940.0000140.0000110.0010210.7779350.7818930.0054820.7800240.7800800.0053930.0000840.0000500.0000540.0001250.0000160.0000120.0001550.0000790.0000810.0000470.0001980.0000130.0003220.0006450.0022910.0016480.0000990.0001490.0007700.0000160.0000120.0000120.0000120.0000120.0000120.0000120.0000120.0000120.0000120.0000120.0000120.0000540.0000120.0000120.0000120.0000120.0000120.0000120.0000480.0000130.0000130.0003800.0000150.0000130.0000130.0000130.0000130.0000120.0000740.0001190.0002180.0007490.0003960.0000140.0000120.0001820.0001140.3508130.0870100.0004420.0000910.0001790.0002230.0000930.0000130.0000450.0000130.0000120.0000130.5522290.0025930.0000240.0000120.0000120.0000130.6631470.8497680.1956260.0009330.0002820.0056201.1081080.0048921.1794870.0051940.0000380.0009870.0000500.0001520.0000120.0007870.0002250.0000480.0000110.0002200.0002220.0107860.0000590.0000150.0000150.2326710.0010410.0001530.0000860.0000110.0000490.0014940.0000170.0003970.0000120.0000110.0000140.0006650.0000150.0023270.0000290.0508350.0003130.0001300.0004110.0001690.0000470.0000120.0000470.0000800.0000120.0000110.0000790.0000120.0000470.0000590.3130030.0074821.1914430.0047880.0000300.0000490.1508710.0005830.0000490.0017990.0007520.0007910.0000150.0000450.0000460.0000120.0000780.0000450.0008470.0013480.0000720.0003830.0000140.0003300.0003260.0000130.0000860.0000620.6214510.7425530.0024910.0000190.6888520.0022630.0000520.0000110.0000450.0000460.9716230.0030771.0143770.7257560.0023250.8547740.0026660.0000210.0000110.0000460.0022870.0009070.0005390.0034180.9110950.0029910.0002940.0003030.0535961.4300430.0043340.0005250.6028350.0025960.0014512.1223750.6110850.0021810.4716750.0014470.0001220.0000840.0002010.4530420.0031680.0011910.0000170.0003300.0000140.0003490.0000140.0003390.0000140.0000110.0004960.0033690.0000200.0020170.0001050.0000510.2670681.4232820.0038781.3114021.3273290.3641410.0019330.0166500.0000590.0003800.0000151.9088620.0051550.0003810.0003730.0000130.0003400.0000140.0000150.0013870.0004290.0000160.0012750.0051560.0001090.0000480.0018660.0004630.0000150.0018960.0000820.0000845.4839550.0139600.0001490.0001150.0001310.0001180.0002300.0001860.0001500.0001300.0008200.0028931.6336570.0039860.0000200.0007830.7101850.0017220.2517990.0034932.0025441.9126340.0056900.0006600.0000510.0000820.0000811.1721420.9840980.0038220.0019070.0013220.0002840.0827661.0292700.0024660.0005970.0009212.7985770.0064191.1377850.0026070.0006380.0013240.0001780.8738420.0146270.6615721.2643220.0029160.0001890.7435740.7227970.0016141.1022830.0024780.0000170.0000111.1237292.2049430.0048592.2009150.0053452.3156950.1978310.7708830.0026870.0011050.0000810.0000440.0000810.0001430.0001120.0000780.0038540.5391620.2767240.7404580.0015670.0000140.0000800.6871270.0014430.0093340.0424730.0003030.0001370.0004110.0001210.0000110.0000650.0000110.0000140.0000110.0458940.0001570.0000470.0743320.9244240.0018710.0000150.0000110.4691570.0017180.0007910.3007970.0006090.6615300.4911130.0010840.0041880.0046520.0013840.0003700.0064700.0060890.0002440.0001941.1301450.0022390.0000190.0069310.0006290.0003460.0020060.5995020.4878140.0009582.4224230.4705981.0707330.0061930.0508050.0002100.0003431.1332940.6821730.0030210.7533130.0618030.0006090.0008100.8531880.0016211.1900810.7849900.9624741.8158511.6464460.0030220.0000500.0000120.0000120.0000121.1921050.0021680.0000160.0000120.0000120.0001690.0001510.0005420.0011540.0003770.0000470.0000810.0001150.0003670.0001110.0001100.1082290.0005360.0000140.0034970.1344410.0118162.9236080.0051401.7155700.8023480.0072571.1970390.0025280.0055580.0002910.0002810.0000140.0000140.0007080.0005390.0001840.0000660.0001270.0001350.0000870.0001660.0001500.0000720.0001300.0000111.3186020.0023180.0000141.4845142.6123361.8305130.0032482.8168510.9620900.0015970.0002850.0004090.0000120.0000130.0000120.0000120.0000120.0000120.0000120.0004050.0000140.0005240.0004490.0019652.1681881.4998293.4404050.0058260.0006340.8696791.9373372.0360060.0033760.0001170.0000780.0001150.0001121.7436651.1794710.7362940.9064112.4362373.0451790.7713690.0013590.0007670.0000800.0001490.0000130.0000120.0000120.0000110.0000120.7492180.7101410.0010990.0000640.0000450.0000120.0000750.0000430.0000110.0000470.0004380.0006320.0094640.0012390.0006631.1051870.0022660.0000510.0000120.0001260.0000470.0000860.0000800.0000970.0002210.0000940.0002610.0003790.0002700.0000610.0003350.0001141.1922543.5266914.4131805.0467600.0088100.0014340.7243690.7339730.0011460.0002280.0000870.0001160.0000810.9455610.3081420.0005940.0149431.0465640.0034220.0003531.8047561.0742531.9475860.0031170.0001590.0002230.0001210.0010850.0000480.0001171.0685650.0019060.0009770.0000170.0003910.0004530.0000190.0030250.4290080.7849770.0010990.0000150.8695140.6219950.0008760.8779220.0848020.0001310.0000140.0207820.2925720.3456790.1456810.0003070.0001980.0001810.0024130.0083170.0087100.0067700.7584690.0139500.0000310.0000130.0000130.2510910.0004010.0000120.0000110.0000600.0021551.2986280.7204590.9119540.6557420.0008770.0068020.0037030.0030580.0026730.0006522.1227021.0816522.1626530.0028310.0000151.0233881.0387041.0868240.4023300.5076380.0007150.0000130.0001100.0000850.0000780.0567120.0002200.0000920.0000770.0000891.4596060.4808380.7023521.1209781.1109371.2991941.0062910.4415670.8133790.0010360.0001510.0000110.0000110.0000580.0000110.0000670.0001820.0000110.0000110.0002080.0000110.0002370.0001540.0000520.0001780.0000110.0000110.0000110.0001590.0000110.0000110.0000810.0002950.0003000.0030900.0145470.0035890.2748214.5140441.5797831.7849200.2097840.0005372.2971730.4262950.0027140.0024340.0081220.0002670.0002050.0000110.0006440.0000120.0003640.0004080.0000450.0018220.0035940.0044850.0137040.2285630.0007630.0000450.0000120.0001570.0000870.0000120.0000120.0000480.0000120.0000120.0000120.0000120.0000462.5181593.0776445.3721270.0076060.0012620.0006640.0005650.0001010.0005380.0016460.0000880.0010250.0003870.0004630.0005042.3793902.4701882.5218200.0038060.8832371.9289971.5522362.0157811.9552731.9999371.0831160.0012370.0002850.0115650.0002920.0003200.0002812.1387642.2291031.5155530.0020420.0000130.0001920.0001950.0002000.0001000.0003500.0003410.0006460.0003430.0003300.0000141.6146550.0027500.0011390.0006470.0000330.0006260.0000171.9901441.0560861.0394802.1602672.0412720.0022411.0369850.0015220.0000170.0189090.0009000.0120970.0150130.0017650.0074910.0098640.1784390.0012541.0590630.0047090.5603810.0018440.0135451.0815242.0510290.0022000.0000141.0163750.0010930.0000573.6440830.0038760.0000163.3965450.5247260.0009800.0000660.0000500.0000620.0000750.0000510.0000510.0000120.0000120.0000241.0819770.2948480.0044740.5112510.4526770.0063870.0000220.0000820.0000480.0000840.0148930.0003530.0006460.0000130.0057300.0003300.0005720.0003250.0000120.0000120.0000110.0000110.0027530.0000140.5127350.0005750.0000120.0000630.3878090.2597690.0030540.0033380.4935950.5287551.4638540.0017980.0006650.0003190.0000460.0001200.0001210.0001270.0000980.0001130.0003710.0001110.5964990.0027790.0000150.6481891.1252080.3485400.0003580.8808150.0008840.0000140.1637240.0001740.0000540.0000130.0028400.0000150.0000130.0000140.0015890.0009430.0000140.0015680.0000140.0004070.0004220.0004730.0000120.0004330.0003810.0006340.0038850.0102110.1520250.0003530.0002400.0001510.0001210.0002020.0012590.7088920.0021710.0007800.0005831.1524810.1160620.0113550.0018410.1460050.4542010.0380470.0031670.0337750.0027230.0002310.0003440.0005163.7662605.5172641.6052060.0015910.0000140.0000491.1978190.0019230.0015211.3321970.0106100.1999170.0002000.0000140.0008590.0013430.0016920.0011860.0000150.0004800.0000140.0000132.3157330.0045170.0023032.2263520.0021640.7545600.0009181.4887520.0014110.7587981.4020771.4468870.1404260.7630190.7650570.0007780.0000460.0010270.0015010.0002841.4450640.0262080.5903040.0007770.0002150.0001450.0001780.0002330.0002570.0002400.0002450.0021560.6549820.0043761.3170130.0012360.0003923.8907473.4617950.0052930.0004110.0008020.0005210.0011840.0025230.0008730.0038260.0014350.0006150.0006100.0018130.1854320.2372010.2452520.5220171.1564240.8832990.7966430.0756860.1540130.2743900.0142940.5496551.3756990.9485240.4260950.3356041.1525440.2591090.9047230.0339980.5929260.0460180.0172370.0100020.5053250.0129631.2178610.0785692.0042920.9689840.2378201.7022681.4480270.2986730.5311890.5695610.7412780.4899300.3207790.6728901.1512750.7119530.4432630.2040410.3163671.1274370.8774030.0158370.6377820.7198991.3819670.2102050.1368710.2720000.0952940.4628970.0196841.7177330.0957240.4590700.0004060.0269030.5244610.3062410.2106270.8534500.2257420.9114710.3450090.6222420.0076110.0069830.0104570.6105540.5678251.2702710.0011810.5860720.7659900.0008000.5896750.5415880.0021952.0627590.5771050.5432961.2566591.0607230.1000870.6327011.3508840.4629110.2611461.4163500.0079390.7979550.0440340.8880330.0158160.1567591.8132210.0020680.6880440.0105430.4112210.2452500.1139050.0242650.0124450.4964280.2768750.2880300.9194040.0050830.0062531.5329240.4583121.3246840.0039580.7885370.0012221.2667841.9923101.4127030.9543970.0094110.5644000.9404400.4848250.0176170.0029680.5495240.4943380.7989771.8312970.4639910.7612611.5006291.0983560.8265120.8068200.0627270.2462010.0069530.4918400.2457781.4878580.0357910.1632430.2397960.1378040.5357090.8574210.9913070.6686500.6948912.3833951.1669510.4500220.0077011.4013670.7000200.0261160.2931190.1166871.6669820.8786290.4072260.2849880.4942380.1836420.0136100.0028711.5813600.0060290.7864771.0468280.7667830.0053671.0225841.5001721.3077110.0050600.4938760.6596940.1119420.0156010.5357491.4239200.0208020.6664540.0376490.0613310.0170130.6854440.0024820.6678100.4422070.0105200.9184971.0569030.3027070.4592550.0084250.8247360.0144820.4553500.9636130.1268850.0019580.1611640.0480910.7256022.0476420.1513872.5373380.4195560.0219830.0413250.2542740.0825720.0042260.9121040.0512721.0315380.8938540.1717010.7605140.6051680.4568181.2084620.0095000.5672320.7468860.0087690.6700720.8779820.0006571.1347900.7630910.0073430.0049421.2452751.0466390.7312890.3294490.0003970.4955011.4001970.9470741.7896171.1264350.5473910.0029740.0194720.0105250.0043770.0089170.0108030.0176610.0034872.2032970.0216191.2143590.8008071.8783590.0123070.6603661.0112731.4588740.0140820.6393670.3813680.2542210.0259130.4264310.5910821.2924980.0051250.3685350.0150551.5203500.9895370.0165041.5977740.1475820.3522420.0404210.4927870.7319551.0886920.1920321.8266861.6889670.1489280.5741890.8478100.1010831.5419160.0081620.4208330.1756710.4482421.2472830.4517290.5634210.0357470.8852131.0048580.2471270.2988830.0136770.8304520.0288310.8425930.7449110.2325400.5449190.0137230.0153960.5098131.5385180.4258410.4711990.1703270.7456031.6043370.9651901.3062320.2435690.0323660.4185320.1663130.6233541.9953882.8578842.6466030.4256940.4170430.3076980.0344770.4298750.3402290.0323360.1757190.3334601.2573440.0046711.7746220.3877750.3137220.8821980.0006520.4305490.6060971.057481

*******************************************
EVALUATING PIPELINE 
Pipeline directory: /home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_0341f7ae_2020-02-21_23-27-42ea6x5_w3/
With following parameter combination: {'batch_size_seq_length': 2, 'lr': 4e-05, 'lr_type': 'linear'}
EVALUATION OF CHECKPOINT /home/ubuntu/fnd_implementation/xlnet/grid_search/results/pipeline_0341f7ae_2020-02-21_23-27-42ea6x5_w3/outputs/checkpoint-3
-------------------------------------------------------------
|           |   agree   | disagree  |  discuss  | unrelated |
-------------------------------------------------------------
|   agree   |    704    |    95     |    131    |    19     |
-------------------------------------------------------------
| disagree  |    81     |    274    |    74     |    15     |
-------------------------------------------------------------
|  discuss  |    223    |    72     |   1512    |    64     |
-------------------------------------------------------------
| unrelated |    29     |    27     |    62     |   8516    |
-------------------------------------------------------------
Score: 8694.0 out of 9226.0	(94.23368740515933%)
Accuracy: 0.9250294167086905
F1 overall: 0.7814524729367469
F1 per class: [0.7089627391742196, 0.6008771929824561, 0.8284931506849315, 0.9874768089053804]
*******************************************


real	63m23.825s
user	183m3.200s
sys	21m41.437s
ubuntu@run-gpu-mg:~/fnd_implementation$ 
ubuntu@run-gpu-mg:~/fnd_implementation$ exit
exit

Script done on 2020-02-22 14:31:28+0000
