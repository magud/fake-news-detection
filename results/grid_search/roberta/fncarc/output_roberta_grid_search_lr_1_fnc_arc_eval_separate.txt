Script started on 2020-02-14 20:01:41+0000
ubuntu@run-gpu-mg:~/fnd_implementation$ exittime python3 eval_separate.py --model=robberta --model_type=roberta-base --dataset_anem=fnc_arc[1P=fnc_arc[1P=fnc_arc[1P=fnc_arc[1P=fnc_arcn=fnc_arca=fnc_arcm=fnc_arce=fnc_arc
/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/home/ubuntu/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/ubuntu/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/ubuntu/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/ubuntu/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/ubuntu/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/ubuntu/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
There are 2 GPU(s) available.
The following GPU is used:  Tesla V100-PCIE-16GB
INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-config.json from cache at /home/ubuntu/.cache/torch/transformers/e1a2a406b5a05063c31f4dfdee7608986ba7c6393f7f79db5e69dcd197208534.a7ab0e5de2d8321d6d6a15b199110f2c99be72976b7d151423cb8d8c261a13b6
INFO:transformers.configuration_utils:Model config {
  "architectures": [
    "RobertaForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": "multi",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-05,
  "max_position_embeddings": 514,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 1,
  "use_bfloat16": false,
  "vocab_size": 50265
}

INFO:transformers.tokenization_utils:loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at /home/ubuntu/.cache/torch/transformers/d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
INFO:transformers.tokenization_utils:loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at /home/ubuntu/.cache/torch/transformers/b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
INFO:transformers.configuration_utils:loading configuration file /home/ubuntu/fnd_implementation/roberta/model_pretrained/config.json
INFO:transformers.configuration_utils:Model config {
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-05,
  "max_position_embeddings": 514,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 1,
  "use_bfloat16": false,
  "vocab_size": 50265
}

INFO:transformers.modeling_utils:loading weights file /home/ubuntu/fnd_implementation/roberta/model_pretrained/pytorch_model.bin
INFO:__main__:Loading initialized pretrained model from /home/ubuntu/fnd_implementation/roberta/model_pretrained
  ******************************************* 
           Freezing Embedding Layers          
  *******************************************
 
name:  roberta.embeddings.word_embeddings.weight
param.requires_grad:  False
=====
name:  roberta.embeddings.position_embeddings.weight
param.requires_grad:  False
=====
name:  roberta.embeddings.token_type_embeddings.weight
param.requires_grad:  False
=====
name:  roberta.embeddings.LayerNorm.weight
param.requires_grad:  False
=====
name:  roberta.embeddings.LayerNorm.bias
param.requires_grad:  False
=====
name:  roberta.encoder.layer.0.attention.self.query.weight
param.requires_grad:  True
=====
name:  roberta.encoder.layer.0.attention.self.query.bias
param.requires_grad:  True
=====
name:  roberta.encoder.layer.0.attention.self.key.weight
param.requires_grad:  True
=====
name:  roberta.encoder.layer.0.attention.self.key.bias
param.requires_grad:  True
=====
name:  roberta.encoder.layer.0.attention.self.value.weight
param.requires_grad:  True
=====
name:  roberta.encoder.layer.0.attention.self.value.bias
param.requires_grad:  True
=====
name:  roberta.encoder.layer.0.attention.output.dense.weight
param.requires_grad:  True
=====
name:  roberta.encoder.layer.0.attention.output.dense.bias
param.requires_grad:  True
=====
name:  roberta.encoder.layer.0.attention.output.LayerNorm.weight
param.requires_grad:  True
=====
name:  roberta.encoder.layer.0.attention.output.LayerNorm.bias
param.requires_grad:  True
=====
name:  roberta.encoder.layer.0.intermediate.dense.weight
param.requires_grad:  True
=====
name:  roberta.encoder.layer.0.intermediate.dense.bias
param.requires_grad:  True
=====
name:  roberta.encoder.layer.0.output.dense.weight
param.requires_grad:  True
=====
name:  roberta.encoder.layer.0.output.dense.bias
param.requires_grad:  True
=====
name:  roberta.encoder.layer.0.output.LayerNorm.weight
param.requires_grad:  True
=====
name:  roberta.encoder.layer.0.output.LayerNorm.bias
param.requires_grad:  True
=====
name:  roberta.encoder.layer.1.attention.self.query.weight
param.requires_grad:  True
=====
name:  roberta.encoder.layer.1.attention.self.query.bias
param.requires_grad:  True
=====
name:  roberta.encoder.layer.1.attention.self.key.weight
param.requires_grad:  True
=====
name:  roberta.encoder.layer.1.attention.self.key.bias
param.requires_grad:  True
=====
name:  roberta.encoder.layer.1.attention.self.value.weight
param.requires_grad:  True
=====
name:  roberta.encoder.layer.1.attention.self.value.bias
param.requires_grad:  True
=====
name:  roberta.encoder.layer.1.attention.output.dense.weight
param.requires_grad:  True
=====
name:  roberta.encoder.layer.1.attention.output.dense.bias
param.requires_grad:  True
=====
name:  roberta.encoder.layer.1.attention.output.LayerNorm.weight
param.requires_grad:  True
=====
name:  roberta.encoder.layer.1.attention.output.LayerNorm.bias
param.requires_grad:  True
=====
name:  roberta.encoder.layer.1.intermediate.dense.weight
param.requires_grad:  True
=====
name:  roberta.encoder.layer.1.intermediate.dense.bias
param.requires_grad:  True
=====
name:  roberta.encoder.layer.1.output.dense.weight
param.requires_grad:  True
=====
name:  roberta.encoder.layer.1.output.dense.bias
param.requires_grad:  True
=====
name:  roberta.encoder.layer.1.output.LayerNorm.weight
param.requires_grad:  True
=====
name:  roberta.encoder.layer.1.output.LayerNorm.bias
param.requires_grad:  True
=====
name:  roberta.encoder.layer.2.attention.self.query.weight
param.requires_grad:  True
=====
name:  roberta.encoder.layer.2.attention.self.query.bias
param.requires_grad:  True
=====
name:  roberta.encoder.layer.2.attention.self.key.weight
param.requires_grad:  True
=====
name:  roberta.encoder.layer.2.attention.self.key.bias
param.requires_grad:  True
=====
name:  roberta.encoder.layer.2.attention.self.value.weight
param.requires_grad:  True
=====
name:  roberta.encoder.layer.2.attention.self.value.bias
param.requires_grad:  True
=====
name:  roberta.encoder.layer.2.attention.output.dense.weight
param.requires_grad:  True
=====
name:  roberta.encoder.layer.2.attention.output.dense.bias
param.requires_grad:  True
=====
name:  roberta.encoder.layer.2.attention.output.LayerNorm.weight
param.requires_grad:  True
=====
name:  roberta.encoder.layer.2.attention.output.LayerNorm.bias
param.requires_grad:  True
=====
name:  roberta.encoder.layer.2.intermediate.dense.weight
param.requires_grad:  True
=====
name:  roberta.encoder.layer.2.intermediate.dense.bias
param.requires_grad:  True
=====
name:  roberta.encoder.layer.2.output.dense.weight
param.requires_grad:  True
=====
name:  roberta.encoder.layer.2.output.dense.bias
param.requires_grad:  True
=====
name:  roberta.encoder.layer.2.output.LayerNorm.weight
param.requires_grad:  True
=====
name:  roberta.encoder.layer.2.output.LayerNorm.bias
param.requires_grad:  True
=====
name:  roberta.encoder.layer.3.attention.self.query.weight
param.requires_grad:  True
=====
name:  roberta.encoder.layer.3.attention.self.query.bias
param.requires_grad:  True
=====
name:  roberta.encoder.layer.3.attention.self.key.weight
param.requires_grad:  True
=====
name:  roberta.encoder.layer.3.attention.self.key.bias
param.requires_grad:  True
=====
name:  roberta.encoder.layer.3.attention.self.value.weight
param.requires_grad:  True
=====
name:  roberta.encoder.layer.3.attention.self.value.bias
param.requires_grad:  True
=====
name:  roberta.encoder.layer.3.attention.output.dense.weight
param.requires_grad:  True
=====
name:  roberta.encoder.layer.3.attention.output.dense.bias
param.requires_grad:  True
=====
name:  roberta.encoder.layer.3.attention.output.LayerNorm.weight
param.requires_grad:  True
=====
name:  roberta.encoder.layer.3.attention.output.LayerNorm.bias
param.requires_grad:  True
=====
name:  roberta.encoder.layer.3.intermediate.dense.weight
param.requires_grad:  True
=====
name:  roberta.encoder.layer.3.intermediate.dense.bias
param.requires_grad:  True
=====
name:  roberta.encoder.layer.3.output.dense.weight
param.requires_grad:  True
=====
name:  roberta.encoder.layer.3.output.dense.bias
param.requires_grad:  True
=====
name:  roberta.encoder.layer.3.output.LayerNorm.weight
param.requires_grad:  True
=====
name:  roberta.encoder.layer.3.output.LayerNorm.bias
param.requires_grad:  True
=====
name:  roberta.encoder.layer.4.attention.self.query.weight
param.requires_grad:  True
=====
name:  roberta.encoder.layer.4.attention.self.query.bias
param.requires_grad:  True
=====
name:  roberta.encoder.layer.4.attention.self.key.weight
param.requires_grad:  True
=====
name:  roberta.encoder.layer.4.attention.self.key.bias
param.requires_grad:  True
=====
name:  roberta.encoder.layer.4.attention.self.value.weight
param.requires_grad:  True
=====
name:  roberta.encoder.layer.4.attention.self.value.bias
param.requires_grad:  True
=====
name:  roberta.encoder.layer.4.attention.output.dense.weight
param.requires_grad:  True
=====
name:  roberta.encoder.layer.4.attention.output.dense.bias
param.requires_grad:  True
=====
name:  roberta.encoder.layer.4.attention.output.LayerNorm.weight
param.requires_grad:  True
=====
name:  roberta.encoder.layer.4.attention.output.LayerNorm.bias
param.requires_grad:  True
=====
name:  roberta.encoder.layer.4.intermediate.dense.weight
param.requires_grad:  True
=====
name:  roberta.encoder.layer.4.intermediate.dense.bias
param.requires_grad:  True
=====
name:  roberta.encoder.layer.4.output.dense.weight
param.requires_grad:  True
=====
name:  roberta.encoder.layer.4.output.dense.bias
param.requires_grad:  True
=====
name:  roberta.encoder.layer.4.output.LayerNorm.weight
param.requires_grad:  True
=====
name:  roberta.encoder.layer.4.output.LayerNorm.bias
param.requires_grad:  True
=====
name:  roberta.encoder.layer.5.attention.self.query.weight
param.requires_grad:  True
=====
name:  roberta.encoder.layer.5.attention.self.query.bias
param.requires_grad:  True
=====
name:  roberta.encoder.layer.5.attention.self.key.weight
param.requires_grad:  True
=====
name:  roberta.encoder.layer.5.attention.self.key.bias
param.requires_grad:  True
=====
name:  roberta.encoder.layer.5.attention.self.value.weight
param.requires_grad:  True
=====
name:  roberta.encoder.layer.5.attention.self.value.bias
param.requires_grad:  True
=====
name:  roberta.encoder.layer.5.attention.output.dense.weight
param.requires_grad:  True
=====
name:  roberta.encoder.layer.5.attention.output.dense.bias
param.requires_grad:  True
=====
name:  roberta.encoder.layer.5.attention.output.LayerNorm.weight
param.requires_grad:  True
=====
name:  roberta.encoder.layer.5.attention.output.LayerNorm.bias
param.requires_grad:  True
=====
name:  roberta.encoder.layer.5.intermediate.dense.weight
param.requires_grad:  True
=====
name:  roberta.encoder.layer.5.intermediate.dense.bias
param.requires_grad:  True
=====
name:  roberta.encoder.layer.5.output.dense.weight
param.requires_grad:  True
=====
name:  roberta.encoder.layer.5.output.dense.bias
param.requires_grad:  True
=====
name:  roberta.encoder.layer.5.output.LayerNorm.weight
param.requires_grad:  True
=====
name:  roberta.encoder.layer.5.output.LayerNorm.bias
param.requires_grad:  True
=====
name:  roberta.encoder.layer.6.attention.self.query.weight
param.requires_grad:  True
=====
name:  roberta.encoder.layer.6.attention.self.query.bias
param.requires_grad:  True
=====
name:  roberta.encoder.layer.6.attention.self.key.weight
param.requires_grad:  True
=====
name:  roberta.encoder.layer.6.attention.self.key.bias
param.requires_grad:  True
=====
name:  roberta.encoder.layer.6.attention.self.value.weight
param.requires_grad:  True
=====
name:  roberta.encoder.layer.6.attention.self.value.bias
param.requires_grad:  True
=====
name:  roberta.encoder.layer.6.attention.output.dense.weight
param.requires_grad:  True
=====
name:  roberta.encoder.layer.6.attention.output.dense.bias
param.requires_grad:  True
=====
name:  roberta.encoder.layer.6.attention.output.LayerNorm.weight
param.requires_grad:  True
=====
name:  roberta.encoder.layer.6.attention.output.LayerNorm.bias
param.requires_grad:  True
=====
name:  roberta.encoder.layer.6.intermediate.dense.weight
param.requires_grad:  True
=====
name:  roberta.encoder.layer.6.intermediate.dense.bias
param.requires_grad:  True
=====
name:  roberta.encoder.layer.6.output.dense.weight
param.requires_grad:  True
=====
name:  roberta.encoder.layer.6.output.dense.bias
param.requires_grad:  True
=====
name:  roberta.encoder.layer.6.output.LayerNorm.weight
param.requires_grad:  True
=====
name:  roberta.encoder.layer.6.output.LayerNorm.bias
param.requires_grad:  True
=====
name:  roberta.encoder.layer.7.attention.self.query.weight
param.requires_grad:  True
=====
name:  roberta.encoder.layer.7.attention.self.query.bias
param.requires_grad:  True
=====
name:  roberta.encoder.layer.7.attention.self.key.weight
param.requires_grad:  True
=====
name:  roberta.encoder.layer.7.attention.self.key.bias
param.requires_grad:  True
=====
name:  roberta.encoder.layer.7.attention.self.value.weight
param.requires_grad:  True
=====
name:  roberta.encoder.layer.7.attention.self.value.bias
param.requires_grad:  True
=====
name:  roberta.encoder.layer.7.attention.output.dense.weight
param.requires_grad:  True
=====
name:  roberta.encoder.layer.7.attention.output.dense.bias
param.requires_grad:  True
=====
name:  roberta.encoder.layer.7.attention.output.LayerNorm.weight
param.requires_grad:  True
=====
name:  roberta.encoder.layer.7.attention.output.LayerNorm.bias
param.requires_grad:  True
=====
name:  roberta.encoder.layer.7.intermediate.dense.weight
param.requires_grad:  True
=====
name:  roberta.encoder.layer.7.intermediate.dense.bias
param.requires_grad:  True
=====
name:  roberta.encoder.layer.7.output.dense.weight
param.requires_grad:  True
=====
name:  roberta.encoder.layer.7.output.dense.bias
param.requires_grad:  True
=====
name:  roberta.encoder.layer.7.output.LayerNorm.weight
param.requires_grad:  True
=====
name:  roberta.encoder.layer.7.output.LayerNorm.bias
param.requires_grad:  True
=====
name:  roberta.encoder.layer.8.attention.self.query.weight
param.requires_grad:  True
=====
name:  roberta.encoder.layer.8.attention.self.query.bias
param.requires_grad:  True
=====
name:  roberta.encoder.layer.8.attention.self.key.weight
param.requires_grad:  True
=====
name:  roberta.encoder.layer.8.attention.self.key.bias
param.requires_grad:  True
=====
name:  roberta.encoder.layer.8.attention.self.value.weight
param.requires_grad:  True
=====
name:  roberta.encoder.layer.8.attention.self.value.bias
param.requires_grad:  True
=====
name:  roberta.encoder.layer.8.attention.output.dense.weight
param.requires_grad:  True
=====
name:  roberta.encoder.layer.8.attention.output.dense.bias
param.requires_grad:  True
=====
name:  roberta.encoder.layer.8.attention.output.LayerNorm.weight
param.requires_grad:  True
=====
name:  roberta.encoder.layer.8.attention.output.LayerNorm.bias
param.requires_grad:  True
=====
name:  roberta.encoder.layer.8.intermediate.dense.weight
param.requires_grad:  True
=====
name:  roberta.encoder.layer.8.intermediate.dense.bias
param.requires_grad:  True
=====
name:  roberta.encoder.layer.8.output.dense.weight
param.requires_grad:  True
=====
name:  roberta.encoder.layer.8.output.dense.bias
param.requires_grad:  True
=====
name:  roberta.encoder.layer.8.output.LayerNorm.weight
param.requires_grad:  True
=====
name:  roberta.encoder.layer.8.output.LayerNorm.bias
param.requires_grad:  True
=====
name:  roberta.encoder.layer.9.attention.self.query.weight
param.requires_grad:  True
=====
name:  roberta.encoder.layer.9.attention.self.query.bias
param.requires_grad:  True
=====
name:  roberta.encoder.layer.9.attention.self.key.weight
param.requires_grad:  True
=====
name:  roberta.encoder.layer.9.attention.self.key.bias
param.requires_grad:  True
=====
name:  roberta.encoder.layer.9.attention.self.value.weight
param.requires_grad:  True
=====
name:  roberta.encoder.layer.9.attention.self.value.bias
param.requires_grad:  True
=====
name:  roberta.encoder.layer.9.attention.output.dense.weight
param.requires_grad:  True
=====
name:  roberta.encoder.layer.9.attention.output.dense.bias
param.requires_grad:  True
=====
name:  roberta.encoder.layer.9.attention.output.LayerNorm.weight
param.requires_grad:  True
=====
name:  roberta.encoder.layer.9.attention.output.LayerNorm.bias
param.requires_grad:  True
=====
name:  roberta.encoder.layer.9.intermediate.dense.weight
param.requires_grad:  True
=====
name:  roberta.encoder.layer.9.intermediate.dense.bias
param.requires_grad:  True
=====
name:  roberta.encoder.layer.9.output.dense.weight
param.requires_grad:  True
=====
name:  roberta.encoder.layer.9.output.dense.bias
param.requires_grad:  True
=====
name:  roberta.encoder.layer.9.output.LayerNorm.weight
param.requires_grad:  True
=====
name:  roberta.encoder.layer.9.output.LayerNorm.bias
param.requires_grad:  True
=====
name:  roberta.encoder.layer.10.attention.self.query.weight
param.requires_grad:  True
=====
name:  roberta.encoder.layer.10.attention.self.query.bias
param.requires_grad:  True
=====
name:  roberta.encoder.layer.10.attention.self.key.weight
param.requires_grad:  True
=====
name:  roberta.encoder.layer.10.attention.self.key.bias
param.requires_grad:  True
=====
name:  roberta.encoder.layer.10.attention.self.value.weight
param.requires_grad:  True
=====
name:  roberta.encoder.layer.10.attention.self.value.bias
param.requires_grad:  True
=====
name:  roberta.encoder.layer.10.attention.output.dense.weight
param.requires_grad:  True
=====
name:  roberta.encoder.layer.10.attention.output.dense.bias
param.requires_grad:  True
=====
name:  roberta.encoder.layer.10.attention.output.LayerNorm.weight
param.requires_grad:  True
=====
name:  roberta.encoder.layer.10.attention.output.LayerNorm.bias
param.requires_grad:  True
=====
name:  roberta.encoder.layer.10.intermediate.dense.weight
param.requires_grad:  True
=====
name:  roberta.encoder.layer.10.intermediate.dense.bias
param.requires_grad:  True
=====
name:  roberta.encoder.layer.10.output.dense.weight
param.requires_grad:  True
=====
name:  roberta.encoder.layer.10.output.dense.bias
param.requires_grad:  True
=====
name:  roberta.encoder.layer.10.output.LayerNorm.weight
param.requires_grad:  True
=====
name:  roberta.encoder.layer.10.output.LayerNorm.bias
param.requires_grad:  True
=====
name:  roberta.encoder.layer.11.attention.self.query.weight
param.requires_grad:  True
=====
name:  roberta.encoder.layer.11.attention.self.query.bias
param.requires_grad:  True
=====
name:  roberta.encoder.layer.11.attention.self.key.weight
param.requires_grad:  True
=====
name:  roberta.encoder.layer.11.attention.self.key.bias
param.requires_grad:  True
=====
name:  roberta.encoder.layer.11.attention.self.value.weight
param.requires_grad:  True
=====
name:  roberta.encoder.layer.11.attention.self.value.bias
param.requires_grad:  True
=====
name:  roberta.encoder.layer.11.attention.output.dense.weight
param.requires_grad:  True
=====
name:  roberta.encoder.layer.11.attention.output.dense.bias
param.requires_grad:  True
=====
name:  roberta.encoder.layer.11.attention.output.LayerNorm.weight
param.requires_grad:  True
=====
name:  roberta.encoder.layer.11.attention.output.LayerNorm.bias
param.requires_grad:  True
=====
name:  roberta.encoder.layer.11.intermediate.dense.weight
param.requires_grad:  True
=====
name:  roberta.encoder.layer.11.intermediate.dense.bias
param.requires_grad:  True
=====
name:  roberta.encoder.layer.11.output.dense.weight
param.requires_grad:  True
=====
name:  roberta.encoder.layer.11.output.dense.bias
param.requires_grad:  True
=====
name:  roberta.encoder.layer.11.output.LayerNorm.weight
param.requires_grad:  True
=====
name:  roberta.encoder.layer.11.output.LayerNorm.bias
param.requires_grad:  True
=====
name:  roberta.pooler.dense.weight
param.requires_grad:  True
=====
name:  roberta.pooler.dense.bias
param.requires_grad:  True
=====
name:  classifier.dense.weight
param.requires_grad:  True
=====
name:  classifier.dense.bias
param.requires_grad:  True
=====
name:  classifier.out_proj.weight
param.requires_grad:  True
=====
name:  classifier.out_proj.bias
param.requires_grad:  True
=====

*******************************************
Evaluating the following pipelines 
['/home/ubuntu/fnd_implementation/roberta/grid_search/results/pipeline_b47e61f2_2020-02-14_18-17-08cdsiwx5g/', '/home/ubuntu/fnd_implementation/roberta/grid_search/results/pipeline_abfb6296_2020-02-14_16-10-26vjyufsvp/', '/home/ubuntu/fnd_implementation/roberta/grid_search/results/pipeline_a346ee22_2020-02-14_13-30-04pt14317i/', '/home/ubuntu/fnd_implementation/roberta/grid_search/results/pipeline_9d68f9e6_2020-02-14_12-43-39nu71avtu/', '/home/ubuntu/fnd_implementation/roberta/grid_search/results/pipeline_a62e43b0_2020-02-14_15-20-00k1ezj_za/', '/home/ubuntu/fnd_implementation/roberta/grid_search/results/pipeline_94a4aaf8_2020-02-14_10-35-264sn7w7m_/', '/home/ubuntu/fnd_implementation/roberta/grid_search/results/pipeline_a91c6cfa_2020-02-14_15-24-194owxwho2/', '/home/ubuntu/fnd_implementation/roberta/grid_search/results/pipeline_a05fc7c4_2020-02-14_13-16-42bz1jp7c7/', '/home/ubuntu/fnd_implementation/roberta/grid_search/results/pipeline_97a80d26_2020-02-14_10-35-31kc2oa1dy/', '/home/ubuntu/fnd_implementation/roberta/grid_search/results/pipeline_aed962e2_2020-02-14_16-11-36n4nunba2/', '/home/ubuntu/fnd_implementation/roberta/grid_search/results/pipeline_b1b487d0_2020-02-14_18-01-23w9m6wpb8/', '/home/ubuntu/fnd_implementation/roberta/grid_search/results/pipeline_9a8264c4_2020-02-14_12-25-27rzj0ei1x/']

*******************************************

*******************************************
EVALUATING PIPELINE 
{'batch_size_seq_length': 4, 'lr': 1e-05, 'lr_type': 'cosine'}
INFO:__main__:Creating features from dataset file at /home/ubuntu/fnd_implementation/data/processed
  0%|                                                 | 0/11898 [00:00<?, ?it/s]  0%|                                       | 1/11898 [00:00<2:52:22,  1.15it/s]  4%|â–ˆâ–Œ                                   | 501/11898 [00:01<1:55:36,  1.64it/s] 13%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ                               | 1501/11898 [00:01<1:13:50,  2.35it/s] 25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                            | 3001/11898 [00:01<44:14,  3.35it/s] 34%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                         | 4001/11898 [00:01<27:29,  4.79it/s] 38%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                       | 4501/11898 [00:01<18:02,  6.83it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                    | 5501/11898 [00:02<10:55,  9.75it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–          | 8501/11898 [00:02<04:03, 13.93it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11898/11898 [00:02<00:00, 5189.86it/s]
  ******************************************* 
              Running Evaluation                
  *******************************************
 
  Length dataset evaluation: 11898
  Length dataloader evaluation: 372
  Number of epochs: 3
  Batch size: 32
  ******************************************* 
 
['/home/ubuntu/fnd_implementation/roberta/grid_search/results/pipeline_b47e61f2_2020-02-14_18-17-08cdsiwx5g/outputs/checkpoint-3']
INFO:__main__:Evaluate the following checkpoints: ['/home/ubuntu/fnd_implementation/roberta/grid_search/results/pipeline_b47e61f2_2020-02-14_18-17-08cdsiwx5g/outputs/checkpoint-3']
INFO:transformers.configuration_utils:loading configuration file /home/ubuntu/fnd_implementation/roberta/grid_search/results/pipeline_b47e61f2_2020-02-14_18-17-08cdsiwx5g/outputs/checkpoint-3/config.json
INFO:transformers.configuration_utils:Model config {
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-05,
  "max_position_embeddings": 514,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 1,
  "use_bfloat16": false,
  "vocab_size": 50265
}

INFO:transformers.modeling_utils:loading weights file /home/ubuntu/fnd_implementation/roberta/grid_search/results/pipeline_b47e61f2_2020-02-14_18-17-08cdsiwx5g/outputs/checkpoint-3/pytorch_model.bin
eval_separate.py:214: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0
Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`
  for batch in tqdm_notebook(eval_dataloader, desc="Evaluating"):
HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=372.0, style=ProgressStyle(description_width='initial')), HTML(value='')))
0.2009330.3576840.3378510.1141540.0288820.0062150.0014170.2878780.2788300.3233430.8282780.2573560.0394740.1218030.5221090.0352520.0025330.4192810.4480050.0702050.1179720.0061360.0059940.0008200.0012040.0027870.0014180.3900170.0149500.0008220.0061630.0005340.0026450.2059910.1855620.0077320.0836920.0028240.0020970.0007250.0174220.0055960.0004410.0003160.0004090.0003220.0004360.0006360.0003330.0021070.0011200.0430320.0037670.0006200.0004850.0951040.2439190.3858250.0076930.0212570.1078180.3100910.0062290.0007350.0006240.0636540.0055860.0006660.0004690.0668210.2064480.3152700.0065600.0006670.2171330.0035270.0474540.0389260.0010330.5171600.1962700.4197391.1710870.5373410.2821960.5624150.0087370.6954050.0102960.0031430.0272420.3299590.3443380.1531060.1920370.1743870.0452040.0048350.0151481.0733010.0119840.0020310.4098790.0421450.8494130.0090210.4953860.0553420.5331510.3730000.0064190.3407520.2154710.0041590.1832031.4658240.2522030.0032900.2776250.0635620.0613980.0722050.0011560.0019600.0003270.0793570.0152700.0520470.1579400.1753950.1195470.3020020.1652700.3251520.1503220.3648530.4800030.0039530.1927190.1432110.4496120.0043180.1192470.5317571.2450830.1920280.2095470.0080740.0010590.0026170.5596300.7541680.0054750.0004350.0007770.7557350.7249320.9268750.0081830.0316210.1317840.0015530.0052560.0432270.0009510.0052900.2481880.0060940.0054270.0876370.0245570.8440940.1453630.0023870.1567620.0416130.0166020.0026040.1834770.0017100.2874120.0884590.1871010.0235730.0867280.3537530.1501790.1078360.2708260.0259610.0280470.4861190.3945660.0027810.0009870.0012350.4966430.6759890.2161340.0015620.2338650.1597240.1064750.0843410.0419311.0575700.6612760.0141230.0008460.0008220.1477650.0690050.0014420.0003931.3279660.6973510.0379650.0123151.7178171.1238700.0207990.0025240.8453540.3926130.0030240.0015550.1483830.0767570.8932780.3982340.0393310.0475440.2142340.5923510.7220970.2076050.2394210.0018180.0007420.2495100.7609760.2364190.2170370.0020950.1060660.0106840.3633650.6060760.0035390.0011260.1215320.7288540.0317410.0111660.0043990.0479770.0240110.0067340.2291450.0076200.0124410.1488070.0658210.0056550.0024340.0379210.1774721.3450250.0130690.0040010.3098840.5675020.4648570.4378100.0053260.1799520.1372190.0489530.2488991.2230070.0150340.1180020.0039400.2805010.7905540.2327130.6316050.5313570.2459370.4631770.4208910.4800920.6938500.4085800.3623970.2820920.3547130.5385150.2022590.5121870.3204350.2727250.4777840.1938130.3626140.5758570.7098430.1264890.3794920.2300800.2744750.3679090.2339090.3806120.3641650.3472920.5061500.6409330.2976250.4599880.2416940.4414770.7397520.5518830.5810730.4049620.3492180.5119360.2303760.2858860.4552100.2642150.4592230.3424830.3609430.1692320.6777540.2600700.2194090.4970190.3555560.4990220.3808960.6434040.6453800.9184110.1761480.1422480.3437190.3296280.7900220.1491090.2062650.5082250.4367670.6140660.9070370.4827010.3015120.4378870.2551870.3739610.1465840.6525090.4833700.3545810.8735190.4309250.3069870.2314840.6339210.253408

*******************************************
EVALUATING PIPELINE 
Pipeline directory: /home/ubuntu/fnd_implementation/roberta/grid_search/results/pipeline_b47e61f2_2020-02-14_18-17-08cdsiwx5g/
With following parameter combination: {'batch_size_seq_length': 4, 'lr': 1e-05, 'lr_type': 'cosine'}
EVALUATION OF CHECKPOINT /home/ubuntu/fnd_implementation/roberta/grid_search/results/pipeline_b47e61f2_2020-02-14_18-17-08cdsiwx5g/outputs/checkpoint-3
-------------------------------------------------------------
|           |   agree   | disagree  |  discuss  | unrelated |
-------------------------------------------------------------
|   agree   |    722    |    102    |    136    |    14     |
-------------------------------------------------------------
| disagree  |    74     |    263    |    61     |    19     |
-------------------------------------------------------------
|  discuss  |    215    |    76     |   1522    |    50     |
-------------------------------------------------------------
| unrelated |    26     |    27     |    60     |   8531    |
-------------------------------------------------------------
Score: 8710.25 out of 9226.0	(94.40982007370475%)
Accuracy: 0.9277189443603967
F1 overall: 0.7842121136846107
F1 per class: [0.7180507210343113, 0.5943502824858757, 0.8358045030203185, 0.9886429481979372]
*******************************************


*******************************************
EVALUATING PIPELINE 
{'batch_size_seq_length': 1, 'lr': 1e-05, 'lr_type': 'cosine'}
INFO:__main__:Creating features from dataset file at /home/ubuntu/fnd_implementation/data/processed
  0%|                                                 | 0/11898 [00:00<?, ?it/s]  0%|                                       | 1/11898 [00:00<3:15:21,  1.01it/s]  4%|â–ˆâ–Œ                                   | 501/11898 [00:01<2:11:02,  1.45it/s] 13%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ                               | 1501/11898 [00:01<1:23:41,  2.07it/s] 21%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                              | 2501/11898 [00:01<52:57,  2.96it/s] 38%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                       | 4501/11898 [00:01<29:10,  4.23it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                    | 5501/11898 [00:02<17:40,  6.03it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–          | 8501/11898 [00:02<06:34,  8.61it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11898/11898 [00:02<00:00, 5398.35it/s]
  ******************************************* 
              Running Evaluation                
  *******************************************
 
  Length dataset evaluation: 11898
  Length dataloader evaluation: 2975
  Number of epochs: 3
  Batch size: 4
  ******************************************* 
 
['/home/ubuntu/fnd_implementation/roberta/grid_search/results/pipeline_abfb6296_2020-02-14_16-10-26vjyufsvp/outputs/checkpoint-3']
INFO:__main__:Evaluate the following checkpoints: ['/home/ubuntu/fnd_implementation/roberta/grid_search/results/pipeline_abfb6296_2020-02-14_16-10-26vjyufsvp/outputs/checkpoint-3']
INFO:transformers.configuration_utils:loading configuration file /home/ubuntu/fnd_implementation/roberta/grid_search/results/pipeline_abfb6296_2020-02-14_16-10-26vjyufsvp/outputs/checkpoint-3/config.json
INFO:transformers.configuration_utils:Model config {
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-05,
  "max_position_embeddings": 514,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 1,
  "use_bfloat16": false,
  "vocab_size": 50265
}

INFO:transformers.modeling_utils:loading weights file /home/ubuntu/fnd_implementation/roberta/grid_search/results/pipeline_abfb6296_2020-02-14_16-10-26vjyufsvp/outputs/checkpoint-3/pytorch_model.bin
HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=2975.0, style=ProgressStyle(description_width='initial')), HTML(value='')))
1.8053861.8053980.9027110.3010610.0757180.0151560.0025700.0003800.0000600.0000190.0000140.0000491.8714660.1439710.0102960.0006990.0000620.0000161.9482310.1025510.0051400.0002600.0000240.0000130.0000130.0000470.0000140.0003950.0000260.0000130.0000130.0001040.0007350.0000350.0000130.0000130.0000130.0000410.0000130.0000150.0000430.0000130.0000130.0000680.0000140.0000130.0000130.0000130.0000480.0000130.0000130.0000130.0000130.0000130.0000130.0000130.3444500.0063060.8901732.4648690.0411240.0006870.0000230.0000150.0000130.0000130.0000130.0000142.4946330.0361670.0005290.0000200.0000130.0000130.0000130.0000131.4932600.0195730.0002650.0000160.0000992.5079290.0305972.5083420.0299070.0005272.5208300.0289870.0003720.0000172.5322670.0278400.0003150.0003040.0000160.0000130.0004050.0000170.0000130.0000130.0000130.0000130.0000140.0000140.0000780.0000130.0000130.0000430.0000160.0000130.0000132.0394522.0613212.0645723.9956941.8396100.0159310.0001490.0000140.0000130.0000130.0000130.0000130.0000130.0000130.0000130.0000440.0000130.0000120.0000120.0000120.0000120.0000120.0000120.0000120.0000122.4269371.5839484.7101460.0338982.4776451.8487410.0130530.0062662.2929762.2273320.0152680.0001160.0000140.0000140.0000120.0000120.0000120.0003070.0000450.0000430.0000130.0030730.0000320.0001230.0000130.0000120.0000130.0000120.0000120.0000120.0000560.0000130.0000120.0000130.0000120.0000120.0000150.0000180.0000130.0000130.0000330.0000130.0000130.0000120.0000130.0000130.0000120.0000120.0000120.0000130.0000120.0000120.0000120.0000130.0001930.0000140.0000120.0000150.0000140.0000140.0000140.0000130.0000140.0000870.0000770.0000140.0000140.0000850.0000450.0000140.0001600.0000130.0000120.0001660.0000440.0000130.0000120.0000130.0000140.0000120.0000130.0001840.0005200.0001452.1554622.1948580.0101300.0000580.0000130.0000120.0000120.0000120.0000130.0000120.0001930.0000130.0000120.0000120.0000120.0000120.0000120.0000120.0000120.0000122.2169900.0092120.0000500.0000130.0000120.0000120.0000120.0000130.0000120.0000120.0000120.0000120.0000120.0000150.0000120.0000120.0000120.0000120.0001920.0000130.0000120.0003300.0002050.0000130.0000740.0000132.3922360.0090360.0000510.0000430.0000140.0000120.0000130.0000130.0000201.7685770.0064210.0000360.0000130.0000120.0001740.0003210.0000141.7019211.3649910.0048020.0000290.0000120.0000121.8666661.8322990.0063090.0000340.0000450.0000130.0000430.0000430.0000130.0000440.0000130.0000430.0000600.0000130.0000120.0000120.0000120.0000740.0000760.0000430.0000440.0000130.0000730.0000440.0000130.0000120.0000790.0000130.0000150.0001620.0000130.0000150.0003080.0000140.0006120.0004270.0001110.0000130.0000740.0000450.0001060.1109630.0004000.0000140.0000120.0000120.0000120.0000120.0000120.0000120.0000120.0000120.0000120.0000120.0000120.0000120.0000120.0000120.0000120.0000120.0000120.0000120.0000120.0000120.0000130.0000120.0000120.0000500.0000130.0000120.0000120.0000120.0000120.0000120.0000120.0000120.0000120.0000130.0000120.0000120.0000120.0000120.0000470.0000130.0000130.0000130.0000130.0001630.0000130.0000120.0000120.0000130.0000120.0000130.0000130.0000120.0000120.0000120.0000120.0000120.0000130.0000130.0000120.0000820.0000430.0001510.0000430.0001690.0000130.0001630.0000130.0000130.0000120.0000120.0000130.0001080.0000860.0000460.0000741.9892700.0188291.0002030.0024760.0000190.0000120.0000440.0000430.0000500.0000440.0000130.0000740.0000740.0000130.0000120.0000130.0000720.0000130.0000120.0000120.0000120.0000120.0000120.0000120.0000120.0000480.0000430.0000120.0000120.0000120.0000120.0000120.0000120.0000120.0000120.0000120.0000120.0002870.6124340.4845270.0017980.0007960.0000140.0000430.0000450.0003550.0000130.0004670.0739511.8498180.0040510.0000540.0000132.5234080.0055070.0000590.0000130.0000120.0003340.0000130.0000120.0000440.0001190.0000130.0000120.0000120.0000120.0002610.0001020.0000130.0000430.0000120.0000120.0000120.0000490.0000440.0001050.0000450.0002250.0000130.0000120.0000120.0000120.0000120.0000130.0000130.0195471.1398670.0023110.0001040.0000470.0000750.0000760.0000260.0000120.0000120.0000120.0002020.0000130.0000230.0000120.0000120.0001750.0000130.0000120.0000120.0000130.0000120.0000120.0000120.0001600.0001670.0000130.0000120.0000760.0008010.0000150.0000130.0003910.0000130.0000130.0000120.0000130.0000130.0000320.0001580.0000270.0000120.0000710.0000130.0000120.0000120.0000120.0000560.0000530.0000600.0000130.0000120.0000120.0000120.0000120.0000970.0000130.0000120.0000510.0000120.0000120.0000580.0000131.8502890.0034510.0000191.7502572.0234440.0038590.0000190.0000130.0000130.0000440.0000121.8619651.2785380.0022550.0000480.0000440.0000120.0004970.0011810.0001970.0001630.0003600.0000560.0000120.0000120.0000630.0000130.0000120.0000430.0000120.0000120.0000120.0000820.0000500.0000120.0000120.0059310.0008410.0003590.0000450.0000300.0001910.0000130.0000130.0000120.0001560.0000130.0000120.0001570.0000130.0000120.0000760.0000130.0000120.0000432.1950912.2659880.0037032.2529900.0037010.0000480.0000120.0000122.2539460.0036420.0000490.0000120.0000120.0000450.0000120.0000120.0000120.0000500.0000430.0000120.0000122.3463060.0037130.0000182.2956510.0036161.9315290.0030350.0000170.0000572.3607150.0036840.0000180.0000120.0000120.0000120.0000120.0000120.0000120.0000430.0004960.0006540.0002080.0002010.0002150.0000132.0995853.8344164.0912490.0064981.0946660.0017980.0008510.0000751.2729250.0019843.0911145.0777213.1821043.8049700.0057350.0000210.9654400.0014430.1938660.0012770.0003480.0000130.0197870.0269500.0000520.1907770.0008870.0000140.0000120.0001670.0003440.0000590.0000540.0000500.0000600.0000780.0000130.0000750.0001270.0001150.0001410.0241165.3790742.6739450.0039100.0000770.0000130.0000120.0000120.0001610.0000130.0000130.0001570.0000130.0000120.0000120.0000120.0001610.0000130.0000120.0000120.0000130.0000130.0001290.0002471.2901930.0017950.0000150.0000930.0001600.0000550.0000140.0000460.0000120.0000120.0017470.0104970.0058900.0000200.0000120.0245710.0012740.0000140.4905130.0181140.0000670.0000120.0003820.1992900.0004260.0000130.0000130.0001580.0000130.0000120.0000120.0000120.0020350.0002850.0000130.0327980.0000560.0014240.0000140.0000120.0000120.0000120.0002260.0000130.0000120.0000120.0000130.0000120.5493410.0008710.0000140.0000120.0000170.0000830.0004150.0009800.0000450.0000500.0000430.0000450.0000130.0000120.0000510.0001660.0000510.0000120.0000120.0010700.0000140.0000440.0000120.0000430.0000554.6856527.1507970.0091040.0000890.0000440.0000730.0000430.0000730.0000450.0001280.0000450.0000810.0000750.0001790.0000600.0004840.0001060.0000560.0000750.0000472.3414220.0030900.0006061.3647432.0038070.0024530.0000150.0000120.0000120.0000130.0001560.0000130.0006010.0001590.0000130.0000140.0001650.0001660.0005060.0000130.8342864.3289994.2224150.0050462.5412410.0030350.0000500.0000450.0000490.0000120.0000120.0000790.0000510.0000120.0000122.4844560.0041792.9957810.0038040.0001410.0001350.0003380.0006770.0002150.0001770.0002120.0004141.7752620.0022821.8876140.0021920.0000810.9023120.1299960.0001920.1462625.5865151.8846070.0021690.0000152.0198562.0708730.0023710.0000150.0000150.0003060.0004840.0001950.0000840.0000430.0000501.9173770.0022330.0006920.0007690.0003040.0000430.0001770.0000430.0000430.0000430.0001040.0000830.0001070.0000430.0000810.0000160.0000120.0002670.0000130.0000430.0000120.0000120.0000120.0000120.0000120.0000120.0001901.6861440.0019180.0000140.0000570.4474360.0017540.0000150.0000420.0006070.0059030.0000840.0009620.4412730.0024970.0000460.0004830.0005200.0000750.0000430.0000430.0000120.0000440.0000740.0000120.0001060.0000440.0000750.0000430.0000120.0000760.0001810.0000130.0003410.0008520.0012260.0004700.0129540.0000260.0000120.0000120.0000120.0000130.0000830.0000130.0000440.7519440.0007960.0000130.0003070.0010180.0015160.0001460.0000760.0000450.0000440.0000520.0001080.0001140.0002420.0000130.0000120.0000121.0583780.0010970.0000140.0000120.0000120.0000120.0000130.0000120.0000130.0005960.0000130.0000430.0000130.0000660.0009570.0003120.0000130.0000160.0000120.0000120.0000130.0000130.0000120.0000130.7435090.0011720.0000150.0003060.0000130.0003120.0002080.0000130.0000410.0000130.0012160.0000140.0002010.0004040.0001750.0000130.0000990.0004250.0001800.0003210.0000130.0036760.0001660.0000130.0009891.6280080.0019230.0006680.0001070.0001100.0000750.0001112.9728030.0029230.0000470.0000120.0000120.0000120.0001010.0094820.0002940.0001400.0001370.9126431.3592860.0014590.0001600.0000130.0875460.0002460.0000130.0000120.7058362.6428000.0048920.0000470.0005390.0005580.0007480.0005640.0011480.0001650.0000750.0000440.0000770.0000730.0001770.2136250.0019070.0006590.0001920.0013300.0000141.1277230.0015120.0000140.0003510.0000440.0000120.0012180.0069400.0000490.0000450.0000120.0000122.5354750.0026330.0000450.0000120.0002750.0000431.4282460.0027200.0000150.0000120.0000120.0000120.0000460.0000120.0000120.0000120.0000120.0000120.0000122.3793910.0021660.0000140.0000120.0000120.0000120.0000120.0000120.0000120.0000120.0000460.0000660.0001130.0000121.7705250.0016261.5281663.4357251.7138550.0015390.0000450.0000120.0000780.0000120.0000820.0000480.0000120.0000190.0000840.0000460.0000830.0000490.0000471.9530470.0017290.0001580.0000130.0000140.0001580.0022950.0004300.0008132.4914940.0026764.0145372.4556790.0021480.0000492.0790372.1118382.8284860.0026650.0008410.0007053.8570374.0589480.0035120.0001610.0002010.0000131.8627290.0017340.0001350.0000130.0000120.0000120.0000120.0010002.8245871.9313360.0018092.0118760.0018600.0000800.0000120.0000660.0000550.0000990.0000460.0000770.0000120.0000750.0000450.0000750.0000770.0000760.0000440.0000120.0000730.0000430.0000120.0000130.0003950.0385480.0000750.0000440.0000120.0000120.0387190.0174550.0005552.4865212.1380442.4929240.0021670.0001072.1333094.5911962.4904020.0022180.0000140.0000120.0000120.0000130.0001630.0000130.0000120.0000120.0000120.0000140.0000120.0000130.0000120.0000130.0000120.0000120.0000130.0000120.0000120.0000120.0001600.0000130.0000120.0000130.0000130.0001870.0001630.0000130.0005270.0005900.0007674.2072680.8826653.7569564.2010831.7911690.0014460.0001590.0001570.0001590.0000130.0241560.0001540.3983660.0004520.4193450.0004180.0000940.0000880.0000540.0000120.0000900.0000960.0000520.0000470.0000960.0000120.0029581.5939400.0014260.0032031.5371980.4907910.0013640.0002730.0005290.0005361.2819250.0012590.0001510.0001110.0000450.0000760.0000120.0000120.0000760.0001400.0000130.0000120.0000120.0000120.0000120.0000120.0000120.0000120.0000120.0000120.0000120.0000121.6586962.2740120.0018250.0000140.0000120.0000120.0000950.0000430.0000120.0000120.0000120.0000120.0000550.0000670.0000120.0000120.0000120.0000460.0000120.0001610.0000130.0001600.0000130.0003670.0001800.0000200.0003960.0003380.0000750.0000132.5131840.0020320.0001200.0000120.0000480.0000120.0000120.0001270.0000130.0000470.0000120.0000120.0000890.0000800.0000120.0000120.0001230.0001220.0001120.0000480.0000600.0001110.0001390.0001380.0001370.0001360.0001140.0000460.0021060.0001130.0001270.0000430.0000490.0001200.1481424.3397493.6834125.3389995.7287017.7528164.4841840.0035850.0002380.0001690.0001620.0000660.0003330.0004230.0000470.0000780.0000120.0001130.0001130.0000460.0000450.0000120.0001090.0000520.0000421.1600310.0010390.0005240.0000130.0001220.0000440.0003910.0002480.1404350.0006960.0005940.0004562.1592710.0025230.0003151.0713310.0009281.7709570.0015550.0003880.0002660.0001070.0000910.0000820.0000990.0001450.0000550.0000910.0001020.0000540.0000120.0000430.0000120.0001240.0000810.0014120.0000140.0003180.0000130.0000120.0000130.0000120.0001740.0000130.0000130.0001940.0000130.0000140.0001880.0000141.8809200.0013160.7814412.0837460.0014530.0000170.0000140.0000120.0000121.9771520.0013740.9271740.0006700.0000140.0000120.0132250.0000221.7634680.0012200.0000130.0000130.0000120.0000120.0707920.0009140.0000430.0000790.0003920.0004790.0001460.0000580.0000420.0001350.0000590.0000830.0000950.0000120.0005480.0005920.0005940.0007730.0202230.0010970.0000130.0005030.0000130.0000120.0009270.0000130.0000120.0000120.0000120.0000120.0000120.0012690.0000130.0000470.0000120.0000120.0000120.0000120.0000120.0000570.0000120.0001070.0000170.0013290.0000130.0000140.0000120.0000120.0000570.0004860.0000130.0000120.0000120.0010290.0010250.0011490.0006280.0007090.0002580.0005980.0005510.0002700.0001392.3216512.2987942.3230690.0015302.3000612.2877170.0015040.0000130.0000130.0000122.3605230.0015472.3154930.0015152.3070220.0015080.0000760.0000120.0002540.0001250.0000120.0000430.0000130.0000150.0000740.0000440.0000440.0000430.0000750.0000130.0000480.0000450.0000440.0001080.0000120.0000820.0000130.0000740.0000560.0000461.8968513.9752271.9153980.0012650.0000430.1010120.1816740.2688522.0181121.8723741.9990943.8205120.0024304.0770240.0026580.0072443.3609810.0021330.0000140.0000120.0000120.0076780.0000170.0000120.0000120.0000120.0000430.0000120.0000120.0000120.0000430.0000120.0000430.0001410.0000120.0000120.0000120.0000130.0000120.0305560.0000310.0000130.0001370.0000120.0000120.0002730.0000130.0000440.0006490.0000130.0000120.0000120.0000120.0000120.0000120.0000120.0002730.0000150.0000120.0000120.0000120.0000120.0000120.0000760.0001330.0001360.0001360.0001390.0002020.0002630.0002220.0006730.0004680.0000590.0002890.0010441.7801382.0751081.1663230.0026200.2406300.0007870.0049150.0001470.0001420.0001432.0355556.3659220.0043050.0001650.0001620.0003080.0001590.0003050.0001630.0003050.0000130.0000750.0000480.0000120.0000120.0000130.0000120.0000790.0000220.0000140.0000880.0000130.0000850.0000130.0000460.0000130.0000810.0000800.0000120.0017040.0008680.0001770.0003641.7593810.0028680.0001730.0000130.0001900.0000440.0000120.0000120.0000120.0000430.0001530.0002870.0000430.0000120.0000120.0000120.0000120.0001120.0000120.0000120.0000120.0000120.0000120.0000120.0000120.0000120.0000120.0000120.0000483.8645965.8869021.9212766.1105252.3361910.9328240.0009560.0000480.0002480.0007490.0003860.0000460.0000140.0002090.0000810.0000140.0002280.0000450.0089510.0004270.0000870.0000150.0000120.0006980.0000920.0002500.0003310.0001350.0001460.0001790.0001355.9888202.0149353.9048455.7181760.4670840.0003480.0006261.9260060.0017121.4434621.9887311.9588312.0632300.0021285.8723851.9485323.9660422.0543864.1523022.0904301.9925740.0011390.0000130.0001370.0001370.0001380.0001560.0001350.0001380.0001350.0001360.0001370.0001412.3635152.5442970.0015716.6203532.3372471.0227150.0006460.0001060.0000130.0000120.0001040.0000120.0000750.0000430.0001040.0000430.0000120.0000730.0000120.0001880.0000130.0002150.0000130.0003680.0000130.0001840.0001750.0000120.0000120.0000132.0897700.0013690.0002100.0002050.0002400.0003320.0005610.0033000.0000190.0000150.0006120.0000130.0000230.0000132.5186181.9903723.1064700.0017130.0000132.4595472.4202232.5434062.3320972.5365970.0013950.0000132.5057450.0015860.0000130.0001700.0000120.0000130.0004580.0004180.0003810.0001140.0012610.0003980.0663780.0089890.0001430.0005830.0005960.0003660.0000740.0004140.0000740.0004890.0003650.0001980.0004262.2390390.0014840.0000610.0000630.0014340.0000820.0003520.0002560.0003540.2645443.4404426.5373411.6387950.0008870.0000130.0000130.0000130.0007000.0000130.0000120.0000130.0000120.0000431.6353042.8538310.0015260.0000130.0000120.0000133.5453610.0025140.0005460.0000130.0000120.0001660.0000130.0000640.0000130.0000500.0000220.0000500.0000620.0000140.0000120.0000530.0000550.0000140.0000120.0000150.0000140.0000130.0000150.0002520.0026950.0003010.0010540.0014690.0004871.9308301.8620881.9475873.7383761.7679090.0015640.0005750.0000130.0000120.0000120.0067770.0000160.0000490.0000470.0000460.0000120.5681530.0003060.0002320.0003940.0000130.0000120.0000120.0001890.0044960.0001830.0000120.0000130.0045370.0000150.0001800.0000130.0000120.0000120.0000120.0000120.0000120.0000120.0000122.2495551.9682130.0010170.0000130.0000171.4747770.0007970.0000130.0000120.0000130.0000120.0000442.1651860.0011122.2061920.0011310.0000131.9946870.0010224.2704172.1594040.0011342.1832410.0012180.0001401.4472180.0008890.0000130.0003080.0000130.0001600.0000120.0000440.0000120.0000120.0001070.0000440.0000430.0001040.0000130.0000430.0000440.0000770.0000430.0001060.0000440.0000120.0000760.1195731.2681871.2163850.0006180.0000130.0000120.0000121.6757315.2945960.0026410.0000141.8727580.0009410.0000131.8727581.7701690.0008880.0000130.0000120.0000131.0478591.8064130.0009030.0000130.0000140.0000480.0000120.0000120.0003520.0000130.0000120.0000130.0000130.0000130.0000130.0000680.0002010.0000130.0000120.0004390.0000130.0000130.0000120.0001960.0000120.0000120.0000120.0001740.0000120.0001890.0001890.0000120.0000120.0000120.0000430.0001590.0001690.0000131.8641240.0010630.0000130.0006500.0007820.0007150.0007603.0984660.0016320.0001960.0001200.0002320.0000960.0001250.0001430.0000120.0001150.0001950.0001600.0004500.0026060.0001600.0003050.0003050.0001900.0001580.0001980.0001411.8530070.0010710.0002610.0000800.0001730.0000120.0000440.0002181.6682170.0008070.0001901.8137060.0010470.0000130.0001670.0000130.0000130.0001830.0001800.0000150.0000130.0001390.0001400.0001460.0001442.6492720.0014120.8499540.0006100.0427772.1871300.0012620.0000450.0000650.0000120.0000120.0000470.0000120.0000442.4819950.0011770.0003290.0006230.0000130.2900461.5177925.2006846.1404731.8440960.0008740.0000130.0000120.0000120.0000120.0001880.0000120.0001600.0001600.0000120.0006620.0005170.0000130.0000120.0000120.0001710.0000120.0000120.0000120.0000120.0000121.7837555.1558050.0028700.0003600.0005670.0003944.0996241.9052830.0009210.0000731.9763140.0009531.4150870.0007254.9361160.0023100.0000450.0000121.9386100.0009320.0000133.6572321.9401231.9129550.0008880.1351192.0096060.0009301.5988290.0008060.0000430.0000430.0000120.0000430.0000440.0004580.0006250.0122530.0004250.0006170.0002440.0001790.0001930.0000120.0001932.4017560.0012250.0001080.0001390.0001040.0001090.0000450.0000750.0001040.0000790.0001360.0002060.0001410.0000780.0002030.0001390.0001070.0005910.0004500.0005931.2914960.0008370.0000440.3134740.0013920.0000130.0000440.0000120.0001705.4534904.5421684.2414353.0264090.0017600.0003090.0000130.0001570.0001580.0001690.0880880.0001160.0004010.0001090.0002680.0010310.0002520.0014070.0002110.0006240.0002640.0004660.0000770.0002660.0002580.0001100.0004280.0004340.0002400.0010570.1364310.0004730.4637190.0002780.3095510.1573590.0009112.7930180.6286660.0002921.9658400.0101370.0077540.0038000.0000210.3621500.1093420.4484890.0002090.0523170.0036731.1896211.1011042.3499840.0044811.2898010.0005780.0019020.8046460.0019970.8543331.9154940.0013671.4653081.9448640.0038670.0024600.0032370.0029730.1968621.0805680.2358840.0041800.0008060.5893610.5805321.3899820.7495800.0021010.0009091.4164612.0899600.2925790.3032351.0155942.1188420.0020450.0000461.6857130.0008310.6372411.7277250.0025392.5063340.0018690.4326540.8589421.7055831.2540281.3905240.3679971.5766701.6240370.0007140.5506250.0003500.3940761.2759590.4750923.0058900.2761290.1792990.1462070.9594030.1911900.0001070.1058680.3220192.1158150.1134010.9835890.3149920.0013670.0000231.1075820.0004840.0008370.0030311.7694011.5839120.0008000.0153970.0007620.3664170.1515670.0035020.0045190.0000762.4504520.0010471.1984110.0186303.2316132.4419120.0271430.0000260.5471680.0499170.0000340.0000130.0041400.0227281.1554720.0012250.7080240.6050890.0067871.1210841.0221041.7710701.5564900.0016430.4384352.1738540.0016051.8088061.2963411.5967060.0023110.4187830.0018651.4602830.0019150.0017180.1582610.0001411.6898720.0008080.0011741.6780523.9951630.0017280.0066120.6330611.8323020.0018380.0070400.0001000.0000990.5161981.4619850.0006240.0003660.0003281.6731330.0007400.0479531.6441530.0014160.0004950.0000771.7467351.5806111.8869230.6658891.4635661.4595910.0009471.9134981.2360662.5916300.0030712.9867000.0012360.9963842.5566950.0010580.0031960.9598882.2177120.0009240.0022930.8770590.6230110.0022760.0018320.3598620.0001640.1055281.3839600.0045950.0001671.9411220.2446860.2990940.0001360.2237260.9961110.7858720.0243780.0000270.3989580.4240840.0002670.0012700.0006840.0017251.5988050.0035980.0017610.0063970.3959830.3016591.7025040.0024180.0002750.0050530.0000432.6376211.3991220.0005781.0779341.6989070.0013980.0007900.0003800.0024751.5631090.0013710.0000420.3914551.1312671.7677451.2264910.0008491.5928232.4203480.0024360.0039880.0011260.0007291.4638593.1028510.0020890.0014041.4643360.0027220.0025440.0010690.0000270.8359140.5156450.0045560.1487181.2654232.0051362.1047690.5668850.0002641.2243791.2966760.0028331.1074111.9062430.6666210.7246580.0012850.6902500.0005030.6901250.1233580.0000640.0033131.2113930.0005090.0023460.5421620.3991480.0130510.0492010.2760402.4080610.0009580.0025290.0000151.7440230.0006991.1996400.0004820.7944491.3849360.0005581.3780080.7035730.5557960.6036981.4370960.0009330.0014150.0000161.5708453.9051290.0081481.3885011.4946690.0006000.0008810.0000232.9148970.2095820.6780030.7443800.0429660.0000290.0003182.0898020.0008250.0009642.8580390.5986340.0007261.7784330.0070920.0003522.0317620.4269400.0002261.5586420.0006120.3839840.0001610.7306140.0006110.0159832.1342471.3372751.0749390.0010501.8631150.0008101.6869301.6671840.3913370.7640060.0034710.0007950.0162670.8212411.0324170.6686200.0056930.0055330.0000460.0019511.5351570.8858601.1659290.0004720.0000510.0028460.3406390.2236850.1792080.0024640.0019841.8486390.0007670.2387561.3184231.4426151.7631740.0007471.4189070.0033020.0024600.0238850.0002181.8291210.0012090.0004921.5624301.7770361.4217890.0038410.0046630.0000201.8043570.0020702.0848670.0017310.0011221.0718581.4120240.0032860.0009500.0002620.0008512.0883330.0027730.0009520.0000760.3513330.0059770.0044270.0000360.0266140.0006310.0000860.6097620.5433270.3875740.0064360.0000221.1859220.0012670.9387320.7867740.0004903.6445511.3840161.4261051.3679320.0032000.0049470.0260760.0000251.4059000.0015530.0022140.0029000.0017920.0000220.0011742.8274370.2144181.0998621.8111370.0525520.3165270.8387510.6341670.0002490.0379281.6424941.4590631.1804891.4770080.0022180.0930590.0021110.0000160.0508870.0000391.8006762.7758701.5264280.0008870.0019231.3295550.7238280.7909750.1633740.0000800.0000140.1900400.3675420.8116230.7498380.0015560.0000540.0000310.0014281.4034981.1548880.0570481.8450480.9758581.6619971.0301900.0071150.0000300.0011970.6863440.0982730.0022572.8122440.0742931.2163902.4848601.3602570.7285562.0949730.0010051.2689160.0027000.0000160.0061250.0009230.0003021.8562790.0027220.0011310.0013420.0011610.0000141.1871050.3539670.0007300.0000150.0006120.0010244.3175140.0044120.0047672.2688611.5116800.0026840.0002370.0664532.1116700.0953670.0015100.0011221.6557932.5127170.0032323.1874590.0025940.0009160.0025640.0016602.8659601.1865420.1410780.1257150.0036180.2706390.0001540.0006361.1082970.0739290.3396260.5659231.5126580.0014790.0001590.0375390.0011020.0010010.0015720.0020360.8768580.8264110.7622780.0508460.0026543.4247320.0033230.4085580.0232840.0003651.5378720.0884220.0013581.2966730.0045751.5530520.4610412.4216860.0026660.0332590.7652981.8293832.7399100.8360313.1697971.8339730.0020590.0882310.0001301.5595931.8153970.6250580.0002532.2879581.6088330.0022520.0022910.0000290.5538870.0204480.0004040.3726780.0329080.9519501.4567791.2938450.0008800.1639601.3621710.0011900.0125572.0777790.0026860.0019150.5182410.0578770.0021960.0013360.3340300.0486670.0007732.6901380.0009510.0018050.0019261.6021460.4744131.5148991.2462211.6525620.0005880.7389071.2830460.0015280.0298470.0029860.0438071.0672060.2308731.4681803.3619720.0463100.0006820.0000160.0812250.8918900.0014271.2193870.0016160.1943880.0077101.1037651.1968001.4570000.0006411.1433490.0038910.0014180.0016181.0956310.0076670.8168460.4301630.0012101.6274721.4934562.6348522.0884802.5699230.1453232.9235960.0013721.5700961.9161360.0014470.0040011.4665510.0045820.0000310.0150890.0020350.0150850.3024951.4104750.0006280.0000410.5431370.0004900.0260121.5585681.6999070.0024640.0000332.0910083.1338840.2118050.0125410.0929340.0010300.0027130.0046580.0000300.0000180.0023520.0004861.8403160.1370720.217180

*******************************************
EVALUATING PIPELINE 
Pipeline directory: /home/ubuntu/fnd_implementation/roberta/grid_search/results/pipeline_abfb6296_2020-02-14_16-10-26vjyufsvp/
With following parameter combination: {'batch_size_seq_length': 1, 'lr': 1e-05, 'lr_type': 'cosine'}
EVALUATION OF CHECKPOINT /home/ubuntu/fnd_implementation/roberta/grid_search/results/pipeline_abfb6296_2020-02-14_16-10-26vjyufsvp/outputs/checkpoint-3
-------------------------------------------------------------
|           |   agree   | disagree  |  discuss  | unrelated |
-------------------------------------------------------------
|   agree   |    746    |    49     |    143    |     7     |
-------------------------------------------------------------
| disagree  |    80     |    315    |    67     |    11     |
-------------------------------------------------------------
|  discuss  |    191    |    69     |   1513    |    53     |
-------------------------------------------------------------
| unrelated |    20     |    35     |    56     |   8543    |
-------------------------------------------------------------
Score: 8758.0 out of 9226.0	(94.92737914589205%)
Accuracy: 0.9343587157505463
F1 overall: 0.8127813789844165
F1 per class: [0.7527749747729566, 0.6695005313496281, 0.8393897364771151, 0.9894602733379662]
*******************************************


*******************************************
EVALUATING PIPELINE 
{'batch_size_seq_length': 2, 'lr': 1e-05, 'lr_type': 'linear'}
INFO:__main__:Creating features from dataset file at /home/ubuntu/fnd_implementation/data/processed
  0%|                                                 | 0/11898 [00:00<?, ?it/s]  0%|                                       | 1/11898 [00:01<3:34:15,  1.08s/it]  4%|â–ˆâ–Œ                                   | 501/11898 [00:01<2:23:42,  1.32it/s] 17%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                              | 2001/11898 [00:01<1:27:22,  1.89it/s] 25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                            | 3001/11898 [00:01<54:59,  2.70it/s] 29%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                          | 3501/11898 [00:01<36:20,  3.85it/s] 38%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                       | 4501/11898 [00:02<22:24,  5.50it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                  | 6001/11898 [00:02<12:30,  7.85it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–          | 8501/11898 [00:02<05:02, 11.22it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11898/11898 [00:02<00:00, 4497.06it/s]
  ******************************************* 
              Running Evaluation                
  *******************************************
 
  Length dataset evaluation: 11898
  Length dataloader evaluation: 1488
  Number of epochs: 3
  Batch size: 8
  ******************************************* 
 
['/home/ubuntu/fnd_implementation/roberta/grid_search/results/pipeline_a346ee22_2020-02-14_13-30-04pt14317i/outputs/checkpoint-3']
INFO:__main__:Evaluate the following checkpoints: ['/home/ubuntu/fnd_implementation/roberta/grid_search/results/pipeline_a346ee22_2020-02-14_13-30-04pt14317i/outputs/checkpoint-3']
INFO:transformers.configuration_utils:loading configuration file /home/ubuntu/fnd_implementation/roberta/grid_search/results/pipeline_a346ee22_2020-02-14_13-30-04pt14317i/outputs/checkpoint-3/config.json
INFO:transformers.configuration_utils:Model config {
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-05,
  "max_position_embeddings": 514,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 1,
  "use_bfloat16": false,
  "vocab_size": 50265
}

INFO:transformers.modeling_utils:loading weights file /home/ubuntu/fnd_implementation/roberta/grid_search/results/pipeline_a346ee22_2020-02-14_13-30-04pt14317i/outputs/checkpoint-3/pytorch_model.bin
HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=1488.0, style=ProgressStyle(description_width='initial')), HTML(value='')))
0.8939170.8941290.4475630.1492500.0373400.0075340.8748170.1250000.0156560.8520520.0852370.0077750.0007170.0005010.0000630.0001860.8264160.0486440.6499240.0342350.0017720.0001580.0000340.0000280.0000690.0000290.0000270.0000270.9855900.8460160.0282600.0009480.0000580.0001481.1671600.0333760.0009560.0000551.3335230.0342240.6701220.5973000.9134721.2717150.0289601.1670700.0257800.0005770.0005470.0000380.0000280.0000280.0001210.0000690.0003330.9116621.8116181.7630570.0304880.0005450.0000380.0000290.0000280.0000640.0000290.0000290.0000290.0000290.0672742.1238241.1712120.0166012.1542550.0295380.0004260.0000340.0000380.0000920.0041620.4995650.0062720.0001050.0000290.6920940.0082660.0001260.0000320.0000270.0000340.0000290.0000300.0000280.0000270.0000270.0000270.0002380.0000450.0000360.0000340.0000930.0000920.0000620.0000600.0002990.0003040.0000670.0000290.0000280.0003450.0009061.8360230.0171420.0001790.0000290.0000310.0002820.0000290.0000260.0000260.0000270.7418660.0061580.0000780.0000930.0000290.0000300.0001300.0000290.0000280.0002440.6673360.0053510.0001271.0406000.0078260.0000880.0000290.9203420.0066960.0000740.0006400.8225470.5494620.0038710.3469150.7261480.0050340.0000910.0000590.0000570.0001160.0000270.0000270.0001540.0000880.0000860.0000580.0000960.0000290.0002040.0003800.0014020.0006110.0000940.0001490.0025340.0000430.0000280.0000280.0000280.0000280.0000280.0000280.0000280.0000280.0000280.0000280.0000280.0000640.0000280.0000280.0000280.0000280.0000270.0000280.0000620.0000280.0000310.0002430.0000280.0000280.0000280.0000270.0000270.0000290.0000270.0001340.0002050.0002370.0002300.0000290.0000280.0002330.0001190.8676380.9743390.0047600.0001130.0000970.0000900.0000880.0000270.0001320.0000280.0000280.0000280.0003860.0000620.0000280.0000270.0000280.0000270.0004260.0005940.0110820.0001100.4623510.0027230.8341440.0037031.1655960.0051410.0000490.0004240.0000600.0000700.0000260.6484040.1374100.0006340.0000300.0001220.0001810.0003420.0000300.0000280.0000271.0333500.0047730.0001710.0000920.0000280.0000310.0000440.0000280.0002180.0000280.0000280.0000270.0004000.0000280.0014420.0000390.0005160.0000380.0000320.4111830.0017080.0001210.0000270.0000760.0001090.0000270.0000270.0001120.0000270.0000620.0000640.7597130.0027521.7317660.0066300.0000570.0000601.4860160.0052730.0000790.0977860.0008830.0004980.0000300.0000650.0000570.0000280.0000910.0000590.9540431.7813400.0060360.0002650.0000280.0002060.0002110.0000290.0000880.0000591.0186600.8797560.0029450.0000380.9585480.0031410.0000690.0000280.0000600.0000580.8679170.0027670.8578430.3338060.0011220.9752770.0030580.0000390.0000300.0000610.0011790.0004890.6568900.0045980.0215910.0004200.0003180.0002811.2941471.3054750.0039730.7639790.2987180.0014530.8575120.6143930.9024960.0028540.0005950.0000910.0001170.0000860.0001690.0003474.9743520.0292800.0001110.0002130.0000280.0002070.0000290.0002140.0000290.0000280.0001600.0003040.0000280.0002130.0000670.0000630.1843302.0491580.0055951.5544581.5550760.5465660.0017440.7465680.0020240.0002190.0000280.0014650.0005580.0014470.0015300.0000310.0002620.0000270.0000260.0004900.0003240.0000590.0004560.0010520.0000930.0000640.0039290.0003120.0000270.0007280.0000630.0001025.5837700.0142470.0001590.0001200.0001430.0001220.0002400.0003730.0001520.0001250.0005360.0016501.2703990.0031200.0000360.0002840.0008950.0000330.0008220.0002441.7998601.7539420.0042050.0001200.0000670.0001660.0001601.1041170.9728860.0027610.0005030.0007980.0002971.0716680.9983790.0024180.8004550.2911910.0538060.0001531.7293390.0039660.0006560.0008390.0001300.5960580.0020470.6478111.5131480.0034740.0001900.7987160.3442700.0007940.0003340.0000620.0000300.0000300.8919741.6348450.0036480.6125890.0013941.4668631.0142061.8598910.0046620.0007440.0000940.0000660.0000930.0001650.0001260.0000960.0002940.0019640.1189170.0032440.0000330.0000260.0000880.4459170.0009550.0014880.0118230.0002770.0001200.0004840.0002360.0000280.0007550.0000290.0000270.0000270.1724430.0004070.0000640.7047100.0014480.0000300.0000270.0000280.2339080.0008700.0004640.0003050.0000370.0003280.0004950.0001480.0009780.0007490.4231330.0010760.0456190.0010410.0002200.0001830.8155770.0016390.0000291.6212530.0035741.3699702.1110890.0043510.9034970.0017480.4488330.0024810.0035800.0014660.2631960.0006160.0001570.0007320.0026560.0007700.8561330.0018260.0002830.0004550.0046270.0000851.1063050.0024090.0003040.8207160.0295470.0000810.0000640.0000270.0000270.0000271.1822160.0021650.0000310.0000270.0000270.0001810.0001400.8634962.6007780.8539990.0015770.0000920.0001240.0000300.0001300.0001300.8499330.0017060.0000300.0094450.0059081.3942322.7188450.0048371.3074850.9651700.0038733.8818850.0069240.0002860.8313630.0015820.0000310.0002940.4733030.0015250.0040900.0000820.0001820.0001260.0000930.0001260.0001520.0000640.0001230.0000290.0004650.0000960.0000270.0004510.9313751.5022180.0026992.2697640.9899740.0016580.0000320.0002560.0000280.0000290.0049280.0000380.0000280.0000270.0000280.0002340.0000280.2734010.0007670.0012691.7712822.1756262.7123010.0045470.0004060.7132231.1187651.4387540.0024770.0001550.0001030.0001600.0001500.0206540.1121101.6948920.0089340.0015920.7020570.0016940.0001590.0000890.0000890.0001500.0000280.0000280.0000270.0000270.0000270.0201511.0003340.0015590.0000980.0000570.0000260.0000600.0000590.0000260.0000580.0002180.0002250.0005920.0005300.0002811.3094960.0314250.0001410.0000260.0002100.0000780.0001550.0001150.0003140.0003640.0005080.0003080.0002830.0002540.0000670.0002200.0001020.0025142.9861894.7905865.0878410.0081090.0006780.0002970.0003800.0000980.0002360.0000980.0001230.0000930.0058240.0004690.0001630.7065310.0035360.0074750.0016240.0002810.6380540.0020670.0117470.0011380.0038350.0014260.0593070.0001400.0069660.0008690.0002770.0000290.0000280.0002290.0002190.0000420.0002870.7407670.7422960.0010540.0000320.0010160.0005310.0000340.0014190.5711220.0008090.0000300.6472770.2989700.0009440.2651110.0007810.1104740.0006990.0006360.0015270.0058950.6133920.6010770.2190330.0003280.0000350.0000290.9553940.0013360.0000290.0000270.0000660.0000912.0219260.0027230.2245160.1514380.0002270.0014390.0013820.0012040.0046480.0005122.0066470.9955202.0534170.0027040.0000301.0509920.9575841.0292230.0015240.0005990.0000690.0000270.0001190.0000990.0000870.0000890.0001520.0001040.0000880.0000952.1652910.9611650.4534891.8754702.5827982.6991841.8561401.1057801.8623230.0023760.0007160.0000300.0000280.0000590.0000280.0000630.0001660.0000280.0000270.0002100.0000280.0001460.0002440.0000640.0001580.0000280.0000270.0000280.0001150.0000270.0000280.0001330.0002790.0003060.0006900.0009780.0038170.0356901.6540290.0084940.0152420.0005040.0002792.1358480.0039280.0006110.0005620.0005790.0001060.0000770.0000270.0001500.0000290.0001220.0001470.0000670.0001880.0603590.0009470.4579600.0047550.0003320.0000570.0000260.0001110.0000930.0000260.0000260.0000570.0000260.0000260.0000270.0000260.0000584.2732643.5668752.9011100.0043090.0647790.0004670.0003020.0002650.0006170.0220500.0001930.0004530.5373840.5380550.0009751.8933382.4436432.3192850.1934972.6414691.5000030.7466810.0242250.0006290.0006040.0004100.0000280.0002760.0005200.0002850.0002840.0002842.2692762.2271152.1260830.0025890.0000310.0001440.0001440.0001720.0000950.0002490.0002340.0004200.0002280.0002210.0000280.6367160.0011700.0007080.0009780.0000880.0004390.0000492.1594280.9443421.0929472.1895092.1655490.0023881.1110240.0014290.0000300.0019390.0005610.7617270.6739530.0015630.0014940.0005020.6954660.0014360.9979760.0016020.0573410.0007040.0009952.4050974.0481980.0043470.0000310.5840990.0006480.0000592.3588410.0025280.0000290.2327100.0007870.0002160.0000760.0000580.0000690.0000660.0000610.0000640.0000270.0000290.0000381.0206313.0200832.0657952.7450892.8668580.0043640.0000310.0000650.0000630.0000910.0536990.0002850.0004140.0000301.0901010.0013420.0003740.0002200.0000270.0000260.0000260.0000271.7141160.0017750.0602810.0001260.0000270.0000590.7895790.9170590.6683951.4453040.9612130.9471451.3660760.0015960.0004170.0002070.0000590.0001290.0000990.0001280.0000950.0001280.0001770.0000960.8078790.7833260.0008070.7547342.6100270.8544230.0008751.6727980.0016820.0000301.6716740.0016760.0000740.0000280.0005900.0000280.0000280.0000280.0002720.0007280.0000310.0002540.0000280.0002970.0002820.0003540.0000280.0002890.0003320.0344010.0007760.0017281.2863770.5918020.5334420.4232780.5787250.0124390.0038220.4614650.0012680.0004460.0004411.1788520.6806240.0019370.0004640.4274890.3915040.0008340.0003960.0005600.0003130.0001550.0003160.0003170.0003100.0002781.2246950.0012710.0000290.0000770.8864860.0012810.0008500.8413800.9658630.8546650.0008240.0000270.0002630.0004570.0008140.0006070.0000260.0002400.0000260.0000282.5967300.0034280.0011001.7050970.0016910.8399070.0030331.3144240.0012630.6262510.7059211.2560670.0033010.8545750.0009890.0000880.0000560.0007490.2859620.0015600.0003400.0001491.1097020.0012480.0002310.0001540.0001810.0002110.0002610.0001840.0002430.0012950.0023200.0008390.0006820.0000630.0001353.2204482.9832710.0035620.0002320.0005070.0003380.0006290.0021730.8345740.0017110.0008390.0003970.0004440.0009720.0125250.1497440.1281220.3856701.5795500.1338710.8394580.0290310.4036050.5629470.0216620.4282811.2641410.3305300.1018860.3185041.0909270.3779611.2904970.0457700.1782290.8937450.0299240.0025070.8515740.0023961.3134900.0995410.9981250.0017920.8299140.8597400.9494630.1960440.8358661.0057060.9331981.1565400.3833140.3862861.5244260.2544390.3915780.1070700.3123390.8324430.5399240.0008640.3730160.3453200.6206300.0152270.0629530.3580780.0826831.1192520.8569321.3227590.0583920.2727390.0002740.0084440.7324840.6485870.0076251.7106130.8255061.1028930.3129771.0549320.1816650.4680831.4201060.7586070.6048370.6111602.0425680.2766641.0873130.0021070.7344530.2285150.0006140.2562350.7954480.0665420.0595901.7475360.4854810.7935860.8579680.5900250.6565881.6894760.0469651.8858700.5082970.3263750.0023690.3322170.2505380.0006971.5087000.3547580.7934910.0050960.0658000.1958790.0015710.7809140.2131050.4561130.4039510.0067090.0045472.0848790.5732150.9220450.0033800.4061810.0007870.0667361.3370360.3827360.7086100.0338460.5340150.7802590.6614190.0419480.0008131.2131870.0209351.0297751.3323040.1917280.5859311.3678020.9161140.1059030.1144570.0290020.4573500.3415910.4143140.3678551.2162290.0035670.3613640.5273220.4802960.6833551.6600060.2728810.4857950.0738352.3918450.6441800.8958440.0012661.7926880.6259410.0064220.6195930.0012622.1488131.0245540.0032211.7158240.6270960.3541360.0376500.0009360.8645670.0039980.7743121.1705280.9563060.0029860.6032710.7069570.0019290.0008981.2248270.8363290.0040830.3658700.3966681.0120190.2825240.7931370.3424090.5093660.2934710.8444870.0027771.6217980.7119890.0037301.2416650.9748390.5985780.6098940.0020010.9762890.0051700.2099820.1871980.0012990.0004240.3267841.3531480.9572680.6705780.3226011.8622780.0720940.0102600.0194140.6016390.0061220.0027671.1220800.3374770.8533090.3889100.4226450.4355541.1729410.8111950.0519560.0496340.6957730.8416700.0020631.1273190.4432000.0003600.3160390.6213010.0014210.0003611.4425120.7461001.5196200.6065570.0006430.2239261.3259500.4993431.3139411.2227050.8148510.0015760.0047140.3433560.0039590.0038370.5944400.4868520.0008571.4995770.0052201.2683580.0031360.6998210.0461830.8721311.2286721.1821400.0022201.1417140.2337890.0882140.0113090.6572160.5957201.3846740.0190370.0084990.0073100.8736670.7007120.1049401.0679680.3404910.8428320.0731590.0763721.0936601.0369470.1514411.5077481.7933170.0850990.4431591.3249000.4032211.6029970.0044120.1393520.3232860.1935211.2943600.4589980.1660260.1157190.8502070.9171650.0476070.5497630.0592470.6200820.0177790.7080790.5413540.6719920.5164620.0030710.0038820.5618841.5902640.1467750.0452180.5546050.6746050.7249370.6754500.6085610.5890360.0052960.5296510.6979160.6337481.9041412.3918781.4140610.7175410.4120490.6590300.0125300.0433580.3998100.3492450.2494410.0234711.2735430.0018031.5110650.3508400.1890350.0371380.0000710.0036710.9785560.629835

*******************************************
EVALUATING PIPELINE 
Pipeline directory: /home/ubuntu/fnd_implementation/roberta/grid_search/results/pipeline_a346ee22_2020-02-14_13-30-04pt14317i/
With following parameter combination: {'batch_size_seq_length': 2, 'lr': 1e-05, 'lr_type': 'linear'}
EVALUATION OF CHECKPOINT /home/ubuntu/fnd_implementation/roberta/grid_search/results/pipeline_a346ee22_2020-02-14_13-30-04pt14317i/outputs/checkpoint-3
-------------------------------------------------------------
|           |   agree   | disagree  |  discuss  | unrelated |
-------------------------------------------------------------
|   agree   |    756    |    76     |    143    |    14     |
-------------------------------------------------------------
| disagree  |    65     |    284    |    67     |    21     |
-------------------------------------------------------------
|  discuss  |    197    |    78     |   1512    |    46     |
-------------------------------------------------------------
| unrelated |    19     |    30     |    57     |   8533    |
-------------------------------------------------------------
Score: 8730.25 out of 9226.0	(94.62659874268373%)
Accuracy: 0.9316691880988401
F1 overall: 0.8000732603452771
F1 per class: [0.7462981243830207, 0.6276243093922652, 0.8372093023255814, 0.9891613052802412]
*******************************************


*******************************************
EVALUATING PIPELINE 
{'batch_size_seq_length': 4, 'lr': 1e-05, 'lr_type': 'constant'}
INFO:__main__:Creating features from dataset file at /home/ubuntu/fnd_implementation/data/processed
  0%|                                                 | 0/11898 [00:00<?, ?it/s]  0%|                                       | 1/11898 [00:00<3:08:50,  1.05it/s]  4%|â–ˆâ–Œ                                   | 501/11898 [00:01<2:06:39,  1.50it/s] 17%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                              | 2001/11898 [00:01<1:16:59,  2.14it/s] 20%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                              | 2390/11898 [00:01<51:47,  3.06it/s] 34%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                         | 4001/11898 [00:01<30:06,  4.37it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                      | 5001/11898 [00:01<18:24,  6.24it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                  | 6001/11898 [00:02<11:02,  8.91it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11898/11898 [00:02<00:00, 5551.12it/s]
  ******************************************* 
              Running Evaluation                
  *******************************************
 
  Length dataset evaluation: 11898
  Length dataloader evaluation: 372
  Number of epochs: 3
  Batch size: 32
  ******************************************* 
 
['/home/ubuntu/fnd_implementation/roberta/grid_search/results/pipeline_9d68f9e6_2020-02-14_12-43-39nu71avtu/outputs/checkpoint-3']
INFO:__main__:Evaluate the following checkpoints: ['/home/ubuntu/fnd_implementation/roberta/grid_search/results/pipeline_9d68f9e6_2020-02-14_12-43-39nu71avtu/outputs/checkpoint-3']
INFO:transformers.configuration_utils:loading configuration file /home/ubuntu/fnd_implementation/roberta/grid_search/results/pipeline_9d68f9e6_2020-02-14_12-43-39nu71avtu/outputs/checkpoint-3/config.json
INFO:transformers.configuration_utils:Model config {
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-05,
  "max_position_embeddings": 514,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 1,
  "use_bfloat16": false,
  "vocab_size": 50265
}

INFO:transformers.modeling_utils:loading weights file /home/ubuntu/fnd_implementation/roberta/grid_search/results/pipeline_9d68f9e6_2020-02-14_12-43-39nu71avtu/outputs/checkpoint-3/pytorch_model.bin
HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=372.0, style=ProgressStyle(description_width='initial')), HTML(value='')))
0.1013050.3115590.3537290.1184390.0297440.0061590.0011780.4201570.4996830.4806751.1192550.5024070.0491640.1717740.7174930.0480080.0031251.0712900.3201140.2319240.2055280.0105590.0058720.0006080.0003010.0009510.0028530.4007010.0153640.0006580.0005150.0001520.0174130.2416960.0162540.0308040.3005530.0083600.0005750.0003790.0122130.0651710.0016780.0001630.0002310.0001340.0001750.0003200.0001290.0007410.0004070.2012970.0041820.0026210.0002940.0196780.1948980.3544330.0255900.0711840.0718430.2221880.0066360.0005750.0003880.0280820.0277420.0029710.0002430.0424340.0758170.2676290.0045210.0003110.0039360.0004300.1658950.0464970.0008190.3514410.1952730.0416160.3101160.8437080.4089480.3206470.0791810.6217830.0074220.0003190.3267060.0199950.0106260.1445220.1031620.0021030.0079000.0052040.0184851.2826170.0134670.0009450.1098410.0132270.9036620.0102190.7214260.0756540.0451010.8718560.0415910.3587850.2193150.1866071.0075031.4771210.3221690.0032130.0162200.0010580.0123500.0237070.0482470.0049120.0001740.0128120.0394420.1405200.0678050.0087850.0974580.1445350.1947660.1103450.0888220.5762270.8543910.0063870.2406390.1350110.4471140.0036800.1955250.6801390.4992210.2777880.4083960.0646220.0010850.0006280.5261200.7488530.0052030.0001680.0003981.1881830.9834480.0551650.0024640.9995510.0377090.0005400.0011780.0112300.0002870.0025180.8141920.0079340.0253650.1245560.0064962.4990150.4495230.0031530.1135860.2347000.3696250.0749760.0444560.0006520.4048170.3624290.2444950.1608770.0040910.1416930.0082000.0684530.0417570.0574930.0943650.9691430.6007230.2398270.0016100.0004450.1945870.4297100.2347030.0013650.4080750.3405020.2075060.2043300.0045631.5382520.4122640.0037780.0003050.0002910.0273970.0052590.0007210.0001711.6702740.7154310.1199120.0293890.3258280.8353780.0090280.0012220.9797100.2781860.0019400.0007970.1215600.0844500.3954800.0391660.1235050.0957940.1578600.2745850.1678180.1722980.1501300.0009850.0001941.1110210.0149960.2189130.0034280.0008540.2974290.0244280.4845600.8073760.0053690.0004620.3221800.8605500.1632930.1311780.0010250.0005530.0023450.0011730.3391270.3360330.3003650.2050510.1315220.0422450.4062670.3863650.1031480.2645260.0133340.0085010.5773340.6697430.7446600.6187520.1554380.8379200.0069400.1065530.3824921.5117830.0166930.1035930.0021770.2287770.5499550.3561950.2999430.4863190.1954980.4502170.3959260.6675780.5552950.5587440.6558420.3880470.4928740.5382650.2844480.6810450.1912620.3059650.6773890.3786900.6135300.6328100.7357660.1611920.5161810.2974880.2356460.3300390.2063980.3798620.4589890.2791400.4909510.5641180.2956670.7742200.2070090.4081640.5566970.5923100.8490170.4160310.2539210.4593130.3274360.2558390.5197910.2210960.5144410.3551140.2388030.3352730.9482710.1739930.1768950.7765160.5085980.7200290.4325330.9120100.5288821.0253730.1756560.2009470.3890410.2809490.8846690.2016670.3901560.3359010.4249990.6974030.8090640.5334760.3045400.6000550.4432340.4683180.2864950.5993090.4617700.3060310.9236050.6110910.1072490.2153940.8694450.189389

*******************************************
EVALUATING PIPELINE 
Pipeline directory: /home/ubuntu/fnd_implementation/roberta/grid_search/results/pipeline_9d68f9e6_2020-02-14_12-43-39nu71avtu/
With following parameter combination: {'batch_size_seq_length': 4, 'lr': 1e-05, 'lr_type': 'constant'}
EVALUATION OF CHECKPOINT /home/ubuntu/fnd_implementation/roberta/grid_search/results/pipeline_9d68f9e6_2020-02-14_12-43-39nu71avtu/outputs/checkpoint-3
-------------------------------------------------------------
|           |   agree   | disagree  |  discuss  | unrelated |
-------------------------------------------------------------
|   agree   |    733    |    46     |    176    |     8     |
-------------------------------------------------------------
| disagree  |    146    |    349    |    126    |    28     |
-------------------------------------------------------------
|  discuss  |    121    |    37     |   1399    |    35     |
-------------------------------------------------------------
| unrelated |    37     |    36     |    78     |   8543    |
-------------------------------------------------------------
Score: 8684.75 out of 9226.0	(94.13342727075656%)
Accuracy: 0.9265422760127753
F1 overall: 0.793770604954243
F1 per class: [0.733, 0.6248880931065354, 0.8300207653515277, 0.9871735613589092]
*******************************************


*******************************************
EVALUATING PIPELINE 
{'batch_size_seq_length': 3, 'lr': 1e-05, 'lr_type': 'linear'}
INFO:__main__:Creating features from dataset file at /home/ubuntu/fnd_implementation/data/processed
  0%|                                                 | 0/11898 [00:00<?, ?it/s]  0%|                                       | 1/11898 [00:01<3:35:19,  1.09s/it]  4%|â–ˆâ–Œ                                   | 501/11898 [00:01<2:24:25,  1.32it/s] 17%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                              | 2001/11898 [00:01<1:27:48,  1.88it/s] 21%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                              | 2501/11898 [00:01<58:23,  2.68it/s] 38%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                       | 4501/11898 [00:02<32:10,  3.83it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                  | 6001/11898 [00:02<17:57,  5.47it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11898/11898 [00:02<00:00, 4795.95it/s]
  ******************************************* 
              Running Evaluation                
  *******************************************
 
  Length dataset evaluation: 11898
  Length dataloader evaluation: 744
  Number of epochs: 3
  Batch size: 16
  ******************************************* 
 
['/home/ubuntu/fnd_implementation/roberta/grid_search/results/pipeline_a62e43b0_2020-02-14_15-20-00k1ezj_za/outputs/checkpoint-3']
INFO:__main__:Evaluate the following checkpoints: ['/home/ubuntu/fnd_implementation/roberta/grid_search/results/pipeline_a62e43b0_2020-02-14_15-20-00k1ezj_za/outputs/checkpoint-3']
INFO:transformers.configuration_utils:loading configuration file /home/ubuntu/fnd_implementation/roberta/grid_search/results/pipeline_a62e43b0_2020-02-14_15-20-00k1ezj_za/outputs/checkpoint-3/config.json
INFO:transformers.configuration_utils:Model config {
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-05,
  "max_position_embeddings": 514,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 1,
  "use_bfloat16": false,
  "vocab_size": 50265
}

INFO:transformers.modeling_utils:loading weights file /home/ubuntu/fnd_implementation/roberta/grid_search/results/pipeline_a62e43b0_2020-02-14_15-20-00k1ezj_za/outputs/checkpoint-3/pytorch_model.bin
HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=744.0, style=ProgressStyle(description_width='initial')), HTML(value='')))
0.4099650.4107450.2055690.3910420.4550010.0911070.0157530.0025350.0004150.0001460.0002700.0001260.0001620.0001171.0167780.2851320.2974320.5010510.0279470.7560630.0951820.9613200.5450030.0241670.0014860.0001690.0002560.3860331.5141090.0523870.0018460.0002120.0001060.0001010.5378320.3125060.6876230.0186830.0006730.4007570.0101530.3699040.0089350.0003550.0007920.0001520.0001190.0003720.0016790.0002420.0002670.0004730.0012800.0001680.0029910.8543520.0153650.0012360.0001220.0001040.0003830.0001770.0001520.0002240.0006370.0503700.4842890.0073800.2602590.0038760.0008140.0001620.0002170.0001830.0001860.0002000.0002940.0002660.0002270.0002800.0019330.0021490.0038340.0001450.0001000.0001000.0001000.0001020.0001020.0001590.0001020.0001040.0001510.0001410.0003090.0001290.0001110.0001130.0004550.0005480.0001130.0004460.2553360.0029150.0003110.0001890.0002250.0001030.0002610.0001150.0001050.0015380.1538800.1287970.2345180.4592420.0044890.0003920.0005060.0004060.0002300.0043410.0001540.0462940.0027590.0002240.0001310.0003060.0001010.0004360.0034910.0043890.0001460.0110470.0002880.0003610.0001020.0002080.0002290.3423280.7131310.0065490.5216110.0053410.0011320.0001810.0001420.0002380.9664210.0068890.0003200.0002830.0002730.4488330.0030980.4069030.0027510.0002080.4458530.8705870.4701010.0030180.0001570.8718700.0189800.9748670.3659430.8221530.3585080.6302701.5520250.4135220.0030580.0003380.0008381.9794240.0115360.0003550.0003000.0001010.0049080.0003520.0002251.3650680.7449161.0314960.1559770.0011070.1730550.0120470.0023230.0003170.0066600.0005090.2613070.0015740.0004430.0013860.0002602.4425820.0125610.0004670.0006630.0004630.3203080.2644530.0015920.1660210.0030551.8734790.0093140.0003100.5256660.7518910.0054330.1177860.5249170.4265920.1286900.8101030.0051860.0008550.2406110.3533650.1156680.0188550.3655860.0017091.2083970.8710481.5550412.4920190.6166290.0028890.0003980.0003280.0192110.2290120.0010630.0008980.0113180.0524090.0019450.0002930.2899500.0012850.0007390.0017510.0001100.0001050.0054780.0659490.0209820.0011050.0014710.3497820.1271420.0010960.4541290.3903920.0037521.0274120.9509460.0224530.0067460.0015170.1871390.1251680.0981040.0018190.1119390.5724261.0158860.3571320.0014460.0001060.5098240.0019400.0008010.3177741.0924090.0041430.0002550.0004080.3857500.0784900.3565790.5324380.9118230.9856370.0042260.7991860.0028420.2617630.0015280.0004000.0003240.0003110.0002400.2121760.4571950.8848300.8611460.2790290.0012420.0001160.0003290.0001150.0002910.0003200.0017052.3502811.9945610.4417731.7533140.0060180.0003880.0250340.1082700.0031100.2348660.0010890.0003640.0001030.0001160.3101110.3616080.0013940.0001590.0001420.0003400.0042370.0067240.5524910.0018140.0043670.0005510.0020130.0110070.0008070.0009640.0021103.3438682.2825330.2982750.0091390.0005200.0003310.0237860.0771630.0835180.2494640.3042010.5018450.2276290.5186600.6101940.0020090.0002850.0002850.0647230.7762140.4038790.4055800.5238110.0015430.4517650.3438520.0223520.0039750.0914120.3062370.1425070.0005680.4357570.0012610.0003310.9933750.8699130.0054430.0039380.0033851.2700150.7795920.4702860.8081550.0029920.0001830.0003300.0003180.0003880.0004310.9687340.7991991.4791470.5850830.3684600.2854420.0008700.0001610.2212630.1432730.0007300.1585680.2939720.0008300.1383500.0006620.0199400.0017941.4208791.1781920.5076610.8478110.0035750.0012440.0002390.0001940.0002070.0002420.0201390.4713380.0150170.0001760.0003310.0000990.0001620.0001000.0001403.2356541.6284310.0113470.0015010.0447040.0011210.0011981.0987652.3623940.3883800.6520850.2516080.0015580.0004470.1190730.0011102.2878830.8827370.0022170.0004370.0004940.0010800.0005900.2037260.0016460.4171160.0097361.0081441.0226340.6411390.4330350.0019021.1523001.5498610.7520780.1828500.3020160.0246380.2741261.2169190.4175520.0010331.3013610.3562690.0026470.0002270.0002200.0002090.0001070.1591302.0270252.7395040.0129710.0002360.4162300.0018360.1623420.0011140.0003300.0001120.6986750.4286670.0010360.4581880.9052491.1996361.0337470.0027150.0003210.0003220.0003410.0004220.3329570.5093751.2930990.0933590.2589340.0015480.0001960.0007150.0001450.0004260.0015300.0007600.0006740.0003500.0006160.5167990.5090350.0032190.0032410.0085430.0017010.0011040.0700820.0007310.1967900.0015040.0008980.0006160.0157490.3159580.0008990.4579130.0020691.4416200.4065510.0011220.0700870.0010470.0003150.7862430.0035290.8831490.4402400.6154890.7245130.6474950.3675320.0008880.0330331.4552621.1247380.4382640.0012830.3479870.4981990.1298960.1651370.0006222.2604410.0069060.0015090.1949780.0135590.0011770.0015310.0916430.2998140.7295490.5700580.4435580.1408551.1838010.4044090.9618550.4788570.6844570.2531740.2560130.2426790.4330960.7234320.9473431.0271910.6894590.3631550.7742190.2749700.7354830.3924540.2402340.2305910.3959160.5165501.1623920.2154390.0785990.4101350.2741880.7400360.4674150.1880150.2636150.2989200.8806610.3512470.3340040.1618700.2150410.5625180.8137000.8622431.0655611.0251270.1616400.1297930.4812190.5887930.2623740.3142430.2285570.2133180.2733790.7286380.4319720.1406370.3615580.9247220.6097950.3968780.3254970.2924400.2017580.7667960.8414510.3642220.0992510.6253230.5170620.7425340.1759030.2389000.7676610.3468011.3767820.2176531.3271650.0893210.7985110.4624870.8931680.1536640.4549930.4116590.8882070.2147190.4214020.3212320.2210850.6204290.5521750.2609730.1414300.3437310.8643110.4852620.6319670.2504760.4667130.1884590.0283270.7524190.6978120.8227090.1925840.2320420.0249320.4700150.6668540.2937560.8774040.0805830.6696180.3549720.1234330.4776920.0072911.2418851.0311340.2376520.7667491.2914210.3312580.1090590.2334980.3901930.7660350.5698920.4766740.3836721.0312910.5900990.2985180.2053510.8313440.0500600.4254080.4766220.6435560.3893040.6545040.6250231.5532960.4171810.8705720.4610220.1125990.3593890.2269500.7680150.3497820.2562450.3425880.4783150.4271490.0599431.0315150.5868320.4022710.6719520.4530880.2216340.4635701.4207900.8604970.3628730.0472310.0675460.0361890.5915591.1576950.2377450.0723720.662951

*******************************************
EVALUATING PIPELINE 
Pipeline directory: /home/ubuntu/fnd_implementation/roberta/grid_search/results/pipeline_a62e43b0_2020-02-14_15-20-00k1ezj_za/
With following parameter combination: {'batch_size_seq_length': 3, 'lr': 1e-05, 'lr_type': 'linear'}
EVALUATION OF CHECKPOINT /home/ubuntu/fnd_implementation/roberta/grid_search/results/pipeline_a62e43b0_2020-02-14_15-20-00k1ezj_za/outputs/checkpoint-3
-------------------------------------------------------------
|           |   agree   | disagree  |  discuss  | unrelated |
-------------------------------------------------------------
|   agree   |    708    |    90     |    143    |    13     |
-------------------------------------------------------------
| disagree  |    103    |    274    |    81     |    22     |
-------------------------------------------------------------
|  discuss  |    200    |    76     |   1495    |    64     |
-------------------------------------------------------------
| unrelated |    26     |    28     |    60     |   8515    |
-------------------------------------------------------------
Score: 8682.5 out of 9226.0	(94.10903967049643%)
Accuracy: 0.9238527483610691
F1 overall: 0.7760611910503369
F1 per class: [0.7112004018081366, 0.5780590717299579, 0.8273381294964028, 0.9876471611668504]
*******************************************


*******************************************
EVALUATING PIPELINE 
{'batch_size_seq_length': 1, 'lr': 1e-05, 'lr_type': 'constant'}
INFO:__main__:Creating features from dataset file at /home/ubuntu/fnd_implementation/data/processed
  0%|                                                 | 0/11898 [00:00<?, ?it/s]  0%|                                       | 1/11898 [00:01<4:19:35,  1.31s/it] 13%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ                               | 1501/11898 [00:01<2:38:48,  1.09it/s] 17%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                              | 2001/11898 [00:01<1:45:50,  1.56it/s] 38%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                       | 4501/11898 [00:01<55:22,  2.23it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                    | 5501/11898 [00:02<33:32,  3.18it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–          | 8501/11898 [00:02<12:27,  4.54it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11898/11898 [00:02<00:00, 4964.59it/s]
  ******************************************* 
              Running Evaluation                
  *******************************************
 
  Length dataset evaluation: 11898
  Length dataloader evaluation: 2975
  Number of epochs: 3
  Batch size: 4
  ******************************************* 
 
['/home/ubuntu/fnd_implementation/roberta/grid_search/results/pipeline_94a4aaf8_2020-02-14_10-35-264sn7w7m_/outputs/checkpoint-3']
INFO:__main__:Evaluate the following checkpoints: ['/home/ubuntu/fnd_implementation/roberta/grid_search/results/pipeline_94a4aaf8_2020-02-14_10-35-264sn7w7m_/outputs/checkpoint-3']
INFO:transformers.configuration_utils:loading configuration file /home/ubuntu/fnd_implementation/roberta/grid_search/results/pipeline_94a4aaf8_2020-02-14_10-35-264sn7w7m_/outputs/checkpoint-3/config.json
INFO:transformers.configuration_utils:Model config {
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-05,
  "max_position_embeddings": 514,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 1,
  "use_bfloat16": false,
  "vocab_size": 50265
}

INFO:transformers.modeling_utils:loading weights file /home/ubuntu/fnd_implementation/roberta/grid_search/results/pipeline_94a4aaf8_2020-02-14_10-35-264sn7w7m_/outputs/checkpoint-3/pytorch_model.bin
HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=2975.0, style=ProgressStyle(description_width='initial')), HTML(value='')))
2.1054442.1054651.0527530.3514510.0890080.0178260.0030720.0004600.0000790.0000300.0000330.0000981.4683810.1129730.0080910.0005610.0000620.0000251.5977510.0841130.0042260.0002690.0000330.0000240.0000220.0000940.0000251.2849060.0459100.0016040.0000740.0003050.0000890.0000230.0000210.0000210.0000210.0000340.0000210.0000220.0000870.0000230.0000210.0000900.0000220.0000210.0000210.0000200.0000880.0000220.0000210.0000210.0000200.0000210.0000210.0000210.0083050.0154240.0235580.0004330.0000980.0000220.0000210.0000210.0000210.0000210.0000210.0000212.2709610.0329330.0004910.0000270.0000210.0000210.0000210.0000210.0000222.2747310.0293500.0003920.0001402.2868250.0279092.2872280.0273492.2603372.3822650.0274030.0003980.0000262.2826020.0251040.0002940.0010250.0000330.0000220.0006450.0000270.0000210.0000210.0000210.0000210.0000210.0000210.0002010.0000220.0000200.0000920.0000210.0000210.0000211.3201441.2972301.3322152.9317880.0315800.0003730.0000230.0000200.0000200.0000200.0000200.0000200.0000370.0000200.0000210.0000950.0000210.0000210.0000200.0000210.0000200.0000200.0000200.0000200.0000203.9513314.5107374.5044480.0324262.3086976.3787190.0449902.2109582.2943611.5974610.0109620.0000950.0000210.0000200.0000200.0000200.0000200.0000310.0000860.0000870.0000210.2609240.0016720.4287370.0027000.0000370.0000210.0000210.0000210.0000210.8015780.0048200.0000490.0000220.0001440.0000210.0000920.0000780.0000210.0000210.4751570.0027050.0000360.0000210.0000210.0000210.0000210.0000210.0000210.0000200.0000210.0000210.0000200.0000621.8322150.0096160.0000710.0001910.0003930.0000250.0000250.0000210.0000210.0001690.0001580.0000220.0000220.0000890.0001170.0004290.0005590.0000240.0000230.0005980.0000930.0000240.0000230.0000230.0000270.0000230.0000250.0006410.0020691.7369231.8934891.7919500.0084900.0000590.0000210.0000210.0000210.0000210.0000220.0000210.0012600.0000260.0000200.0000200.0000200.0000200.0000210.0000200.0000200.0000202.1062710.0087600.0000560.0000210.0000220.0000210.0000220.0000700.0000220.0000210.0000230.0000210.0000210.0000740.0000220.0000210.0000210.0000210.0009260.0000250.0000210.0009760.0009750.0000240.0001600.0000212.1851130.0083430.0000520.0000880.0000210.0000210.0000210.0000210.0000211.3639810.0049630.0000390.0000210.0000210.0009710.0015000.0000251.5255890.0129650.0000680.0000200.0000200.0000201.5696221.5313190.0052830.0000380.0000880.0000210.0000890.0000890.0000200.0000870.0000210.0000860.0000900.0000210.0000210.0000200.0000200.0001570.0001580.0000880.0000870.0000210.0001550.0000880.0000210.0000200.0001690.0000210.0000200.0005760.0000220.0000260.0010950.0000240.0029190.0012960.0002400.0000210.0001540.0000870.0002241.2358820.0038310.0000320.0000200.0000200.0000200.0000200.0000200.0000200.0000210.0000200.0000200.0000200.0000200.0000200.0000200.0000200.0000200.0000200.0000210.0000200.0000200.0000210.0000230.0000200.0000200.0000950.0000200.0000200.0000200.0000210.0000210.0000210.0000200.0000200.0000200.0000200.0000200.0000200.0000200.0000210.0000950.0000210.0000210.0000210.0000220.0006700.0000240.0000210.0000210.0000220.0000220.0000220.0000210.0000210.0000210.0000210.0000210.0000210.0000220.0000220.0000210.0001620.0000890.0003100.0000870.0008210.0000230.0006750.0000220.0000210.0000480.0000210.0000210.0002220.0001870.0000970.0001582.2345220.0101240.5194330.0013510.0000260.0000200.0000850.0000860.0000910.0000850.0000200.0001520.0001520.0000210.0000210.0000210.0001330.0000210.0000210.0000210.0000210.0000210.0000210.0000210.0000210.0001580.0000910.0000210.0000210.0000200.0000210.0000210.0000200.0000210.0000210.0000210.0000210.0001870.0028670.0041740.0071291.2296340.0027540.0001001.3441410.6395280.0014320.0549850.0028621.1380460.0025050.0000940.0000212.3271280.0051250.0001030.0000210.0000200.0013030.0000290.0000200.0000950.0001070.0000200.0000200.0000200.0000200.0002450.0001670.0000210.0000860.0000210.0000210.0000210.0001270.0000930.0001790.0000940.0016590.0000250.0000220.0000220.0000220.0000220.0000220.0000220.0017591.6196610.0032870.0003880.0001660.0002900.0001670.0000510.0000200.0000200.0000200.2696390.0005530.0000630.0000210.0000210.0007710.0000220.0000210.0000200.0000200.0000200.0000210.0000210.0006280.0006100.0000220.0000210.0001550.0024130.0000970.0000220.0021000.0000270.0000280.0000280.0000250.0001300.0000860.0005860.0002690.0000230.0000890.0000200.0000200.0000200.0000200.0000880.0000880.0000860.0000200.0000200.0000200.0000200.0000200.0001530.0000200.0000210.0000940.0000210.0000200.0000970.0000210.6631390.0019330.0000241.2345331.7808660.0063740.0000320.0000230.0000770.0000950.0000211.3328092.0140940.0035540.0001370.0000910.0000210.0007240.0018570.0011540.0025770.0036420.0001000.0000200.0000200.0000900.0000200.0000200.0000860.0000210.0000200.0000200.0001570.0000890.0000200.0000202.0678242.1071631.8788670.0032450.0000260.0007620.0000220.0000210.0000210.0006080.0000220.0000210.0006100.0000220.0000210.0002190.0000200.0000200.0134151.9197362.1330830.0034941.6743190.0028070.0000920.0000200.0000201.8146620.0029420.0000940.0000200.0000200.0000900.0000200.0000200.0000202.2274120.0036960.0000260.0000202.1321980.0033830.0000252.1533630.0034011.9366980.0030510.0000260.0000872.1847520.0034180.0000250.0000200.0000200.0000200.0000200.0000200.0000200.0000870.0024220.0034300.0006500.0008030.0010420.0000230.0033410.0094771.0690060.0018420.0964560.0005070.0004150.0001680.0003830.0001620.0008522.5765955.1488983.0368160.0046730.0000301.9303850.0028811.6580511.5221570.0049060.0000281.7617540.0036000.0000268.6172314.3625450.0063910.0000320.0006080.0016320.0001030.0000890.0000890.0000880.0001580.0000210.0001540.0000870.0002360.0002970.0003034.7360112.3534790.0040180.0000410.0000200.0000200.0000210.0006220.0000210.0000210.0006410.0000210.0000210.0000210.0000210.0005690.0000210.0000210.0000210.0000210.0000211.3260091.1646061.3565260.0018950.0000241.0369200.8597290.0012770.0000230.0000950.0000210.0000210.0425170.0187280.0437500.0000790.0000211.2157801.0957170.0015012.5269250.0091300.0000980.0000210.0017720.2486060.0009520.0000230.0000220.0005820.0000220.0000210.0000210.0000214.5131290.0062400.0000280.0009110.0000211.3552330.0018010.0000220.0000200.0000200.0006970.0000210.0000200.0000200.0000200.0000200.0016830.0006140.0000380.0000221.4782140.0020570.0017920.0029900.0000930.0000910.0000910.0000890.0000220.0000220.0000990.0006560.0001280.0000210.0000220.0032260.0000260.0000900.0000220.0000910.0000884.3991946.6219450.0086440.0001720.0000880.0001770.0000940.0001670.0000940.0001690.0000950.0001670.0001600.0003170.0000950.0002500.0002320.0000960.0001590.0000914.1511080.0058240.0023630.9680733.5059480.0042910.0000740.0000200.0000210.0003980.0008090.0000210.0014200.0007040.0000640.0000220.0013150.0020590.0014830.0000680.0011703.1294253.9403330.0047170.0000340.0000210.0000910.0000920.0000870.0000200.0000200.0002050.0001090.0000200.0000202.3740322.1187550.0028420.0019630.0002890.0002970.0009930.0027960.0003060.0002240.0002920.0015520.0062420.0007840.4792330.0005740.0001683.0603001.4707580.0017773.0974380.0083040.0001560.0000220.0000241.6964771.6625480.0019140.0000230.0002010.0010710.0016770.0006310.0001650.0001050.0001730.7196060.0009771.3558010.0040611.6195770.0019042.8417190.0032660.0000930.0000900.0002411.4311170.0018250.0000901.0615430.0011970.0000210.0059690.0000270.0001010.0000200.0000200.0000200.0000200.0000200.0000200.0019040.1811060.0003510.0000200.0000970.9101670.8667020.0009640.0000941.9185434.0492440.0045502.0767104.1040240.0045040.0000970.0021040.0020890.0001650.0000870.0000930.0000200.0000920.0001580.0000200.0002230.0000940.0001530.0000870.0000210.0001581.2484280.0013421.1781150.0124552.8587051.7164910.7243990.0007830.0000220.0000210.0000210.0000210.0001550.0000210.0000871.6843380.0017750.0000230.0013340.0050140.0043020.0003260.0001740.0000940.0000860.0000930.0002400.0002680.0002630.0000200.0000200.0000200.0020870.0000230.0000210.0000210.0000210.0000250.0000220.0000210.0000230.0025430.0000230.0000870.0000220.0000860.0022560.0009390.0000220.0003880.0000220.0000210.0000210.0000210.0000210.0000250.0010770.0012310.0000220.0013190.0000220.0013500.0044730.0000260.0001040.0000230.0065670.0001490.0021290.0003350.0002360.0000220.0001070.0014480.0006240.0013340.0000221.7034420.0022600.0000241.8649391.6953781.9035281.2009930.0013910.0002240.0001550.0002224.9956660.0049240.0001120.0000210.0000210.0000210.0001060.0032960.0008180.0002900.0002900.0007700.0004181.8664351.7369170.0016791.9527581.9643950.0018910.0000222.0802012.4719661.1658150.0011950.0166940.0033580.0042480.0025440.0013440.0004280.0001560.0000880.0001700.0001550.0002400.3726021.6302582.9102391.7246990.0035670.0000241.5090420.0044610.0000240.0008730.0000870.0000210.0025241.8210920.0017730.0000910.0000200.0000202.3679561.8529070.0017910.0000222.0252620.0019464.2172913.8265040.0035210.0000230.0000200.0000200.0000920.0000210.0000200.0000210.0000200.0000200.0000202.2918260.0020940.0000220.0000200.0000200.0000200.0000210.0000200.0000200.0000200.0000920.0008820.0052430.0000251.6379060.0015531.6410233.2447961.6079950.0014520.0000920.0000200.0001550.0000210.0001600.0001230.0000210.0000210.0001600.0000880.0001620.0000940.0000881.5684620.0014050.0005770.0000330.0000340.0006190.0027730.0023680.0057191.8918600.0043004.3483022.4196260.0021240.0000953.8648941.6632950.0050210.0003150.0024200.0038192.0950062.9400870.0025590.0006610.0006630.0000241.4050520.4917790.0007060.0000210.0000200.0000200.0000210.0000242.7024121.5784850.0016571.5939800.0609800.0002120.0000200.0000920.0000910.0001600.0000970.0001560.0000200.0001570.0000910.0001570.0001550.0001550.0000950.0000200.0001540.0000930.0000200.0000211.7124771.7571570.0015540.0000890.0000200.0000211.9312571.7493911.6783652.8853320.2187050.8299790.0009090.0002200.0352140.1202731.3527120.0017680.0000220.0000210.0000210.0000900.0007250.0000210.0000210.0000210.0000210.0000220.0000200.0000210.0000210.0000720.0000210.0000210.0000220.0000210.0000210.0000210.0006590.0000220.0000210.0000210.0000210.0009090.0007540.0000220.0022850.0038460.0027234.9727011.6537693.2986404.9795053.2096250.0025880.0006160.0005840.0005780.0000200.2456060.0004900.1798190.0004451.5774660.0014100.0001590.0001570.0000860.0000200.0001590.0001560.0000900.0000860.0001560.0000210.7273131.3137040.0016720.0003271.0954440.0012380.0909560.0009560.0052190.0023221.0476170.0078300.0003020.0002260.0000860.0002090.0000200.0000200.0001630.0003030.0000200.0000200.0000200.0000200.0000210.0000210.0000260.0000210.0000230.0000250.0000220.0000210.0071132.0915090.0018140.0000230.0000220.0000210.0001020.0000880.0000210.0000210.0000210.0000210.0000900.0000890.0000210.0000210.0000210.0000890.0000210.0006790.0000210.0006970.0000220.0019180.0006840.0000740.0019520.0002500.0001820.0000202.3090590.0020840.0745180.0000770.0007310.0000210.0000200.5495380.0004300.0002990.0000210.0000210.0004740.0003510.0000210.0000210.0043740.0013250.0004770.0002681.0325050.0011300.0002890.0002950.0002920.0002890.0002210.0000870.0000220.0002200.0001750.0000860.0000880.0002210.0036081.5661421.4529212.1996371.0436151.5392600.0132790.0014440.0008650.0002650.0002550.0001030.0021250.0007660.0000880.0001530.0000200.0002220.0002200.0000870.0000870.0000200.0002190.0000920.0000940.0085100.0008360.0011430.0000220.0002240.0000900.0007650.0008800.0276780.0022530.0022490.0013540.0124230.0006600.0004730.0004870.0001961.1671410.0010720.0155020.0007020.0001990.0001680.0001620.0001750.0002390.0001010.0001700.0001900.0000960.0000200.0000880.0000200.0002600.0627112.1093820.0015000.0066750.0000260.0000210.0000210.0000210.0009090.0000220.0000210.0009150.0000280.0000250.0013910.0000490.4611470.0003420.5599220.4332790.0003200.0000210.0000230.0000210.0000210.4976530.0003641.4295370.0010170.0004300.0000211.4855070.0010400.0021950.0000220.0000210.0000260.0000210.0000210.7321310.2460130.0002570.0001610.0674940.0797980.0003510.0001480.0000860.0003010.0001300.0001910.0002190.0000210.0023860.0017320.0017200.0034380.0101242.2604760.0015430.0020310.0000230.0000211.2922680.0008910.0000230.0000220.0000210.0000210.0000210.0086200.0000260.0000920.0000210.0000200.0000210.0000200.0000210.0001320.0000210.0001330.2250143.5075110.0023450.0001330.0000200.0000210.0262440.0006760.0000210.0000200.0000210.0063050.0060650.0038910.0028630.2012230.0009490.0027630.0027420.0009730.0002882.0188681.8798241.9385380.0012861.9498541.7839700.0011830.0000220.0000200.0000201.9736970.0013031.8056870.0011921.9074980.0012570.0001380.0000200.0003150.0001410.0000210.0000910.0000210.0000210.0001580.0000880.0000920.0000890.0001580.0000210.0000930.0000870.0000900.0002320.0000210.0001660.0000210.0001580.0000910.0000912.3214244.1294222.0596560.0014010.0000922.2576442.3763922.3371844.4468852.1321452.0585424.1863210.0026704.1647380.0027242.2710144.1633660.0026480.0000230.0000210.0000210.0001060.0000210.0000210.0000210.0000210.0000890.0000210.0000210.0000210.0000910.0000210.0000890.0001180.0000210.0000210.0000210.0000240.0000210.0001030.0000220.0000250.0001660.0000210.0000210.0001110.0000210.0000880.0001050.0000210.0000210.0000210.0000210.0000210.0000210.0000210.0001072.2702200.0014170.0000220.0000210.0000210.0000210.0001700.0002880.0002940.0003000.0003000.0007490.0011950.0007700.0021720.0042650.0002460.3802750.6626405.8586913.2191770.0049070.0063540.0035630.1072650.0008870.0002970.0002960.0002943.4756405.9730650.0055210.0006720.0006800.0013620.0005770.0011860.0006440.0016860.0000210.0001550.0000910.0000200.0000200.0000200.0000200.0001590.0000200.0000200.0001620.0000200.0001580.0000200.0000860.0000200.0001650.0001550.0000200.0025510.0023620.0007350.0014601.9892970.0054370.0007360.0000210.0009370.0000910.0000210.0000210.0000210.0000900.0001530.0001110.0000940.0000210.0000210.0000210.0000200.0000910.0000200.0000200.0000210.0000200.0000200.0000200.0000210.0000200.0000210.0000210.0000913.0739924.0325781.4510914.6837582.9681402.5204350.0033320.0000930.0007990.0008650.0010810.0000920.0000240.0007620.0001620.0000220.0042320.0000910.1798730.0014420.0007470.0000240.0000220.0036230.0006260.8964390.8984970.0008260.0748670.0004590.0002924.4802521.6813403.0020543.6802480.0025150.0001624.1209818.6588154.1522082.0760341.1234390.0033802.3714090.0023672.9639521.4421990.2379840.0071741.7330190.0049510.0082110.0000250.0000200.0002900.0002890.0002920.0002960.0002870.0002880.0002870.0002940.0002880.0002862.1578092.1965470.0015214.4242752.1971100.5980940.0005030.0002660.0000200.0000200.0002500.0000200.0001710.0000990.0002500.0000880.0000200.0001660.0000200.0017070.0000210.0010970.0000210.0020690.0000210.0011820.0009680.0000210.0000200.0000211.5309200.0016630.0006771.4148350.0024751.1157050.2655261.1594000.0007470.0000320.0021320.0000230.0000360.0000232.1025102.1302100.4049440.0002420.0000212.3355272.3491222.3348522.3288732.3422700.0012980.0000222.3673160.0020640.0000220.0006370.0000220.0000220.0017191.8629380.0025650.0002212.3407110.0027830.0371002.3296930.0015520.0824440.0198060.0014800.0001610.0007720.0001592.1418850.0020980.0008420.0007381.9190200.0019070.0000920.0000900.6799440.0004560.0021600.0047070.0012893.4613615.1982387.8036992.0753490.0011280.0000210.0000210.0000212.1664510.0011740.0000220.0000210.0000210.0000962.0711833.6803410.0019720.0000220.0000210.0000210.3779980.0102560.0029980.0000280.0000310.0006030.0000230.0000960.0000210.0000910.0000210.0000950.0000950.0000210.0000210.0000930.0000890.0000200.0000200.0000210.0000200.0000200.0000210.0000222.0733280.0013810.0036700.0080911.3844693.9615893.7547531.8155203.6580761.9721280.0035540.0021490.0000220.0000210.0000210.0002010.0000210.0000970.0000900.0000910.0000210.1004120.0000730.0010890.0021360.0000220.0000210.0000210.0012711.9929790.0018320.0000210.0000200.0012600.0000210.0008070.0000210.0000200.0000210.0000200.0000210.0000200.0000200.0000201.8501551.6357820.0008550.0000210.0000501.6055730.0009090.0000210.0000210.0000200.0000200.0000951.9415200.0010061.9500570.0010080.0000211.9853980.0010253.7793712.0256260.0011122.0589700.0012900.0003041.2028630.0011470.0000230.0010340.0000220.0005210.0000210.0000890.0000200.0000210.0002340.0000960.0000880.0002370.0000210.0001000.0000910.0001630.0000900.0002500.0001110.0000210.0001800.2727540.2491360.4778100.0002590.0000210.0000200.0000210.7364711.2686800.0006500.0000221.0563130.0005450.0000211.0563131.0197630.0005250.0000210.0000210.0000220.5245511.0542560.0005430.0000220.0000250.0001370.0000220.0000220.0076940.0000290.0000220.0000230.0000340.0000230.0000230.0000350.0026420.0000400.0000220.0069140.0000260.0000270.0000220.0079840.0000270.0000230.0000230.0006840.0000220.0007490.0007130.0000220.0000210.0000220.0000950.0006770.0007380.0000220.0013470.0023060.0000220.0088330.0036640.0085920.0052602.3893820.0013300.0002740.0001740.0003650.0001890.0001670.0002620.0000200.0001740.0002550.0002510.0017960.0032850.0006270.0011720.0011710.0006540.0005900.0006990.0003952.6853750.0015210.0003150.0001580.0001710.0000200.0001160.0007340.0012680.0001020.0007740.0003300.0006880.0000320.0007960.0002190.0000280.0006630.0013200.0000250.0000340.0002900.0002910.0002960.0002990.0003150.0003160.0003270.0002950.0003060.0732580.0005060.0000950.0000990.0000200.0000200.0000980.0000210.0000932.2433260.0010720.0013860.0026420.0000222.2920650.0014895.9027387.7743842.0639610.0009850.0000210.0000210.0000210.0000210.0006940.0000220.0006640.0006630.0000220.0024500.0018780.0000260.0000210.0000210.0007380.0000220.0000210.0000210.0000210.0000210.0003653.0406050.0043480.0020790.0027260.0021273.1975541.4049670.0007360.0001621.5864410.0008240.8720490.0005692.2437680.0011240.0000890.0000211.5655950.0008230.0000842.8599511.3046051.5781250.0007461.4336411.6082090.0007561.0302610.0006360.0000920.0000880.0000210.0000880.0000900.0018390.0024780.0003260.0003520.0003970.0002720.0001870.0001630.0000200.0001724.4000410.0022890.0002360.0002961.0677940.0007140.0000990.0001590.0002270.5245060.0005302.1775600.0012870.0028941.8559570.0011320.0002370.0022220.0018010.0021611.4535680.0043290.0000920.9622760.0008020.0000220.0000910.0000210.0002604.8261322.1677873.8097602.4468890.0046940.0012370.0000920.0006080.0006540.0006360.0006870.0001610.0102090.0002400.0007480.0121190.0007670.0007900.0006350.0019460.0006890.0013240.0001580.0008050.0009170.0002280.0012850.0012710.0007530.0887910.2469160.0001350.5523120.0003090.6364220.3506410.0043691.2873822.3021390.0011491.4825200.5910820.1407700.6685260.0003160.1706300.4362440.2464150.0001300.9385620.2458161.3425300.2115930.8272530.5282080.4103130.0003691.5466801.2136360.5703560.2543371.2612640.0052502.8269643.6226570.4493730.0043530.0055440.0055791.1618150.2729780.0074680.6489310.0037910.3151460.0004460.0195370.0061410.0077880.0046270.3502440.4525020.1093130.0946561.2061382.1008850.0044440.0000271.7064540.0007780.5673620.8709310.0023081.2259490.0019200.4111540.3902730.3485941.6152990.8308240.3499601.4691852.3377590.0010250.6341550.0003092.0625520.2847071.0985992.8003210.3060530.3067050.3554841.9367600.7086060.0009490.3150811.6872271.9763350.0563672.0479550.1856590.0113910.0000450.4722460.0002310.0089800.3089360.3939540.4213980.0004160.2853570.2585600.1755280.3578570.3406770.3404280.0003312.2566810.0009972.5781811.3200593.3943600.5473660.0066550.0000281.6072420.0131640.0000290.0000230.0026140.0097291.1432090.0036251.4496730.0143630.0061290.0972580.3025021.7814164.3565390.0020790.3728011.5823140.0044400.6919810.0084031.2626650.0048490.0029660.0027430.0030480.6684800.6686501.0359300.0004901.2471170.0025530.8551630.0192554.2354570.0021040.0416860.1555491.9478230.0067460.3984310.0979500.0005680.1546171.2110090.0005240.0014540.0000333.5672240.0015140.1883372.0857252.1223620.0033220.0064422.5773643.3776951.2226140.0008472.8971331.6907160.0016591.4000912.4066220.9005060.0007171.5506090.0006570.1274792.4064470.0010110.7969891.2555172.3104880.0010310.3196620.1900480.2947500.0031010.0052470.4942350.0003110.3241460.7919200.0009250.0005671.7147930.3303360.3058690.0001550.3466140.6581520.0112200.0021300.0000250.3057820.2404540.0005750.0047960.0080330.0004601.3408710.0088940.0056790.3214440.2186430.3258320.1834880.0065040.0002900.0078500.0000612.1426211.1595610.0005161.4990250.2228360.0029650.0040620.0016710.0003201.4601350.0019010.0000261.2376351.3074533.9080002.1504290.0020234.6566252.8622440.3027720.0115950.0032110.0424090.5882660.9433010.0006510.0195280.7695130.1009940.0763690.0168350.0000562.0270170.3616570.1692140.4193832.1516380.2060790.4239192.4679100.0014620.1736230.5265191.0011830.2542651.7984700.5683170.6333410.0109770.4254660.0001970.3328350.3461060.0001620.6463921.0167170.0009850.4128481.1648740.2857450.3417191.7537961.1254591.9656860.0007980.0067680.0000312.1318250.0008590.7808810.0003330.4332311.0221860.0004451.2291852.0591220.3841950.0024201.7861930.0021880.0484750.0000501.4445732.8472020.5121810.3460560.4454390.0001960.0056470.0000272.6655670.6012890.2157680.1973820.2845770.0001340.0372230.3308300.0001580.1540662.5967742.1323590.0764913.1387640.0014610.0019900.3914621.1646640.0004830.2599280.0001232.2337480.0008810.2062100.0031530.0002790.3019600.6677740.0978130.0002911.5643260.0006351.5724560.9037600.2011131.0471490.0064110.0000950.1342240.5926471.3963430.2442200.0158840.5711440.0113010.4607200.2060151.2304091.6882760.0006670.0000780.3297350.2775761.9177240.3326081.4106830.3229002.5246290.0010302.3978950.2170270.1913704.6265560.0020510.3397950.0035850.0052130.0075930.0000561.0401990.0012960.0335361.2333800.0095261.2438330.0036770.0075930.0000632.5261500.4726991.1741790.0035060.0028951.1818091.2811970.0071350.0037060.0000560.0029302.1404510.0066570.0030260.0002620.2841430.0044340.2311130.0001320.1701020.1566050.0006340.3427680.2030071.1628580.3310950.0002582.5980800.5386381.4215340.1728660.0003063.2759891.2690181.2696341.2298500.0062100.0363050.2088450.0003561.0765130.0052080.0436910.0065870.2954020.0008870.0075302.4013230.0099370.3178570.7386030.1308370.2321241.3763880.1967740.0000990.3505050.7840620.6106542.0899650.2260310.8731310.3274300.0101570.0000280.2505120.0007051.2184421.0699990.3384280.0022120.0015790.4154170.3773410.7270920.7746870.0003090.0000230.5784940.4714902.2230722.4849580.0100290.0000340.0000620.0025752.6982551.8077280.3210691.8085700.5919222.8170840.7297230.5826330.0002730.0001040.2201490.3118650.0033132.7751051.8892872.5401942.7936681.1197760.0062521.7829780.0008961.1570270.0051160.0001090.0110020.0045310.0012560.4005390.0049931.7661201.6016060.0054950.0000510.4681500.3378460.0014540.0000560.0018990.0714933.9815431.1252802.1191080.4602720.4439280.3306920.0010550.4398530.6368980.4328560.0506260.0056030.4192102.7378910.0857402.9722870.0044730.2669751.8144950.1107643.6837810.5393630.2918360.2790520.0081440.0916440.0000860.0309561.2193190.1986601.2388301.0641151.9767110.0048010.0002910.3986720.0054600.0041190.0050360.0012261.1620690.2049660.8226480.3443860.3357340.8173320.6119670.7375630.0214560.0000711.3816130.0252620.0080910.1367390.0038581.3658870.2130192.0386140.0149160.0133910.1905520.5743272.2001240.3217672.8353191.8094610.0087422.0081340.0008890.3776441.4140440.6890600.0002990.5815221.4471690.0044170.0058180.0000342.2399550.3259790.0017710.5790200.1360841.2251500.2927991.0135540.5805400.2836601.5585830.3459761.9520523.0118080.9538160.3417652.3482410.2796880.0040930.7550150.1628420.0667150.2262402.3213610.0008390.0029510.0039040.8699940.3295082.6222630.4212781.5880730.0005780.0241141.3037990.0045500.0203380.5073350.7384890.1712560.3839220.3550912.1761180.6955490.0026560.0000230.7794290.0197260.0038030.9768610.0042360.9277020.5927361.2208431.2210403.1009580.0010921.3148970.0060270.0033820.0028231.3019470.0179651.2083260.0035820.0026841.6850140.5485901.2394580.5747152.1961490.5157332.7808940.0059791.6039250.3468540.0005620.0224110.9096580.0182720.0000400.2243990.0009780.2928770.3180980.3106580.0008570.0000330.2087280.0012190.1127150.4147521.2202970.0060500.0000331.5322003.1380701.3806762.6352852.1058240.0043401.2836762.0393490.0007140.0000380.0078800.0034581.6167380.0136940.852166

*******************************************
EVALUATING PIPELINE 
Pipeline directory: /home/ubuntu/fnd_implementation/roberta/grid_search/results/pipeline_94a4aaf8_2020-02-14_10-35-264sn7w7m_/
With following parameter combination: {'batch_size_seq_length': 1, 'lr': 1e-05, 'lr_type': 'constant'}
EVALUATION OF CHECKPOINT /home/ubuntu/fnd_implementation/roberta/grid_search/results/pipeline_94a4aaf8_2020-02-14_10-35-264sn7w7m_/outputs/checkpoint-3
-------------------------------------------------------------
|           |   agree   | disagree  |  discuss  | unrelated |
-------------------------------------------------------------
|   agree   |    747    |    129    |    185    |    31     |
-------------------------------------------------------------
| disagree  |    50     |    237    |    37     |    16     |
-------------------------------------------------------------
|  discuss  |    210    |    64     |   1502    |    68     |
-------------------------------------------------------------
| unrelated |    30     |    38     |    55     |   8499    |
-------------------------------------------------------------
Score: 8655.5 out of 9226.0	(93.81638846737481%)
Accuracy: 0.9232644141872584
F1 overall: 0.7759275939859922
F1 per class: [0.7017379051197745, 0.5866336633663366, 0.8291471156500138, 0.986191691807844]
*******************************************


*******************************************
EVALUATING PIPELINE 
{'batch_size_seq_length': 4, 'lr': 1e-05, 'lr_type': 'linear'}
INFO:__main__:Creating features from dataset file at /home/ubuntu/fnd_implementation/data/processed
  0%|                                                 | 0/11898 [00:00<?, ?it/s]  0%|                                       | 1/11898 [00:01<3:20:41,  1.01s/it]  4%|â–ˆâ–Œ                                   | 501/11898 [00:01<2:14:35,  1.41it/s] 13%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ                               | 1501/11898 [00:01<1:25:57,  2.02it/s] 21%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                              | 2501/11898 [00:01<54:23,  2.88it/s] 25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                            | 3001/11898 [00:01<36:03,  4.11it/s] 38%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                       | 4501/11898 [00:01<20:59,  5.87it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                  | 6001/11898 [00:01<11:43,  8.39it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–          | 8501/11898 [00:02<04:43, 11.98it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11898/11898 [00:02<00:00, 5007.50it/s]
  ******************************************* 
              Running Evaluation                
  *******************************************
 
  Length dataset evaluation: 11898
  Length dataloader evaluation: 372
  Number of epochs: 3
  Batch size: 32
  ******************************************* 
 
['/home/ubuntu/fnd_implementation/roberta/grid_search/results/pipeline_a91c6cfa_2020-02-14_15-24-194owxwho2/outputs/checkpoint-3']
INFO:__main__:Evaluate the following checkpoints: ['/home/ubuntu/fnd_implementation/roberta/grid_search/results/pipeline_a91c6cfa_2020-02-14_15-24-194owxwho2/outputs/checkpoint-3']
INFO:transformers.configuration_utils:loading configuration file /home/ubuntu/fnd_implementation/roberta/grid_search/results/pipeline_a91c6cfa_2020-02-14_15-24-194owxwho2/outputs/checkpoint-3/config.json
INFO:transformers.configuration_utils:Model config {
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-05,
  "max_position_embeddings": 514,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 1,
  "use_bfloat16": false,
  "vocab_size": 50265
}

INFO:transformers.modeling_utils:loading weights file /home/ubuntu/fnd_implementation/roberta/grid_search/results/pipeline_a91c6cfa_2020-02-14_15-24-194owxwho2/outputs/checkpoint-3/pytorch_model.bin
HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=372.0, style=ProgressStyle(description_width='initial')), HTML(value='')))
0.1732840.3462250.1969380.0670510.0170340.0037890.0009650.5584340.2939730.2273600.4908620.2612400.0379570.1381260.5608210.0377420.0026440.7763620.4574590.1451770.1451170.0075190.0181150.0012720.0022430.0146760.0035810.3884380.0218600.0010320.0080070.0006960.0036510.2213440.1810360.0437240.1492400.0045200.0010000.0006430.0202800.0034150.0003500.0002760.0003630.0002770.0003970.0004970.0002830.0013600.0008630.1110640.0027560.0005780.0004610.0229810.2062180.3649340.0071410.0213630.0698330.2987190.0069800.0006040.0006080.1303320.0034470.0005970.0003960.0595260.2040470.2928670.0055500.0005530.1005270.0020340.1828260.0802980.0014630.5404600.2071850.2107750.7703750.5375970.4563930.5322920.0074181.0178430.0122330.0006520.0518320.2315910.3500700.0228820.1909690.0660440.0157710.0230110.0073561.1367620.0123900.0016630.3898810.0087180.8202460.0086740.3895120.1109280.3500310.3999720.0063020.2766950.1056080.0725400.7035731.7971270.2813280.0033800.1522860.1653230.0439940.0031360.0485360.0023050.0003070.0223120.0085510.0549030.1059510.3878840.2659500.5051780.3255500.1033060.0872680.2677170.2925640.0024990.2118690.1572020.4278010.0043950.0379790.5873250.8262180.1816250.1048550.0037650.0008370.0054580.6168370.8420920.0059710.0003510.0141720.9384850.8704140.7308720.0074140.0692040.1165030.0013220.0240900.1034110.0010810.0091450.2480540.0024300.0023510.0022230.0175030.8581090.0419820.0014980.3811960.0644930.0187440.0023470.1938030.0021320.2816450.1888650.1377360.1761380.0047220.1401180.0519650.1345860.0650040.1023300.0456430.8206110.5189090.0038270.0007680.0008540.6466341.2050130.4048820.0024250.2653770.1748130.1341550.1648040.0728661.1868250.7299710.0069790.0007060.0007550.2506400.0337460.0011230.0003581.3926370.8920360.1645950.0644411.7648391.0967100.0084910.0014880.8562870.3905750.0029240.0013660.1404840.1163770.6989110.2388160.0175750.0532250.2131620.8841960.9119390.3246520.2716440.0017520.0004310.1161060.4012340.2674470.1782480.0044130.1473550.0092770.3255640.4506000.0029860.0008280.1290740.6235980.0058680.0028510.0025700.0315600.0193160.0033650.3505540.0863630.0091380.0509960.0752060.0067790.0262080.1704400.1454971.2401390.0092880.0024990.3213630.7187120.7533700.6291070.0065200.2155870.1264500.0390250.0743051.1552090.0715820.0155890.0045100.2652380.5729720.2491120.4388340.4957940.4731090.3788140.4995490.5088260.5410280.3803640.3555010.1983530.4553920.6085640.2748010.5226480.2421720.2590070.5806370.2363490.3377090.4154400.8499220.1734400.5886620.2865130.3180770.3555110.2824710.4445770.3462360.2595480.3517330.5370850.3703960.4934530.2061610.4804900.7128390.6624980.6125810.4916620.3540350.4742700.3000810.5663420.3232740.1893010.4563040.3712430.2750110.2167900.6904290.2414960.1508580.3895190.3848920.5536790.3601720.5343650.5085690.8522460.1717200.1373490.2415410.3272170.8895040.1844380.3512860.4669260.3618490.4894900.7169840.7875040.4379680.4267250.2981980.3443850.1786250.5492230.4350980.3160780.8948160.4863390.2572240.2152430.6112980.357871

*******************************************
EVALUATING PIPELINE 
Pipeline directory: /home/ubuntu/fnd_implementation/roberta/grid_search/results/pipeline_a91c6cfa_2020-02-14_15-24-194owxwho2/
With following parameter combination: {'batch_size_seq_length': 4, 'lr': 1e-05, 'lr_type': 'linear'}
EVALUATION OF CHECKPOINT /home/ubuntu/fnd_implementation/roberta/grid_search/results/pipeline_a91c6cfa_2020-02-14_15-24-194owxwho2/outputs/checkpoint-3
-------------------------------------------------------------
|           |   agree   | disagree  |  discuss  | unrelated |
-------------------------------------------------------------
|   agree   |    715    |    87     |    124    |    11     |
-------------------------------------------------------------
| disagree  |    75     |    275    |    73     |    19     |
-------------------------------------------------------------
|  discuss  |    223    |    81     |   1525    |    57     |
-------------------------------------------------------------
| unrelated |    24     |    25     |    57     |   8527    |
-------------------------------------------------------------
Score: 8718.5 out of 9226.0	(94.49924127465857%)
Accuracy: 0.92805513531686
F1 overall: 0.787454782982144
F1 per class: [0.7244174265450861, 0.6043956043956044, 0.8321964529331515, 0.9888096480547341]
*******************************************


*******************************************
EVALUATING PIPELINE 
{'batch_size_seq_length': 1, 'lr': 1e-05, 'lr_type': 'linear'}
INFO:__main__:Creating features from dataset file at /home/ubuntu/fnd_implementation/data/processed
  0%|                                                 | 0/11898 [00:00<?, ?it/s]  0%|                                       | 1/11898 [00:01<4:20:43,  1.31s/it]  4%|â–ˆâ–Œ                                   | 501/11898 [00:01<2:54:51,  1.09it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                    | 5120/11898 [00:01<1:12:47,  1.55it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 6556/11898 [00:02<40:10,  2.22it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11898/11898 [00:02<00:00, 5156.69it/s]
  ******************************************* 
              Running Evaluation                
  *******************************************
 
  Length dataset evaluation: 11898
  Length dataloader evaluation: 2975
  Number of epochs: 3
  Batch size: 4
  ******************************************* 
 
['/home/ubuntu/fnd_implementation/roberta/grid_search/results/pipeline_a05fc7c4_2020-02-14_13-16-42bz1jp7c7/outputs/checkpoint-3']
INFO:__main__:Evaluate the following checkpoints: ['/home/ubuntu/fnd_implementation/roberta/grid_search/results/pipeline_a05fc7c4_2020-02-14_13-16-42bz1jp7c7/outputs/checkpoint-3']
INFO:transformers.configuration_utils:loading configuration file /home/ubuntu/fnd_implementation/roberta/grid_search/results/pipeline_a05fc7c4_2020-02-14_13-16-42bz1jp7c7/outputs/checkpoint-3/config.json
INFO:transformers.configuration_utils:Model config {
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-05,
  "max_position_embeddings": 514,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 1,
  "use_bfloat16": false,
  "vocab_size": 50265
}

INFO:transformers.modeling_utils:loading weights file /home/ubuntu/fnd_implementation/roberta/grid_search/results/pipeline_a05fc7c4_2020-02-14_13-16-42bz1jp7c7/outputs/checkpoint-3/pytorch_model.bin
HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=2975.0, style=ProgressStyle(description_width='initial')), HTML(value='')))
1.8360831.8360930.9180570.3061600.0768280.0153750.0026000.0003810.0000590.0000160.0000110.0000471.7075200.1313570.0093920.0006360.0000730.0000142.0164010.1061360.0053160.0002630.0000210.0000110.0000100.0000390.0000110.0002790.0000190.0000100.0000100.0001020.0000230.0000110.0000110.0000110.0000130.0000240.0000110.0000120.0000370.0000110.0000100.0000650.0000110.0000100.0000100.0000100.0000480.0000110.0000100.0000100.0000100.0000100.0000110.0000100.6046310.0107900.9018891.0349970.0172870.0002940.0000150.0000250.0000110.0000110.0000130.0000112.2788950.0330410.0004840.0000170.0000120.0000120.0000110.0000120.0000110.9134010.0684180.0008770.4238982.0528640.0250462.0479600.0244090.0960150.0073440.0000950.0000370.0000120.1422850.0015750.0000290.0002750.0000130.0000100.0001760.0000130.0000110.0000120.0000120.0000110.0000150.0000130.0000840.0000120.0000130.0000390.0000150.0000130.0000112.0154192.0211402.0079143.8592240.0340340.0003830.0000140.0000100.0000100.0000100.0000100.0000100.0000110.0000100.0000110.0000400.0000110.0000100.0000100.0000110.0000100.0000100.0000100.0000100.0000110.0000360.0000342.1109660.0151962.1546470.0153200.0001190.0000192.0077692.4113300.0165270.0001230.0000140.0000130.0000110.0000110.0000110.0000160.0000370.0000370.0000110.0011040.0000170.0000390.0000100.0000100.0000100.0000100.0000100.0000100.0004200.0000120.0000100.0000100.0000100.0000100.0000110.0000110.0000100.0000100.0001220.0000100.0000100.0000100.0000100.0000100.0000100.0000100.0000100.0000100.0000100.0000100.0000100.0000100.0002090.0000120.0000100.0000250.0000110.0000110.0000140.0000130.0000140.0000720.0000660.0000160.0000160.6417450.0031850.0000260.0002290.0000110.0000100.0001480.0000370.0000110.0000100.0000110.0000100.0000100.0000100.0001430.0004970.0001242.1648801.8855670.0086030.0000480.0000100.0000100.0000100.0000100.0000100.0000100.0002280.0000110.0000100.0000100.0000100.0000100.0000100.0000100.0000100.0000101.5605490.0064850.0000360.0000100.0000100.0000100.0000100.0000100.0000100.0000100.0000100.0000100.0000100.0000320.0000100.0000100.0000100.0000100.0001470.0000100.0000100.9059040.0036310.0000230.0000640.0000102.3396950.0088280.0000500.0000370.0000150.0000110.0000120.0000220.0000282.0686810.0075050.0000370.0000100.0000100.0002230.0002760.0000110.0001160.0000980.0000100.0000100.0000100.0000100.0432541.9740350.0067930.0000330.0000360.0000100.0000360.0000360.0000100.0000360.0000100.0000360.0000580.0000100.0000100.0000100.0000100.0000630.0000690.0000360.0000360.0000110.0000620.0000360.0000100.0000110.0000620.0000120.0000140.0001420.0000100.0000120.0002770.0000120.0005540.0003350.0000980.0000120.0000620.0000380.0000910.0002280.0000400.0000100.0000100.0000100.0000100.0000100.0000100.0000100.0000100.0000100.0000100.0000100.0000100.0000100.0000100.0000100.0000100.0000100.0000100.0000100.0000100.0000100.0000100.0000100.0000100.0000390.0000100.0000100.0000100.0000100.0000100.0000100.0000100.0000100.0000100.0000100.0000100.0000100.0000100.0000100.0000370.0000100.0000100.0000100.0000110.0001470.0000100.0000100.0000100.0000110.0000100.0000100.0000100.0000100.0000100.0000100.0000100.0000100.0000100.0000100.0000100.0000650.0000360.0001240.0000360.0001390.0000100.0001400.0000100.0000100.0000100.0000100.0000100.0001040.0000980.0000380.0000621.1915252.2735992.2444600.0054980.0000260.0000100.0000370.0000360.0000870.0000370.0000100.0000620.0000650.0000100.0000100.0000100.0000670.0000100.0000100.0000100.0000100.0000100.0000110.0000100.0000100.0000410.0000380.0000100.0000100.0000100.0000100.0000110.0000100.0000100.0000100.0000100.0000100.0005630.0001550.0001441.2871891.4625060.0032600.0000440.0009700.0000120.0000100.0002820.0001571.7595560.0038520.0000450.0000102.6186640.0057050.0000490.0000120.0000100.0002950.0000120.0000100.0000360.0000400.0000100.0000100.0000100.0000100.0003010.0004430.0000100.0000430.0000100.0000100.0000100.0000580.0000420.0001470.0000400.4278960.0008890.0000120.0000100.0000100.0000100.0000100.0000110.0003031.9153930.0038730.0001870.0000520.0000640.0000620.0000290.0000100.0000100.0000100.0000160.0000100.0011620.0000120.0000100.0002000.0000100.0000100.0000100.0000100.0000100.0000100.0000100.0001440.0001430.0000100.0000100.0000780.0007400.0000140.0000110.0003840.0000110.0000130.0000120.0000120.0000110.0000160.0001430.0000270.0000100.0000540.0000100.0000100.0000100.0000100.0000570.0000430.0000370.0000100.0000100.0000100.0000100.0000100.0000880.0000100.0000100.0000380.0000100.0000100.0000410.0000100.7319420.0013330.0000121.0942712.3126251.4142360.0025220.0000150.0000140.0000360.0000102.0540542.3017180.0040480.0000450.0000390.0000100.0004300.0010570.0001760.0001410.0002820.0000390.0000100.0000100.0000360.0000100.0000100.0000360.0000100.0000100.0000100.0000620.0000370.0000100.0000102.0048962.0049641.6706110.0028420.0000270.0001720.0000100.0000110.0000100.0001430.0000100.0000100.0001450.0000110.0000100.0000630.0000100.0000100.0000372.0240560.0033840.0000152.1095490.0034600.0000410.0000100.0000101.9895410.0032130.0000410.0000100.0000100.0000370.0000100.0000100.0000100.0000380.0000370.0000100.0000102.4439200.0038650.0000172.4219280.0038122.1718810.0034090.0000160.0000422.4450040.0038140.0000160.0000100.0000110.0000110.0000100.0000100.0000100.0000361.2028112.1377060.0034100.0001640.0006200.0000102.0190053.9197754.2306420.0065750.0774950.0003790.0002280.0000650.0002360.0001180.0011512.4467263.7605552.1874960.0033170.0000150.0061650.0000191.7964511.3551271.1876600.0017590.2010651.9108590.0028111.4792380.0502260.0000830.0000100.0001400.0003330.0001120.0000440.0000430.0000460.0000760.0000120.0000650.0000450.0000990.0001190.0040605.1801994.6835590.4941520.0007250.0000110.0000100.0000100.0001690.0000100.0000100.0001440.0000100.0000100.0000100.0000100.0001500.0000100.0000100.0000100.0000100.0000100.0000760.0001321.6796700.0023300.0000130.0000740.0001130.0000440.0000100.0000370.0000100.0000101.7460861.9857613.3689020.0045870.0000161.9518001.9478680.0026422.1046291.8053850.0024660.0000130.0002921.6673460.0023750.0000130.0000100.0001430.0000100.0000100.0000100.0000100.0010760.0001870.0000100.0009530.0000111.0653090.0014090.0000110.0000100.0000100.0002830.0000100.0000100.0000100.0000100.0000100.0004600.0001550.0000110.0000100.0000110.0002490.0005040.0011330.0000410.0000390.0000370.0000400.0000100.0000100.0002280.0001580.0000450.0000100.0000100.0005170.0000100.0000370.0000100.0000370.0000484.7515547.3406310.0093220.0000780.0000400.0000650.0000380.0000650.0000440.0000770.0000560.0000690.0000760.0001370.0000500.0001510.0000900.0008480.0000680.0000572.1265180.0027990.0006190.0005673.9512940.0048230.0000160.0000100.0000100.0000170.0001400.0000100.0004810.0001410.0000120.0000110.0001410.0001410.0006600.0000110.0002523.4251121.4623180.0017540.0000150.0000110.0000410.0000450.0000400.0000100.0000100.0000900.0000770.0000100.0000102.1869370.0122450.2816850.0007540.0001240.0001370.0003150.0004170.0001370.0001110.0001400.0003880.0193030.0002481.3622360.0015830.0000771.9270050.0024980.0000410.4877180.0019500.0004420.0000110.0000112.0744292.1154970.0024200.0000130.0001280.0002710.0004310.0001680.0000670.0000390.0000500.0001800.0000630.0004700.0014041.6359850.0018701.3436170.0015390.0000380.0000360.0000891.3475900.0015910.0000380.0001120.0000100.0000102.1701090.0024080.0000390.0000100.0000100.0000100.0000100.0000100.0000102.2455804.4801780.0049590.0000150.0000422.2397122.1831970.0023830.0000391.5330322.9673050.0033001.8831864.0568360.0044360.0000430.0004100.0004810.0000650.0000370.0000370.0000100.0000370.0000650.0000110.0000910.0000370.0000630.0000370.0000100.0000640.0001420.0000100.0002710.0009321.5444642.0080400.0872770.0001030.0000100.0000100.0000100.0000100.0000640.0000100.0000360.5189130.0005500.0000110.0002730.1324890.0017600.0001720.0000910.0000470.0000360.0000750.0001150.0001590.0007000.0000100.0000100.0000101.1212330.0011580.0000110.0000100.0000100.0000100.0000100.0000100.0000100.0059850.0000160.0000370.0000100.0000390.1158540.0006700.0000100.0000840.0000100.0000100.0000110.0000100.0000100.0000100.6032321.7939970.0018010.0002720.0000100.0003290.0001820.0000100.0000330.0000110.0001590.0000170.0001740.0001920.0001100.0000100.0000750.0002680.0001400.0002710.0000100.0938710.0002370.0000100.0006270.0006870.0003700.0006540.0000900.0000900.0000640.0000890.0798880.0001150.0000460.0000100.0000100.0000100.0000520.0023680.0002340.0001190.0001161.5969871.5093140.0015890.0001410.0000102.0954690.0021500.0000120.0000100.0155250.0261730.0002450.0000460.0002570.0005900.0005950.0004650.0005060.0001330.0000640.0000370.0000670.0000630.0001720.1987770.0658080.0006230.0001430.1496220.0001491.6294430.0018470.0000110.0001880.0000370.0000100.0005922.1276720.0020040.0000410.0000100.0000102.4270331.8751570.0017610.0000112.1894260.0020444.3093433.9433770.0036180.0000130.0000110.0000100.0000380.0000100.0000100.0000100.0000100.0000110.0000112.5147590.0022860.0000120.0000100.0000100.0000100.0000100.0000100.0000100.0000100.0000371.5321150.0017020.0000111.8672480.0017272.0050023.6654481.8951520.0016980.0000380.0000100.0000650.0000100.0000630.0000380.0000110.0000120.0000640.0000370.0000740.0000370.0000381.9996420.0017670.0001460.0000100.0000100.0001460.0005930.0005490.0013011.2534960.0016513.9867892.3105640.0020190.0000453.8894530.2338553.0095060.0027340.0006010.0007073.6620315.2631060.0045470.0001450.0001740.0000101.9384430.0018060.0001430.0000100.0000100.0000100.0000100.0000142.0196421.9450820.0017990.3469370.0100350.0000730.0000100.0000430.0000390.0000650.0000380.0000640.0000100.0000640.0000380.0000620.0000650.0000630.0000370.0000100.0000630.0000360.0000110.0000100.0001510.0001790.0000370.0000560.0000100.0000100.0001690.0001600.0001681.6416170.8402000.6062280.0005900.0000950.8936020.1041391.5858480.0014540.0000110.0000100.0000100.0000100.0001410.0000100.0000100.0000100.0000100.0000110.0000100.0000100.0000100.0000110.0000100.0000100.0000100.0000100.0000100.0000100.0001390.0000100.0000100.0000100.0000100.0001390.0001420.0000100.0004370.0003690.0005881.9567690.5466454.0684732.5452330.1455140.0001260.0001410.0001380.0001430.0000100.0780990.0001821.4568130.0012770.3117750.0003140.0000780.0000670.0000370.0000100.0000690.0000670.0000400.0000360.0000750.0000100.0012190.0005840.0001411.2945872.3307320.0042680.0004650.0002430.0005840.0004780.0006450.0002270.0001350.0000910.0000420.0000660.0000110.0000100.0000630.0001160.0000110.0000110.0000100.0000110.0000100.0000100.0000100.0000100.0000100.0000100.0000100.0000100.0002560.0880960.0001470.0000100.0000100.0000100.0000620.0000360.0000100.0000100.0000100.0000100.0000420.0000410.0000100.0000100.0000100.0000370.0000100.0001390.0000100.0001390.0000100.0003710.0001390.0000110.0003040.0002070.0000650.0000112.6866790.0021330.0001040.0000100.0000450.0000100.0000100.0001140.0000100.0000440.0000100.0000100.0001760.0000670.0000100.0000100.0001100.0001140.0000990.0000420.0000700.0000960.0001170.0001190.0001180.0001170.0000900.0000370.0000140.0000880.0000690.0000370.0000370.0000900.5364773.9208303.6178675.5122995.7520737.0881843.8263490.0030880.0002040.0001260.0002630.0000591.6451110.0029140.0000380.0000630.0000110.0000890.0000890.0000370.0000370.0000100.0000900.0000370.0000401.6888180.0022630.0007370.0000100.0000960.0000380.0002870.0009661.8013690.0018210.0005350.0003450.0003110.0001630.0001870.0001600.0001040.0004040.0001610.0003110.0002920.0001840.0001360.0000920.0001321.8635480.0013840.0001040.0001500.0000780.0000100.0000380.0000100.0003290.0013200.0007480.0000160.0003010.0000100.0000110.0000140.0000110.0001480.0000330.0000110.0001560.0000120.0000150.0001500.0000141.5572390.0010891.8465181.8924100.0013180.0000110.0000140.0000100.0000100.0017150.0000111.8717900.0013020.0000110.0000101.6236820.0011251.6205520.0011200.0000110.0000100.0000100.0000100.0012441.0698030.0007650.0000640.0003970.0009210.0001430.0000550.0000360.0001270.0000540.0000750.0000950.0000100.0005260.0004960.0005070.0007940.0012440.0010220.0000100.0012930.0000110.0000101.7167350.0011620.0000100.0000100.0000100.0000100.0000100.0003810.0000100.0000370.0000100.0000100.0000100.0000100.0000100.0000370.0000100.0000760.0000101.7716610.0011840.0000120.0000100.0000100.0000450.0001520.0000100.0000100.0000100.0011460.0011370.0007330.0005830.0007810.0002250.0005650.0004450.0002290.0001162.4450452.4197422.4204700.0015922.4257162.4243600.0015910.0000120.0000120.0000102.4418030.0016002.4124270.0015762.4080250.0015710.0001150.0000100.0002900.0000870.0000100.0000380.0000100.0000140.0000640.0000380.0000380.0000370.0000650.0000150.0000380.0000390.0000370.0000980.0000100.0000760.0000100.0000640.0000610.0000380.0006171.8837171.3544230.0009010.0000440.0013880.0004031.8100181.1776421.6790671.3517043.0123640.0019162.1635220.0014040.0003943.0883140.0019580.0000110.0000100.0000101.6136700.0010250.0000100.0000100.0000100.0000360.0000100.0000100.0000100.0000420.0000100.0000360.4875810.0003140.0000100.0000100.0000100.0000100.4631490.0002980.0000110.0001000.0000100.0000100.1666270.0001130.0000390.0537540.0000430.0000100.0000100.0000100.0000100.0000100.0000100.0006270.0000100.0000100.0000100.0000100.0000100.0000100.0000800.0001170.0001210.0001220.0001230.0001770.0001990.0001830.0008240.0004660.0000590.0003100.0015283.0141422.7622340.0024200.0017960.0008750.0006560.0002030.0001200.0001180.0001194.5152986.2229340.0041620.0001450.0003240.0002720.0001430.0002760.0001440.0002730.0000100.0000650.0000390.0000100.0000110.0000100.0000100.0000680.0000830.0000130.0000660.0000110.0000680.0000110.0000360.0000100.0000670.0000640.0000100.0008200.8763090.0006630.0002740.0006591.2869800.0009030.0000100.0001540.0000360.0000100.0000110.0000100.0000360.0000570.0000540.0000380.0000100.0000100.0000100.0000100.0000380.0000100.0000100.0000100.0000100.0000100.0000100.0000100.0000100.0000100.0000100.0000403.9264415.6574991.9929796.0157823.0423801.8971830.0021330.0000390.0006930.0004690.0003240.0000380.0000100.0001830.0000680.0000110.0006630.0000380.0006100.0001840.0000670.0000110.0000100.0030910.0001180.0034880.0036090.0001220.0001340.0001600.0001206.2634882.0984334.0284135.9412820.0237890.0000833.8480047.6829693.8138211.9080070.2132960.0006260.0015890.0002510.0015140.0557440.0025110.0004770.1018660.0005090.0016860.0000110.0000100.0001190.0001190.0001220.0001350.0001180.0001220.0001180.0001210.0001190.0001212.3426432.4308730.0014835.5785792.3802221.9226410.0011500.0001020.0000100.0000100.0001050.0000100.0000730.0000390.0001050.0000370.0000100.0000680.0000100.0003300.0000100.0001840.0000100.0003230.0000100.0002520.0001680.0000100.0000100.0000102.1270480.0013770.0001880.0001850.0001960.0002960.0001792.5273560.0014070.0000600.0003010.0000100.0000130.0000102.5213242.3070811.5049590.0008340.0000102.5149272.5114532.5411852.5018172.5293800.0013890.0000112.5199930.0015380.0000110.0001490.0000100.0000100.0003420.0138080.0003370.0001290.0007270.0004230.0003870.0007150.0001260.0003710.0004060.0003610.0000630.0022470.0000640.0024350.0002820.0002210.0016882.2931770.0015130.0000480.0000540.8666520.0005310.0002190.0002390.0002873.2609045.0487847.9252161.0706190.0005810.0000100.0000100.0000100.0006470.0000100.0000100.0000100.0000100.0000361.0663882.9530880.0015750.0000100.0000100.0000101.6669370.0015590.0004550.0000820.0000100.0001420.0000100.0000450.0000100.0000380.0000130.0000410.0000440.0000100.0000100.0000390.0000370.0000110.0000100.0000100.0000110.0000110.0000190.0000110.0161130.0005142.1284542.0769720.0016622.0068794.0548981.8035344.3370122.0017480.0015750.0005800.0000110.0000100.0000100.0000510.0000100.0000480.0000400.0000380.0000100.6935160.0003680.0002220.0003950.0000100.0000100.0000100.0002631.1803720.0007950.0000100.0000100.0002850.0000100.0001880.0000120.0000100.0000100.0000110.0000120.0000110.0000100.0000102.3294932.0742550.0010690.0000110.0781722.1211190.0011200.0000110.0000110.0000110.0000110.0000362.2200910.0011422.3422560.0011980.0000102.2134310.0011314.4817902.3004750.0011992.2436410.0012430.0001321.6188740.0009550.0000100.0002760.0000100.0001400.0000110.0000370.0000100.0000130.0000910.0000380.0000370.0000910.0000110.0000370.0000360.0000660.0000380.0000950.0000390.0000110.0000650.0004530.0003722.0416880.0010260.0000100.0000100.0000101.6896244.2004330.0020950.0000110.0003270.0000100.0000100.0003270.0005140.0000100.0000100.0000100.0000100.0001160.0001740.0000100.0000100.0000120.0000410.0000100.0000100.0002820.0000100.0000100.0000100.0000110.0000100.0000100.0000100.0001490.0000100.0000100.0003630.0000100.0000100.0000100.0002210.0000100.0000100.0000100.0001420.0000100.0001690.0001710.0000100.0000100.0000100.0000520.0001430.0001440.0000101.9985420.0011190.0000100.0009120.0008210.0007870.0034062.2799830.0011850.0001410.0000860.0001660.0000680.0001020.0001040.0000100.0000900.0001350.0001170.0004050.0017010.0001450.0002750.0002720.0001690.0001420.0001830.0001412.4101660.0013330.0002570.0000660.0002160.0000100.0000650.0001711.0429750.0005090.0001510.4645610.0005410.0000110.0002010.0000120.0000120.0001840.0001450.0000110.0000110.0001180.0001170.0001170.0001260.0001200.0001160.0001350.0001170.0001152.3694170.0014540.0000400.0000490.0000100.0000100.0000430.0000110.0000392.4743680.0011700.0002830.0005530.0000100.0134670.0005646.1365998.1669742.1800900.0010280.0000100.0000100.0000100.0000100.0001970.0000101.6221420.0009170.0000100.0005310.0003970.0000100.0000100.0000100.0001670.0000100.0000100.0000100.0000100.0000101.6023904.0502040.0027850.0005290.0004160.0004623.9793751.8841690.0009040.0000631.9784820.0009460.6323880.0003563.9370550.0018440.0000370.0000101.7661060.0008480.0000133.8809641.9477711.8807380.0008701.7186761.9732610.0009111.5950360.0007920.0000370.0000360.0000100.0000360.0000360.0004270.0005350.0001570.0001480.0001510.0002410.0002160.0001920.0000100.0002240.3042920.0002540.0000940.0001180.0011100.0000930.0000400.0000630.0000900.0000680.0001160.0001050.0001200.0000710.0007830.0001170.0000900.0005420.0004130.0005370.0007050.0000780.0000370.0005340.0003540.0000100.0000370.0000100.0001376.8689823.6416094.7314193.4851490.0019790.0002730.0000100.0001420.0001400.0001400.0001990.0000690.0003710.0000990.0002010.0165730.0002120.0002380.0001450.0004540.0001610.0003520.0000710.0002140.0002570.0000930.0003230.0003410.0001760.0030340.2505860.0001350.3673790.0001990.2048350.2258560.0022122.7116430.6728620.0003073.0370730.0070130.0064300.0057150.0000160.9625800.5907190.7947910.0003580.0059550.0037910.0225101.0141572.5176450.0033861.4585440.0006610.0074111.3015160.0019003.5751141.4967030.0019460.2174251.6629990.6795520.0052630.0045660.0052311.6285670.6633492.4830590.0174440.0023140.0047100.0002820.0025491.1605180.0021780.0013081.3445042.5918330.2380510.1389080.0623840.8867670.0021030.0000401.5686850.0006890.0001211.4318432.0223061.4747410.0007041.1054341.3063551.2388851.2473081.2507620.5293451.9801711.9883920.0008620.6575410.0002990.9455540.3508550.2827912.9008280.2791610.2693000.2196820.5922110.2407270.0001310.2163370.2905931.8263690.0774721.5153150.3991050.0011990.0000221.2806300.0005660.0014590.2449680.8347350.8663260.0008270.0420500.0022430.0034141.3357690.0105610.0274290.0002292.8285800.0012061.0739461.1013303.2257300.5277300.8335330.0003621.2067800.0363960.0000260.0000110.0022420.7865181.3995070.0018271.2317270.0031560.0075530.3088910.6391201.6671532.0720760.0009770.4807282.9233580.0015860.0396850.0226011.4145940.0035870.0033480.0023420.9917030.0048860.0042030.8805690.0004061.2981800.0005692.0119350.0185103.9696380.0016680.4956870.8612921.7824450.0021510.6126790.0003960.0000210.8330771.4411610.0006540.0009740.0000191.2583810.0005310.0215360.7519840.0018640.0007830.0002241.6811851.9351811.8127450.0009961.4646282.1559260.0069671.8714961.9750731.6364130.0038482.6951140.0011211.1702782.0214320.0008380.0765262.2993131.5258170.0006441.3711401.0382690.4446020.0020570.0031470.5295540.0004420.1272331.3145800.0022050.0004312.4061680.2843090.9065750.0003810.3215570.7184511.0433860.0035830.0000150.0566951.1349110.0004950.0020880.0015410.0167961.4304500.0289740.0050260.7997450.7642280.2742420.1866540.0021890.0000231.6778730.0007021.9710210.7665310.0003201.4770210.6849930.0005740.0006700.0002520.0000611.4290410.0009350.0000601.2930881.6136541.7669031.5323560.0011400.0012872.3284760.0092610.0062220.0034290.0545961.4470462.0249170.0008520.0021081.2051220.2537680.0253310.0028230.0000231.4886600.3924010.0250320.2094630.2894660.9158831.7494461.9242740.0007861.0544721.1957630.0061850.9866111.0443270.5745730.9064180.0045250.0071350.0000200.0079840.0646870.0000440.0119581.6809970.0006721.5377550.7523441.1932950.0049361.1370040.0714772.0451220.0008150.0046330.0000420.7263140.0002961.1539850.0004621.2998771.2238280.0005061.7234280.6323440.6686900.9364610.2842280.0008440.0085360.0000171.4466554.6318830.6659390.7163981.4666630.0005820.0021680.0000122.8479791.2452890.3727090.3310970.0184090.0000180.0004501.0004260.0003990.0021574.7857091.9407820.0026140.7601511.7557160.0012142.6575160.4475090.0004000.0942460.0000490.5337310.0002160.7999580.0008810.0002610.0891191.1870960.0029190.0000651.7098270.0006661.4976931.4923970.6215330.8757570.0055900.0000411.3108860.5308791.1978280.5064380.0019741.7865130.0007250.0040251.2302701.2057320.1957900.0000920.0000210.0057060.2782480.0923080.1125850.0101200.0382172.5086640.0009670.4022161.1034140.9215521.6384390.0006611.2050460.6026570.0049580.0055950.0002521.9033750.0013600.0008621.4722621.6743021.3709680.0035000.0047490.0000532.4683920.0029732.1303930.0027260.0020461.1544811.2829870.0048120.0027030.0000730.0016512.1656810.0050280.0017680.0000221.2149790.9879010.0018620.0000250.0020910.0004680.0002971.4202250.0239651.9917770.0061220.0000361.0622790.5707601.5644071.3570770.0005263.1565661.0967271.1642301.1097050.0038970.0107750.0091040.0000171.1982700.0027660.0038080.0031820.0588430.0000350.0027732.4075590.0037460.0086911.5422351.0253120.4126991.7374170.5012060.0001980.2383021.4857101.5472371.6821971.8635710.0050751.3804700.0051410.0000170.0129750.0118351.3618042.1129730.1707160.0007740.0026101.1621272.0624080.7171321.2282570.0004610.0000110.2014870.1794511.8198550.7612200.0040560.0000370.0000120.0019792.6508841.5058401.2924742.6862470.0013922.9895401.6138890.0403920.0000370.0001590.3416680.2164900.0032602.9376780.6595920.0640892.8195571.4662790.0035284.4777910.0018431.3595440.0019940.0000120.0035730.0018330.0002782.1406340.0025760.0001300.0015450.0016190.0000131.1234450.1551370.0005260.0000120.0004720.0003763.8744880.0055960.0060902.2663721.6883560.0815640.0000760.0403562.0821370.2491740.0013350.0011861.6284072.8301240.0023713.2234950.0024350.0014220.0016380.0013773.0673331.1406070.0254120.0745500.0033700.0180210.0001190.0004371.1418070.1914081.1239890.0269543.1105680.3952390.0015700.0035680.0046180.0051310.0064991.0468931.9983440.6907790.9334320.0174830.0047582.8304100.0051500.9539880.0350830.0004561.4822240.0087990.0021071.1150940.0079821.5458680.2855842.3320370.0022440.0013900.0716561.9919762.8937780.0912713.2124241.6764880.0021502.1838350.0007851.3037221.3198351.4998120.0005422.1896231.1566800.0040200.0037150.0000311.0999361.5495360.0016120.1205950.6045222.7117391.5115280.6391770.0007020.2030911.5177780.3293590.3184522.0419300.0019440.0021310.7486800.2512760.0908370.6499550.5894050.4030260.0192161.9072940.0006720.0028410.0037381.6577600.0094990.0485320.0109460.0066800.0000200.0024341.3087810.0021810.0062920.0024710.0030700.2158540.4216261.4191103.0396710.0091420.0011470.0000142.6035020.2943090.0022872.5648490.0036660.4015830.8176871.1396031.0976201.2207720.0004361.1591190.0063510.0027630.0032001.1597690.0053751.3317230.0048040.0025901.9030511.6457071.7236644.0065882.7835760.9129992.8198270.0017151.5147751.4314660.0005641.0573401.5386730.0039610.0000200.0111540.0029660.0099660.0076201.4076850.0007950.0000180.7035050.0051970.0007001.2711471.3986760.0039270.0000321.9913762.1478530.7968380.0130980.9214860.0027640.0742610.0060400.0000600.0000110.7302940.0019480.8089060.5245100.187601

*******************************************
EVALUATING PIPELINE 
Pipeline directory: /home/ubuntu/fnd_implementation/roberta/grid_search/results/pipeline_a05fc7c4_2020-02-14_13-16-42bz1jp7c7/
With following parameter combination: {'batch_size_seq_length': 1, 'lr': 1e-05, 'lr_type': 'linear'}
EVALUATION OF CHECKPOINT /home/ubuntu/fnd_implementation/roberta/grid_search/results/pipeline_a05fc7c4_2020-02-14_13-16-42bz1jp7c7/outputs/checkpoint-3
-------------------------------------------------------------
|           |   agree   | disagree  |  discuss  | unrelated |
-------------------------------------------------------------
|   agree   |    725    |    65     |    125    |    14     |
-------------------------------------------------------------
| disagree  |    97     |    315    |    74     |    18     |
-------------------------------------------------------------
|  discuss  |    197    |    59     |   1525    |    40     |
-------------------------------------------------------------
| unrelated |    18     |    29     |    55     |   8542    |
-------------------------------------------------------------
Score: 8763.25 out of 9226.0	(94.98428354649903%)
Accuracy: 0.9335182383593882
F1 overall: 0.8057065595534677
F1 per class: [0.7375381485249237, 0.6481481481481481, 0.8472222222222222, 0.9899177193185769]
*******************************************


*******************************************
EVALUATING PIPELINE 
{'batch_size_seq_length': 2, 'lr': 1e-05, 'lr_type': 'constant'}
INFO:__main__:Creating features from dataset file at /home/ubuntu/fnd_implementation/data/processed
  0%|                                                 | 0/11898 [00:00<?, ?it/s]  0%|                                       | 1/11898 [00:01<4:47:35,  1.45s/it]  4%|â–ˆâ–Œ                                   | 501/11898 [00:01<3:12:53,  1.02s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                   | 5501/11898 [00:02<1:15:47,  1.41it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11898/11898 [00:02<00:00, 5418.84it/s]
  ******************************************* 
              Running Evaluation                
  *******************************************
 
  Length dataset evaluation: 11898
  Length dataloader evaluation: 1488
  Number of epochs: 3
  Batch size: 8
  ******************************************* 
 
['/home/ubuntu/fnd_implementation/roberta/grid_search/results/pipeline_97a80d26_2020-02-14_10-35-31kc2oa1dy/outputs/checkpoint-3']
INFO:__main__:Evaluate the following checkpoints: ['/home/ubuntu/fnd_implementation/roberta/grid_search/results/pipeline_97a80d26_2020-02-14_10-35-31kc2oa1dy/outputs/checkpoint-3']
INFO:transformers.configuration_utils:loading configuration file /home/ubuntu/fnd_implementation/roberta/grid_search/results/pipeline_97a80d26_2020-02-14_10-35-31kc2oa1dy/outputs/checkpoint-3/config.json
INFO:transformers.configuration_utils:Model config {
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-05,
  "max_position_embeddings": 514,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 1,
  "use_bfloat16": false,
  "vocab_size": 50265
}

INFO:transformers.modeling_utils:loading weights file /home/ubuntu/fnd_implementation/roberta/grid_search/results/pipeline_97a80d26_2020-02-14_10-35-31kc2oa1dy/outputs/checkpoint-3/pytorch_model.bin
HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=1488.0, style=ProgressStyle(description_width='initial')), HTML(value='')))
0.7741360.7742930.3874350.1292280.0323410.0065540.9293930.1327940.0166640.9290090.0929340.0084710.0007970.0003560.0000470.0002290.0000380.0000250.0000500.0000240.0000780.0001340.0000270.0000220.0001280.0000260.0000210.0000230.4295801.6729450.0558420.0018910.0000850.2368191.1608670.0331960.0009570.0000581.7458260.0448052.2186141.1428651.1430771.1640970.0265551.1357650.0250050.0005550.6691510.0136790.0002960.0000300.0006460.0001530.0000270.6964911.4012141.5924790.0275810.0004890.0000290.0000230.0000270.0000770.0000230.0000220.0000220.0000240.4781440.8910800.0131650.0003500.2420130.0033380.0000720.0000240.0000250.0001370.0042740.0001630.0000240.0000340.0000240.0066360.0001090.0000710.0001160.0000230.0001900.0000240.0000230.0000220.0000230.0000220.0000220.0002050.0000470.0000960.0000290.0001430.0001400.0000970.0000930.0001700.0001920.0001290.0000350.0000360.0001770.0012271.2522540.6764840.0060630.0000760.0000240.0001740.0000240.0000220.0000220.0000220.8837220.0073250.0000820.0000340.0000220.0000230.0001730.0000240.0000220.0001880.0003440.0002090.0001350.9914360.0074860.0000790.0000240.8753520.0063650.0000680.0003990.8768890.8467480.0059430.9095330.9298610.0064470.0001210.0000870.0000780.0001950.0000230.0000210.0002690.0001350.0001320.0000770.0001690.0000280.0001500.0002930.0028430.0007490.0001590.0002510.7541210.0045650.0000490.0000220.0000220.0000220.0000220.0000220.0000230.0000230.0000210.0000220.0000220.0000970.0000220.0000230.0000220.0000230.0000260.0000220.0000840.0000240.0000260.0001560.0000260.0000350.0000370.0000230.0000220.0000260.0000270.0002470.0005220.0001570.0001590.0000500.0000250.0045000.0002160.0341690.0007550.0000420.0001380.0002020.0001650.0001420.0000260.0001660.0000260.0000210.0000220.0001280.0000820.0000210.0000230.0000210.0000230.0719500.0619180.0008790.0000930.0030620.0021910.3160340.0014901.2761660.0056870.0000480.0003900.0000910.0005950.0000250.0005190.0065130.0001180.0000230.0001580.0002720.0004130.0000440.0000370.0000500.0826060.0009570.0003290.0002600.0000220.0001690.0000620.0000230.2791220.0011120.0000250.0000220.0002870.0000260.0029150.0000490.0020200.0000460.0000350.0002160.0000420.0002900.0000220.0002850.0002740.0000220.0000210.0003910.0000220.0000910.0001030.5020680.0018841.4078430.0068890.0003960.0000861.0189710.0036650.0001010.0144590.0004160.0003540.0000220.0001060.0000770.0000210.0001600.0000970.0002230.0005030.0001090.0002090.0000240.0001500.0001470.0000250.0001420.0000951.1363200.5368940.0018760.0000270.5355900.0018010.0000820.0000220.0001890.0000990.9169250.0029140.7971820.6225670.0020410.9172160.0028700.0000310.0000210.0000920.0007690.0002770.0001550.4016220.6045410.3912840.0020430.0010303.3074102.4962130.0075690.0003970.4656040.0020670.0039250.0045490.0399020.0003100.0003990.0001420.0001920.0001310.0002610.0004832.3960100.0637540.0002040.0001500.0000230.0001660.0000230.0001530.0000230.0000220.0012361.2656940.0035190.0015420.0000970.0000910.0024160.0039450.0000320.0008750.0111110.0007620.0022340.6290590.0017030.0001790.0000220.0006030.0004300.0001660.0001590.0000220.0001500.0000210.0001260.0025200.0002130.0000740.0041490.0008930.0001770.0001420.0318950.0003130.0000320.0024670.0000990.0001554.9875970.0128940.0002190.0002160.0007350.0002120.0004150.0008920.0002590.0002091.1249441.0901170.9669460.0023870.0001270.0001640.0019930.0000340.0003030.0019251.0319100.6487200.0143690.0001890.0000890.0002560.0001170.9270750.5399520.0018160.0008640.0007090.0005530.0696290.6119570.0016172.5839541.7524833.3721220.0077740.9549740.0022000.0251870.0008500.0002110.0004240.0005520.9096321.5788200.0037360.0002870.8985830.6777690.0015240.7554510.0017460.0000240.0000210.7157141.8427450.0041091.6478710.0036631.6151360.6514480.9853440.0025850.0005870.0001390.0000860.0001420.0002590.0002080.0001380.0001570.0064210.0105750.0002270.0000360.0000240.0001480.0002960.0000320.0029690.0043290.0002810.0002110.0004550.0002590.0000210.0002150.0000220.0000280.0000230.0003490.0000870.0001080.0026740.0001430.0000230.0000230.0000290.0006640.0002860.0002920.0001840.0001520.0003860.0057520.0009600.0008990.3729380.0043130.0002060.4396340.0069610.0003810.0003141.1669770.0023490.0000280.0037820.0006400.8948680.8162640.0018551.2487180.0024030.0030850.0007260.0036440.0074590.0034460.0001980.0002650.4757430.0038940.0005170.9081140.0018570.0002410.0003010.0110690.0002150.9533770.0019960.0001790.0032300.0003370.0000320.0000800.0000260.0000230.0000291.1556780.0021140.0000300.0000240.0000240.0001470.0001900.9047002.7061080.9185580.0017140.0001580.0005480.0001460.0002980.0002810.7082710.0014230.0000240.0026340.2686960.0106470.0087570.0001001.3924951.5190990.0058790.3340370.0007470.0002260.8485550.0016870.0000270.0000532.1709830.7997840.6569120.0012070.0002380.0002080.0001420.0002040.0002510.0001070.0001940.0000220.0031580.0001460.0000210.0008060.0134050.5015000.0758771.0088110.0375540.0000860.0000410.0001710.0000230.0000710.0001240.0000750.0000260.0000290.0000230.0001660.0000260.0002410.0002020.0009452.8032482.8002874.6561700.0076040.0002920.0026530.0058910.2406770.0008880.0003240.0002060.0003520.0003921.5306121.4522650.8526820.0048731.1819160.0060850.0057580.0002870.0001370.0001360.0002470.0000230.0000220.0000270.0000320.0000380.9299490.7003090.0011000.0001090.0000840.0000220.0001530.0000770.0000220.0000850.0001590.0001600.0023480.0004831.5238171.1798480.0024140.0001640.0000210.0003760.0003330.6710060.0012100.0005430.0006220.0003570.0005020.0004720.0004330.0000940.0003750.0001470.0015183.1205974.4877344.9199100.0077080.0101680.8146730.0410440.0002120.0004010.0001550.0002100.0001360.6715080.1650760.0005210.1783700.0086220.0010360.0007360.0017030.6027660.1931611.4081090.0023270.0004510.0002530.0003100.0000850.0002550.2926300.0006250.0000380.0000270.0001690.0001690.0001100.0002010.4416230.0050130.0000290.0000300.0022380.0022320.0000880.0021710.5253070.0007420.0000250.0248330.4725480.0016710.3111210.0005890.0002990.0002850.0027681.2276700.6889700.0061450.0022550.0025240.0000310.0000270.0000310.0001760.0001010.0000210.0000200.0000910.0008300.0045680.0001470.0005191.0155090.0013600.0173320.0070620.0051580.0011360.0005762.0015631.0017981.9855800.0026100.0000311.0219390.9784120.9957540.0022760.0476680.0001500.0001230.0001950.0001400.0001580.0001390.0002540.0001460.0001400.0001632.7216420.8904060.6153381.7418002.7354942.2002441.8204960.0078491.4858090.0018950.0009330.0000230.0000210.0000880.0000210.0000820.2676220.0003550.0000230.0212610.0000560.0049210.0013670.0000950.0051330.0000280.0000210.0000220.0097520.0000330.0000210.0001760.0005020.0005710.0004860.0007210.0006310.0066813.4797420.9698110.4708040.5430580.0012682.7703270.0039460.0004820.0004110.0004130.0001670.0001090.0000220.0001740.0000240.0002570.0001930.0000840.0003330.0021030.0022640.0027490.0039670.0001730.0000780.0000230.0001560.0001550.0000220.0000210.0000810.0000210.0000230.0000220.0000210.0000874.6211513.5963433.8865600.0056500.0027710.0044490.0003650.0001880.0004760.0004530.0003670.2826630.7466860.8997260.4976312.1306761.4130951.0658690.0019490.8851271.1982910.0058941.7103272.6684162.3980981.7978560.0020600.0004580.0004640.0004580.0004580.0004612.0317382.0485511.4380660.0019810.0000240.0002470.0002280.0002930.0001780.0001760.0001670.0003060.0001660.0001580.0000250.8753380.0222820.8797030.5036760.0008860.0002590.0000441.5860970.0037660.3734541.5755850.9965790.0011120.4893780.0006840.0000260.0005490.0016030.0032330.0029490.0008280.0219810.0004490.0024440.0954181.3229140.0020000.0044910.0006070.1028720.5678230.3022760.0003440.0000220.0024130.0000240.0000761.4927750.0016040.0000231.0251050.0035640.0001770.0000990.0000820.0000950.0002120.0000870.0000990.0000240.0000240.0004971.3655992.3270941.3858461.7880730.9566600.0039790.0000270.0000810.0000950.0001620.0003520.0001620.0003160.0000230.0031890.0001620.0004370.0001590.0000230.0000220.0000210.0000211.5826080.0016370.0065360.0000960.0000220.0000910.7189270.8399810.8317261.3196640.7956530.8701010.6715730.0008370.0003160.0001650.0000760.0001930.0001400.0002010.0001390.0001970.0002640.0001561.4070100.7917850.0008120.8829812.3299560.9334330.0009521.8527130.0018560.0000271.8379440.0018430.0003010.0000280.0003920.0001820.0000510.0000490.0003290.0008330.0000330.0002150.0000290.0001690.0002630.0002240.0000210.0002900.0001600.6692000.0052760.0078300.8070730.9719471.3969880.1066841.2294201.1689930.6163450.0030630.0005980.0003880.0004621.5726340.0079010.6476000.0010340.0010440.0006150.0002840.0002860.0002040.0002740.0003030.0004890.1418340.0062750.0004780.0182160.0001560.0000240.0000871.1388200.0013500.0005520.0060871.7381130.6942820.0006700.0000220.0002280.4215410.0026240.0020830.0000230.0002250.0000220.0000232.7347830.0032800.0007222.5635960.6470570.8997851.5260432.4432740.0023650.8975991.5646521.5835630.8934480.9018080.8476380.0009590.0001030.0007940.6412231.5852640.0030990.0004211.0506670.0013760.0007770.0002580.0003080.0005920.0004490.0011340.0004200.0009250.0026470.0002780.0402810.0001220.0002413.8061342.9505200.0053780.0002030.0003320.0003500.0005030.1853600.0007040.0005380.0005160.0003930.0005160.0006970.0012300.0847990.2505181.5536361.3009100.3434121.6201390.7428560.2032100.9954810.3854320.5601041.8097530.3759970.9543191.2544181.9223030.7761450.6529880.0656700.1706001.3327290.0641760.0311451.1965810.2769881.2846860.1821471.2004960.0051520.8601300.8492230.9031310.7858320.8871801.3248860.6831300.1164190.5080110.2678111.3341400.0988100.2418800.0932840.2027130.9650940.8808330.0020010.6376260.2186491.0830050.2073300.1779670.2629450.0424830.8838311.2923541.7895120.0475150.2795940.0003120.0145340.6341080.3100380.0298291.0580420.7240011.8969810.1809991.5138540.0243090.6504910.0301960.3417590.4103981.5356351.3272290.7266820.7739900.9426170.6111790.3845330.0013531.4510581.0672620.4885530.6906602.5668180.1237490.7081031.7101021.1618061.8013271.2597170.0458780.9187080.0134700.2379770.0272910.7139230.3000710.0022441.4049460.1317740.3789770.4415540.5812410.6627940.0201510.4236380.9264811.3283820.9755960.0034310.0018282.3777910.8049900.7727310.0015140.6715420.0008761.4921772.1317010.9177480.9941520.1227140.6168840.9255160.3700380.0363740.0028660.8462620.5944881.2724671.7475280.6554890.3955871.1956040.8666120.1522260.1222830.4011970.7431320.5964320.8308920.1871851.0718780.2990030.0442340.3683050.0587600.3814651.1993351.3713840.8699510.2251532.5348391.2764680.2919370.0009241.6313340.2147140.1194680.4477190.0012351.7433830.8297520.0045082.0641090.7048640.1703210.0112910.0023721.6735430.0054650.7623241.4316270.8249870.0535061.7644681.6379080.5568390.8816700.6086690.2398770.1756720.7201290.4632831.3716930.2239750.2360340.6318210.3422550.0444840.8162010.0284491.2739430.3945090.0313160.5105560.8946920.2553240.4055510.0113680.8349110.0253500.7483630.7194160.0034550.0008280.4352820.2984080.7880670.2969030.5603941.2142060.3008800.0350400.0287220.4486880.0164700.0118230.8362600.7149241.1262100.5846340.1326420.7640030.1912300.2956100.4648090.0149670.4443971.0698360.0031710.5007080.7044300.0006310.7180720.4853220.0353470.0075021.2045270.4957710.2091070.3006930.0012910.3048751.1034061.4655891.0186780.9047750.8595260.0013800.0016940.1932120.2969770.0019490.2950340.0854130.0005601.0731840.0385351.1712310.0165731.6181650.0504090.5915711.3150351.3666770.8106431.3245860.4827840.2712900.0215010.3749420.3818201.4132510.0232850.0538150.0309751.1325980.6785040.2270050.6825640.1572420.6552050.1044320.2406991.6573061.5650530.0155331.5141171.5887600.2422090.3066530.9241700.7550030.7107540.0881150.1712840.7267800.1325391.1555970.2788220.8482950.5007710.8245940.9069350.8106550.3554740.0890330.8775210.0839770.4680620.5433330.8072500.9237290.0405680.2969340.8634161.6489410.1120990.1112930.3231691.8740040.4144550.2818530.5026590.2044980.0548520.2413000.4998100.3955132.3592412.2060611.3919820.7386560.8871390.7235990.0029120.0207580.0716330.7860250.0319470.0039660.8616550.0120861.6667050.5668630.3402230.0262330.0002690.3249970.8301842.267521

*******************************************
EVALUATING PIPELINE 
Pipeline directory: /home/ubuntu/fnd_implementation/roberta/grid_search/results/pipeline_97a80d26_2020-02-14_10-35-31kc2oa1dy/
With following parameter combination: {'batch_size_seq_length': 2, 'lr': 1e-05, 'lr_type': 'constant'}
EVALUATION OF CHECKPOINT /home/ubuntu/fnd_implementation/roberta/grid_search/results/pipeline_97a80d26_2020-02-14_10-35-31kc2oa1dy/outputs/checkpoint-3
-------------------------------------------------------------
|           |   agree   | disagree  |  discuss  | unrelated |
-------------------------------------------------------------
|   agree   |    770    |    74     |    175    |    18     |
-------------------------------------------------------------
| disagree  |    86     |    317    |    89     |    13     |
-------------------------------------------------------------
|  discuss  |    137    |    34     |   1443    |    30     |
-------------------------------------------------------------
| unrelated |    44     |    43     |    72     |   8553    |
-------------------------------------------------------------
Score: 8708.5 out of 9226.0	(94.39085194016909%)
Accuracy: 0.9315010926206085
F1 overall: 0.8061354801089543
F1 per class: [0.742526518804243, 0.6515930113052415, 0.8431200701139352, 0.9873023202123975]
*******************************************


*******************************************
EVALUATING PIPELINE 
{'batch_size_seq_length': 2, 'lr': 1e-05, 'lr_type': 'cosine'}
INFO:__main__:Creating features from dataset file at /home/ubuntu/fnd_implementation/data/processed
  0%|                                                 | 0/11898 [00:00<?, ?it/s]  0%|                                       | 1/11898 [00:01<3:45:51,  1.14s/it]  4%|â–ˆâ–Œ                                   | 501/11898 [00:01<2:31:28,  1.25it/s]  8%|â–ˆâ–ˆâ–ˆ                                 | 1001/11898 [00:01<1:41:24,  1.79it/s] 13%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ                               | 1501/11898 [00:01<1:07:45,  2.56it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                    | 5501/11898 [00:01<29:10,  3.65it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                  | 6172/11898 [00:02<18:17,  5.22it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–          | 8501/11898 [00:02<07:35,  7.45it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11898/11898 [00:02<00:00, 4815.85it/s]
  ******************************************* 
              Running Evaluation                
  *******************************************
 
  Length dataset evaluation: 11898
  Length dataloader evaluation: 1488
  Number of epochs: 3
  Batch size: 8
  ******************************************* 
 
['/home/ubuntu/fnd_implementation/roberta/grid_search/results/pipeline_aed962e2_2020-02-14_16-11-36n4nunba2/outputs/checkpoint-3']
INFO:__main__:Evaluate the following checkpoints: ['/home/ubuntu/fnd_implementation/roberta/grid_search/results/pipeline_aed962e2_2020-02-14_16-11-36n4nunba2/outputs/checkpoint-3']
INFO:transformers.configuration_utils:loading configuration file /home/ubuntu/fnd_implementation/roberta/grid_search/results/pipeline_aed962e2_2020-02-14_16-11-36n4nunba2/outputs/checkpoint-3/config.json
INFO:transformers.configuration_utils:Model config {
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-05,
  "max_position_embeddings": 514,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 1,
  "use_bfloat16": false,
  "vocab_size": 50265
}

INFO:transformers.modeling_utils:loading weights file /home/ubuntu/fnd_implementation/roberta/grid_search/results/pipeline_aed962e2_2020-02-14_16-11-36n4nunba2/outputs/checkpoint-3/pytorch_model.bin
HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=1488.0, style=ProgressStyle(description_width='initial')), HTML(value='')))
0.7645410.7647530.3832960.1278370.0319920.0064790.8381380.1197620.0149990.8617740.0862080.0078650.0007350.0005590.0000690.0001520.8203370.0482900.9110600.0479850.0024670.0001850.0000370.0000320.0000730.0000320.0000300.0000330.0048981.4933770.0498490.2766590.0086750.0011831.1415290.0326450.0009370.0000591.3522070.0347161.0617411.0867321.2094021.1298100.0257601.0749830.0237820.0005360.5039560.0103160.0002360.0000360.0001330.0000730.0000330.9002711.8207931.8255990.0315770.0005650.0000390.0000310.0000330.0000710.0000310.0000310.0000300.0000310.0006931.7035670.9787440.0138482.1792660.0298810.0004330.0000340.0000340.0001030.0100040.0002720.0000320.0000300.0000330.0001570.0000310.0000290.0000380.0000290.0000530.0000290.0000300.0000290.0000300.0000290.0000290.0002460.0000470.0000580.0000420.0001280.0001250.0001070.0000800.0002700.0002390.0000900.0000320.0000290.0002500.0008981.9826790.0181020.0001890.0000290.0000290.0002210.0000310.0000290.0000290.0000290.9572960.0079400.0000930.0000300.0000290.0000300.0000420.0000290.0000290.0003190.0003010.0002900.0001061.0676520.0080430.0001020.0000481.0111460.0073560.0000810.0005790.7753200.0396280.0003060.8620020.8927520.0061820.0001070.0000670.0000650.0001110.0000300.0000290.0001800.0001040.0001060.0000670.0001020.0000300.0001970.0003680.0059530.0006410.0001080.0001790.0003120.0000310.0000290.0000290.0000280.0000290.0000290.0000290.0000290.0000290.0000290.0000290.0000290.0000690.0000290.0000290.0000290.0000290.0000290.0000280.0000680.0000290.0000330.0002680.0000300.0000320.0000290.0000280.0000290.0000300.0000300.0001430.0002260.0002400.0002250.0000300.0000290.0002710.0001481.7517860.7312320.0035800.0001200.0001210.0001070.0001020.0000300.0001240.0000310.0000290.0000280.0000830.0000670.0000290.0000290.0000290.0000290.0229750.0013521.4565400.0065390.2705040.0017520.8373820.0037251.1648020.0051520.0000540.0004150.0000730.0001130.0000280.0002750.0001510.0000680.0000290.0001140.0003340.0012670.0000350.0000300.0000310.7815700.0039070.0001770.0001090.0000300.0000460.0000340.0000290.0002470.0000300.0000290.0000290.0004190.0000300.0286070.0001470.0007030.0000350.0000320.0002280.0000350.0000750.0000290.0000730.0001160.0000290.0000290.0001140.0000290.0000690.0000750.5836760.0021251.3639250.1195580.0004540.0000681.6328340.0058020.0000920.0014400.0004830.0004810.0000310.0001570.0000660.0000290.0001030.0000670.5403980.6832140.0023690.0002540.0000300.0002010.0002010.0000300.0001040.0000670.7576700.8448650.0028470.0000380.6923460.0022930.0000740.0000290.0000700.0000661.0217680.0032510.9658120.0768920.0003191.0239870.0032080.0000380.0000280.0000690.0011970.0004040.0003162.2159241.6791421.0195220.0035050.0005090.4550101.2992390.0039740.0010440.0029110.0006950.0040671.7360421.2546230.0038790.0006630.0001110.0001480.0001030.0002080.0003761.3850080.0048090.0000430.0002270.0000330.0002230.0000310.0002110.0000310.0000280.0000860.6239240.0017520.0001960.0000740.0000700.0043601.0081760.0027681.2717470.5552040.4085910.8655020.8739490.0023660.0002110.0000310.0027180.0002370.0003800.0003140.0000300.0002260.0000290.0000290.0012550.0004530.0000340.0025610.0035560.0001240.0000900.0231830.0003280.0000300.0008990.0000720.0001215.4476070.0139280.0001850.0001420.0001710.0001490.0002820.0002480.0001990.0001491.0155300.0040860.8913610.0022090.0000340.0002330.0024300.0000380.0004650.0005582.1506342.0394490.0297020.0002040.0000870.0001060.0000691.0815900.0556190.0006780.0005370.0010030.0003260.2059191.0229710.0025182.2107130.8576570.4286470.0010171.7996560.0041290.0004330.0008080.0001590.8226810.0024260.0414321.5382260.0035470.0002020.6436020.4507800.0010310.0002380.0000770.0000290.0000290.0003750.8355420.0019580.3544380.0008372.4335180.8935171.7989340.0045030.0007140.0001080.0000830.0001070.0001860.0001450.0001090.0002270.0016760.0024910.2570020.0005690.0000300.0001170.5197070.0011150.0015670.0534160.0003390.0001710.0008050.0002000.0000290.0000980.0000280.0000280.0000280.0229190.0001120.0000741.8615480.0037880.0000360.0000280.0000301.8129190.0040410.0004710.0003480.0000400.0004440.0006370.0001970.0010930.0006520.0011680.0002320.0035270.0017070.0002840.0002461.1661870.0023300.0000320.0048090.0005730.8294301.5229980.0031170.7776370.0015100.4007830.0011890.0012770.3795300.0867960.0003060.0001840.0010570.0019210.0624290.0667360.0004030.0002560.0010210.8514260.0016401.0759440.7945660.7359501.3437600.6646540.0012440.0000690.0000290.0000290.0000301.1480020.0021040.0000320.0000290.0000290.0018990.0001590.7747112.4942050.8287820.0015440.0001080.0001520.0000330.0001480.0001440.8870620.0017810.0000360.0825560.0037721.1036190.3912130.0007532.1416431.1673800.0054240.8162340.0016450.0003610.8471400.0016700.0000310.2454812.3960720.9222710.0025630.0000950.0002140.0001600.0001060.0001510.0001780.0000810.0001460.0000320.0005660.0001080.0000290.0007321.0111252.0637440.0036762.8749381.0614030.0017770.0000340.0002180.0000290.0000360.0000360.0000330.0000290.0000310.0000290.0002110.0000290.0005850.0002350.0014352.1469192.5180032.9921110.0050060.0004170.4281601.7282851.5785220.0027070.0001540.0001130.0001590.0001550.0224900.1503630.1119450.5810830.0021020.1920840.0021650.0002120.0001040.0001030.0001800.0000310.0000290.0000290.0000300.0000290.0017220.7116640.0011190.0001490.0000650.0000280.0000870.0000750.0000290.0000660.0002420.0002450.0008830.0005620.0003171.1871680.0021860.0000960.0000280.0013690.0001000.0001500.0001500.0156990.0004370.3258930.0008190.0003290.0003080.0000950.0002580.0001200.0010163.1216944.7162424.1665490.0067710.0003890.0013310.0005170.0001080.0002620.0001080.0001450.0001050.6836900.1173680.0003600.0009550.4022700.0017550.0004410.0002030.0002220.0005560.0011600.0002580.0003450.0002180.0005330.0000680.0010570.2837020.0008470.0000310.0000310.0002270.0002290.0000360.0003090.7168660.1263810.0002030.0000320.0017150.0199790.0001030.0007610.7076290.0009980.0000340.0016010.0017960.0004140.0242320.0002050.0002900.0002320.0008240.0016190.5595090.0021230.0085290.0021970.0000340.0000310.0000300.0002550.0000790.0000290.0000290.0001160.0004640.7829310.0010870.0162710.0002830.0000290.0027560.0016730.0013510.0013660.0005281.6802410.7943291.6642930.0021980.0000310.9641170.7947630.8858520.0012720.0003460.0000690.0000320.0001420.0001120.0001180.0001090.0001830.0001080.0001040.0001121.8402590.9352130.0728680.3034751.8668462.8356141.8768241.0130421.8367000.0023440.0045350.0000340.0000280.0000660.0000280.0000700.0002190.0000280.0000290.0003310.0000290.0002600.0001340.0000730.0005090.0000290.0000280.0000280.0001280.0000280.0000290.0001450.0003390.0003730.3155500.0013270.0014730.0033403.9892770.0090740.4806500.0010970.0003523.8351000.0053880.0005990.0005420.0005640.0001050.0000710.0000290.0001070.0000310.0001110.0001120.0000690.0001830.0151630.0011570.6714420.0250760.0003180.0000690.0000290.0001970.0001470.0000280.0000290.0000670.0000290.0000280.0000290.0000290.0000723.8310863.5190362.8929000.0041400.0005580.0003830.0002970.0001680.0003290.0033200.0001430.1261220.9084130.8752241.4654122.4582492.2768054.0171560.0052610.8685461.0837761.0609331.8151722.9620662.9663131.9995300.0022920.0003380.0004430.0003370.0003290.0003352.0928002.1783012.1135790.0025890.0000320.0001450.0001460.0001830.0001050.0003040.0003510.0005280.0003220.0002140.0000290.8581800.0014390.0006690.5008110.0006750.0016400.0000392.2432200.4168451.1641732.3312982.3361160.0025761.1646740.0014930.0000330.0008780.0005530.0290170.0011570.0009080.0323430.0004350.0219220.0006621.2138530.0020090.5650380.0010570.0007873.5718694.6055790.0049430.0000340.4662200.0005240.0000672.2061570.0023670.0000311.3658820.0097580.0002280.0002000.0000680.0000860.0000800.0000770.0000760.0000300.0000300.0000450.0061480.0317600.9517772.8212902.8893210.0049460.0000340.0000910.0000720.0001090.0122880.0003250.0005730.0000291.0941870.0014010.0002850.0002750.0000310.0000320.0000330.0000302.0058110.0020790.8479070.0009340.0000320.0000680.9861721.0495560.9376541.9066351.0489171.0000940.7023730.0009550.0004230.0002180.0000690.0001560.0001140.0001620.0001050.0002850.0001890.0001130.6064240.8280370.0008530.8266392.5324890.8305900.0008541.6642320.0016750.0000321.5355810.0015430.0000880.0000290.0005120.0000310.0000320.0000380.0002620.0005530.0000320.0003100.0000290.0002570.0002520.0002840.0000290.0002570.0002780.0004120.0019190.0027170.8980820.2962070.0014280.0008880.0006870.0010180.0008690.8749210.0015760.0004360.0004371.1548050.0018080.0003850.0003830.7900300.3625430.0006300.0004180.0002810.0002490.0001970.0003450.0132580.0009640.0004080.5586250.0006550.0000300.0000771.1290680.0015210.0008630.8083165.1828390.9209640.0008880.0000290.0002530.2225480.0009990.0006140.0000280.0002090.0000280.0000281.6853520.0025180.0010432.7025510.0026430.8848060.8368692.4714010.0023350.8907341.0254031.6203250.8385780.8855280.3274320.0004140.0000750.0006580.0011030.0004190.0005400.0002310.7055840.0009360.0003950.0001950.0002220.0002580.0003420.0002540.0002970.0012710.6393490.0891910.0015750.0000820.0002133.2339833.0222090.0036960.0002130.0004100.0003620.0006350.1450450.7383210.0015680.0007990.0004100.0004690.0009680.1621340.2189950.2854570.1440301.3571680.8020131.1100810.8578770.5049230.7535100.4389410.6765621.5869000.8162930.3040560.3422881.6551920.3932131.9343920.0053800.0085581.6790380.6755040.0064690.6175520.0026851.0278430.0085231.1626440.0018540.1269200.6772041.1914280.1995750.6443730.5392931.3009800.9913470.4442630.2842351.4139740.1994260.4151360.1060130.2193101.3678150.8916810.0015240.8275930.0342890.3057530.0247670.6463330.2222680.0850281.7779411.7800842.1126610.2952770.3956130.0003800.2519590.8020760.5558130.0688130.9123660.7401821.1437710.9392870.6757440.0029980.0100250.0032420.0785980.7439350.7127751.9395650.6388570.2586990.0101990.4160700.5904750.0007990.8174300.7572730.0035770.7762402.1545030.2060681.0338661.4976100.9486381.1214021.8876200.0285102.2296520.0048980.7311620.0098110.3320221.3383550.0018291.5384290.1481421.0316360.0019860.1151000.2092990.0029320.6790010.1960670.3351940.6604650.0019810.5390252.0640130.6942990.9474800.0031560.0291590.0005670.4147771.4329330.5727351.0906900.0054740.9309290.3763550.1943560.6648870.0162981.0566790.2209320.2045380.9090710.3150490.5168990.7714891.0862830.1419000.0166280.0173870.6280620.7586300.4856400.6123951.2980910.0021540.1323480.6159050.0557940.7183770.8728620.3896970.9907350.0033943.1762500.8112390.8863250.0013891.4583370.3702200.0172560.2340300.0021982.2477240.7880870.1922881.4411630.4005970.2751920.0421390.0014461.2813100.0034940.8598311.6011480.9134210.0037070.7320740.5743590.0758370.0122750.7208070.4070620.0408350.5106110.5765040.7831440.0225450.3346170.1215820.2195690.0162350.6265360.0036411.3344740.5900620.0042681.0574370.9014200.2198440.5941390.0017111.0114840.0040190.5842850.3205400.0073150.0003630.7726760.3439441.1576490.6121870.0762792.2325720.7620480.0081620.0081130.6317000.0279500.0029861.2615360.1016600.5627410.9072430.2123530.6416881.6581710.8011410.0421960.0029820.7649030.7865040.0014200.9749660.8319580.0006731.0515780.6467260.0030720.0011891.3267510.6775871.0438030.5497480.1022040.5482261.1917750.1217111.2137031.2563350.7681970.0010420.0020190.5738010.0015160.0023450.5345440.0906340.0005371.9344000.0059910.7402860.0031880.4127740.1133460.7492971.1455281.3819750.0030101.2213310.1583760.0664770.0568360.4934920.4907281.4261330.0028880.0364140.0025571.2529101.0899900.0203811.4237550.3358040.8264280.0565920.4037341.3236121.2525770.2964931.7255751.3843280.4315350.5106320.8502400.3568541.8434400.0041450.3256410.0146180.5017810.9364230.4519910.9351850.3698741.2095530.3014160.1597100.4063890.0082790.8990350.0033400.8653360.9428200.3317610.5379340.0038630.0329580.4713911.8332250.1001881.2239100.9707250.2233040.1594350.9525680.5591820.5015520.0026540.6294000.7232710.2161462.2422822.3145471.3770790.7809870.8977500.5084180.0109640.0685170.5627440.3094060.3678140.0019351.1301160.0022961.9291690.7053750.1167960.2059190.0002800.0228500.8868890.578780

*******************************************
EVALUATING PIPELINE 
Pipeline directory: /home/ubuntu/fnd_implementation/roberta/grid_search/results/pipeline_aed962e2_2020-02-14_16-11-36n4nunba2/
With following parameter combination: {'batch_size_seq_length': 2, 'lr': 1e-05, 'lr_type': 'cosine'}
EVALUATION OF CHECKPOINT /home/ubuntu/fnd_implementation/roberta/grid_search/results/pipeline_aed962e2_2020-02-14_16-11-36n4nunba2/outputs/checkpoint-3
-------------------------------------------------------------
|           |   agree   | disagree  |  discuss  | unrelated |
-------------------------------------------------------------
|   agree   |    717    |    59     |    132    |     9     |
-------------------------------------------------------------
| disagree  |    86     |    315    |    74     |    15     |
-------------------------------------------------------------
|  discuss  |    212    |    70     |   1524    |    54     |
-------------------------------------------------------------
| unrelated |    22     |    24     |    49     |   8536    |
-------------------------------------------------------------
Score: 8757.75 out of 9226.0	(94.92466941252981%)
Accuracy: 0.9322575222726509
F1 overall: 0.8047650289548572
F1 per class: [0.7338792221084954, 0.6576200417536534, 0.8375927452596867, 0.9899681066975935]
*******************************************


*******************************************
EVALUATING PIPELINE 
{'batch_size_seq_length': 3, 'lr': 1e-05, 'lr_type': 'cosine'}
INFO:__main__:Creating features from dataset file at /home/ubuntu/fnd_implementation/data/processed
  0%|                                                 | 0/11898 [00:00<?, ?it/s]  0%|                                       | 1/11898 [00:01<4:34:29,  1.38s/it] 38%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                      | 4501/11898 [00:01<1:59:27,  1.03it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                   | 5522/11898 [00:01<1:12:05,  1.47it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                 | 6398/11898 [00:01<43:31,  2.11it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–          | 8501/11898 [00:01<18:49,  3.01it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11898/11898 [00:01<00:00, 6112.34it/s]
  ******************************************* 
              Running Evaluation                
  *******************************************
 
  Length dataset evaluation: 11898
  Length dataloader evaluation: 744
  Number of epochs: 3
  Batch size: 16
  ******************************************* 
 
['/home/ubuntu/fnd_implementation/roberta/grid_search/results/pipeline_b1b487d0_2020-02-14_18-01-23w9m6wpb8/outputs/checkpoint-3']
INFO:__main__:Evaluate the following checkpoints: ['/home/ubuntu/fnd_implementation/roberta/grid_search/results/pipeline_b1b487d0_2020-02-14_18-01-23w9m6wpb8/outputs/checkpoint-3']
INFO:transformers.configuration_utils:loading configuration file /home/ubuntu/fnd_implementation/roberta/grid_search/results/pipeline_b1b487d0_2020-02-14_18-01-23w9m6wpb8/outputs/checkpoint-3/config.json
INFO:transformers.configuration_utils:Model config {
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-05,
  "max_position_embeddings": 514,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 1,
  "use_bfloat16": false,
  "vocab_size": 50265
}

INFO:transformers.modeling_utils:loading weights file /home/ubuntu/fnd_implementation/roberta/grid_search/results/pipeline_b1b487d0_2020-02-14_18-01-23w9m6wpb8/outputs/checkpoint-3/pytorch_model.bin
HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=744.0, style=ProgressStyle(description_width='initial')), HTML(value='')))
0.2613690.2629210.1316320.4436340.5120160.1025010.0175250.0027470.0004780.0001500.0002130.0001090.0001610.0001030.4504100.0340120.4383480.5205770.0290230.8510600.7662410.8974890.5391860.0237940.0015180.0001550.0007980.3817131.5677820.0542210.0019010.0002090.0000990.0000972.7822562.0564741.0677850.0289530.0009590.0253800.0007300.2438350.0059050.0002480.0002920.0001040.0000970.0002750.0005340.0001980.0003010.0002790.0003290.0001280.0011221.1061260.0198430.0006850.0001080.0000950.1777440.0030220.0001440.0001680.0002230.0709090.4685800.0071830.3675880.0054240.3860130.2795500.7766840.0108200.0003280.0001950.0026700.0003090.0002370.0002420.0014480.0007420.0041930.0001410.0000920.0000920.0000910.0000910.0000940.0001470.0000930.0000920.0001440.0002030.0002160.0001010.0000940.0000960.0005470.0003410.0000960.0005510.4097380.0071970.0016830.0002100.0002410.0000910.0002100.0000950.0000910.0247640.0156090.4788240.2196770.5859890.0054430.0003300.0004250.0002860.0002360.0028810.0001170.4719510.0042930.0002530.0002490.0003160.0000980.0003490.0026640.0009250.0001130.0003280.0001650.0003120.0000950.0002010.0002170.3265400.7285410.0053730.6737650.0057000.0007920.0001730.0001380.0002380.1068970.0010950.0002310.0002290.0002270.1044660.0008600.1536370.0011210.0001920.4317070.8072100.4357520.0027960.0001600.0011970.7009050.5221390.0038730.6881490.4413920.4844920.5919480.0067370.0020430.0003350.0008162.2756230.0131820.0003070.0002360.0000950.0687440.0008890.0002300.2003120.1427200.3059550.2745500.0016930.0011820.4153640.4040540.2768960.0075980.0002850.0100990.0003590.0003960.0032980.0003012.3773420.0122670.0006620.0011280.0010930.5922810.0068460.1799320.1701670.3178741.5731870.0078090.0003940.4650760.3901580.0030530.3072000.4957200.4596060.1603510.3752730.0384900.0631400.4093420.7311900.1905010.2215390.0018060.0001000.6199780.5088811.4692432.7631790.6060460.0028430.0003990.0003360.0029840.0180710.0001660.0004390.3916650.0104270.0010010.0007890.0463570.0002820.0003170.0006600.0000980.0000990.0006790.1378320.0014220.0008950.0014970.0020750.3603670.0020920.5818650.0035940.0010570.0020470.2827580.0031620.0027210.5987560.0084670.3720150.4083390.0021460.0030410.4799800.1744840.0016100.0001570.0000940.5121210.0019390.0003400.4279961.7040410.0063200.0003050.0004540.1381760.0051880.2989391.0623791.3809450.0513040.0469400.6335140.0022950.8595400.0035640.0005220.0004020.0004300.0003200.0007910.0009441.4490111.4086940.5164750.0019100.0001010.0001130.0000970.0002150.0005430.0012342.3582241.8288490.3949990.8155700.0030990.0004060.0008010.0605680.0049830.1198420.0007450.0003950.0000920.0001070.0200060.0136500.0004970.0003130.0001590.0002740.0012710.0008230.4900220.0016260.0007280.0043630.0009620.0016450.0009800.4100590.0725063.1754431.7805720.1931800.0015680.0005060.0003520.1970940.1386430.0973770.0015950.0010910.0023900.0064040.0004310.0325100.0003240.0002370.0002370.2707740.7379970.3959400.3854470.6706710.0019340.6938270.1824330.0009790.0011340.2882000.1789400.1776000.0005720.0003780.0001030.4624730.0058970.4025680.0042600.0115570.0032621.3364260.8762230.4673760.8989730.0028280.0001640.0003800.0003140.0004650.0003481.6354130.7300872.2019511.1126110.8399170.0926920.0003820.0001620.0669740.0026190.0004000.0136770.0408340.0001930.0024760.0016290.0013330.0011990.8209050.9495000.0360941.5070180.0046890.0008840.0003190.0002290.0002560.0002990.0129900.2806790.0037920.0001500.0004680.0000940.0001600.0001060.0001493.6893511.6222170.0411810.0008430.1189060.1167910.2725780.8633871.4281040.7819740.1420010.0032320.0008400.0004610.0025760.0008701.8623380.9001380.0022920.0004800.0003570.0005200.0003760.4635790.0021230.1154610.0009001.0472380.8259280.5207870.3669270.0014500.0035560.2515580.3083180.0038380.1935740.2425261.9316431.6985650.0046270.0001520.6312940.3657350.0018860.0002520.0002750.0003430.0000970.3535290.3382051.1988510.0042810.0039160.3556400.0012590.4775180.0019280.0002320.0000930.4162750.0066600.0001740.2770940.3567100.3585360.5996920.0016700.0002640.0003590.0003910.0005060.5488210.3042000.9043200.0108510.0109700.0386650.0002340.0007310.0000990.0002540.0021120.0004320.0005280.0002920.0006720.3256250.4532470.0025230.0011620.0017910.0012630.0010120.0069150.0006240.3858090.0015350.0005040.0006920.3006160.4872970.0011780.3602720.0015852.1479300.3996300.0010170.0017870.0005950.0002331.2506280.2956281.1795020.7718841.1367060.9349421.1069580.4553640.0010800.0024910.0091300.6595470.3809240.0012100.3894350.3605990.0035100.4085860.0011882.8439060.0062900.0008370.0239380.0385600.0009770.0011470.0814580.4083990.7887640.3717130.4253020.0264800.7775070.5654160.4209190.5955960.6362820.2555150.2054280.4600650.3388050.4878230.4302231.0376860.9652540.3967760.6367600.1775310.7029630.2401530.3540710.3474030.3699030.4010450.8116470.2583640.1921950.5223310.4665240.5453540.5954470.0152250.0396880.3038050.9717790.3349470.4393770.1854000.3160190.6569150.2305800.9708531.1120370.5769150.3238580.0728860.4304590.5617730.3655830.3878660.3193120.6888910.3050340.2684890.4691290.0325480.1847020.6298590.3949790.4579940.4182840.2528110.0711430.8181630.7160830.2947970.0279400.5000250.3297420.5990580.1280600.1922950.6089850.0956851.3521790.2997110.9682130.1698711.2787900.5635830.7141820.1960570.6049110.3859370.9506400.1710300.3906710.4484540.2391970.3974840.6723470.1542120.0571730.3125721.0667960.4326380.2710660.2181500.4852610.2306610.0436120.3357770.5985520.7946550.3310680.1645100.0251930.4656630.5576600.2452300.5308800.0796730.6320430.4877330.1742070.5277980.0087691.7933410.9477330.2153230.7793271.1955890.2797160.1545080.0192000.4594670.8721890.3751570.2701060.3803271.1994470.6489570.1052880.1227220.3523500.0703360.5573290.3357070.4793050.4131380.6285240.4728501.7415990.3586841.0403880.5607810.4663950.4418670.2703710.5866160.2758760.2440470.4477820.2627350.6227770.0448110.6986680.5096220.4954290.6485920.5282370.2978870.4478011.7301310.7821480.2810060.0770500.4727860.0776910.6495991.5644570.1933480.0025320.353386

*******************************************
EVALUATING PIPELINE 
Pipeline directory: /home/ubuntu/fnd_implementation/roberta/grid_search/results/pipeline_b1b487d0_2020-02-14_18-01-23w9m6wpb8/
With following parameter combination: {'batch_size_seq_length': 3, 'lr': 1e-05, 'lr_type': 'cosine'}
EVALUATION OF CHECKPOINT /home/ubuntu/fnd_implementation/roberta/grid_search/results/pipeline_b1b487d0_2020-02-14_18-01-23w9m6wpb8/outputs/checkpoint-3
-------------------------------------------------------------
|           |   agree   | disagree  |  discuss  | unrelated |
-------------------------------------------------------------
|   agree   |    752    |    70     |    134    |     8     |
-------------------------------------------------------------
| disagree  |    82     |    297    |    69     |    14     |
-------------------------------------------------------------
|  discuss  |    180    |    77     |   1523    |    72     |
-------------------------------------------------------------
| unrelated |    23     |    24     |    53     |   8520    |
-------------------------------------------------------------
Score: 8739.0 out of 9226.0	(94.72143941036202%)
Accuracy: 0.9322575222726509
F1 overall: 0.8044911015654107
F1 per class: [0.751624187906047, 0.6387096774193548, 0.8388873588543101, 0.988743182081931]
*******************************************


*******************************************
EVALUATING PIPELINE 
{'batch_size_seq_length': 3, 'lr': 1e-05, 'lr_type': 'constant'}
INFO:__main__:Creating features from dataset file at /home/ubuntu/fnd_implementation/data/processed
  0%|                                                 | 0/11898 [00:00<?, ?it/s]  0%|                                       | 1/11898 [00:01<4:47:44,  1.45s/it]  4%|â–ˆâ–Œ                                   | 501/11898 [00:01<3:12:58,  1.02s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                   | 5501/11898 [00:01<1:15:49,  1.41it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                 | 6346/11898 [00:01<46:04,  2.01it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–          | 8501/11898 [00:02<19:43,  2.87it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11898/11898 [00:02<00:00, 5729.07it/s]
  ******************************************* 
              Running Evaluation                
  *******************************************
 
  Length dataset evaluation: 11898
  Length dataloader evaluation: 744
  Number of epochs: 3
  Batch size: 16
  ******************************************* 
 
['/home/ubuntu/fnd_implementation/roberta/grid_search/results/pipeline_9a8264c4_2020-02-14_12-25-27rzj0ei1x/outputs/checkpoint-3']
INFO:__main__:Evaluate the following checkpoints: ['/home/ubuntu/fnd_implementation/roberta/grid_search/results/pipeline_9a8264c4_2020-02-14_12-25-27rzj0ei1x/outputs/checkpoint-3']
INFO:transformers.configuration_utils:loading configuration file /home/ubuntu/fnd_implementation/roberta/grid_search/results/pipeline_9a8264c4_2020-02-14_12-25-27rzj0ei1x/outputs/checkpoint-3/config.json
INFO:transformers.configuration_utils:Model config {
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-05,
  "max_position_embeddings": 514,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 1,
  "use_bfloat16": false,
  "vocab_size": 50265
}

INFO:transformers.modeling_utils:loading weights file /home/ubuntu/fnd_implementation/roberta/grid_search/results/pipeline_9a8264c4_2020-02-14_12-25-27rzj0ei1x/outputs/checkpoint-3/pytorch_model.bin
HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=744.0, style=ProgressStyle(description_width='initial')), HTML(value='')))
0.4617790.4621950.2312320.1187090.4209310.0842610.0143290.0022410.0003470.0001050.0001500.0000750.0001070.0000700.6085140.0407040.0026360.4328460.0243790.4173650.6842730.7057610.5142000.5550190.3662960.0147200.0007690.4324352.0219070.0698320.0023920.0002540.0000710.0000661.1207090.4316751.0235750.0277420.0008680.1111860.0028450.5285090.0126530.0004370.0001310.0000680.0000670.0001890.0001310.0001640.0001980.0001870.0002390.0000730.0067531.0061270.0180330.2062620.0036220.0001300.1640190.0027560.0001090.0000760.0001810.0006070.5211880.0078840.3683650.0054050.2938520.2391040.8498900.0117860.0002980.0001500.0002340.0002150.0001780.0001380.0006000.0006240.0005080.0000710.0000660.0000650.0000670.0000650.0000660.0004880.0000700.0000670.0001220.0001400.0001550.0001130.0000720.0000700.0003570.0002340.0000790.0004340.3583600.0036570.0002440.0001380.0002330.0000640.0001600.0000650.0000640.1288300.3993240.1386320.3967410.5441500.0049500.0002230.0002620.0002020.0003680.0007440.0000700.1068130.0013040.0001670.0001660.0001510.0000710.0002120.0009920.0004450.0000700.0006530.0001370.0002610.0000660.0001710.0001520.7546680.8267140.0060330.9177590.0070230.0005300.0001060.0000970.0001761.3717840.0095210.0002080.0001460.0001840.9345410.0062070.4613320.0030610.0003340.5088930.9939720.5161090.0032680.0001220.0010081.0626541.3417990.2328131.3850720.4425480.9306942.3181360.8613920.0053570.0002810.3427003.5679950.2210890.2762210.2689300.0015690.0003730.0002290.0001521.4393180.7621221.1326860.0887430.0006130.0016750.4503710.4273810.2898960.0020080.0248390.1798730.0010980.0002390.0033520.0001902.5575080.0130880.0138580.0006610.0022800.4836590.0062290.0006770.0013260.0033071.9412320.0095210.0002720.4780600.3597660.0032660.0025920.3614310.0031470.0025970.9704340.0051390.0003600.4348950.8707150.4426510.4297060.2996090.0013880.9586230.7158750.4948492.5510890.6267190.0028840.0003310.0002670.0017220.0253330.0001690.4405170.0471820.0045440.0004650.0001960.0002080.0000700.0002090.0004770.0001080.0000710.0004780.0007440.0008350.0004790.3090700.4422500.0047110.0006190.2328850.0018180.0007320.0010290.3071142.1152510.4130540.4351650.0035170.0075550.3396660.0022760.3845640.7712480.8797530.2951380.0011910.0000680.4743730.0017750.4458160.7381011.5695520.0057620.0001990.0002890.1123290.0010130.1708881.4985582.0197950.7699240.0192340.3801450.0014360.1970180.0019060.0003470.0002630.0002600.0001860.0019860.0989111.4764891.3348320.4843660.0017560.0000820.0000810.0000770.0001590.2366880.0052730.0015360.0011620.3319861.1222920.0039750.0003230.0008580.3616300.0027480.0059130.0003430.0002910.0000690.0000780.0005540.3728960.0026520.0001270.0001160.0001790.0015110.0005010.5192360.0016690.0002600.0002740.0004510.0004340.0006420.0011040.0006632.6089771.5348070.0058150.0004770.0004030.0002690.0740120.0036370.2835770.0029330.0010350.0008830.0004440.0002680.3148840.0010460.0001480.0001530.0594710.9367110.4886890.4849030.7516390.0021250.3435840.0047430.0004020.0007890.1166060.0164170.0032510.0000860.1770330.0005560.0003870.2157530.2534720.0023290.0026080.2381971.4357560.9679320.4981540.9394590.0056800.0001320.0002620.0002220.0002880.0002641.6903871.3230522.6581811.3077620.9096670.0026820.0001120.0001060.0002090.0001870.0001660.0002330.0001840.0000670.0001510.0001600.0007020.0013451.0444371.5277691.1647551.7220890.0074210.0005130.0001780.0001490.0001490.0001830.0007090.0087030.0012980.0001060.0003840.0000670.0001070.0000670.0001053.5557041.7016920.0051800.0029740.0393440.0028940.0009801.1624632.4314743.1640002.2522552.7703272.2524260.0054610.3214030.0014312.1063290.9006790.0022110.0003530.0002830.0003390.0002560.4103160.0015530.1384760.0004820.6728640.4842860.4617100.2621350.4534000.2060760.3625730.0016940.2317860.4920410.0017450.4826091.1152360.0026770.0001150.7429080.7015210.0575340.0002920.0001920.0013160.0000810.1151960.2899950.9803050.0031850.0002370.0004980.0003480.2564250.0007680.0001510.0000670.8098580.3147170.0007500.4324250.8245521.2493210.8847580.0021010.0001790.0002540.0002490.0003350.4522950.4953301.5316820.4409790.8788290.8404810.0017650.0003570.0000630.0001670.0017790.0002340.0005270.0002040.0005970.4175140.3431310.0029280.0011320.0017200.0062360.0037320.4514620.0012710.0101590.0486130.0008120.0005760.4544280.4201690.0048950.2864880.0010783.7306180.7991520.0016800.0033300.0003650.0001521.2336010.0031291.2503190.4254990.7250260.8167330.3625340.7314670.0015070.0008360.0005840.5056990.0400090.0004640.4856860.3889510.0033220.0009640.0002462.5042350.0051300.0004470.0036170.1912370.0010400.0008580.1244330.5450760.5600030.6354510.8367140.2835161.3488540.4056870.9716230.4266410.3905430.0690160.5315230.3546391.0134910.5878140.4026091.1306310.9786010.2877420.5069240.2190690.3993840.2424770.4712240.1972450.2801070.2420960.9595710.0712190.0016710.4016560.1450950.6044910.4909980.0117710.2088000.7191080.9373060.1988890.4012160.2270300.2637791.0129920.3502150.9528871.0808230.7055240.2131950.1735400.4554950.6574950.3692850.1277780.1769150.2336550.4800760.2458290.4889640.0147210.6745862.1552610.6831390.7984510.2029000.0322720.2913170.8142590.7853770.6135310.1952820.6039620.3934080.6365390.0478600.3167390.5009280.0986901.0642970.3388441.3244540.3039990.7702790.6306440.7124270.1401480.5833100.4160030.7549230.3886100.2260180.3881390.2935920.1943650.2363700.4770480.1644780.3078680.9378310.5107930.2124620.2495020.4939220.6442890.0266970.5032080.8342550.8570900.0330680.2451880.0058120.7027900.7551550.5404660.6527030.1103430.6445890.3439070.2646720.8620900.0046111.0098590.5691410.2483031.0221111.4871850.3483740.0306240.0228190.2708990.7951700.6016300.2234440.4353910.9876050.5412970.3600380.1491130.5954580.0175880.3428720.4613550.5940790.3984890.7410410.5164171.2611450.1429550.7740170.5017210.1583790.3962820.8402801.1811310.6004830.2844930.7674070.6852690.5168290.0765161.0518120.6200760.3176220.5869470.4638380.2772000.2524492.2031321.1136460.3220970.1644910.3892030.0730860.5237741.2171890.3633760.0082870.520315

*******************************************
EVALUATING PIPELINE 
Pipeline directory: /home/ubuntu/fnd_implementation/roberta/grid_search/results/pipeline_9a8264c4_2020-02-14_12-25-27rzj0ei1x/
With following parameter combination: {'batch_size_seq_length': 3, 'lr': 1e-05, 'lr_type': 'constant'}
EVALUATION OF CHECKPOINT /home/ubuntu/fnd_implementation/roberta/grid_search/results/pipeline_9a8264c4_2020-02-14_12-25-27rzj0ei1x/outputs/checkpoint-3
-------------------------------------------------------------
|           |   agree   | disagree  |  discuss  | unrelated |
-------------------------------------------------------------
|   agree   |    701    |    70     |    93     |     7     |
-------------------------------------------------------------
| disagree  |    72     |    293    |    76     |    14     |
-------------------------------------------------------------
|  discuss  |    236    |    74     |   1531    |    50     |
-------------------------------------------------------------
| unrelated |    28     |    31     |    79     |   8543    |
-------------------------------------------------------------
Score: 8737.0 out of 9226.0	(94.69976154346412%)
Accuracy: 0.9302403765338713
F1 overall: 0.7979837716752232
F1 per class: [0.7348008385744235, 0.6348862405200434, 0.8343324250681199, 0.9879155825383059]
*******************************************


real	23m0.637s
user	20m50.876s
sys	7m53.484s
ubuntu@run-gpu-mg:~/fnd_implementation$ ei[Kxit
exit

Script done on 2020-02-14 20:36:27+0000
