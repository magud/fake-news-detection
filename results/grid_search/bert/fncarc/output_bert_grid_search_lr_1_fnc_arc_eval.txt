Script started on 2020-02-15 09:07:57+0000
ubuntu@run-gpu-mg:~/fnd_implementation$ exitscript output_bert_grid_search_lr_1_fnc_aarc_eval.txtM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Cexit[K
[KM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Ccd exitfnd implementationtime python3 eval_separate.py --model=berrt --model_type=bert-base-cased --dataset_name=fnc_arc
/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/home/ubuntu/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/ubuntu/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/ubuntu/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/ubuntu/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/ubuntu/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/ubuntu/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
There are 2 GPU(s) available.
The following GPU is used:  Tesla V100-PCIE-16GB
INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-config.json from cache at /home/ubuntu/.cache/torch/transformers/b945b69218e98b3e2c95acf911789741307dec43c698d35fad11c1ae28bda352.3d5adf10d3445c36ce131f4c6416aa62e9b58e1af56b97664773f4858a46286e
INFO:transformers.configuration_utils:Model config {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": "multi",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 28996
}

INFO:transformers.tokenization_utils:loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-vocab.txt from cache at /home/ubuntu/.cache/torch/transformers/5e8a2b4893d13790ed4150ca1906be5f7a03d6c4ddf62296c383f6db42814db2.e13dbb970cb325137104fb2e5f36fe865f27746c6b526f6352861b1980eb80b1
INFO:transformers.configuration_utils:loading configuration file /home/ubuntu/fnd_implementation/bert/model_pretrained/config.json
INFO:transformers.configuration_utils:Model config {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 28996
}

INFO:transformers.modeling_utils:loading weights file /home/ubuntu/fnd_implementation/bert/model_pretrained/pytorch_model.bin
INFO:__main__:Loading initialized pretrained model from /home/ubuntu/fnd_implementation/bert/model_pretrained
  ******************************************* 
           Freezing Embedding Layers          
  *******************************************
 
name:  bert.embeddings.word_embeddings.weight
param.requires_grad:  False
=====
name:  bert.embeddings.position_embeddings.weight
param.requires_grad:  False
=====
name:  bert.embeddings.token_type_embeddings.weight
param.requires_grad:  False
=====
name:  bert.embeddings.LayerNorm.weight
param.requires_grad:  False
=====
name:  bert.embeddings.LayerNorm.bias
param.requires_grad:  False
=====
name:  bert.encoder.layer.0.attention.self.query.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.0.attention.self.query.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.0.attention.self.key.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.0.attention.self.key.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.0.attention.self.value.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.0.attention.self.value.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.0.attention.output.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.0.attention.output.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.0.attention.output.LayerNorm.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.0.attention.output.LayerNorm.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.0.intermediate.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.0.intermediate.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.0.output.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.0.output.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.0.output.LayerNorm.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.0.output.LayerNorm.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.1.attention.self.query.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.1.attention.self.query.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.1.attention.self.key.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.1.attention.self.key.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.1.attention.self.value.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.1.attention.self.value.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.1.attention.output.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.1.attention.output.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.1.attention.output.LayerNorm.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.1.attention.output.LayerNorm.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.1.intermediate.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.1.intermediate.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.1.output.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.1.output.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.1.output.LayerNorm.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.1.output.LayerNorm.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.2.attention.self.query.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.2.attention.self.query.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.2.attention.self.key.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.2.attention.self.key.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.2.attention.self.value.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.2.attention.self.value.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.2.attention.output.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.2.attention.output.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.2.attention.output.LayerNorm.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.2.attention.output.LayerNorm.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.2.intermediate.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.2.intermediate.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.2.output.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.2.output.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.2.output.LayerNorm.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.2.output.LayerNorm.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.3.attention.self.query.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.3.attention.self.query.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.3.attention.self.key.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.3.attention.self.key.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.3.attention.self.value.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.3.attention.self.value.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.3.attention.output.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.3.attention.output.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.3.attention.output.LayerNorm.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.3.attention.output.LayerNorm.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.3.intermediate.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.3.intermediate.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.3.output.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.3.output.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.3.output.LayerNorm.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.3.output.LayerNorm.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.4.attention.self.query.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.4.attention.self.query.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.4.attention.self.key.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.4.attention.self.key.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.4.attention.self.value.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.4.attention.self.value.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.4.attention.output.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.4.attention.output.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.4.attention.output.LayerNorm.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.4.attention.output.LayerNorm.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.4.intermediate.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.4.intermediate.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.4.output.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.4.output.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.4.output.LayerNorm.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.4.output.LayerNorm.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.5.attention.self.query.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.5.attention.self.query.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.5.attention.self.key.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.5.attention.self.key.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.5.attention.self.value.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.5.attention.self.value.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.5.attention.output.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.5.attention.output.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.5.attention.output.LayerNorm.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.5.attention.output.LayerNorm.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.5.intermediate.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.5.intermediate.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.5.output.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.5.output.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.5.output.LayerNorm.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.5.output.LayerNorm.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.6.attention.self.query.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.6.attention.self.query.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.6.attention.self.key.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.6.attention.self.key.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.6.attention.self.value.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.6.attention.self.value.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.6.attention.output.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.6.attention.output.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.6.attention.output.LayerNorm.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.6.attention.output.LayerNorm.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.6.intermediate.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.6.intermediate.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.6.output.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.6.output.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.6.output.LayerNorm.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.6.output.LayerNorm.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.7.attention.self.query.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.7.attention.self.query.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.7.attention.self.key.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.7.attention.self.key.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.7.attention.self.value.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.7.attention.self.value.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.7.attention.output.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.7.attention.output.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.7.attention.output.LayerNorm.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.7.attention.output.LayerNorm.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.7.intermediate.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.7.intermediate.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.7.output.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.7.output.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.7.output.LayerNorm.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.7.output.LayerNorm.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.8.attention.self.query.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.8.attention.self.query.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.8.attention.self.key.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.8.attention.self.key.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.8.attention.self.value.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.8.attention.self.value.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.8.attention.output.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.8.attention.output.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.8.attention.output.LayerNorm.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.8.attention.output.LayerNorm.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.8.intermediate.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.8.intermediate.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.8.output.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.8.output.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.8.output.LayerNorm.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.8.output.LayerNorm.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.9.attention.self.query.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.9.attention.self.query.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.9.attention.self.key.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.9.attention.self.key.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.9.attention.self.value.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.9.attention.self.value.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.9.attention.output.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.9.attention.output.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.9.attention.output.LayerNorm.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.9.attention.output.LayerNorm.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.9.intermediate.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.9.intermediate.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.9.output.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.9.output.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.9.output.LayerNorm.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.9.output.LayerNorm.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.10.attention.self.query.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.10.attention.self.query.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.10.attention.self.key.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.10.attention.self.key.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.10.attention.self.value.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.10.attention.self.value.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.10.attention.output.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.10.attention.output.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.10.attention.output.LayerNorm.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.10.attention.output.LayerNorm.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.10.intermediate.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.10.intermediate.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.10.output.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.10.output.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.10.output.LayerNorm.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.10.output.LayerNorm.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.11.attention.self.query.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.11.attention.self.query.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.11.attention.self.key.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.11.attention.self.key.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.11.attention.self.value.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.11.attention.self.value.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.11.attention.output.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.11.attention.output.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.11.attention.output.LayerNorm.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.11.attention.output.LayerNorm.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.11.intermediate.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.11.intermediate.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.11.output.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.11.output.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.11.output.LayerNorm.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.11.output.LayerNorm.bias
param.requires_grad:  True
=====
name:  bert.pooler.dense.weight
param.requires_grad:  True
=====
name:  bert.pooler.dense.bias
param.requires_grad:  True
=====
name:  classifier.weight
param.requires_grad:  True
=====
name:  classifier.bias
param.requires_grad:  True
=====

*******************************************
Evaluating the following pipelines 
['/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_309d0768_2020-02-14_22-59-31mc5_xa5z/', '/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_3d603614_2020-02-15_02-50-13rbtp20hg/', '/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_3ae2d568_2020-02-15_01-59-14rz07nvx6/', '/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_42755d14_2020-02-15_05-44-56l2s3fsmf/', '/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_35bf9aee_2020-02-14_23-50-27vk3n1m5c/', '/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_2e2bd1ee_2020-02-14_21-09-32h520viza/', '/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_384c138c_2020-02-15_00-02-45gk0skut_/', '/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_44ed1942_2020-02-15_07-34-23v9ip97sc/', '/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_3fecf930_2020-02-15_03-37-121b3xitaa/', '/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_3333275a_2020-02-14_23-16-30la61ez_j/', '/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_2b71f0fa_2020-02-14_21-09-28awnqa5gn/']

*******************************************

*******************************************
EVALUATING PIPELINE 
{'batch_size_seq_length': 3, 'lr': 1e-05, 'lr_type': 'constant'}
INFO:__main__:Creating features from dataset file at /home/ubuntu/fnd_implementation/data/processed
  0%|                                                 | 0/11898 [00:00<?, ?it/s]  0%|                                       | 1/11898 [00:02<7:44:08,  2.34s/it]  4%|█▌                                   | 501/11898 [00:03<5:11:23,  1.64s/it] 50%|██████████████████▏                 | 6001/11898 [00:04<1:52:47,  1.15s/it]100%|███████████████████████████████████| 11898/11898 [00:04<00:00, 2949.03it/s]
  ******************************************* 
              Running Evaluation                
  *******************************************
 
  Length dataset evaluation: 11898
  Length dataloader evaluation: 744
  Number of epochs: 3
  Batch size: 16
  ******************************************* 
 
['/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_309d0768_2020-02-14_22-59-31mc5_xa5z/outputs/checkpoint-3']
INFO:__main__:Evaluate the following checkpoints: ['/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_309d0768_2020-02-14_22-59-31mc5_xa5z/outputs/checkpoint-3']
INFO:transformers.configuration_utils:loading configuration file /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_309d0768_2020-02-14_22-59-31mc5_xa5z/outputs/checkpoint-3/config.json
INFO:transformers.configuration_utils:Model config {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 28996
}

INFO:transformers.modeling_utils:loading weights file /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_309d0768_2020-02-14_22-59-31mc5_xa5z/outputs/checkpoint-3/pytorch_model.bin
eval_separate.py:214: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0
Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`
  for batch in tqdm_notebook(eval_dataloader, desc="Evaluating"):
HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=744.0, style=ProgressStyle(description_width='initial')), HTML(value='')))
0.0022780.1933190.0969850.0333820.3469950.0694390.3884440.0558810.0070270.0008210.0002330.0000630.0001220.0000501.3756980.4387560.0503800.4790020.0266810.5740571.2187311.6480210.6133810.0273170.0034770.0001930.0003870.3994991.7398410.4355420.0145560.0005250.0000490.0000370.7789230.7325920.3716860.0100820.0003610.4552400.0114270.0094240.0002660.0002160.0000520.0000400.0000420.0018770.0001130.2988990.1532010.0033690.0005260.0000610.0395220.2738150.0049290.0012120.0000770.0000580.1657190.0027550.0000810.0000380.0007100.0010870.4178250.0063370.0003390.0000470.3817150.3310220.7847130.0108220.0002300.0000860.0001520.0001230.0049170.0004150.1971610.0689970.1516580.0018650.0000610.0000400.0000370.0000390.0000370.0000690.0000400.0000380.0000680.0806150.0012270.0000990.0000430.0000530.0015040.0005380.0000450.6013770.9205470.0090470.0002800.0001510.0001120.0000390.0003520.0000400.0000380.0726650.3112300.0050660.2689460.5290790.0051180.0001350.1623170.0225910.0004450.0018850.0000520.0127350.0004380.0001110.0000430.0003470.0000430.0005820.0026850.0130770.0001510.0012940.0000860.0002740.0000370.0001690.0806430.1798700.4577970.0033120.4270370.0047940.0021550.0001150.0000630.0002310.0021970.0004200.0003370.0002720.0001140.1356170.0009710.0008890.0000690.0005140.4330180.8392840.4221570.0026620.0000810.2986720.3453801.7855361.6458160.1443970.3694901.2228050.8899990.0072510.0011990.0001660.5907951.4606090.0445730.1414800.0010240.0000420.3390180.0022340.0007220.4708540.0176670.3847440.4731260.0031000.2608320.0023520.0003210.0005390.0013460.0006540.0053580.0006110.0009360.0035370.0001382.3826400.0120740.3520830.1089701.1059680.0124840.3103760.0019990.0271180.0214340.5373820.0027570.0001410.3590400.1076570.0032080.2612780.4109871.3212560.0299520.5725370.3089470.1470190.4764650.5148250.2482320.2148660.2555350.0011621.3114820.8346340.9629952.8898500.6814120.0055940.0441330.0226580.1543170.9037890.0038350.3423090.0388380.5951540.0027540.3092230.3573490.2721890.1806390.0230720.8198510.0331890.0093260.0161970.6966870.0212470.0049210.3682801.0496990.0044460.5100610.3464910.0041900.0048850.0514891.8913320.4463200.8536250.8545170.0241730.3574490.0021880.4031120.3299880.3455430.0019500.0000590.0000330.6372630.0023330.0001260.0179880.0111410.0005120.3791670.3221460.3216770.2437130.4119161.2678961.1067061.4689930.0073680.3663700.0013021.2944500.2122840.0011310.0040090.0005360.0001490.0041500.0027190.5782910.6371670.1968360.0010260.0000430.0000420.0000420.0004360.0004750.0056691.1339620.8019990.4157171.4854730.0049530.0002430.0136171.9738550.7103220.1200030.0005670.0002000.0000350.0000370.3967010.5131880.0016510.0000760.0000670.0005780.0035630.0024730.5739520.0018330.0002780.0002630.2236320.0012420.0004350.2912480.0203680.9114550.3283410.1666690.3529180.0014520.4519070.0048130.0057970.0045220.0228000.0011470.4812200.6686210.2939040.5812180.0021920.0004110.0004070.1572880.2963310.2656160.3211580.4179100.0012160.6789950.0473650.0399970.0347880.5404180.3774110.6494500.0017950.0103560.0000630.0001250.6887480.3104340.0043610.0191260.5330051.2321720.8600940.8902580.8988490.0028420.0000780.0002300.0001400.0002810.0002230.6283620.9093520.9945960.3914400.1762200.3734120.0010140.0000860.3645910.3857350.3977350.3915700.3754730.0009640.3883560.0010580.0012440.0027171.0540133.2923271.0008231.3737780.8620071.2099280.3645740.2685280.1060790.2298150.8329320.2134300.3261670.0009050.0010860.0000390.3410470.0008370.0001123.1700711.7635590.0061350.0010260.0022080.0007040.2305450.1074780.9737630.3344591.7419652.0714601.3048410.0033010.1859120.0034621.8168640.8138360.0019360.0002310.0007620.0013820.0008980.1228650.0697700.0071310.0010241.4623880.8685680.7704820.4119680.1307560.9604151.5192150.7621380.3886090.0048350.1015160.5422920.9925660.1000170.0002741.3962661.4952640.1437730.5182730.0881830.0005660.0000550.0255742.5815212.2296860.0766110.0022760.0889910.0016500.1968820.0054720.0004280.0000370.4021260.4237510.0009210.3914720.6604310.5284200.8167600.0031310.0005530.0001860.0001830.0003700.7253200.6063311.4169450.1351430.3511480.0306510.0073770.0118690.0000710.0012210.0209720.0012100.0017320.0005000.0020680.2738991.2750060.0357010.0013310.0087650.1833180.0033140.3281200.2833870.2422780.0075970.0121760.0014150.6787990.0388300.0001610.3681940.3025751.4896160.3643750.0013110.1432720.1404620.0008221.1003870.1183421.0241040.6465490.7227320.9398620.9048890.5863870.0011840.0031520.0895710.3130130.0034990.0003330.5744250.0017450.5852850.3566590.0014303.6506580.1270500.0028070.1410780.0022170.1983270.0214090.1521830.3728531.2667820.4240550.4554040.5316490.8242360.5534810.3951410.2731880.7518700.2842420.0191620.7245610.8568320.3472330.4026030.8169390.7064940.4089790.7392370.3151700.5668190.2663110.3016810.4237710.3590881.0089770.8638010.0948170.0025600.5767340.6255711.0876470.4362460.0191370.5534120.8299190.7521750.3413880.3965180.1342820.2151751.1803160.5010390.8806581.1146550.5413540.4579850.1391600.2918400.4771980.2872020.1030950.2707950.4475620.4072260.6106290.3210930.2442000.5510531.5496220.3424070.5905820.2108660.4634500.4621420.9822970.7631510.9126140.0926870.5502390.5359480.5167990.4229150.1795050.5429570.0740961.7696460.5952361.6179680.2498210.8559890.6353421.8022550.3299950.4035760.3525010.4422810.3210560.7093450.0581560.3322240.2101910.7028000.3666540.1682670.3785960.8868511.0909570.6431040.2217360.4342080.4494870.0474210.5553590.9865511.0648290.0637480.2108990.0128090.9712360.6424900.4414980.4865700.2048230.9275010.3609900.1202530.4688040.0112360.7788600.4559010.1820821.3547541.1510700.2693890.2658850.0059650.2620290.4000150.4232150.3616130.3738731.2669740.6239670.1228950.0881100.3560840.0507510.4742300.3883391.2319020.3983710.6594590.8876412.0677020.6249150.4090610.7349170.0422400.3932120.3922550.8050590.6469470.1866460.5258660.2878380.5950910.1399850.5380690.1624930.6415710.5336470.3798060.1689060.7306882.0842091.3313740.6108120.3698980.3659070.4298580.5334360.5740980.2742920.1227401.350736

*******************************************
EVALUATING PIPELINE 
Pipeline directory: /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_309d0768_2020-02-14_22-59-31mc5_xa5z/
With following parameter combination: {'batch_size_seq_length': 3, 'lr': 1e-05, 'lr_type': 'constant'}
EVALUATION OF CHECKPOINT /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_309d0768_2020-02-14_22-59-31mc5_xa5z/outputs/checkpoint-3
-------------------------------------------------------------
|           |   agree   | disagree  |  discuss  | unrelated |
-------------------------------------------------------------
|   agree   |    735    |    138    |    184    |    10     |
-------------------------------------------------------------
| disagree  |    90     |    227    |    64     |    21     |
-------------------------------------------------------------
|  discuss  |    170    |    54     |   1434    |    46     |
-------------------------------------------------------------
| unrelated |    42     |    49     |    97     |   8537    |
-------------------------------------------------------------
Score: 8606.25 out of 9226.0	(93.2825709950141%)
Accuracy: 0.9188939317532359
F1 overall: 0.7571632240504161
F1 per class: [0.6986692015209125, 0.5218390804597701, 0.8234280792420328, 0.9847165349789492]
*******************************************


*******************************************
EVALUATING PIPELINE 
{'batch_size_seq_length': 4, 'lr': 1e-05, 'lr_type': 'linear'}
INFO:__main__:Creating features from dataset file at /home/ubuntu/fnd_implementation/data/processed
  0%|                                                 | 0/11898 [00:00<?, ?it/s]  0%|                                       | 1/11898 [00:02<7:08:05,  2.16s/it]  4%|█▌                                   | 501/11898 [00:02<4:47:08,  1.51s/it] 38%|█████████████▌                      | 4501/11898 [00:02<2:10:27,  1.06s/it] 46%|████████████████▋                   | 5501/11898 [00:03<1:18:59,  1.35it/s] 52%|███████████████████▋                  | 6183/11898 [00:03<49:24,  1.93it/s]100%|███████████████████████████████████| 11898/11898 [00:03<00:00, 3081.22it/s]
  ******************************************* 
              Running Evaluation                
  *******************************************
 
  Length dataset evaluation: 11898
  Length dataloader evaluation: 372
  Number of epochs: 3
  Batch size: 32
  ******************************************* 
 
['/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_3d603614_2020-02-15_02-50-13rbtp20hg/outputs/checkpoint-3']
INFO:__main__:Evaluate the following checkpoints: ['/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_3d603614_2020-02-15_02-50-13rbtp20hg/outputs/checkpoint-3']
INFO:transformers.configuration_utils:loading configuration file /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_3d603614_2020-02-15_02-50-13rbtp20hg/outputs/checkpoint-3/config.json
INFO:transformers.configuration_utils:Model config {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 28996
}

INFO:transformers.modeling_utils:loading weights file /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_3d603614_2020-02-15_02-50-13rbtp20hg/outputs/checkpoint-3/pytorch_model.bin
HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=372.0, style=ProgressStyle(description_width='initial')), HTML(value='')))
0.0282560.0302070.0445770.1076320.1103480.0254880.0046600.4101520.2634130.2530270.9226650.2764230.0518780.0737710.5208140.0351260.0024090.7921050.1976250.1843380.0103010.0015330.0038880.0125220.0534570.0312860.0033180.1990750.0223400.0010340.0111060.0006020.0090120.1084930.0584410.0862180.1905650.0057390.0013280.0019580.0812280.0649380.0017790.0003180.0003430.0002720.0013090.0149030.0015710.0291140.0492150.2305520.0082380.0006610.0031570.0272220.1534080.2690890.0073350.0999710.0676300.1951460.0088480.0012580.0036730.0828140.0123570.0008590.0004950.0458370.1963140.1571680.0340670.0014200.0123740.0028270.1282200.0063860.0007580.5442780.1772640.0240990.5956900.6617290.5417530.2902390.0463610.9726290.0137210.0012190.0067730.5508710.6790290.1160900.5254270.1184330.0258010.0441720.0629831.0272330.1985330.3588670.2241300.0512930.6513370.0072960.7595850.2405580.6622600.5275030.1254610.0290190.0064490.0080520.1074621.5479840.3271460.0552140.5385360.0934310.1864720.1243270.1038660.2658980.2530010.3457070.1513480.0865060.2658500.2545690.0541150.7923490.8277410.1119370.1071710.2286960.1949800.0017330.2495490.0124620.0325780.0379870.1342471.2853211.4221150.0335090.0167180.0053150.0132060.0098450.3145370.4791010.0046510.0002900.0028300.3072110.3872020.7195580.1508120.3143460.1609090.0017970.1712730.2247570.0018670.0561060.4334290.0422340.0408850.0592280.1302910.7486350.1036990.0054790.1763770.2502870.2446220.0969980.0988630.0051390.0910790.1210320.0595370.1320360.2314590.8993900.1965180.2069730.4396830.3105680.3004000.4762320.5049910.0649540.0024880.0045740.2476250.3849740.1641700.0012310.2554860.0682990.1379030.1028110.0845830.8144690.4448450.0239460.0062410.0030470.2327390.1439010.0017930.0011071.0054720.7076230.2503190.1712270.4269160.6798020.1585520.0076330.7759360.2268880.0064390.0383350.1337410.0443740.7613090.4124390.2135460.3758570.2477200.2974060.4622920.5867070.7658610.0573560.0016131.3777600.5332960.1117390.1467630.0158850.0110130.0070900.0137840.1195190.0069930.0014540.1005850.2736290.0092700.0022570.1093820.1929090.1167900.0218231.2561550.0117700.1116400.1360040.1665080.0135840.0355380.0364450.1673490.5304100.0993750.0714190.4444910.0589340.0928970.0682630.0185770.4693450.0204250.0144440.0241761.0013530.1259910.1232780.0351460.3309040.5796870.2000060.4595330.4575450.3546340.3585990.4640000.3789530.5949430.3595540.4011170.2841380.4707990.4640630.2743130.5434460.2760490.3419820.3236760.2409040.5494610.6072450.6377790.1724340.3113960.2881140.2066650.3683790.1811600.4672600.4457300.1718050.5238120.6981870.3502270.4883570.2131060.5233361.0000550.7040760.6574620.2347400.2349780.4485900.3199950.1444450.4781710.2872130.3244480.1873210.3062350.2393960.6627040.2016720.1635030.4825970.5266450.5380680.3339380.4589610.3875941.0356930.1239970.2660130.4065170.4202510.5522500.1764860.4085500.4979250.5431730.3469160.7427270.5064140.3752950.6446320.4856050.4117760.3687910.3527080.6219110.2756921.0353230.5797950.2000680.2770660.5556360.428199

*******************************************
EVALUATING PIPELINE 
Pipeline directory: /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_3d603614_2020-02-15_02-50-13rbtp20hg/
With following parameter combination: {'batch_size_seq_length': 4, 'lr': 1e-05, 'lr_type': 'linear'}
EVALUATION OF CHECKPOINT /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_3d603614_2020-02-15_02-50-13rbtp20hg/outputs/checkpoint-3
-------------------------------------------------------------
|           |   agree   | disagree  |  discuss  | unrelated |
-------------------------------------------------------------
|   agree   |    636    |    109    |    114    |     5     |
-------------------------------------------------------------
| disagree  |    131    |    226    |    83     |    19     |
-------------------------------------------------------------
|  discuss  |    244    |    107    |   1516    |    67     |
-------------------------------------------------------------
| unrelated |    26     |    26     |    66     |   8523    |
-------------------------------------------------------------
Score: 8649.25 out of 9226.0	(93.74864513331889%)
Accuracy: 0.9162044041015297
F1 overall: 0.7402984581301671
F1 per class: [0.6691215149921094, 0.48759439050701187, 0.8165903582009157, 0.9878875688206317]
*******************************************


*******************************************
EVALUATING PIPELINE 
{'batch_size_seq_length': 3, 'lr': 1e-05, 'lr_type': 'linear'}
INFO:__main__:Creating features from dataset file at /home/ubuntu/fnd_implementation/data/processed
  0%|                                                 | 0/11898 [00:00<?, ?it/s]  0%|                                       | 1/11898 [00:02<7:33:42,  2.29s/it]  4%|█▌                                   | 501/11898 [00:03<5:04:21,  1.60s/it] 46%|████████████████▋                   | 5501/11898 [00:03<1:59:35,  1.12s/it] 52%|██████████████████▋                 | 6176/11898 [00:03<1:14:53,  1.27it/s]100%|███████████████████████████████████| 11898/11898 [00:03<00:00, 3049.14it/s]
  ******************************************* 
              Running Evaluation                
  *******************************************
 
  Length dataset evaluation: 11898
  Length dataloader evaluation: 744
  Number of epochs: 3
  Batch size: 16
  ******************************************* 
 
['/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_3ae2d568_2020-02-15_01-59-14rz07nvx6/outputs/checkpoint-3']
INFO:__main__:Evaluate the following checkpoints: ['/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_3ae2d568_2020-02-15_01-59-14rz07nvx6/outputs/checkpoint-3']
INFO:transformers.configuration_utils:loading configuration file /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_3ae2d568_2020-02-15_01-59-14rz07nvx6/outputs/checkpoint-3/config.json
INFO:transformers.configuration_utils:Model config {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 28996
}

INFO:transformers.modeling_utils:loading weights file /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_3ae2d568_2020-02-15_01-59-14rz07nvx6/outputs/checkpoint-3/pytorch_model.bin
HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=744.0, style=ProgressStyle(description_width='initial')), HTML(value='')))
0.0041430.0998070.0504280.0587330.2729210.0547810.0979490.0206620.0027860.0006540.0004300.0002040.0002420.0001881.0480830.1170340.0078380.4382020.0253050.5339191.2122371.2326550.5340220.0257640.0215910.0018320.0005800.2149401.3850980.0920380.0032840.0003880.0001730.0001682.1256111.9231870.3758550.0103510.0005890.4541590.0115720.0012840.0002580.0006530.0061870.0003500.0002040.0160060.1544520.0155770.0147590.0029850.0038840.0003620.2940640.8074310.0145880.0714620.0014220.0001960.0016760.0002020.0001640.0001690.3541050.0073300.4564000.0073900.0014790.0002340.3349570.0367500.7036130.0098930.0004510.0008570.0005450.0003750.0010430.0009690.0523750.1037560.0022190.0001890.0001640.0001640.0001630.0001910.0001640.0003290.0001770.0001660.0002250.0002140.0034610.0003290.0001850.0003130.0010860.1196790.0013670.0231351.0358220.0111790.0005800.0004000.0003140.0001890.0007250.0002030.0001720.1981750.2228960.3532050.0844060.3862800.0052270.0003590.1831210.0488560.0018580.4483540.0038600.7215920.0064060.0004390.0002220.0012780.0001680.0017740.2156650.0428650.0041180.0019590.0002550.0004370.0001880.0003190.0004590.0835310.4347040.0034670.0569730.0048850.0136690.0010860.0002290.0003730.0023440.0011620.0008570.0010030.0003250.2860460.0021280.2305050.0017780.0003720.4108360.8519540.4507650.0033240.0002231.1110560.4113441.3545051.6287470.2874060.1592360.5386310.5512730.0257350.0040730.0181420.2036651.0685770.4261690.4009590.1701280.0011230.2002870.0728150.0008231.3224840.8282891.0901110.1345170.0018160.8242440.1148220.2709660.0343400.0060270.0038970.0104400.0005130.0031480.1734640.0015442.5158520.0133720.0909500.0363830.4318680.2739720.4570320.0056510.1790080.0945341.1710780.2939280.0019230.4813411.5266010.0134870.2694100.3156370.0097740.0066250.4132000.0586250.0324060.1746790.0529600.0555740.0049370.0021010.0002061.2416090.8426471.4099303.0663840.6022680.0111350.0135460.0015320.3413511.1388910.0049470.3160930.3780420.2551100.0031810.1576400.2269480.0012260.0161110.0178560.4443020.0020700.0109620.0204270.4285860.1323760.0133740.1163830.2814970.0018520.4478930.4373810.2393270.8038030.2520451.4830540.5412590.6044770.1905230.2815590.3651810.0052420.1512590.4726320.3858150.2058230.0009650.0001730.4571450.0018160.0526150.0119720.0005680.0004010.3085430.0290430.0016930.2225060.9024581.2770542.2070161.6414500.0088210.0046420.0003440.3141470.0130920.0009970.0009450.0008720.0810790.1350890.0021120.6299030.3381950.2406510.0031550.0001920.0001730.0001830.0014940.0016260.0208621.0022260.9959720.4905642.4567140.0084940.0006630.3618270.4863560.3738900.1100640.0008980.0005020.0002190.0001990.4166680.4744070.0017480.0002380.0002200.0021530.0991880.0114690.4696510.0016570.0181240.0010130.0355280.0303940.0019690.4448660.2369563.0040101.5616030.2451010.5024550.0024240.0851400.0522200.2201020.0371970.8934190.0195420.0064640.0045800.0015340.2036330.0021070.0009740.0015790.0216140.0574540.1437650.1205480.1948430.2091311.3822810.4124040.0023020.0435100.2905510.3318690.2178620.0008440.4965580.0015540.0228530.8771990.4435460.0109400.3636680.4388291.2463420.9605520.8112630.9811900.0045820.0004090.0005900.0005060.0005080.0004951.1363810.4625411.7898590.8632270.9076340.0025790.0002110.0002130.0461880.1234920.0008450.0071460.0010790.0001650.0065910.0068200.1979360.0078410.7688411.2624550.5720680.3827980.3074610.0088360.0032260.0012180.0012510.0010940.0352490.5151770.3098450.0009700.0005710.0001840.1610400.0005490.0002102.7684281.1397480.0574400.5209370.1226480.2044990.0197820.0476640.1172000.1590092.9135240.6207290.0057410.0009650.4445340.0034491.8025520.7676410.0020270.0005250.0012660.0029490.0021440.2760780.0375770.0026810.0400801.4921521.4142891.0121060.5223930.0065880.4159450.4870850.0875430.3192950.3050440.0851800.1989650.7166040.1592480.0006020.7966731.3667260.0303970.2359340.0057480.0008000.0004090.3757863.2511911.8471320.0204610.0010060.0451390.0030840.4782550.0062010.0009800.0001830.0111990.0038110.0003340.0016030.0043440.0071470.2739540.0041530.0012040.0005460.0012080.0006620.1287160.1869260.0047180.0005340.0006020.0005120.0003040.6322510.0015370.2458950.1045360.0078170.0099160.0020730.0741370.1826100.7908770.4617080.5478200.8096090.0759580.0054710.5903710.3708160.1809170.0196870.0049550.0009751.1617001.4790110.0031620.4645380.0110123.2599160.4874440.0050750.1175040.0562820.0018940.9648550.3638660.6059210.3445130.4141350.6112380.4691090.3061960.0009980.0063000.0019260.0164590.0020250.0011800.0069650.0182900.2163730.0044830.0006663.1883780.1407980.1403080.0788780.0090370.0040890.0802070.2694560.4947040.7029930.4663970.1359770.2162660.8339700.3681840.2729040.2245660.5521230.0317670.1635060.7573780.9550960.4959200.8498280.8831100.7395800.6610970.9920990.3682780.6102210.3874710.2410530.3199170.5590160.8052160.7807370.2495470.0642690.5736830.1809660.5751860.8110790.0430410.3672680.8383640.0509940.2322640.3929430.3192030.1868720.6030860.5705960.9641441.0111950.8131960.2472020.0834380.1720050.3563740.6107360.3099840.3766790.1653850.2671350.6727320.3731390.1551900.1464220.5067850.0748930.6602350.1901960.0473130.4566080.7714200.7077380.5654930.1923350.5910480.4623730.8193210.3738990.1871820.5343290.2338731.2066810.3462121.2143230.1878430.5276280.6627380.4120370.0562210.2762660.3459860.7262560.3695520.6265350.3172350.0650380.4358620.7626570.5100600.1496660.7468670.7037720.4339280.2697020.2180470.4827150.2552160.0586130.6910470.8592170.7981150.1421780.2267940.0246360.3711140.9118080.2764650.5476710.1854100.7721080.3950680.1618020.6353750.1891941.1540290.4112480.2648720.6755631.0723610.0884040.0905140.1371820.1518190.5949240.5343440.7582900.4286421.2435750.7919540.2351060.1989930.7262200.0424170.4403350.5725150.7609140.4472480.5646460.4800581.3522460.6701450.4215670.5724880.2412330.5483470.4465400.6584200.2925200.5031330.4807490.6406660.3512900.2525160.5996650.1408560.4722090.6202770.4915090.1711250.5839471.6129190.8179240.7343660.0625560.3225090.3900630.4566700.9523920.1323830.0499241.216555

*******************************************
EVALUATING PIPELINE 
Pipeline directory: /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_3ae2d568_2020-02-15_01-59-14rz07nvx6/
With following parameter combination: {'batch_size_seq_length': 3, 'lr': 1e-05, 'lr_type': 'linear'}
EVALUATION OF CHECKPOINT /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_3ae2d568_2020-02-15_01-59-14rz07nvx6/outputs/checkpoint-3
-------------------------------------------------------------
|           |   agree   | disagree  |  discuss  | unrelated |
-------------------------------------------------------------
|   agree   |    684    |    127    |    139    |    16     |
-------------------------------------------------------------
| disagree  |    104    |    229    |    67     |    22     |
-------------------------------------------------------------
|  discuss  |    211    |    74     |   1497    |    66     |
-------------------------------------------------------------
| unrelated |    38     |    38     |    76     |   8510    |
-------------------------------------------------------------
Score: 8631.0 out of 9226.0	(93.55083459787556%)
Accuracy: 0.9178013111447302
F1 overall: 0.7520599082432569
F1 per class: [0.6829755366949576, 0.5146067415730337, 0.8254755996691481, 0.9851817550358879]
*******************************************


*******************************************
EVALUATING PIPELINE 
{'batch_size_seq_length': 2, 'lr': 1e-05, 'lr_type': 'cosine'}
INFO:__main__:Creating features from dataset file at /home/ubuntu/fnd_implementation/data/processed
  0%|                                                 | 0/11898 [00:00<?, ?it/s]  0%|                                       | 1/11898 [00:02<8:19:41,  2.52s/it]  4%|█▌                                   | 501/11898 [00:03<5:35:09,  1.76s/it] 46%|████████████████▋                   | 5501/11898 [00:03<2:11:41,  1.24s/it] 50%|██████████████████▏                 | 6001/11898 [00:04<1:25:00,  1.16it/s]100%|███████████████████████████████████| 11898/11898 [00:04<00:00, 2967.47it/s]
  ******************************************* 
              Running Evaluation                
  *******************************************
 
  Length dataset evaluation: 11898
  Length dataloader evaluation: 1488
  Number of epochs: 3
  Batch size: 8
  ******************************************* 
 
['/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_42755d14_2020-02-15_05-44-56l2s3fsmf/outputs/checkpoint-3']
INFO:__main__:Evaluate the following checkpoints: ['/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_42755d14_2020-02-15_05-44-56l2s3fsmf/outputs/checkpoint-3']
INFO:transformers.configuration_utils:loading configuration file /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_42755d14_2020-02-15_05-44-56l2s3fsmf/outputs/checkpoint-3/config.json
INFO:transformers.configuration_utils:Model config {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 28996
}

INFO:transformers.modeling_utils:loading weights file /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_42755d14_2020-02-15_05-44-56l2s3fsmf/outputs/checkpoint-3/pytorch_model.bin
HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=1488.0, style=ProgressStyle(description_width='initial')), HTML(value='')))
0.9929430.9934470.8597670.2867240.0717550.0215890.0079750.0011910.0002030.4517110.0452220.0041630.0004531.0250480.0732750.0055071.1220750.0660561.1520730.0606890.0031380.0002880.0000640.0000540.0001150.0000560.0000530.0000541.0058811.6624030.0555160.0093030.0003420.0000901.1338500.0324660.0048660.0001831.1349120.0291641.6581061.1714760.7290310.2557920.0059161.0953040.0247950.0005850.0188300.0004360.0000610.0000910.0002160.0001480.0000580.7252481.4116961.8540660.6925740.0117890.0002460.0000790.0001200.0001200.0000510.0000510.0000510.0000513.0634011.9354472.2325372.2604050.7328570.0100930.0002020.0000570.0000700.0001840.0433710.9993530.0125620.0002060.0000540.0000690.0000520.0000540.0002180.0000600.0020870.0000770.0000630.0000520.0000520.0000520.0023180.0007270.0717150.0010270.0049580.1799440.2914010.0311260.0004390.0011960.0021550.0001260.0000560.0000510.0010180.2762141.8666600.0171540.0002040.0000530.0000540.0071950.0001130.0000550.0000530.0000520.0593600.0005440.0000560.0000590.0000510.0000510.0000530.0000520.0000511.0349340.0090100.0012250.0001590.9308720.0070520.0001080.0000510.0006870.0000580.0000530.0022830.4974760.0057310.0000930.4909400.7676840.0053580.0001530.0001380.0001050.0002200.0001370.0000540.0002620.0001520.0001470.0001000.0003510.0001510.0005800.0009800.1658380.0610350.0005620.0003110.7114910.0043370.0000760.0000510.0000510.0000500.0000510.0000500.0000500.0000510.0000580.0000500.0000500.0001390.0000510.0000500.0000510.0000500.0000510.0000510.0001710.0003970.0000600.0006970.0000550.0000530.0000800.0000510.0000540.0000500.0007720.0003510.0003980.0008190.0009010.0000550.0000520.1432400.0009090.9263532.2624000.0110480.0002270.0007550.0004780.0001710.0000600.0001260.0000540.0000510.0000550.0001490.0001100.0000510.0000540.0000510.0000510.0033310.0318760.8070320.0041180.0000920.0040440.6490510.0029731.0324710.0046710.0000710.0011780.0002220.0004040.0000530.0882890.0009330.0001150.0000570.0003700.0003640.2791080.0011970.0000580.0000530.9163190.0039240.0003140.0001630.0000520.0000550.0001780.0000540.0006840.0000550.0000520.0000540.0012150.0000570.0433540.0029340.0662220.0014650.0091010.0009000.0000660.0006300.0000530.0001460.0003700.0000530.0000510.0004180.0000520.0002610.0001290.6937390.8787050.9252010.3483610.0012980.0001251.5215260.0055130.0001312.2872140.0091700.0143330.0001030.0301770.0002080.0000530.0001800.0001350.0005660.0014620.0001090.0007320.0000580.0005850.0005640.0000560.0001570.0001300.7967070.2826840.0010760.0000550.9248400.0030780.0001110.0000680.0001120.0001051.0625090.0034091.0351821.0183150.0032881.0621810.0033500.0000940.0000510.0001100.0107090.0138490.0603290.0031201.2033790.0681230.1706800.6358340.0606430.3399700.0011630.2005500.7906210.0134590.9211200.7534240.0323730.0037710.0023400.0001680.0002250.0001710.0014200.0007000.0006360.0002900.0000540.0005050.0000560.0008020.0000570.0005070.0000540.0000520.0001140.6387790.0018170.0007750.0001410.0001080.6228161.8902760.0051881.3325640.6337500.6025600.4675970.0033240.0000600.0010030.0000532.0436600.0056650.0007900.0007000.0000540.0006700.0000530.0004640.0052120.0010560.0000540.0033550.0036730.0002370.0001050.0001520.0013950.0000540.2671040.0007860.0001735.3238250.0138110.0002450.0035720.0002551.8188780.0065840.0042500.0004081.0803010.9120690.8842101.0158790.0025230.0000660.0008810.0582640.0002000.0018030.0766091.2023061.6731420.1069060.0007290.0001240.0001630.0001121.0100442.0183470.4234860.0028380.0119130.0005580.5513600.8879830.0022590.0014850.1875851.5282740.0035481.2387330.0028780.1422250.5986830.0016100.0005480.5709830.0076160.0265110.0002310.0002870.0037740.0005030.0000550.5686120.0013700.0000570.0000510.8998391.8409630.0041291.7224420.8061252.4731100.9002110.9961660.0037150.0018020.0002300.0002000.0004310.0004740.0003060.0002590.0009881.2259162.1105000.6786990.0014750.0000540.0001600.1684100.0004040.1754680.1641960.0009500.0002180.0004390.0528600.0001590.7705570.0016280.0000550.0001110.0889040.0002890.0001150.0067171.0571580.0021800.0000640.0000530.2363610.0017080.0012150.0854650.0003350.9109140.6482160.0015240.0026240.0042140.0465060.4308110.1252050.2214570.0010020.0004530.9722630.0020000.0000551.6721120.0042120.9243241.1310840.0055730.3941890.0008043.6329350.9364641.2142240.0085860.0015230.0002300.0008510.3447510.4165970.0031440.7274770.0027530.0078040.0018860.0063310.0001930.9882340.0236670.0077000.5015360.0171940.0000810.0001040.0000500.0000500.0000531.1475480.0021250.0000560.0000500.0000500.0006880.0008610.0002040.0002850.0001670.0001000.0002250.0209710.1858480.0006401.0450080.6673280.0019300.0000580.7058940.7008781.8480562.8342040.0050803.9747452.3990241.3551762.6585000.0058390.0022300.0233260.0003520.0000510.0002881.9280720.6435830.0599140.0002360.0002560.0002490.0001640.0002260.0002620.0001160.0002230.0000801.3779900.0024690.0000561.2991751.9454250.4947020.0012510.6000680.3165030.0005720.0000560.0010240.0000530.0000540.0000510.0000510.0000510.0000540.0000510.0007990.0000550.0007740.0019470.0140971.2704921.6471661.4121500.0029450.0014380.8499781.9387792.8320970.0048130.0002550.0001880.0002670.0002640.5676940.1165182.4639421.0024481.6083641.1692140.5241570.0010960.9913750.0017080.0002810.0000520.0001100.0000520.0000520.0000560.9362881.0544350.0016680.0001160.0001630.0000510.0001650.0001770.0000510.0001580.0007520.0027110.1773130.0039810.5634341.1453970.0022300.0001310.0000510.0016290.0001540.0002110.0001980.0008140.0004970.0002500.0006470.0008300.0005011.0636040.0022900.0004150.9032282.4185733.4268143.6377120.0071820.0012800.0087020.0409690.0005050.0006860.0001870.0002540.0199100.1499430.0037240.0003980.8035110.3276550.0061720.5685661.4377330.5862131.1113800.0056540.0005100.0005360.0022040.0180080.0001450.0003761.0747370.0025170.0000560.0000560.0006690.0007010.0006280.0007390.0541570.3346770.0005150.0000530.3780350.4578910.1347420.4346660.1797850.0003290.0005910.0057162.3194030.0100240.0415350.0003080.0008180.0006630.0178900.0268951.2228600.0907921.0186480.6568060.0009330.0000580.0000610.9723170.0014660.0000670.0000510.0001350.2712191.9940000.0027230.0001831.0382460.0014200.0154801.1612110.0193740.0179640.0027781.8709961.0484422.0900480.0027850.0000602.0255351.0495061.0752310.0018460.0021480.0001230.3636260.0817670.0002921.0032980.0014620.0003420.0001750.0001790.0001862.8908200.8928490.6833521.4416532.7606942.5890501.8746871.0623221.9201780.0024910.0069650.0000670.0000530.0001070.0000530.0001040.0089900.0000630.0000530.6044280.0008100.0040590.1396510.0002900.0199350.0000780.0000520.0000530.3831410.0005250.0000540.0004180.0006330.0012490.0012560.0024370.0013010.4530032.0564611.6726321.5043990.4564580.0013081.1293203.3089122.8564031.1619621.5351260.0040120.0002590.0000540.0013370.0000590.0028340.0002980.0001080.0088460.0184770.0257900.5533380.3579270.001967
0.0001350.0000540.0006770.0003670.0000510.0000540.0002040.0000520.0000510.0000530.0000520.0001403.1407623.0207573.5208820.0058630.0050230.0017440.0013821.0613400.0060300.0403570.0006150.0010270.1301880.0966380.0096270.2291050.2058490.7995000.0037340.6452061.9544631.8584702.3393942.1258761.7736371.3166120.0015440.0004751.1765320.0018130.0006440.4337062.0227332.0636832.1246490.0026840.0000550.0002110.0002030.0002620.0001530.0016310.0010360.0015840.0010120.0007650.0000561.4158970.0236720.1767360.4573430.0005600.0084540.0505592.0993900.7504920.9910742.1496432.1598880.0024071.0740760.0023750.0000560.0048830.0024311.6147262.0405140.8768820.6429030.7129140.7116180.0019900.8895900.0032990.0298350.0690870.0100060.4441672.4696740.0026880.0000550.7993450.0009070.0001183.1969990.0034420.0000554.2009500.3369420.0015790.3642060.0006000.0033320.5237680.0007050.0004730.0000540.0004970.0000570.2113272.8894903.4442641.1799080.0085690.0131750.0000640.0049580.0003390.0003470.0659750.0028870.0041980.0000561.0668990.0022490.0541750.0012080.0000530.0000530.0000530.0000530.3263880.0003890.0005980.0001110.0000550.0001130.0800160.3262850.0010940.0279940.0018300.5769290.6179760.0012260.0014290.0007100.0001230.0002490.0001610.0002740.0001660.0002570.0002960.0001760.6847220.0012950.0000520.3329630.1806000.2214670.0002810.3325900.0003810.0000540.1402560.0001930.0001760.0000501.2888260.0013230.0000550.0001620.7169020.0477830.0000980.0127960.0000620.0016530.0014410.0017340.0000520.0011310.0019780.7490320.7554791.5536023.8490340.0526150.0521830.3745980.0616420.3277530.8419200.7111680.0035120.0012540.0012690.7635820.0154290.0098260.0758870.2920070.0074460.0019150.0120030.0127760.0023900.0002570.0005170.0005030.0577100.0006820.0036700.0002170.0000530.0001220.1924880.0017250.0030460.1041615.3544180.8327610.0008520.0000530.0040860.0097780.2215860.2177930.0002520.5001100.0005130.0000512.4220540.8166200.0050501.0241010.0011730.6075060.0009100.0281750.0001280.4225660.8676030.4175970.0036680.1067640.0006050.0001700.0001020.0017040.0032460.0005160.0009780.0003020.2876450.0008050.0005420.0003160.0003610.0005830.4037060.0008600.0005000.0033320.0032730.0010040.0027420.0005010.0005362.9917652.5616230.3723590.0324040.0063170.0022180.0019330.2909410.0017830.0045800.0097000.0009800.0008860.3196750.0425050.6595170.3117931.0680890.7456910.3727731.3504980.9963940.2475640.2779830.0541300.9037291.2217231.2941170.5870920.5277830.3535170.1783890.9701780.0218550.4033730.8324040.1011160.0071930.1120750.0646031.3130200.0061251.5419060.8211530.3887151.1680332.0803920.0745840.6546531.2704721.1341620.5132870.1787550.4700161.4905530.5861570.7142640.1603060.4287350.8291630.6274270.0018510.5331750.1459220.4964920.6075030.1720160.8894430.0934272.0844840.7869641.4402670.0110630.1290450.0001750.0150390.6547520.5631380.0913581.1593901.1918560.9934400.6322510.5191000.0057270.0142610.0128110.3599620.5176270.2324640.0034210.1337940.3161100.5141140.2082560.7908280.0030260.5502700.4560220.0056540.4235000.7157290.5194220.5323701.2068891.0547240.8536041.0933170.0772131.3735200.0199620.5388590.0080230.0795740.4380330.0019610.6808050.0732550.7444960.1041210.2315450.2827180.0034800.7871050.0555950.2587190.6908810.0270700.1264351.0796050.4595310.2629960.0053790.3085190.0023540.8944341.4072170.6388620.0068900.0049470.4427941.2595920.5187850.0101700.0019650.1057490.6129041.0307591.8425700.2313430.7128701.6525540.9647990.1572550.0847580.4565751.0036580.4610240.5907850.1402902.2051430.0068160.1855070.5047450.0382660.4867920.4897080.3346940.3460150.3737542.1508850.8393290.5540030.0022731.7172020.6265770.0211540.2785620.0035060.6951281.0774360.3696590.4542460.4882170.1458470.0034790.0032390.9647630.0083360.5801281.0347910.9098220.0049470.9853280.6485970.5868780.0044930.5318040.0374300.0031260.2788920.0083881.1833670.0303410.9569170.0994910.5307810.0169000.7539720.3915291.4880610.6322370.0122520.8194950.2773630.6425750.3135570.0031780.7833890.0079260.3829820.4857360.0079210.0024710.5267970.7819700.7613171.4636590.0468751.8746090.5930880.0153050.0088400.5416960.0087540.0056361.0726800.2703420.5713721.1824610.0659170.6152000.8344780.7330760.6917590.0098290.4021240.9809940.2666260.6958020.0663570.0001200.6315390.7882110.0111330.0034691.6777940.6606610.5774690.2494100.0005680.7470731.2721501.4866971.7698921.3614620.5133750.0023810.0046920.1565960.3925690.0085080.3832080.0292230.0012021.1338790.0064411.1741110.3710710.8723840.0410910.5970431.3132891.3972000.0087312.1303480.2925130.2885090.0118070.3337400.4837031.3300600.0032620.0256760.2271680.9009791.3141930.0241661.8101630.3662340.6512280.2043280.2079430.6935541.1648550.1969631.4517341.5667090.2467280.9485821.1042590.0968541.5160030.0073810.3316230.0296780.3398800.5085820.3011350.3334710.5610700.8684810.5691560.2456471.1545170.0411960.7948800.2865560.9168820.3473550.4957550.5362610.0096390.0056130.2690511.3862260.0115330.3744170.0924270.7617700.3556180.8240960.5110970.5368120.0061710.5595440.1163830.6090931.2411162.7636971.1912500.7368120.8589250.8238570.1159780.0341050.6011980.2445410.6342700.6399030.9766250.0066561.5738350.1062560.1423500.0551820.0001500.1343241.4353791.895442

*******************************************
EVALUATING PIPELINE 
Pipeline directory: /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_42755d14_2020-02-15_05-44-56l2s3fsmf/
With following parameter combination: {'batch_size_seq_length': 2, 'lr': 1e-05, 'lr_type': 'cosine'}
EVALUATION OF CHECKPOINT /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_42755d14_2020-02-15_05-44-56l2s3fsmf/outputs/checkpoint-3
-------------------------------------------------------------
|           |   agree   | disagree  |  discuss  | unrelated |
-------------------------------------------------------------
|   agree   |    676    |    113    |    134    |    21     |
-------------------------------------------------------------
| disagree  |    88     |    232    |    72     |    18     |
-------------------------------------------------------------
|  discuss  |    251    |    94     |   1516    |    75     |
-------------------------------------------------------------
| unrelated |    22     |    29     |    57     |   8500    |
-------------------------------------------------------------
Score: 8649.0 out of 9226.0	(93.74593539995665%)
Accuracy: 0.9181375021011935
F1 overall: 0.7535544123943315
F1 per class: [0.6824835941443715, 0.5284738041002278, 0.8161507402422611, 0.9871095110904656]
*******************************************


*******************************************
EVALUATING PIPELINE 
{'batch_size_seq_length': 1, 'lr': 1e-05, 'lr_type': 'linear'}
INFO:__main__:Creating features from dataset file at /home/ubuntu/fnd_implementation/data/processed
  0%|                                                 | 0/11898 [00:00<?, ?it/s]  0%|                                       | 1/11898 [00:02<8:24:00,  2.54s/it]  4%|█▌                                   | 501/11898 [00:03<5:38:03,  1.78s/it] 46%|████████████████▋                   | 5501/11898 [00:03<2:12:49,  1.25s/it] 50%|██████████████████▏                 | 6001/11898 [00:04<1:25:43,  1.15it/s]100%|███████████████████████████████████| 11898/11898 [00:04<00:00, 2812.10it/s]
  ******************************************* 
              Running Evaluation                
  *******************************************
 
  Length dataset evaluation: 11898
  Length dataloader evaluation: 2975
  Number of epochs: 3
  Batch size: 4
  ******************************************* 
 
['/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_35bf9aee_2020-02-14_23-50-27vk3n1m5c/outputs/checkpoint-3']
INFO:__main__:Evaluate the following checkpoints: ['/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_35bf9aee_2020-02-14_23-50-27vk3n1m5c/outputs/checkpoint-3']
INFO:transformers.configuration_utils:loading configuration file /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_35bf9aee_2020-02-14_23-50-27vk3n1m5c/outputs/checkpoint-3/config.json
INFO:transformers.configuration_utils:Model config {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 28996
}

INFO:transformers.modeling_utils:loading weights file /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_35bf9aee_2020-02-14_23-50-27vk3n1m5c/outputs/checkpoint-3/pytorch_model.bin
HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=2975.0, style=ProgressStyle(description_width='initial')), HTML(value='')))
2.1109612.1109771.0555060.3523041.2482530.2496780.0417330.0059800.0007670.0001010.0022860.0003570.0002010.0000320.0000190.0000180.0000180.0000171.3282360.0699240.0035120.0001840.0000250.0000170.0000170.0000530.0000180.1567230.0056130.0002100.0000230.0002602.3820340.0722000.0021400.0000780.0000192.4304580.0639770.0016600.0000990.0000180.0000170.0001840.0000210.0000160.0000160.0000170.0000780.0000190.0000160.0000160.0000170.0000180.0000170.0000171.4405771.9114621.5113662.2303160.0372440.0006660.0000411.3251600.0207220.0003360.0009760.0000632.1488390.0311590.0005030.0000240.0000180.0002400.0000190.0000160.0002842.4260470.0311270.0004112.1581802.2763870.0277772.2501110.5041252.3589090.0362530.0004340.0000740.0000172.5383420.0279110.0003620.0009550.0000270.0000180.0101960.0001210.0000170.0000150.0000160.0000160.0000160.0000170.0000930.0000160.0000170.0000650.0000190.0000160.0000201.0650781.6136411.6076232.3272292.0382531.9162850.0163960.0001550.0000170.0000160.0000150.0000160.0001860.0000170.0000270.0000670.0000170.0000160.0000160.0000170.0000160.0000160.0000160.0000160.0000161.0594151.1553043.1725190.0228410.5739701.9441940.0137261.7856540.0139221.5508680.0106410.0000900.0000250.0000200.0000170.0000180.0000200.0000180.0000790.0000660.0004400.0024870.0000322.0222490.0126570.0000950.0000240.0000160.0000170.0000160.0004210.0000210.0000180.0000350.0000180.0000170.4394241.9875350.0114450.0000830.0002790.0000180.0000180.0000170.0000180.0000260.0000170.0000220.0000170.0000200.0000160.0000170.0000170.0000200.0005761.7251230.0093091.5331300.0080111.9314930.0098720.0000670.0000170.0001170.0001070.0000170.0000160.0000850.0000760.0000230.0013770.0000230.0000200.0029400.0000960.0000460.0000170.0000240.0000190.0000250.0000290.0015100.0439560.0004252.2404721.5205190.1740890.0007970.0000200.0000170.0000170.0000170.0000200.0000210.0038330.0000330.0000160.0000160.0000170.0000190.0000170.0000160.0000170.0000161.3885360.0057770.0000410.0000170.0000170.0000180.0000260.0000170.0000170.0000170.0000170.0000170.0000170.0000170.0000170.0000170.0000170.0000172.3321890.0090210.0000520.0004470.0004750.0000180.0000910.0000172.3058260.0087290.0000580.0000640.0000240.0000220.0000200.0000250.0000190.0013410.0000210.0000170.0000170.0000170.0004540.0009090.0000190.0001490.0001160.0000190.0000160.0000180.0000170.0001891.5959000.0055000.0000350.0000580.0000180.0000520.0000550.0000210.0000600.0000170.0000560.0006620.0000190.0169730.0000740.0000170.0000960.0000880.0000480.0000510.0000160.0000900.0000510.0000170.0000170.0066170.0000480.0000170.0004210.0000340.1216850.0012040.0000201.2252350.7904180.0033710.0000260.0003560.0000650.0001230.0592860.0002380.0000160.0000160.0000160.0000160.0000160.0000160.0000160.0000160.0000160.0000160.0000160.0000160.0000160.0000150.0000160.0000160.0000160.0000160.0000160.0000220.0000160.0000160.0000160.0000160.0001080.0000170.0000160.0000160.0000160.0000160.0000180.0000160.0000160.0000160.0000160.0000160.0000160.0000160.0000160.0000610.0000160.0000190.0000170.0000260.0004700.0000180.0000170.0000160.0000170.0000170.0000180.0000260.0000170.0000170.0000170.0000170.0000170.0000180.0018680.0000210.0007670.0000530.0308780.0001300.0004520.0000190.0005000.0000180.0000180.0000170.0000170.0000180.0002580.0007220.0000590.0001190.9860761.7849344.6346030.0113300.0000590.0000170.0000480.0000510.0047940.0000730.0000180.0003470.0000940.0000200.0000170.0000160.0001330.0000170.0000170.0000160.0000170.0000170.0000170.0000170.0000160.0001310.0000520.0000160.0000170.0000170.0000170.0000170.0000160.0000160.0000170.0000170.0000170.0018540.0744611.1340611.2166211.4693810.0033590.0000900.0000720.0000240.0000200.0355780.0016531.3427360.0029490.0000700.0000172.5083590.0054960.0000850.0000170.0000170.0009010.0000310.0000160.0000730.0000900.0000160.0000170.0000170.0000160.0003150.0005310.0000180.0000610.0000170.0000170.0000170.0000890.0000770.0001580.0000691.9114830.0039430.0000250.0000160.0000170.0000170.0000160.0000161.9796231.8108070.0036760.0002790.0001510.0002280.0002130.0000560.0000160.0000160.0000160.0000440.0000150.0000250.0000180.0000190.0004440.0000170.0000160.0000160.0000160.0000160.0000570.0000180.0004750.0005040.0000170.0000170.0001151.5727790.0030190.0004150.0021650.0000220.0000210.0003330.0000330.0033320.0000250.0019780.0000250.0000170.0000550.0000170.0000170.0000160.0000160.0000510.0000550.0000520.0000170.0000160.0000170.0000170.0000170.0001070.0000170.0000170.0000600.0000410.0000160.0007680.0000190.7130061.7153920.0030930.5019330.4637310.0037510.0000260.0000170.0000190.0000760.0000160.8590270.8904920.0015780.0001180.0000720.0000150.0110001.1223380.0025480.0005610.0013540.0001100.0000190.0000170.0000800.0000450.0000170.0000680.0000180.0000180.0000170.0001010.0000830.0000190.0000160.0005340.1769620.0008760.0000550.0000160.0005170.0000190.0000170.0000160.0004250.0000240.0000160.0004590.0000180.0000160.0000970.0000170.0000160.0000682.4283520.0040090.0000232.3684100.0039090.0000620.0000160.0000162.4883080.0040230.0000680.0000160.0000160.0000560.0000170.0000160.0000160.0000540.0000630.0000160.0000162.3346120.0037160.0000312.3933470.0037751.7477930.0027520.0000210.0000542.4290340.0037960.0000230.0000170.0000170.6979830.0010940.0000180.0000180.0000520.0019660.0028460.0009050.0006700.0008880.0000190.1741610.0046190.0034962.7709921.5379480.0027721.6878540.0029280.0533010.0001890.0003370.0971940.6530751.2996150.0020330.0000201.6190340.0024151.3364561.4569381.5004410.0022261.6816861.2648180.0018701.5781990.1722420.0002680.0000170.0799720.0033530.0000860.0000560.0000660.0000920.0001110.0000180.0001070.0000660.0323570.0002930.0002000.0002230.0003760.0000640.0000320.0000160.0000170.0000180.0004460.0000170.0000170.0004630.0000170.0000160.0000160.0000160.0004460.0000170.0000170.0000170.0000160.0000170.0000580.0000790.0010030.0000190.0000160.0000720.0001050.0000640.0000170.0000580.0000170.0000162.3139322.0504004.2830450.0058350.0000232.2829132.4052960.0032664.1460081.7477440.0024210.0000190.8176640.0014380.0011170.0000190.0000160.0010420.0000200.0000170.0000170.0000172.9592190.0044380.0000230.0006970.0000170.0004740.0000170.0000170.0000170.0000160.0004560.0000170.0000170.0000170.0000550.0000170.0022230.0006170.0000200.0000170.0000190.0000400.0016340.0033910.0001350.0000960.0001990.0000980.0000160.0000160.0000770.0006390.0001910.0000160.0000170.2256020.0003010.0000890.0000160.0001030.0000964.9093127.3400650.0095540.0000970.0000720.0001030.0000610.0012010.0001170.0002310.7983400.0061570.0014230.0002320.0000860.0003310.0002450.0001010.0148820.0029901.5832900.0027210.0041031.3307143.5192450.0043050.0000220.0000180.0000180.0000370.0443950.0000740.0036820.0015050.0000190.0000780.0991120.0036560.7417730.0009050.2808000.6733041.5628580.0018841.0429040.0012590.0001990.0059410.0001480.0000260.0000160.0001860.0001490.0000160.0000161.3536834.2005360.0055320.8503070.0012110.0002110.0008640.0018410.0001850.0001280.0001680.0018591.4668470.0036871.5900020.0018520.0000930.0002460.0003070.0000550.0004023.2223910.0512050.0000850.0000261.5755451.5943270.0018340.0000240.8883090.0018850.0017470.0007920.0001000.0000680.0000710.0001560.0001080.0021120.0027831.0556900.0012341.2437410.0014460.0000590.0000630.0002021.5847600.0022630.0000550.1222580.0001550.0000160.0020470.0000210.0000550.0000160.0000160.0000170.0000160.0000160.0000162.1429440.0180330.0001190.0000170.0000490.0080040.0326801.1605700.0013382.0182633.2433180.0036401.4208232.1176070.0023340.0000870.0013260.0013610.0002130.0000660.0001300.0000160.0002630.0001450.0052810.0001730.0001260.0001100.0000690.0000190.0002480.0005060.0000210.0009081.8768486.1142831.5146841.8305020.0019450.0000190.0000170.0000170.0000180.0001020.0000180.0000491.0875260.0011560.0000220.0012230.0412410.1864130.0004510.0002710.0000850.0000540.0001040.0002260.0003920.8471750.0008860.0000170.0000161.5222670.0015770.0000180.0000160.0000160.0000170.0000230.0000160.0000160.0010690.0000170.0000580.0000170.0002000.0017610.0007590.0000172.3816840.0024130.0000210.0000200.0000200.0000160.0000170.0009820.0011230.0000180.0011300.0000200.0009200.0068290.0000250.0000200.0000211.8713090.0018710.2726390.0008140.0001910.0000200.0001850.0009040.0009860.0010360.0000191.0008300.0214470.0000390.6181290.1176690.5057530.0079430.0002360.0002070.0002300.0002031.9623200.0019700.0000520.0000180.0000160.0000170.0000532.3240540.0027820.0002210.0001840.3487981.2986550.0021680.0009500.0000200.0109430.0016830.0000190.0000170.5322473.3235961.2598850.0012601.5029120.0043610.0085250.0015670.0017191.6383790.0016490.0000600.0046410.0001450.0004211.0012081.1581010.0029500.0004400.0017900.0000191.6621640.0055830.0000220.0008470.0000520.0000170.0018440.0203770.0007260.0003400.0000160.0000150.7423990.0029530.0003620.0000160.0013730.0002040.9311030.0065690.0000220.0000150.0000160.0000160.0000600.0000160.0000150.0000160.0000160.0000160.0000152.3768690.0021670.0000170.0000160.0000160.0000160.0000160.0000160.0000150.0000150.0000620.0008370.0004280.0000340.0000650.0000570.0000740.0001460.0000890.0000170.0000600.0000170.0001520.0000160.0064000.0000890.0000161.3053930.0012970.0000742.2345550.0020480.0000920.7300470.0006680.0004790.0000170.0000220.0008501.4097580.1370300.7973243.4263800.4108394.5390722.2174260.0019440.9771284.1324973.2905181.9207020.0018590.0068562.6996344.5029234.1339340.0035800.0013030.0011250.0000180.0000970.0001820.0002120.0000150.0000160.0000160.0000161.4565462.7562311.5598480.0016050.8828980.0034160.0001110.0000170.0000560.0000550.0001160.0000740.0001040.0000180.0001140.0001040.0000950.0001100.0001130.0000800.0000180.0001050.0000680.0000160.0000270.1173480.0399850.0001040.0000640.0000160.0000160.0475750.0012992.0644711.8046270.5109740.5397100.0005840.0001441.7077473.0702661.5995580.0019290.0000190.0000160.0000170.0000180.0005070.0000170.0000170.0000160.0000170.0000260.0000170.0000190.0000160.0000170.0000160.0000160.0000200.0000190.0000160.0000170.0004800.0000170.0000170.0000160.0000160.0004760.0004780.0000260.0067160.0031720.0015615.3309561.7213233.3841844.4292693.6469270.0029470.0004480.0004230.0004230.0000170.7155640.0007333.8989700.0032536.0928830.0049260.0000910.0001020.0000550.0000160.0000940.0001110.0000520.0000590.0000910.0000170.0051780.6005390.0029470.0001950.0003900.0002030.5746100.0044170.6933250.0077780.3173650.0018260.0006490.0001900.0000741.8040260.0014180.0000170.0001550.0002380.0000160.0000160.0000160.0000310.0000160.0000160.0000200.0000160.0000180.0000200.0000170.0000161.7030962.4249460.0021560.0000180.0000180.0000160.0000840.0000940.0000170.0000160.0000160.0000160.0000790.0001000.0000170.0000170.0000160.0000740.0000170.0005200.0000180.0011700.0000180.0022980.0005970.0000170.5831490.0006830.0001000.0000322.3155310.0019120.0005620.0000160.0001980.0000160.0000160.0004580.0000160.0003650.0000160.0000170.0004030.0001130.0000150.0000160.0002460.0005100.0006390.0001070.0004120.0002370.0003320.0003200.0013780.0039920.0001890.0000580.0002350.0001430.0001640.0000770.0000670.0001430.0027353.1310503.4994803.0190313.8832845.8990653.8820710.0036840.0005860.0034120.0114810.0091660.1129810.0010770.0000540.0001040.0000210.0001260.0001850.0000520.0000540.0000170.0001380.0000560.0038610.0139170.0011810.0012180.0000180.0001470.0000580.0118400.0019831.3830670.0027890.0018111.4243143.5710813.6358653.2603461.9250070.6245721.0549872.3223950.9499800.0011280.0024390.0002970.0001410.0001020.0001980.0000550.0001390.0011980.0000770.0000160.0000470.0000160.0001630.0224971.6747270.0011910.0007690.0000180.0000180.0000160.0000190.0004340.0000170.0000180.0004470.0001090.0000200.0007670.0000280.7858050.0005630.9269610.0062530.0000220.0000180.0000200.0000180.0000181.4798790.0010401.5664620.0025340.0000200.0000181.5109430.0011401.3448780.0009460.0000200.0000170.0004180.0000194.0573207.0524510.0048630.0000952.6667262.0261130.0021910.0002340.0000570.0013820.0014800.0004020.0002770.0000160.0404050.0095761.1659060.1524101.3989220.5732840.0004041.2331140.0008470.0000191.3529480.0009250.0000180.0000180.0000190.0000190.0000182.1960620.0014830.0000850.0000160.0000160.0000510.0000160.0000160.0000690.0000160.0000800.0000234.7114940.0031380.0000340.0000160.0000170.0001122.0948340.0013980.0000170.0000160.0035040.0033630.7562420.0175140.0337750.0016600.0100960.0080680.0032481.7867282.1664941.8830452.1715930.0014362.1825061.9392440.0012810.0001430.0000170.0000174.1853590.0027382.1434970.0014082.1584640.0014150.0012720.0000170.0022230.0020600.0000170.0001850.0469080.4729400.0004170.0128511.3257350.0009480.0001192.1553360.0015020.0000680.0000850.0001660.0000460.0001040.0000180.0001080.0000520.0000621.7959883.5468451.8097470.0012180.0000531.8074160.4232401.5297792.1891632.1674800.9679013.9796120.0025354.1526370.0026770.5634254.2518480.0026990.0000220.0000160.0000170.0001460.0000170.0000160.0000160.0000160.0000510.0000160.0000160.0000160.0000670.0000160.0000690.0000800.0000170.0000160.0000160.0000160.0000160.2971440.0002020.0000180.0001200.0000160.0000170.0004420.0000160.0000570.0000760.0000170.0000160.0000160.0000160.0000170.0000160.0000160.0001080.0000170.0000160.0000210.0000170.0000160.0000160.0005070.0002720.0002550.0005190.0008980.0006820.0005370.0004750.0016900.0012330.0000680.0010383.2828513.7727534.3174670.2229604.2836901.5460901.3303650.0039580.0003170.0002580.0142743.9197710.3350605.9472821.5095112.3055242.4494821.3485172.3347252.2309240.3434020.0002220.0003460.0005430.0000160.0000180.0001580.0000170.0015210.0000170.0000220.0008860.0000170.0003120.0000160.0001210.0000150.0002830.0003560.0000170.0066720.8776100.0014040.0022601.1884270.0823880.0009880.0000180.0006480.0000770.0000160.0000160.0000200.0001070.0002210.0000990.0000600.0000160.0000170.0000210.0000180.0009400.0000170.0000160.0000160.0000160.0000160.0000160.0000170.0000170.0000160.0000180.0000573.6388973.7224911.9259945.6629505.2584545.8323324.0591680.0025110.4010221.6339531.5858720.0010190.0000770.0095640.0008142.1554691.7702540.0011480.2657590.8940050.0011131.6940020.0009921.3622980.0010290.0006370.0006910.0002150.0002540.0014260.0002083.4769561.8204422.1903172.3011740.6708090.0005730.0010611.6477970.0027562.4422662.4954876.2934562.3931292.1973142.3840910.0371380.3519980.0010420.0104140.0045130.0130250.0000770.0000160.0002060.0002310.0001912.0682260.0013710.0001840.0001941.6875010.1149502.1110852.2174542.2107250.0015744.0971863.1166510.8505620.0005750.0001920.0000180.0000160.0001610.0000170.0001210.0000600.0001500.0000530.0000170.0001080.0000160.0042210.0000190.0004390.0000160.0009690.0000170.0004570.0005620.0000160.0000160.0000161.0238870.0032750.0006860.0014070.0006760.0015920.0054530.9415970.0005350.0000210.0019690.0000320.0016610.0000192.2292822.0721822.0253580.0011250.0000182.2348131.9868022.3085242.0699702.3865830.0013190.0000172.2772920.0018470.0000170.0004990.0000170.0000190.0013520.0015760.0012870.0001492.1112760.0534481.8278860.5392510.0006020.0019350.0016490.0166310.0001100.0275660.0001151.2037450.0086070.3627620.5608212.3317520.0165710.0006150.9453550.0090730.6035111.0868070.5435890.0013170.0162120.3836154.5703551.1458480.0006280.0000170.0000160.0000160.0737250.0000560.0000170.0000160.0000160.0000751.1434084.0061170.0021410.0000180.0000170.0000175.0328521.9360030.0807340.0000610.0000210.0016600.0000190.0007590.0000170.0000700.0000390.0001380.0001120.0000180.0000170.0000980.0002700.0000240.0000200.0000190.0000260.0000330.0000160.0000481.9430330.0012242.4963894.6945154.3142724.6256164.6229432.3038424.2813092.1232830.0035290.0030390.0000180.0000180.0000180.0002900.0000180.0002570.0000820.0000690.0000181.1035430.0005860.0004630.0009880.0000170.0000160.0000170.0005251.3687280.0011500.0000170.0000160.0055950.0000190.0004460.0000160.0000170.0000160.0000160.0000180.0000170.0000170.0000172.1707201.7892550.0009290.0000160.0000271.5062390.0008300.0000160.0000160.0000170.0000160.0000572.1410430.0011032.2353060.0011490.0000171.9661930.0010114.0148332.2180880.0011742.1571410.0013570.0003131.4271440.0015030.0000240.0011070.0000220.0008970.0000230.0000750.0000170.0000170.0001730.0000620.0000730.0001720.0000190.0000610.0000630.0001580.0000770.0001550.0000580.0000170.0001221.6050071.4172831.5505960.0007880.0000160.0000160.0000160.3681172.3135520.0011640.0000171.6853980.0008510.0000171.6853980.0020390.0000170.0000160.0000160.0000170.0017800.1870680.0001140.0000180.0000210.0001260.0000180.0000180.3058740.0001700.0000210.0000440.0000210.0000240.0000180.0001351.3754560.0007320.0000260.0389820.0000370.0000210.0000180.0017640.0000210.0000190.0000170.0025710.0000180.0479660.0051190.0000220.0000170.0000160.0000860.0136540.0040680.0000191.2262200.0015780.0000181.5209543.6429461.1659042.0871203.6190450.0020920.0002500.0002640.3511260.0003060.0001040.0002970.0000170.0001930.0002480.0002570.0016381.3490320.0011510.0012110.0010460.0006960.0006480.0008680.0003291.9325320.5631851.6481530.0742912.1411810.0010380.0000561.2369500.0359010.0000430.0016430.0024960.0009370.0000200.0014110.0000270.0000210.0016180.0014780.0000220.0000310.0001790.0001730.0002190.0002030.0002810.0002181.1991180.0009020.0002902.4536260.0019170.0000810.0001150.0000160.0000160.0000800.0000160.0000660.0014330.0000170.0010030.0022570.0000171.7151370.0011952.2685453.6177000.0597560.0000470.0000170.0000180.0000170.0000160.0014370.0000170.0053040.0019700.0000170.0994850.0988480.0000830.0000170.0000170.0042030.0000180.0000160.0000190.0000170.0000161.9075553.8342751.8343400.0018110.0012410.0009110.4478830.0007440.0000490.0000850.0047400.0000600.0002570.0001160.0131410.0000650.0000700.0000150.0033750.0000570.0000240.0887510.0024550.0047220.0000180.0029180.0395710.0000330.0014080.0001100.0000550.0000640.0000170.0000740.0000720.0017750.0017890.2296480.0006030.0004630.0430720.0667180.0003070.0000160.4319170.0004690.0002190.0001980.0002290.0000980.0001870.0000600.0001080.0001790.0001650.0027491.3916010.0008560.0001060.0001840.0002770.0001630.0019490.0012720.0016470.0014520.0001660.0000730.0004250.0003650.0000160.0003630.0000170.0002742.4654912.7737253.5786872.4441541.1211160.5907110.0002820.0035140.0009520.4831740.0008290.0001380.0012880.0002210.0005891.1885500.0011360.0004740.0005840.0016750.0005440.0011550.0000961.6554090.0013190.0001821.6594520.0017060.0005080.1453390.2388010.0001451.0995660.0149140.3455320.2797240.0021863.2174990.3349290.0001871.3345890.3422580.1789150.7554310.0004520.8053721.1551400.8321620.0003900.3344280.1563910.0026851.3541201.6579210.3265951.4938590.0007181.3221490.8965240.0011760.0237190.4441410.0021730.0448051.3984130.0028600.0026980.0043510.0125171.4570140.0398770.4507280.0045990.0018060.0033970.0005990.0050810.0373941.2360880.0025531.5584522.4036320.0155080.0030281.4981632.4416540.0040871.4132851.1444870.0009250.0001971.5322160.9335172.5836650.0013741.1244191.3904511.3991371.7179710.4818480.1394510.0624541.3062320.0008970.3570350.0006310.9572480.2933270.5678802.4408170.2820020.3307130.1452470.9950200.3718460.0001890.4456670.0783841.3275230.6189730.3620770.1500740.0011070.0000811.3177000.0006070.4170820.0020741.0971650.0974450.0027130.0005280.0054690.0462040.9929060.0110710.0058090.0023183.2844380.0031230.7255621.7127391.8116620.8332370.1899470.0002640.0981610.4067800.0001980.0000310.1237550.1070170.8617710.0020810.9183000.0067250.3435410.0105641.2975400.0548812.1296220.0009950.0051871.8929000.0032870.7409000.0063291.5360970.0042370.0017540.0021640.0407410.0020120.0023090.4018510.0008551.4761340.0009330.6977050.0330930.0020790.0003080.1556860.5039741.9354740.2056570.0001420.3530600.0002490.5558101.1827480.0006050.0013360.0002420.8691710.0004160.6347430.1663480.1516970.0013450.5687222.0443491.3549561.4545600.0010841.3349131.6641760.0037761.7341261.9310981.5139500.0431551.9486450.1600300.6698071.4074530.0006230.0026530.0601962.5221840.0010820.0039830.9521860.3386180.0083710.0030500.2451450.0002300.0121131.2348060.0025490.0001641.1696370.7340750.1048600.0001160.6347361.6139190.0024560.0875120.0000890.4231790.5613650.0002680.0031290.0017880.0034631.4086120.0059520.0034930.0501950.4421830.2580411.0525470.0861640.0000930.2549090.0001501.2494951.3015610.0010071.0763070.5061600.0007920.0007760.0029090.0002250.4153190.0007420.0000740.5864531.3841862.4846641.5850561.0033650.0030840.0022210.0032540.0023940.0026210.0012011.0663362.9994680.0029310.0097261.1061670.0023850.0097360.0026370.0000510.0001950.0868570.3399851.6140200.7707061.3213521.9061082.1008720.0011210.8850370.9141020.0467310.9628132.5879470.5287500.4336350.0032120.5275700.0002990.4287010.9954410.0004170.0581720.7789130.0006801.3600110.7407901.0395640.1143450.3116822.1474761.7292480.0007440.0326500.0000460.1177890.0000781.2520000.0005330.0149030.9323930.0004212.4125120.0381250.5726721.2352601.9546630.0017430.7213720.0003071.6835313.4038762.0474630.8695261.7383060.0007540.0008700.0002192.6749821.2717240.4807140.8647550.0077030.0000610.0040660.7353290.0003060.0065241.7338341.6066000.0020442.3868371.1363840.0015272.0699241.0723850.0007692.1784170.0008710.2221700.0001250.0018970.0009370.0009950.1861321.7059380.0035290.0002311.5770670.0007531.5036971.4860150.8360220.6763400.0044610.0018251.0670040.6502270.9170440.9527300.9235851.4500050.0007500.0026691.3323631.0539110.2392390.0005090.0000350.0035330.0785820.6940070.2318190.0139210.1164402.2866700.0036690.0222431.1621151.2734280.0104040.0000860.7175240.0026690.0193100.0040400.0001771.9142470.0092840.0036111.5184820.0052611.2372170.0031030.0051300.0000802.2847920.0032041.6547650.0027710.0026741.2322521.1647480.0052490.0023490.0000750.0029791.9254480.0053650.0027360.1625591.1339120.9704840.1525850.0005050.0179440.0007620.0014370.9135810.1552253.1163770.1696070.0002112.8724010.0015742.7119290.1001370.0003102.9098191.0287450.9186130.7300550.0086800.0167660.0107790.0000861.0805960.0068060.0066050.0068080.0082230.0000620.0051702.2269460.0027290.0095311.6691410.6357690.8462821.8246900.2330450.0001300.6718290.6381200.0362850.9543341.2599990.0868191.3297880.0062060.0000700.0052290.0001161.2630911.9042850.1770140.0010640.9605051.3080470.4796291.3685510.6638570.0003010.0000270.6547620.5714780.7929140.5306771.2825560.0008270.0000450.0015051.6836020.3038730.2906490.5450900.0005581.5142480.2155700.0226330.0001440.0001450.9281910.4644020.0022732.3285381.7543190.5442852.3416510.9002850.0042192.6753370.0021700.7735040.0028080.0000300.0040760.0020710.0004890.5781410.0026471.2278760.0019720.0022830.0000871.4533510.6415100.0011590.0000640.0007290.1840511.8825510.0117030.0030181.1448011.6394260.2021991.5554320.3017562.2513390.0354930.0020910.0021321.5036682.6955210.0031822.8746340.0028420.0035760.0366630.0026662.8980650.7388181.1663690.8245620.0039510.0043370.0028130.0108821.0130970.0219261.1306170.0446080.8759540.0023010.0003591.1846590.0032910.0034040.0034640.0046571.9942201.3154841.3024910.3489360.0025862.9451530.0057061.3458670.2597320.0002371.5865570.5222640.0094400.9419190.0062340.9373801.1249532.2059700.0019020.0199540.8788710.5922962.5215160.3340602.5627982.2143470.0025452.0985370.0008690.4026521.4488310.0294930.0001351.7917891.3701840.0031760.0034210.0000700.4757890.0032040.0005670.0066781.0970060.6232971.5100181.0044130.0004870.0258071.4771680.5413321.3313672.1875640.1980230.0105410.9278150.3415610.0072770.9548211.1212600.0105070.0034592.5505770.0009320.0030320.0032461.3721310.6754510.4408450.5082920.4091410.0002320.0026870.6652010.0023830.2264520.0022650.0021670.4021900.0753301.3760481.8427620.0017310.0016730.0000241.1618740.1091940.0019162.1947070.0028191.1361760.9238751.2900840.8507603.1880870.0011280.8255630.0253690.0042500.0030490.7481460.0215840.5792920.1214590.0038491.1239171.2197232.3867451.9443902.1328922.8832222.5899200.0019231.4433572.5181940.0030510.4819340.1429880.0060890.0000420.0172340.0283800.0387340.0077851.1558200.0017900.0000551.2129340.0006821.6946501.5557121.5673490.0024030.0000751.1413281.6571781.2075950.0562131.1731270.0020130.0035590.0026170.0000390.0000530.8264550.1050082.7518280.9445712.738651

*******************************************
EVALUATING PIPELINE 
Pipeline directory: /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_35bf9aee_2020-02-14_23-50-27vk3n1m5c/
With following parameter combination: {'batch_size_seq_length': 1, 'lr': 1e-05, 'lr_type': 'linear'}
EVALUATION OF CHECKPOINT /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_35bf9aee_2020-02-14_23-50-27vk3n1m5c/outputs/checkpoint-3
-------------------------------------------------------------
|           |   agree   | disagree  |  discuss  | unrelated |
-------------------------------------------------------------
|   agree   |    677    |    99     |    117    |    24     |
-------------------------------------------------------------
| disagree  |    101    |    249    |    82     |    21     |
-------------------------------------------------------------
|  discuss  |    235    |    88     |   1520    |    68     |
-------------------------------------------------------------
| unrelated |    24     |    32     |    60     |   8501    |
-------------------------------------------------------------
Score: 8663.75 out of 9226.0	(93.90580966832863%)
Accuracy: 0.9200706001008573
F1 overall: 0.7610531035628066
F1 per class: [0.6929375639713409, 0.5407166123778502, 0.8238482384823849, 0.9867099994196507]
*******************************************


*******************************************
EVALUATING PIPELINE 
{'batch_size_seq_length': 2, 'lr': 1e-05, 'lr_type': 'constant'}
INFO:__main__:Creating features from dataset file at /home/ubuntu/fnd_implementation/data/processed
  0%|                                                 | 0/11898 [00:00<?, ?it/s]  0%|                                       | 1/11898 [00:02<8:21:31,  2.53s/it]  4%|█▌                                   | 501/11898 [00:03<5:36:23,  1.77s/it] 46%|████████████████▋                   | 5501/11898 [00:03<2:12:10,  1.24s/it] 52%|██████████████████▌                 | 6153/11898 [00:04<1:23:06,  1.15it/s]100%|███████████████████████████████████| 11898/11898 [00:04<00:00, 2873.07it/s]
  ******************************************* 
              Running Evaluation                
  *******************************************
 
  Length dataset evaluation: 11898
  Length dataloader evaluation: 1488
  Number of epochs: 3
  Batch size: 8
  ******************************************* 
 
['/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_2e2bd1ee_2020-02-14_21-09-32h520viza/outputs/checkpoint-3']
INFO:__main__:Evaluate the following checkpoints: ['/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_2e2bd1ee_2020-02-14_21-09-32h520viza/outputs/checkpoint-3']
INFO:transformers.configuration_utils:loading configuration file /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_2e2bd1ee_2020-02-14_21-09-32h520viza/outputs/checkpoint-3/config.json
INFO:transformers.configuration_utils:Model config {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 28996
}

INFO:transformers.modeling_utils:loading weights file /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_2e2bd1ee_2020-02-14_21-09-32h520viza/outputs/checkpoint-3/pytorch_model.bin
HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=1488.0, style=ProgressStyle(description_width='initial')), HTML(value='')))
0.0005560.0011580.4524160.1513450.0381060.0077810.0015600.0002540.0000810.7535440.0753860.0068850.0006820.1488130.0106610.0010171.0642890.0626501.0639920.0560670.0029070.0002250.0000390.0000300.0000880.0000330.0000300.0000301.0590031.4765230.0493641.9606300.0613091.7039681.0942410.0313571.0063810.0272411.5761900.0404502.0563141.1819382.2183681.0785360.0246231.1804420.0273870.0006220.0076100.0001860.0000330.0000300.0001590.0000980.0000500.7091891.3262871.6924710.8688600.0147580.0002790.9475010.9390770.0150140.0002670.0000360.0000330.0000311.0462051.7541462.5510901.1879981.4407450.0197720.0003070.0000380.0000550.0001490.0225950.9718970.0121830.0001800.0000320.0000420.0000300.0000310.9627470.0111030.0001890.0000360.0000300.0000320.0000300.0000300.0004670.0007730.6383580.0068571.2965542.7427253.0670172.7946160.0275060.0009380.0007560.0001730.0000770.0000690.0011030.1221820.5118750.2993230.0027020.0000530.0000480.0011170.0000370.0000290.0000300.0000280.0009620.0000380.0000320.0000350.0000310.0000310.0000410.0000310.0000320.9497550.0076560.0004550.0001290.9813740.0091630.0002370.0001850.0411230.0003290.0000330.0015120.7724390.0081730.0000860.8373550.6737640.0047050.0001130.0000920.0000840.0002850.0000850.0000290.0002710.0001390.0001370.0000870.0002200.0000350.0003490.0006630.0176660.1909740.0013030.0002540.0002710.0000300.0000280.0000290.0000290.0000290.0000280.0000290.0000280.0000350.0000480.0000290.0000290.0010130.0000350.0000340.0000320.0000300.0000330.0000290.0000850.0000840.0000320.0008850.0000340.0000290.0000300.0000290.0000290.0000290.0020190.0002030.0003540.0009810.0021620.0000430.0000330.0008930.0002431.7146550.9557680.0049900.0002020.6221050.2031300.0010980.0000350.0001180.0000300.0000320.0000370.0001430.0000960.0000310.0000390.0000310.0000310.0313770.1076920.9650680.0046530.0011450.4779690.5306610.0024191.1074500.0049770.0000570.0015160.0000960.0000900.0000300.1085890.0010540.0001000.0000320.0005840.0002500.6694410.0027790.0000480.0000441.5527510.9168170.0050790.0003630.0000320.0000350.0003210.0000330.0003070.0000330.0000320.0000350.0009870.0000390.0525150.0007050.1840300.0013570.0050120.0011450.0001500.0000920.0000300.0001050.0001560.0000310.0000300.0001500.0000310.0001150.0000960.9479540.2159811.6852700.5706650.0020580.0001221.7644870.0066360.0001650.3293490.0023490.0011070.0000360.0053130.0001080.0000320.0001530.0000920.0004650.0008820.0000870.0004810.0000330.0003480.0003660.0000340.0001460.0000800.4025400.0032370.0001640.0000300.0418780.0002200.0000780.0006370.0011380.0000851.0039260.7817390.9784170.9339500.0030140.9913950.0031120.7979790.0024970.0001170.1930281.5857380.7006540.0074312.1957780.9969831.9078291.0061770.0665941.2151150.0037900.0052160.8054320.9331500.8011220.0040691.5302330.0208850.0037940.0001670.0002320.0001610.0003500.0005450.0007530.0001380.0000310.0003330.0000540.0009480.0000330.0003250.0000330.0000330.0000970.5135450.0014510.0003070.0001140.0000930.5481280.9881130.0027180.9548401.1479080.6092140.5822190.0026900.0000390.0008790.0000340.5244470.0019900.0008080.0005880.0000320.0014490.0000340.4584040.0822530.0029140.0000450.0070050.0045200.0002750.0001060.0002890.0021850.0000380.3065180.0008770.0004265.1131140.0133250.0002610.3533740.1398012.0420111.0808270.9181521.7766240.9530003.6674050.0119781.2058810.0029640.0000390.0010980.1931940.0006150.0034690.1430580.0156850.0010970.2312510.0013440.0001290.0001730.0001101.0106120.5639870.0106040.0009700.0015750.0004751.1090260.4842070.0012930.1147290.6876961.5597840.0036031.0795210.0025000.0022120.0136220.0006060.0002970.0021720.7569030.4913400.0012430.0002780.7230290.0048730.0000430.6605090.0015460.0000340.0000320.8893171.7915350.0039951.7387790.0046282.9113150.9287172.4512120.0063810.0013450.0001870.0003080.0003480.0005520.0005050.0002180.0004221.8050433.3043560.0078540.0000570.0000330.0001890.0030150.0000530.1676820.0986220.0028690.0001780.0007700.5023430.0010630.7578330.0015910.0000400.0000410.0012780.0001350.0001360.0021771.2245430.0025050.0001530.0000660.0018010.0008520.0008380.0140990.0001030.7556110.0355180.0003440.0034800.0033820.0325320.3615100.1512000.1362200.0007060.0003741.3264680.0026620.0000380.5137010.0020380.7509910.8410430.0027290.0064840.0000452.8374960.9133400.7740270.0049750.4817080.0010990.0049340.9338690.1351840.0067430.6691990.0154700.0013560.0022910.0025420.0000900.8436940.0033040.0015131.1122700.0049090.0000420.0000990.0000330.0000300.0000311.0058290.0018500.0000670.0000300.0000350.0006420.0006810.0001710.0002730.0001540.0001010.0001840.0004810.9527430.0019240.0003260.7934340.0039270.0003370.6458231.4634631.8244602.8912310.0051893.1265620.0246490.5086352.0788590.0101360.0122460.0526220.0011760.0000330.4464402.4337210.7097200.3048220.0006450.0002770.0007560.0001440.0002020.0002560.0001010.0002010.0000430.0261120.0005070.0000320.0456820.1948390.6038360.0013341.7863460.1650250.0003030.2038680.0010210.0000330.0001290.0000470.0000480.0000380.0000700.0000330.0005570.5222830.0016890.2258560.0029540.5999731.3601481.0985920.0020800.0006350.9985591.5844762.7728960.0047230.0002250.0040300.0002640.0002470.4137850.4205640.8138670.5496010.6272880.0273230.0050440.0002960.9945120.0017120.0002890.0000320.0000420.0000350.0000380.0000460.9074491.0518620.0016430.0001170.0002280.0000310.0008390.0000940.0000300.0000890.0012600.0014850.0075180.0011910.0004841.0693830.0022220.0000980.0000320.0042300.0000950.0002040.0001400.0004470.0004090.0025050.0005800.0006430.0005490.9331080.1906300.0020390.0021162.5667973.6537204.9864830.0084230.0020460.0024280.0004400.0006210.0006670.0001780.2439970.6097280.2600870.0465200.0003390.0399260.0269080.0033740.0713740.8552350.0119150.1125450.1889730.0007250.0005700.0005190.6088060.0009410.0011900.8869290.0018560.0003650.0000520.0004560.0004570.0004810.9434690.0467610.0685580.0001230.0000280.2321020.3882430.0126520.0387760.3871110.0005620.7561440.0076991.8379110.2603810.9447380.4869301.6031650.8906760.6148600.4655361.0634610.8874210.3177300.1893390.0002920.0000320.0000341.0674540.0015170.0000660.0000310.0000960.0002412.2783230.0031050.0002391.0006240.0013510.0171020.3315320.0156590.0334780.0595812.0738691.0348342.0445070.0027030.0001282.0413781.0189321.0202910.2257600.6234630.0009421.4880210.0045850.8819771.6775200.9636850.0020530.0056650.0001970.0004302.2419770.7491390.1528790.8170942.1435062.6176551.8528060.8226811.6218090.0020790.0145380.0000510.0000330.0000940.0000330.0001000.0002840.0000340.0000400.0012310.0000390.0003500.0023080.0001050.0002150.0000340.0000350.0000320.0003720.0000330.0000320.0002610.0005890.0006760.0016780.0047180.0039740.2170313.4952091.1368881.4205650.1598020.0008110.6199310.7078592.4094581.2685370.0950970.1572240.0087690.0000560.0031880.0000700.0050500.0065120.0001440.0006780.0442190.1321500.0925290.0825810.0083070.0000910.0000310.0007040.0001830.0000310.0000320.0001310.0000320.0000310.0000620.0000320.0001413.4347063.4928422.8447340.4965310.1023810.0015420.0018581.0448680.0037440.1226190.2926360.0028590.0034160.5827920.4950980.0035570.0029330.0202060.0027180.4892851.9628873.6559331.8932410.0034200.0012490.0008350.0003560.0005020.0006010.0005000.0004990.0005131.9598641.9944661.5143500.0020630.0000330.0002320.0002350.0002970.0001680.0005250.0003760.0006860.0006410.0004320.0000301.4225120.0040280.6500200.9680300.0011010.0050320.0017161.8783740.2138751.1465212.3107022.2939070.0025301.1904200.0017640.0000370.0025730.0012420.5019960.5231160.0048320.0048380.0821290.5730320.0355300.7808370.0021240.7120210.0966380.3453013.8041874.0576280.0043630.0000380.8855860.0009760.0000983.1840050.0034100.0000382.8132930.1324880.0050780.4836330.0006400.0040720.0001180.0001150.0006160.0001170.0010350.0000850.8786403.2249192.8734012.0377560.1152830.0378020.0000700.0001600.0002200.0002100.0141640.0004340.0007330.0000320.3505840.0008610.0008390.0005010.0000340.0000360.0000330.0000330.5379230.0005820.0852840.0001840.0000350.0000890.7769070.6152530.5005140.9265750.7989680.7953770.4566490.0017240.0022030.0028660.0000980.0002120.0001700.0002150.0001570.0019190.0003550.0001561.1645910.5721560.0006010.8446931.4018760.8286500.0008541.5920860.0016060.0000331.6223070.0016500.0018150.0000310.0204050.0000520.0000430.0001540.0277570.0146630.0000450.0062600.0000370.0059670.0014410.1630860.0001880.6080670.0449910.0019480.2359850.4809851.5379400.0170830.2353680.0675630.0005440.2807120.0061650.0048560.0049130.0036740.0016340.2946390.0196100.0194710.0024060.0444520.3620440.0018760.0019420.0022390.0011300.0003010.0006330.0014090.0006070.0006110.0078720.0002930.0000340.0000890.8947130.0016360.0014560.4969277.1584831.0036370.0009780.0000330.0023870.0094280.0388980.0346700.0001110.0524870.0001310.0000312.4519740.0083230.0021041.7175670.0017810.7688770.5541270.5510440.0005870.7172991.3073530.5983690.5070760.7958960.4473910.0006610.0000810.0012020.6867250.0012950.0004830.0002201.5572170.0390610.0548390.9439680.0832670.8619580.0320731.4949440.0018580.0021440.7023900.0614990.0430420.0001370.0008114.6501572.6401980.1951670.0065450.0109970.8942430.5024380.0035030.0058690.0024380.0015630.7563620.0017950.0029110.0182130.4563690.9330920.7486951.1548360.3025630.3810030.0198440.3513000.7666450.0098810.8241810.6567540.6706660.3747290.6272590.5875220.5005620.6667880.0129320.0327701.4666150.3163880.0841430.3307290.0732401.3257080.0216901.3100110.0024810.3423061.3251611.3483770.1228230.7249851.5623761.5674220.2689180.4742900.4297650.7016530.1819320.3555480.1180960.2209680.7092890.4840080.0031190.4545040.4791870.6660050.0498730.2036300.2831800.0278401.0036490.7160401.2490880.1053860.6051450.0005720.2125900.3205600.6282020.2183931.0153181.0523921.2707560.3802930.6098100.0267570.0088490.0174670.6547200.4893540.5040990.0021940.1457010.8305620.0038330.5040010.4043330.0031141.2032060.3150790.1272750.6818000.8950530.5398360.7006620.9422730.4922550.9698120.8456030.0079531.0426360.0069790.7492930.0161370.2177390.5965470.3457660.8318880.1269050.7989130.0061340.2402490.1154790.0119910.5848150.0114600.2306880.7248830.0667330.0718121.4949200.2365580.2836900.0031170.7941370.0018751.4319281.6734471.1296400.8473890.0535380.2895070.8600870.2619810.1339130.0248270.0488080.1856641.0904801.6434720.0263940.6776630.9651320.7365110.7899230.0641170.3278350.4514540.2368580.7478710.3057891.1374790.0140760.2593970.4150850.0472160.3961151.0029440.5352470.6451940.6559911.7202201.5532290.4817650.0038231.7235840.8334650.0769330.0944310.0121561.1134490.8397750.4533090.3479270.5830920.0815530.0026090.0029771.1783810.0082630.6994081.1473690.8188880.0204790.9890750.9354130.9565160.0055100.7717740.1751810.0044120.8622590.0136961.3725620.2404890.8971510.6299170.5646930.0252320.8819400.4016680.6353730.5265000.0072830.9920850.0080970.5437940.5020800.0036331.1255000.0095580.3177360.2918970.0115100.0012370.8254120.9003610.8338181.4854180.1417722.2357290.7497110.0316990.0128060.5211500.0135390.0073030.9096060.0177200.5363170.9681410.1188811.4995311.4687810.6634910.4641480.0062340.5788630.7297070.0208760.6159080.2957090.0002820.3414840.5603580.2245820.0047420.6887000.4934420.8749380.5138940.0010220.4951411.1382881.3011771.3178070.8943150.5208260.0036840.0190230.2847900.2753490.0118680.4186710.0658870.0014111.6271260.0297601.0837910.0385331.2844050.0619980.5351111.1623841.6700260.0131711.2683220.4512860.3016890.0135810.3705670.3410410.7120550.0928150.0173430.0702431.0315740.9571870.0320101.4392960.5239450.7923780.0802770.0412781.2405982.0530790.2708021.7636041.8498250.8262230.7996680.8552670.0115271.3121970.1297340.2317650.0079310.3539821.1889390.4134570.2131740.1288470.2171260.1456650.2683710.8545140.0692521.7521570.0153480.7202750.3062500.4613700.3306050.0477680.1251070.1941111.2384300.0078210.6981370.1106770.8228711.0676550.6755300.5692270.4406460.0203010.4061980.3797940.6086440.9708102.1404092.3747320.6353090.7742460.5520230.0321690.0120700.0711780.6788060.2578280.2809441.0362720.0054772.0613990.3744030.4707610.0107170.0000840.5036821.3973201.497334

*******************************************
EVALUATING PIPELINE 
Pipeline directory: /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_2e2bd1ee_2020-02-14_21-09-32h520viza/
With following parameter combination: {'batch_size_seq_length': 2, 'lr': 1e-05, 'lr_type': 'constant'}
EVALUATION OF CHECKPOINT /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_2e2bd1ee_2020-02-14_21-09-32h520viza/outputs/checkpoint-3
-------------------------------------------------------------
|           |   agree   | disagree  |  discuss  | unrelated |
-------------------------------------------------------------
|   agree   |    731    |    117    |    155    |    31     |
-------------------------------------------------------------
| disagree  |    91     |    265    |    88     |    25     |
-------------------------------------------------------------
|  discuss  |    177    |    48     |   1475    |    124    |
-------------------------------------------------------------
| unrelated |    38     |    38     |    61     |   8434    |
-------------------------------------------------------------
Score: 8600.0 out of 9226.0	(93.21482766095816%)
Accuracy: 0.9165405950579929
F1 overall: 0.767972497089149
F1 per class: [0.705939159826171, 0.5656350053361793, 0.8187621426588954, 0.9815536805353506]
*******************************************


*******************************************
EVALUATING PIPELINE 
{'batch_size_seq_length': 2, 'lr': 1e-05, 'lr_type': 'linear'}
INFO:__main__:Creating features from dataset file at /home/ubuntu/fnd_implementation/data/processed
  0%|                                                 | 0/11898 [00:00<?, ?it/s]  0%|                                       | 1/11898 [00:02<8:28:20,  2.56s/it]  4%|█▌                                   | 501/11898 [00:03<5:40:55,  1.79s/it] 17%|██████                              | 2001/11898 [00:03<3:27:15,  1.26s/it] 46%|████████████████▋                   | 5501/11898 [00:03<1:33:46,  1.14it/s] 50%|██████████████████▏                 | 6001/11898 [00:04<1:00:32,  1.62it/s]100%|███████████████████████████████████| 11898/11898 [00:04<00:00, 2776.78it/s]
  ******************************************* 
              Running Evaluation                
  *******************************************
 
  Length dataset evaluation: 11898
  Length dataloader evaluation: 1488
  Number of epochs: 3
  Batch size: 8
  ******************************************* 
 
['/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_384c138c_2020-02-15_00-02-45gk0skut_/outputs/checkpoint-3']
INFO:__main__:Evaluate the following checkpoints: ['/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_384c138c_2020-02-15_00-02-45gk0skut_/outputs/checkpoint-3']
INFO:transformers.configuration_utils:loading configuration file /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_384c138c_2020-02-15_00-02-45gk0skut_/outputs/checkpoint-3/config.json
INFO:transformers.configuration_utils:Model config {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 28996
}

INFO:transformers.modeling_utils:loading weights file /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_384c138c_2020-02-15_00-02-45gk0skut_/outputs/checkpoint-3/pytorch_model.bin
HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=1488.0, style=ProgressStyle(description_width='initial')), HTML(value='')))
0.7422380.7428840.7190690.2398160.0599980.0121480.0026540.0004200.0000930.6681280.0668530.0061170.0006281.6298570.1164600.0080520.9432650.0555280.3464990.0182920.0010060.0001910.0000510.0000440.0001130.0000470.0000440.0000430.8362591.5665610.0523101.2002360.0375490.9953031.1234920.0321440.0279170.0007982.1075340.0541341.9632321.1527562.1116540.5633910.0129061.1120910.4792280.0102410.0061810.0001670.0000440.0000460.0017700.0006100.0000550.7624791.2903212.2468010.8506020.0144570.0002810.0000980.0000450.0001350.0000420.0000410.0000410.0000410.0096820.3809261.0414360.2175120.5498110.0075740.0001570.0000440.0000850.0001530.0193510.9815850.0124010.0001980.0000450.0005230.0000500.0000430.7781810.0089920.6105520.0069030.0001300.0000470.0000420.0000420.0000860.0009770.6462460.6142010.0152090.4406530.0047920.0164040.0002610.0015150.0018160.0001500.0000730.0000610.0014630.0079812.1129080.0464860.0004550.0000450.0000490.0019410.0000570.0000410.0000420.0000410.0118210.0001390.0000420.0000430.0000410.0000410.0000420.0000410.0000410.8344340.0074320.0011070.0001680.9824120.0074350.0000990.0000430.0008100.0000480.0000420.0020930.0184980.0007800.0000480.0239570.0778260.0006240.0000990.0002650.0000970.0009920.0007740.0000460.0002630.0001460.0001430.0000910.0015090.0000510.0006620.5683370.2111840.0849140.0008950.0003490.7170020.0043610.0000670.0000410.0000420.0000410.0000410.0000410.0000410.0000410.0000440.0000470.0000410.0001320.0000420.0000410.0000420.0000410.0000420.0000410.0000990.0001030.0000560.0013860.0000480.0000420.0000420.0000410.0000410.0000400.0064010.0004360.0059030.0018240.0012230.0000460.0000410.2407870.0014061.0773680.8496010.0041910.0002480.3754490.0032910.0002040.0000450.0001150.0000430.0000400.0000440.0006010.0001350.0000410.0000400.0000410.0000400.0024641.3730510.1194750.0007690.0001860.0023620.6257060.0028761.0727960.0048640.0000650.0015750.0000970.0001050.0000410.6478710.0035800.0001020.0000420.0001920.0004970.5789450.0024130.0000500.0000411.0769000.0045830.0002730.0002900.0000420.0002180.0321530.0001670.0007540.0000430.0000400.0000430.0013740.0000470.0087220.0010990.2811660.0012470.0032610.0011800.0000480.0001000.0000410.0000890.0001540.0000420.0000400.0001610.0000400.0000980.0003880.0017800.0050181.0184290.0054710.0000640.0002040.8525810.0032160.0001060.0064260.0018100.4569080.0016190.0015500.0001010.0000410.0001500.0001150.0007040.0022100.0001080.0007770.0000440.0006950.0007180.0000440.0001460.0000990.8842430.8702490.0029730.0000510.8803840.0029210.0001060.0004750.0001020.0001041.0463480.0033661.0276490.9053390.0029401.0392860.0032690.0005980.0000410.0001000.0046920.0337490.0010410.4759862.2147140.7886112.1542170.7856370.0985120.6260640.0020240.0024690.1686850.0028100.7079000.0063120.4230390.0073570.0027000.0001620.0002430.0001520.0007270.0008230.0007470.0012540.0000440.0006670.0000460.0006600.0000430.0006380.0000430.0000410.0001170.0284720.0001200.0006640.0001390.0000970.8053622.2848900.0062501.6328811.3169290.7829440.5301140.2047410.0005880.0010200.0000430.1879090.0013960.0233590.0008680.0000460.0008790.0000450.0030290.0141300.0007430.0000450.0031030.0044340.0004350.0001610.0003340.0013280.0000440.1515210.0005170.0003135.4138560.0141740.0002780.0043400.0013871.5082820.7727011.3346010.0036241.2487931.3693110.3878121.8354180.0045070.0000540.0032080.1983670.0005490.0050680.1730710.0962480.0403470.6762030.1176530.0003910.0005730.0009170.9509350.5167120.6723430.0049590.0036660.0005221.1152750.4449060.0012280.1657740.0030981.1034900.0025701.3859390.0032110.1296380.2408660.0011850.0035550.0016590.3680620.3355440.0009220.0003300.5616480.0017250.0000530.3780390.0009770.0000910.0000400.7465521.6033810.0036311.3687770.8597851.1766160.7515961.7702890.0058420.0023710.0002230.2218730.0015050.0025610.0005620.0685950.0044521.6713803.1524620.5862590.0012730.0000430.0002350.7164340.0015392.0678881.4858580.0037640.0002340.0008320.7367740.0015530.7979800.0016730.0000440.0000410.0014620.0001180.0001180.0081100.7665180.0017090.0000570.0000410.0214920.0013800.0014540.0167700.0000800.2074230.1704540.0006680.0019320.0036490.0080940.2897040.0653790.1234800.0006540.0003550.9865250.0020740.0000441.2696970.0042810.7289380.9852170.0026380.0031630.0000492.3194210.0117650.8428200.0081330.0725340.0003380.0046530.1633090.1182350.0036630.7510080.0028170.0010520.0023190.4580200.0020480.8749150.0033350.0063971.1791740.0044290.0000490.0001110.0000400.0000400.0000410.9692790.0017930.0000440.0000400.0000420.0013530.0029330.0002960.0004070.0002600.0001190.0001420.0002360.8629530.0017390.0003030.8317230.0021490.0000460.6948342.1351432.1797032.5918470.0049542.3920410.4485180.1793062.2280060.0048700.0010440.6870020.0014480.0000430.0370801.7455330.6838750.0019690.0001240.0002930.0007170.0003590.0008360.0003530.0002690.0003820.0000800.0015460.3503760.0006240.0013410.5592220.6418220.0019340.6875270.8475960.0014360.0000440.0008520.0000410.0000550.0000410.0000400.0000400.0000420.0000410.0009970.0000430.0012340.0008620.0414612.4482132.3912973.9214750.0069460.0013070.1166011.7615172.5055620.0043110.0002880.0002080.0003040.0002490.7932000.3210660.0099570.6219160.4403220.5230580.0064740.0002561.0100030.0017390.0002650.0000410.0000460.0000420.0000430.0000440.9071661.0449950.0016410.0000930.0001100.0000410.0001910.0001110.0000410.0001150.0012110.0022510.0144410.0036660.0011350.9358010.0022780.0002550.0000400.3321680.0006690.0005110.0002640.0005650.0238180.0037400.0009240.0009950.0007920.9523000.0019110.0002230.0533653.0501884.7726235.2142260.0096820.0017350.1025510.0011170.0002810.0004220.0001800.0002400.0254210.3417510.0653500.0004470.0086690.5865380.3811752.7431832.0529261.0759951.1670190.2745640.0013000.0009410.3750720.0103320.0001140.0007431.4375930.0028850.0000760.0000540.0007950.0007830.0009900.0007410.0323390.5806980.0008460.0000470.6176730.5710030.0042620.5960710.4946510.0007420.0582790.8460422.1132890.9805650.6026650.0017830.0008960.0009910.0093640.8259951.1989830.3830530.5406620.6454260.0009130.0000460.0000501.0524660.0015010.0000450.0000400.0000880.0004232.1181210.0028490.0001401.0031770.0013640.0093030.7067240.0149070.0091630.5025131.7309530.9454181.8509180.0024600.0000461.8115430.9521310.9207910.0297530.0599610.0002311.0616950.8839130.9690341.1247850.4975250.0034520.0033760.0006620.0002132.8555770.9502740.3509720.7338252.2908552.6258741.5803720.8486461.7309940.0022270.0008190.0000420.0000400.0001380.0000410.0001350.0049170.0000460.0000420.5249360.0006980.0005390.0054460.0001240.0031120.0000450.0000400.0000410.1298820.0002040.0000410.0005740.0007720.5291370.0024660.0027730.0027100.7875454.0389360.8097790.1473580.1060220.0013070.2760950.0505131.3697580.0045580.0042420.0006880.0001970.0000480.0041320.0000540.0005960.0003380.0001040.0005160.0148310.3252900.3819200.2200490.0015760.0001130.0000550.0004980.0005450.0000420.0001590.0001730.0000440.0000430.0000550.0000420.0002843.0080573.1073633.1199030.0076880.3958600.7037010.0028121.1093710.0026450.1908590.9641800.0046210.5668580.4687030.0764310.0047010.5542100.3806210.0020210.7112251.9540433.7229701.8227230.0051270.0027340.0019180.0000460.0006720.0012780.0007030.0006690.0011611.8568141.7212361.2915270.0017800.0000430.0002340.0002250.0002750.0001410.0010730.0009290.0021110.0010390.0011160.0000421.1296510.0051230.3790510.5969670.0006980.0017400.0118131.6654030.9918970.9154461.8030061.4518590.0016240.9534890.0017160.0000440.0038210.0019370.2514581.7686710.0067990.0082280.4217490.7180680.0022630.7733260.0046160.0333520.1107640.0066700.6768661.8488510.0020140.0000420.6311980.0007130.0001053.1678440.0033990.0000433.4565160.0588250.0013700.9356670.0011320.0003170.0026610.0001120.0001490.0000440.0000540.0000520.9336573.4972933.1500281.3549760.5297110.0146450.0000590.0001900.0001450.0001770.1995090.0010550.0019800.0000420.6435850.0015440.0023880.0008850.0000420.0000420.0000400.0000400.7820310.0008410.0014200.0001440.0000420.0001840.7826970.4294580.0021260.8587470.6115260.7619950.7083090.0014190.0014940.0008400.0001050.0002420.0001870.0002400.0001670.0002420.0003280.0001721.5466130.4203700.0004580.6365701.1933900.7213320.0007561.3697110.0013950.0000451.3462510.0013700.0004570.0000410.0059080.0000460.0004510.0000560.3419130.0017220.0000430.0011980.0000420.0033380.0021750.0016920.0000420.0084610.0130200.7319430.7736953.1036993.6989610.5643550.9452630.3684350.6309632.0328360.6395250.6099640.0034280.0016070.0020060.8785252.1026801.5537870.0033020.0819950.0012080.0007710.0009560.0008480.0011440.0002540.0005600.0009080.7837560.6910201.5525120.0017330.0000440.0001220.9669320.0025390.0043460.0854094.6514230.7628960.0007570.0000410.0007940.0019300.6229090.6226190.0006180.0039550.0000440.0000412.4210860.0715360.0048181.3148530.0014690.0354770.0979870.7131930.0007480.5678640.9293590.4685000.1265600.4830020.0012130.0001700.0000960.0024720.0056090.0011121.1602370.5833452.2952860.0026070.0004770.0003110.0003310.0004620.0008430.0033980.0004590.0047770.0080520.0078990.0367970.0009610.0005203.1599203.2818210.0432190.0013310.0049410.0233390.0022550.0777520.0019780.0040650.0027440.0022720.0013740.0081770.0198010.4966210.4358990.6316291.3512010.6023000.5450080.0176040.3391140.2633630.0113310.6742641.0936481.3009630.5960090.2622610.3397870.0799370.8012150.0264790.7719930.2657640.0278020.0023710.1295150.0332701.3255580.0137241.5908370.0098760.5654781.4784501.7520460.0878690.7842891.3425811.4313570.2311960.2596960.5042521.1790590.5729460.6094690.1615130.4956450.8677110.5924870.0243510.4648220.1619390.7341620.0126330.1391731.0523730.0967392.1228090.1917941.3380690.1200030.3157630.0004260.2795310.5232700.4903430.3879050.1088340.8500080.9964650.8253400.6397560.0044830.0061080.0057350.4326730.6788110.1235430.0012080.3366170.6268700.2384620.3811230.5483580.0040980.5878120.3365450.0398490.6758910.8073360.7321790.6103071.2948510.9759500.9251180.8943180.0076701.2806240.0059400.5000980.0099150.0790100.3234910.0170760.5616160.2357920.8531660.4381680.2518450.2259980.0029790.8277140.0123840.4559800.3390270.0469380.0618611.0948330.4963410.2253530.0023541.1021670.0017460.6570371.3134171.2524030.0366340.0261270.4200831.2001650.5103570.0151110.0032940.2119550.3134741.0096402.0329800.3759050.5956341.1998450.5130230.1986460.0785200.2201940.8660690.5246370.8624500.3148951.6299100.0253600.3561580.3666560.1907320.3974291.2252440.3686900.9770110.0095582.5577901.1001460.9425520.0018671.8582070.4003910.0435970.2177100.0041630.4325360.8297820.3063130.6618971.1838870.2789180.0789500.0021301.0792890.0097770.5944360.7954010.8602900.0120970.6384400.4662580.8861000.0415300.8326420.0691040.0069580.7408460.0361041.2644550.3887910.6802230.6414520.4592100.0128230.7213480.8075870.7196300.5841820.0080101.0700690.6302890.5035640.5259560.0088110.8391420.0080330.2675590.2638570.0930850.0029780.2527191.0364290.3865990.8734280.1519551.6195290.5853220.0137750.0056350.4462680.0103700.0040531.0655480.0133350.5632990.6874430.0912430.6507860.7300920.7169140.4708320.0102560.5698530.9942420.1034100.5209200.3215620.0003071.1932220.5091510.5982380.0036931.6634551.2615520.6612940.3896310.0007870.5684431.2144560.4991181.6174021.3595890.5172020.0047440.0117000.4012870.4036880.0094640.5428270.1449120.0010661.6084590.0061181.2613860.4453750.7019890.1938720.6728321.3255981.4361740.0086271.4945510.2250050.2553950.0181290.1877090.3230601.4690660.0031360.0234040.0068131.3018251.2183840.0627991.5828750.2477490.7413180.1313600.2212741.0407671.1808710.2248881.8410362.0697290.8202490.9608181.1631720.0120981.3589880.0853530.1849320.0228170.2983461.1355240.4514160.6993790.3901550.5879720.1763280.2353091.0606540.0461271.0120220.0165590.7586520.3422970.0640080.6206490.0127340.0060240.3304811.4800220.0077250.7803740.2083091.1508590.5674600.7584750.9141880.4980100.0053380.4963560.1019520.3591501.4013622.1209712.1030080.6130471.2347010.5242050.0051560.0775440.0188610.4327910.4387570.3943991.2410260.0041921.0852340.1427430.3182830.0117610.0001130.4323551.2040511.475227

*******************************************
EVALUATING PIPELINE 
Pipeline directory: /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_384c138c_2020-02-15_00-02-45gk0skut_/
With following parameter combination: {'batch_size_seq_length': 2, 'lr': 1e-05, 'lr_type': 'linear'}
EVALUATION OF CHECKPOINT /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_384c138c_2020-02-15_00-02-45gk0skut_/outputs/checkpoint-3
-------------------------------------------------------------
|           |   agree   | disagree  |  discuss  | unrelated |
-------------------------------------------------------------
|   agree   |    731    |    107    |    180    |    26     |
-------------------------------------------------------------
| disagree  |    98     |    251    |    78     |    21     |
-------------------------------------------------------------
|  discuss  |    179    |    83     |   1463    |    76     |
-------------------------------------------------------------
| unrelated |    29     |    27     |    58     |   8491    |
-------------------------------------------------------------
Score: 8629.0 out of 9226.0	(93.52915673097768%)
Accuracy: 0.9191460749705833
F1 overall: 0.7635340893073407
F1 per class: [0.7025468524747718, 0.5480349344978166, 0.8173184357541899, 0.9862361345025844]
*******************************************


*******************************************
EVALUATING PIPELINE 
{'batch_size_seq_length': 3, 'lr': 1e-05, 'lr_type': 'cosine'}
INFO:__main__:Creating features from dataset file at /home/ubuntu/fnd_implementation/data/processed
  0%|                                                 | 0/11898 [00:00<?, ?it/s]  0%|                                       | 1/11898 [00:02<8:09:34,  2.47s/it]  4%|█▌                                   | 501/11898 [00:03<5:28:23,  1.73s/it] 46%|████████████████▋                   | 5501/11898 [00:03<2:09:01,  1.21s/it] 51%|██████████████████▌                 | 6117/11898 [00:03<1:21:38,  1.18it/s]100%|███████████████████████████████████| 11898/11898 [00:03<00:00, 2977.14it/s]
  ******************************************* 
              Running Evaluation                
  *******************************************
 
  Length dataset evaluation: 11898
  Length dataloader evaluation: 744
  Number of epochs: 3
  Batch size: 16
  ******************************************* 
 
['/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_44ed1942_2020-02-15_07-34-23v9ip97sc/outputs/checkpoint-3']
INFO:__main__:Evaluate the following checkpoints: ['/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_44ed1942_2020-02-15_07-34-23v9ip97sc/outputs/checkpoint-3']
INFO:transformers.configuration_utils:loading configuration file /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_44ed1942_2020-02-15_07-34-23v9ip97sc/outputs/checkpoint-3/config.json
INFO:transformers.configuration_utils:Model config {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 28996
}

INFO:transformers.modeling_utils:loading weights file /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_44ed1942_2020-02-15_07-34-23v9ip97sc/outputs/checkpoint-3/pytorch_model.bin
HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=744.0, style=ProgressStyle(description_width='initial')), HTML(value='')))
0.0799920.2903280.1456300.1325760.3315010.0664760.0398160.0485160.0062620.0012350.0005440.0002300.0003050.0002071.5127160.9436870.4656790.4755460.0670360.6024661.2391091.4351710.5591120.2774610.0464640.0022480.0084570.1827601.3028560.4038210.0142290.0008470.0001960.0001780.4896090.6071630.2777270.0077150.0006030.4808650.0124310.0005400.0001970.2199480.0052840.0003330.0001930.0023440.0005850.2267130.0083780.0022670.0079450.0004730.0631230.3804940.0069680.0175020.0004770.0001800.0071390.0002950.0001730.0001790.2051020.0046450.4024230.0065680.0007910.0002170.3017030.0238890.5864860.0083280.0005030.2223390.0034350.0004910.0021290.0007220.0427780.0545530.0085580.0002690.0001690.0001660.0001700.0001860.0001680.0003280.0001780.0001700.0002430.0002550.0022270.0002330.0001730.0004630.0058240.0832320.0010000.0008250.8942630.0092370.0007060.0003290.0005190.0001950.0008180.0001940.0001800.2269830.2385120.0340480.2391580.4187950.0049950.0014330.2913240.0303500.0010880.4302570.0037220.7519150.0069440.0008320.0004850.0013830.0001740.0010510.0802020.1314090.0034730.0029160.0002840.0005330.0001730.0003700.0004030.0171680.2429790.0020080.0756270.1361930.0156850.0066190.0002920.0004400.0044930.0009580.0006660.0008130.0003960.2506500.0019410.0034170.0009560.0003210.4487050.8536610.4613630.0101780.0003050.9205980.4814171.4582940.3253341.0045600.3240861.0581740.8352140.3679660.0061320.0015200.0550730.2919270.0991350.1027420.0013610.0001880.1946960.0071520.0004741.1409200.6156520.8140830.2407310.0019740.9519280.0071140.0007760.0009940.0095400.0158510.0205690.0008280.0021290.1020450.0009382.3616410.0145560.2601850.0091330.8256710.8651040.3043250.0038900.0783590.1071000.8282000.0227850.0007030.4547052.0810960.0185240.2399300.1072690.7904600.5175080.5160910.7566860.0059430.1572080.1636030.2438800.0290740.0052880.0002201.0772090.2519001.1786722.1475690.5765470.0162750.0021740.0014140.4364450.7669990.0033860.1875380.2536130.1299090.0015060.1741470.3454630.1651070.0753180.9418140.6215380.0032540.7142940.0416780.3809110.0341780.0108710.2239220.0639720.0013080.5410500.5647660.0959850.3694400.3116381.9529320.5593620.3676540.0864210.1206480.3158620.0039990.2993160.5503560.5449370.4002380.0017050.0001830.4762950.0018940.0012630.0186360.0009330.0004450.4198420.0023770.0013650.2445091.0715701.0981281.5980161.1121940.0141990.0863470.0159850.1605780.0112430.0039820.0007720.0037300.0007600.0087740.0281241.0697840.9881720.4654140.0022500.0001890.0001660.0001770.0006280.0007190.0038801.7404141.4340920.4626412.3080340.0080580.0006280.3195450.3258610.7063720.7516980.0029050.0005830.0002170.0001890.3482000.4512190.0017980.0003100.0002670.0021820.0262220.0086150.4912280.0037230.0334550.0012140.0381180.0421580.0207350.2957760.1700661.8048331.2989920.0127300.1346120.0022410.0099700.0145510.2548650.0521630.2169570.2572360.0824360.1320630.0037900.4447860.0024070.0009400.0014760.0364690.0385850.0984740.0518970.2275580.1968830.6880110.1183380.0035650.0550260.5939930.2357700.2061930.0007490.4769220.0014770.0006760.9335440.4671440.0095100.5215950.2285561.2985490.9194300.9460360.9429310.0289660.0006140.0006340.0006470.0006120.0007230.8640660.2685460.8632340.4927120.3710420.1331350.0005940.0002590.2355540.3781330.0013920.2081540.1942930.0006580.2846610.0014410.0272850.0049920.6904341.5084040.7957780.4357290.0681810.0188340.0007270.0017290.0006660.0006630.0466700.3538050.2128730.0007710.0009250.0001890.0342990.0002690.0002752.2210230.9687080.0174520.4627000.0257090.1894690.0771180.1863630.6958010.1282582.6138510.4735410.0050640.0008270.2778010.0020761.8853680.5964000.0017150.0006890.0011770.0023880.0020230.8194380.5545750.0209660.0114301.5832361.3942490.9638870.4375680.0039810.3877670.3105020.0244460.5767550.3714580.4756940.6914261.7655310.0864570.0004181.2027361.3693360.0493160.0083790.1364350.0007840.0003060.3662293.0992512.0926460.0385900.0010980.3078330.0041340.4452540.0228530.0011040.0001740.0014260.0017230.0030040.0009680.0025310.0018820.2886360.0035820.0009830.0007220.0007880.0008430.1485050.0005540.4623890.0011790.0003520.0003580.0004910.5338050.0012610.1458570.0757560.0144970.2790760.0242300.0217830.3182052.0623310.0106520.0365370.0144290.0857440.0036520.4040870.0070280.2792980.0204760.0176970.0010260.9432220.8936500.0025680.2959900.0097132.5797740.4069850.0121700.4541890.2185310.0339341.1239620.3502840.1450960.0148150.1120730.2944600.0413690.0057570.0004260.0065030.3344070.2483950.0020340.0011570.0041210.1894100.0392820.0085810.0013921.8607180.1587760.3833440.0916200.4854830.0230630.0036440.2070120.5461500.9905670.4677410.2560810.2054360.6189060.2825170.3448390.3301200.4208110.0656320.0796220.6392260.9725170.2974491.1165170.7573940.8065080.4815210.9943250.2957370.7378320.4582040.2877700.2900010.4222850.8766940.7742850.2852910.0642220.4967100.3321020.7035130.4947420.0313030.2844360.4448670.0377800.4275020.2904280.2767380.0848130.5217170.4196701.0250380.7916810.7308920.3912180.0904420.2697970.4342980.4584110.2579650.3756550.2124510.2777890.5608050.3725730.1924450.3096850.6123690.1410570.4360970.2185690.0813900.7806970.9224530.9796770.5212150.2226790.6999670.4380190.4207670.3467820.2094130.6995610.4287731.3494500.3832700.9807520.1283220.6328470.7137080.6594850.0599260.3392080.2784840.7797340.2908650.4499790.2846080.0859380.4392550.6723400.4012240.2938220.9149040.6502190.5152120.5857840.3055220.5281280.3119430.1662790.6552710.8624600.9589720.3257150.2623150.0275090.3737370.9364670.2495830.3048610.2206710.6641750.4898780.1095140.5550690.2295951.2734300.4204310.2513150.8590531.1715140.1946070.1439450.2094660.1137260.7717360.4853140.7911960.4820421.1956330.6295980.3305120.1477680.9181530.0783170.6229700.5780410.6703030.4491260.6028330.6182961.3818140.8343790.5343870.6471070.1836990.5129510.3524480.4336130.2983720.4509770.4336030.5724130.1965510.1406220.5997100.4046800.3934430.5193230.6784430.2033560.3205741.3678010.9053590.8039810.0313880.0812650.3437000.3638611.1613600.1442320.1673741.519596

*******************************************
EVALUATING PIPELINE 
Pipeline directory: /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_44ed1942_2020-02-15_07-34-23v9ip97sc/
With following parameter combination: {'batch_size_seq_length': 3, 'lr': 1e-05, 'lr_type': 'cosine'}
EVALUATION OF CHECKPOINT /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_44ed1942_2020-02-15_07-34-23v9ip97sc/outputs/checkpoint-3
-------------------------------------------------------------
|           |   agree   | disagree  |  discuss  | unrelated |
-------------------------------------------------------------
|   agree   |    649    |    94     |    114    |    19     |
-------------------------------------------------------------
| disagree  |    111    |    254    |    84     |    28     |
-------------------------------------------------------------
|  discuss  |    241    |    87     |   1515    |    78     |
-------------------------------------------------------------
| unrelated |    36     |    33     |    66     |   8489    |
-------------------------------------------------------------
Score: 8643.0 out of 9226.0	(93.68090179926295%)
Accuracy: 0.9167086905362246
F1 overall: 0.754979380257662
F1 per class: [0.6785154208050183, 0.5375661375661376, 0.8189189189189189, 0.9849170437405732]
*******************************************


*******************************************
EVALUATING PIPELINE 
{'batch_size_seq_length': 1, 'lr': 1e-05, 'lr_type': 'cosine'}
INFO:__main__:Creating features from dataset file at /home/ubuntu/fnd_implementation/data/processed
  0%|                                                 | 0/11898 [00:00<?, ?it/s]  0%|                                       | 1/11898 [00:02<8:04:33,  2.44s/it]  4%|█▌                                   | 501/11898 [00:03<5:24:59,  1.71s/it] 46%|████████████████▋                   | 5501/11898 [00:03<2:07:41,  1.20s/it] 50%|██████████████████▏                 | 6001/11898 [00:04<1:22:24,  1.19it/s]100%|███████████████████████████████████| 11898/11898 [00:04<00:00, 2934.34it/s]
  ******************************************* 
              Running Evaluation                
  *******************************************
 
  Length dataset evaluation: 11898
  Length dataloader evaluation: 2975
  Number of epochs: 3
  Batch size: 4
  ******************************************* 
 
['/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_3fecf930_2020-02-15_03-37-121b3xitaa/outputs/checkpoint-3']
INFO:__main__:Evaluate the following checkpoints: ['/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_3fecf930_2020-02-15_03-37-121b3xitaa/outputs/checkpoint-3']
INFO:transformers.configuration_utils:loading configuration file /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_3fecf930_2020-02-15_03-37-121b3xitaa/outputs/checkpoint-3/config.json
INFO:transformers.configuration_utils:Model config {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 28996
}

INFO:transformers.modeling_utils:loading weights file /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_3fecf930_2020-02-15_03-37-121b3xitaa/outputs/checkpoint-3/pytorch_model.bin
HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=2975.0, style=ProgressStyle(description_width='initial')), HTML(value='')))
2.2240402.2240591.1120490.3710221.5933450.3187640.0532080.0076250.0009750.0001290.0006990.0002030.0001520.0000310.0000220.0000210.0000240.0000210.8521430.0448690.0022630.0001280.0000260.0000200.0000210.0000580.0000210.0797930.0028700.0001190.0000240.0001452.4054320.0729140.0021640.0000840.0000222.3026480.0606160.0015830.0000950.0000220.0000210.0000650.0000210.0000200.0000200.0000200.0000580.0000210.0000190.0000200.0000200.0000200.0000200.0000201.1422011.4612930.8781362.3885640.0398640.0006780.0000381.9029850.0297540.0004770.0000271.5114882.3862000.0346030.0005180.0000280.0000200.0024290.0000530.0000212.2382012.5079990.0321760.0004272.1591892.5644870.0312942.5382480.2603012.1905432.1901430.0251940.0003420.0000252.5106440.0276110.0009642.1201140.0225750.0002660.0057750.0000830.0000210.0000200.0000200.0000210.0000400.0000250.0001200.0000200.0000280.0000600.0000220.0000210.0000241.7202081.6247981.7569873.3911580.8685311.8561830.0158900.0001550.0000220.0000210.0000200.0000210.0001760.0000220.0000200.0000630.0000210.0000200.0000200.0000210.0000200.0000200.0000210.0000210.0000210.0001700.0005341.8327290.0132050.0491201.3748260.0097070.0001460.0000460.3394160.0023460.0000370.0000200.0000210.0000210.0000200.0000310.0000200.0000560.0000570.0004160.0031450.0000402.1979020.0137620.0001070.0000200.0000210.0000210.0000200.0000420.0000260.0000200.0000200.0000220.0000190.0000271.9728780.0113690.0000850.0046230.0000460.0000580.0000240.0000210.0000340.0000200.0000230.0000190.0000200.0000200.0000200.0000200.2059790.0032270.0000540.0006280.0001140.0001920.0000372.3567552.3915621.7812242.2971050.9869032.2713354.5288191.2951730.0064070.0000520.3021310.0014790.0000270.0545030.0003170.0000230.0000230.0000270.0000210.0000200.0000200.0006430.7099000.0039261.5514981.8545170.0086000.0000580.0000190.0000190.0000200.0000200.0000220.0000210.0006120.0000220.0000190.0000190.0000210.0000190.0000190.0000190.0000190.0000190.0046430.0000380.0000210.0000190.0000190.0000200.0000360.0000210.0000200.0000200.0000220.0000190.0000200.0000200.0000200.0000200.0000190.0000200.9863650.0038280.0000340.0004580.0004430.0000220.0000860.0000222.1881150.0082780.0000550.0000560.0000410.0000220.0000200.0000210.0000270.0005010.0000210.0000200.0000200.0000210.0003630.0006450.0000230.7370500.0028950.0000370.0000210.0000200.0000211.5943631.7417970.0060060.0000430.0000500.0000200.0000530.0000520.0001220.0000530.0000190.0000510.0017960.0000260.0000240.0000200.0000200.0000840.0000910.0000520.0000530.0000200.0000850.0000550.0000190.0000260.0008090.0000330.0000210.0003140.0002801.5510730.0054480.0000490.0026980.4384150.0015790.0000240.0001830.0000550.0001240.0002600.0000580.0000200.0000200.0000190.0000190.0000190.0000200.0000200.0000190.0000190.0000190.0000190.0000190.0000190.0000200.0000190.0000200.0000190.0000200.0000190.0000210.0000200.0000230.0000200.0000190.0000850.0000200.0000190.0000200.0000190.0000200.0000280.0000190.0000200.0000190.0000190.0000230.0000190.0000200.0000190.0000640.0000190.2484730.0006830.0000340.0004110.0000210.0000190.0000200.0000200.0000210.0000220.0000870.0000190.0000190.0000190.0000220.0000200.0000220.0019770.0000240.0001040.0000550.0001900.0000550.0005460.0000230.0003490.0000200.0000200.0000200.0000190.0000190.0012190.0049610.0000730.0001080.0000522.2879964.6243170.0113070.0000550.0000200.0000520.0000590.0039480.0000660.0000200.0009920.0000910.0000220.0000200.0000200.0000900.0000200.0000200.0000200.0000200.0000200.0000200.0000220.0000210.0005510.0000620.0000200.0000200.0000200.0000210.0000270.0000190.0000200.0000220.0000190.0000200.0013080.5947530.0032890.5468981.5604990.0036780.0000850.0094040.0000550.0000220.4741560.0350450.3420670.0007690.0000630.0000212.4492580.0053660.0000780.0000220.0000240.0006970.0000250.0000190.0000580.0000620.0000190.0000190.0000190.0000190.0001840.0002530.0000200.0000560.0000200.0000190.0000200.0000750.0000690.0001830.0000811.4380570.0029730.0000260.0000200.0000210.0000200.0000200.0000201.7852681.9826660.0040190.0001450.0000870.0001110.0001130.0000370.0000190.0000190.0000190.0000240.0000200.2932160.0005970.0000220.0003300.0000200.0000200.0000190.0000200.0000200.0000200.0000190.0003810.0003700.0000210.0000240.0000970.0298440.0000760.0048980.0021020.0000240.0000210.0002010.0000280.0208090.0131690.0006360.0000370.0000190.0000680.0000190.0000200.0000190.0000200.0000610.0000720.0000630.0000200.0000200.0000200.0000200.0000190.0001070.0000200.0000190.0000860.0002390.0000200.0001100.0000271.9961360.6288010.0011551.3263380.0654711.8762070.0033560.0000280.0000240.0000980.0000201.8698091.2772720.0022610.0000960.0000630.0000202.3124766.8581780.0122940.0003750.0008550.0001380.0000210.0000200.0000940.0002840.0000200.0000540.0000200.0000200.0000200.0001220.0000760.0000240.0000200.0004780.0011880.0004740.0000670.0000220.0003900.0000210.0000200.0000200.0003630.0001500.0000200.0003480.0000200.0000200.0000920.0000200.0000190.0000532.2461050.0036890.0000252.0192180.0033330.0000570.0000190.0000202.0391980.0033030.0000590.0000200.0000200.0000530.0001590.0000200.0000200.0000680.0000560.0000190.0000192.3757900.0038870.0000642.3751480.0037492.3513250.0037010.0000260.0000572.3861720.0037330.0000260.0000200.0000202.2118700.0034340.0000250.0000350.0000543.8151313.8686501.1417960.0842951.3877720.0021330.0013310.0272620.0033480.5065230.0830900.0003100.7615090.0012450.8778950.0014150.0001790.0045910.0800200.1387180.0003020.0000200.0343370.0000701.9423330.0039970.2838510.0004371.7691251.2171970.0018050.0019840.0492080.0000920.0000240.0071860.0008920.0000670.0000630.0000620.0000760.0001300.0000210.0001140.0000580.0002790.0007820.0002010.0001970.0002230.0000860.1483000.0002300.0000200.0000240.0003680.0000200.0000210.0003930.0000200.0000200.0000200.0000200.0003330.0000200.0000200.0000320.0000200.0000230.0000560.0001230.0329670.0000770.0000220.0000680.0001140.0000940.0000200.0000560.0000200.0000231.5645890.0059351.7309710.0023720.0000230.0011371.0272660.0014081.6589440.4185050.0008940.0000210.0386010.2033990.0007180.0000210.0000190.0004250.0000210.0000200.0000200.0000191.9161690.0029480.0000230.0005910.0000200.0003640.0000200.0000200.0000200.0000200.0003870.0000220.0000200.0000200.0008010.0000230.0006910.0009890.0000210.0000190.0000230.0000290.0009140.0017530.0000580.0000680.0000820.0000720.0000190.0000190.0000730.0005060.0000730.0000200.0000201.3525480.0017300.0000620.0000200.0001870.0000794.7595357.2221310.0092830.0001200.0000550.0000860.0000530.0002530.0000630.0001860.4843200.0286741.5698410.0426290.0007640.2619350.0004690.0000811.2889451.2629941.9855930.0230400.0042140.0022252.9692890.0036740.0000240.0000210.0000260.0001610.0006280.0001150.6793220.0012120.0000220.0001460.0610830.0006290.4338490.0005430.0004503.0669033.6213400.0043382.0987120.0025200.0001190.0001610.0000810.0000230.0000200.0001020.0000710.0000200.0000192.0392442.8708160.0045610.5289470.0007890.0002300.0006900.0014420.0001960.0001270.0001660.0011631.2949330.0022420.1682340.0002130.0001081.4927710.8827120.0010683.5454903.4005310.1758640.0002210.0000201.6076951.6351380.0018830.0000261.0933010.0019270.0012090.0007660.0000940.0001100.0001050.0000800.0001580.0007630.0023041.6783120.0019391.6228570.0018680.0000890.0000530.0001641.8004610.0021960.0000550.8925340.0010120.0000211.9046550.0021240.0000710.0000200.0000200.0000290.0000190.0000210.0000201.9590824.4709170.0049750.0000250.0000562.2393161.8998711.8266200.0023071.8186660.4792750.0006200.7524563.2291470.0036610.0000610.0010610.0010540.0001620.0000590.0001120.0000220.0001650.0001370.0000230.0001980.0001610.0002000.0001210.0000190.0001360.0005330.0000290.0006931.7796216.9886440.0611300.0109780.0000330.0000210.0000200.0000210.0000200.0000950.0000260.0000581.9356140.0020380.0000260.0008290.2034220.0388510.0002910.0001920.0000990.0000750.0001090.0002110.0002460.0001960.0000200.0000200.0000201.6610400.0017210.0000210.0000210.0000210.0000200.0000210.0000200.0000200.0005190.0000200.0000610.0000200.0000720.0018740.0008690.0000231.9987980.0020320.0000260.0001100.0000270.0000200.0000260.0007840.0034600.0000230.0007020.0000220.0006860.0012930.0000210.0000220.0000201.6361200.0016411.3010910.0014790.0001380.0000240.0009280.0007210.0005430.0008160.0000200.0011210.4609770.0004700.0030120.0024780.0008410.0025170.0001520.0001370.0001090.0001382.4098140.0023940.0000870.0000210.0000190.0000190.0000592.0149350.0024810.0001670.0001731.2633951.7206650.0023880.0008500.0000210.0382560.0007580.0000210.0000214.5748434.6617202.2635390.0022152.2945500.0041290.0022420.1434420.0013112.6208910.0025610.0000590.0003720.0001000.0002510.0015910.2406030.0021500.0003791.9610460.0018522.5689091.5591820.0014700.0004600.0000560.0000200.8577430.0025980.0001020.0001030.0000200.0000201.9274900.0021880.0000620.0000200.0006040.0000741.3942320.0032790.0000230.0000200.0000190.0000190.0000630.0000200.0000190.0000200.0000200.0000190.0000202.4523880.0022390.0000210.0000200.0000190.0000190.0000200.0000200.0000190.0000200.0000580.0000960.0001680.0000220.0000560.0000570.0000590.0000940.0000910.0000190.0000590.0000200.0001290.0000200.0001190.0000750.0000200.2657010.0003490.0000620.7957610.0007630.0000771.8008440.0016160.0003440.0000200.0000220.0004361.5912250.0373201.6950024.0006881.0112114.4757781.1396050.0010111.5647295.3660214.1946694.5718830.0041981.4850291.8460243.2667486.2309210.0053920.0010900.0014760.0000211.4168770.0013860.0001640.0000210.0000200.0000200.0000212.0716562.8440971.7258150.0016791.4061960.5065180.0005280.0000200.0000610.0000540.0001330.0000580.0001080.0000200.0001080.0000800.0000870.0000880.0000900.0000660.0000200.0000900.0000560.0000200.0001771.9267140.0023380.0000600.0000770.0000200.0000200.1754220.0007170.0011261.5502670.0945911.6424930.0014850.0001420.0148612.2144011.5858640.0016840.0000210.0000200.0000210.0000780.0003690.0000200.0000190.0000190.0000190.0001600.0000190.0000230.0000200.0000210.0000200.0000190.0000220.0000260.0000190.0000190.0003660.0000200.0000200.0000290.0000190.0003480.0005970.0001350.0011870.0102090.0012595.5536391.8486133.7522055.6273293.7109250.0029890.0003290.0003100.0003350.0000191.9905820.0017424.1654240.0034714.2930170.0034940.0000970.0000930.0000670.0000190.0001160.0000970.0000610.0000570.0000930.0000190.3772330.0530520.0004890.0003370.0004460.0003090.9951620.0020110.9221950.0292051.0682680.0063390.0002120.0001250.0000552.1386590.0016820.0000210.0000970.0001650.0000190.0000190.0000200.0000200.0000200.0000210.0000310.0000200.0000220.0000220.0000380.0000212.1590602.3711450.0019230.0000220.0000400.0000210.0000670.0000690.0000190.0000190.0000190.0000200.0000720.0000750.0000190.0000190.0000190.0000670.0000200.0004800.0000200.0006080.0000200.0024260.0004540.0000200.0009700.2034390.0002470.0001492.3970370.0019580.0001680.0000200.0000780.0000200.0000200.0002070.0000200.0000840.0000200.0000200.0001530.0001310.0000200.0000200.0003030.0002030.0001820.0000870.0001140.0001730.0001760.0001880.0001750.0001830.0001380.0000602.3960580.0018940.0001100.0001110.0000870.0003200.0031553.8104873.5641905.0525474.9947236.7374104.7933560.0041910.0004320.0008280.0033430.0004950.0004570.0002800.0000610.0001210.0000200.0001490.0001790.0000630.0000630.0000200.0001480.0000630.0093920.6867810.0016430.0063690.0000260.0001750.0000700.1027690.0017470.0118090.0012870.0012431.2805641.3279452.8126343.2793111.8693311.3383231.7209503.0236780.7443360.0009280.0005800.0002890.0001740.0001690.0005480.0000840.2449281.1332600.0008960.0000200.0000600.0000200.0008102.2686651.5414410.0011010.0008060.0000230.0000230.0000450.0000210.0004260.0000200.0000220.0004370.0003570.0000310.0003830.0000241.3550760.0009600.0018450.0032520.0000220.0000210.0000240.0000190.0000191.3481740.0009481.5315060.0019990.0000230.0000200.2635150.0003231.5634290.0011280.0000210.0000220.9863360.0006940.0009673.6724710.0025670.0001010.0012520.0005100.0089250.0019430.0000630.0094220.2196780.0005700.0338910.0000420.0071400.4582170.0100060.3143540.0383860.2341710.0001790.8445590.0005880.0000253.3821170.0022900.0000220.0000200.0000210.0000280.0000252.3419180.0015830.0000650.0000190.0000200.0000260.0000190.0000190.0000600.0000190.0000820.0000244.8585640.0032400.0000240.0000190.0000200.0000682.2452390.0015010.0000200.0000190.0023100.0023480.1589930.0081480.0026560.0010960.0068410.0300410.0007340.9662912.3534791.5128352.3596960.0015622.3449402.2174980.0014650.0002650.0000890.0000194.6924710.0030782.3854760.0015672.3743290.0015581.0875100.0007291.4703770.0158130.0000320.0000750.0003420.0012970.0003460.0019420.0001500.0000630.0001182.3307260.0026030.0000680.0000610.0001970.0000520.0001570.0000200.0001400.0000600.0000621.3290904.4070302.2396470.0014820.0000602.3817431.9557672.3469584.2115042.2286702.0106674.3906880.0027984.4808940.0028962.2242044.3227310.0027470.0000240.0000200.0000190.0001260.0000200.0000200.0000190.0000200.0000570.0000190.0000200.0000200.0000590.0000200.0000580.0000970.0000190.0000190.0000210.0000220.0000190.0000880.0000200.0000220.0001200.0000200.0000200.0001390.0000190.0000650.0001020.0000220.0000200.0000200.0000200.0000200.0000190.0000200.0001090.0000590.0000190.0000210.0000190.0000190.0000190.0003080.0002190.0002430.0003340.0005070.0004960.0004100.0003600.0012050.0009960.0001300.0007762.4602506.2044255.9453210.0182255.2808793.0153671.7563710.0019320.0002320.0002180.0002791.7222090.0514695.7712651.9146894.2053492.7268552.0957001.5454562.1319701.1778930.0007270.0002100.0002090.0000200.0000200.0000510.0000190.0012690.0000200.0000500.0018190.0000280.0002370.0000190.0000710.0000200.0005080.0002300.0000201.2147111.2046960.0011500.0007200.8131871.3123970.0011500.0000230.0004270.0000610.0000190.0000190.0000230.0000690.0003120.0001040.0001200.0000190.0000200.0000240.0000200.0001500.0000190.0000190.0000200.0000190.0000190.0000200.0000200.0000200.0000190.0000260.0000623.7211743.8136781.8877585.6230342.0267361.0934920.7975850.0005640.0016400.0056830.0009830.0157330.0000390.0008730.0000942.4405610.0022461.3599000.0834131.9818631.7408880.8494220.0005090.0007300.0001880.0002610.0003470.0002400.0045930.0003840.0001930.0019500.0012010.0023890.0232793.0175930.0018290.0013371.6284650.0028532.3332762.2209376.3842902.4489532.1395542.2784490.0018510.0008240.0003610.0007670.0003730.0008470.0000460.0000200.0001760.0001920.0001821.7645000.0011820.0001800.0001690.0002090.0001790.0002062.1578302.3580600.0015324.7081482.4553450.5260780.0003890.0001280.0000200.0000200.0001270.0000200.0000950.0000540.0001290.0000580.0000190.0000920.0000200.0004300.0000200.0003830.0000200.0007620.0000200.0004450.0005340.0000200.0000200.0000204.4132771.8893190.0025430.0009340.8741570.3195600.0427730.1287460.0000900.0000220.0073830.0000260.0017820.0000212.4296812.3318772.4923020.0013840.0000212.3355562.3914042.3451742.2008332.3426660.0012980.0000202.4073320.0016840.0000210.0004240.0000200.0000260.0012140.0008830.0007230.0001581.9773180.1966773.6220282.3717650.0014800.0169740.4528350.0041090.0001021.2273140.0007611.8376460.0031640.0004750.6746802.0577300.0015880.0000720.0014673.5732640.0019880.3371310.0050300.0009035.7014754.5194217.4204301.9827850.0010770.0000200.0000190.0000200.6714550.0003770.0000200.0000200.0000200.0000531.9788235.0062790.0026740.0000210.0000200.0000205.4165692.6468320.0042700.0000220.0000220.0005910.0000210.0002080.0000200.0001010.2138940.0002110.0238410.0000340.0000220.0000780.0001150.0000880.0000220.0000520.0000280.0014770.0000220.0000932.2715160.0013902.4106454.6786784.1903332.2289364.3468412.0056850.2016051.2972660.0021180.0024950.0000260.0000220.0000290.0002060.0000230.0000780.0000740.0000810.0000210.4928370.0002740.0003590.0007100.0000200.0000200.0000200.0004561.8043060.0013330.0000200.0000200.0005610.0000200.0004040.0000240.0000200.0000200.0000190.0000200.0000200.0000200.0000190.0006830.0004310.0000200.0000190.0000590.0004950.0001630.0000190.0000190.0000200.0000200.0000760.0458100.0000430.7090230.0003790.0000210.0005640.0000190.6063680.0007970.0000540.6620980.0004710.0001941.2288810.0010620.0000210.0009730.0000210.0003550.0000210.0000570.0000190.0000200.0001330.0000590.0000530.0001300.0000200.0000580.0000550.0000980.0000600.0001280.0000550.0000190.0000931.4999841.8926700.6227350.0003300.0000200.0000190.0000201.5991073.6102100.0018110.0000211.6037920.0008150.0000201.6037920.8356320.0004330.0000190.0000200.0000231.4781271.7178980.0008700.0000200.0000210.0000630.0000190.0000190.0726160.0000570.0000190.0000200.0000220.0000210.0000200.0000310.0108830.0005540.0000200.0014470.0000200.0000200.0000200.0005310.0000200.0000200.0000190.0013280.0000200.0016200.0007770.0000200.0000190.0000200.0003240.0008050.0006530.0000201.4457800.0011520.0000202.8118034.8324501.7280945.6122654.4636160.0022922.6707000.0321803.8331471.0794070.0017081.8735280.0009251.7006072.1555323.2353460.0042521.1813260.0017320.0020530.0024870.0007760.0009190.0007500.0002482.4319531.2547940.9709031.2622440.6335930.0003220.0000550.0028770.6105890.0003110.0068460.0115370.0010860.0000200.0106500.0000300.0000200.0025720.0030830.0000230.0000210.0001570.0001790.0001790.0002300.0001640.0001681.6747880.0010340.0001651.1786280.0008910.0000610.0000660.0000220.0000200.0000660.0000210.0000782.2793750.0010900.0007350.0017370.0000200.0019160.7694300.0022561.0960210.0284050.0000330.0000190.0000490.0000200.0000190.0004520.0000190.0009780.0004850.0000201.3550061.3552750.0006700.0000220.0000190.0827120.0000580.0000190.0000310.0000200.0000201.8478393.6330231.8058790.0016180.0012430.0007912.5891310.0056380.0000620.0000991.7210110.0008500.0003740.0001171.5255640.0007670.0000550.0000190.5002210.0003130.0000951.7630050.1505181.6226750.0007620.0053611.6421670.0007700.0252960.0001440.0000580.0000600.0000200.0000550.0000540.0010600.0015880.0003410.0001830.0001763.5197152.3428131.6060780.0007493.6011362.2409130.0011880.0001520.0001840.0000970.0001630.0000590.0000890.0001350.0000950.0001790.0003830.0001761.6774251.0471490.0006420.0001300.0013380.0009430.0012480.0011750.0003050.0000840.0002890.0004940.0000190.0001190.0000200.0002315.7457462.9731994.3454923.0985620.0032450.0090570.0000240.0004700.0005740.0005750.1336880.0001620.0765210.0002130.0008720.3071060.0012200.9648870.0012760.6581020.0089751.8291190.0009140.0053580.0010020.0001570.0030940.0014610.0012360.3199450.2936520.0001530.7895050.0049051.2276020.1496510.0018431.4731691.5211990.0006961.8894720.0481240.0053281.5335480.0007770.5985820.9723561.2023890.0005510.0460590.0350300.0001811.8406421.6024430.0309881.9367850.0009141.3734170.4311820.0003700.2144110.6322630.0013380.7412072.7022300.0027750.0012450.0021150.2235561.5440751.0284410.1504000.7485420.0013670.0018320.0004570.0009980.0048991.9530220.0026670.1240262.3687500.0103850.0259070.7115162.5928250.0063261.0614451.2567720.0007170.0001612.6308570.0028052.6359510.0045060.1699850.9173350.7099901.1172670.3535000.4113731.7807751.0925660.0008170.6393290.0004121.5461840.4985720.2400211.8517120.2773750.2201480.1840710.6054390.2503480.0001370.2769430.3012592.0868330.3222511.4968240.4416030.0031620.0015091.0106850.0006360.0431650.0300241.2253610.0082730.2930060.0008430.0141800.0742481.1756020.0089390.6900470.0021803.8105420.0018330.8974600.1264951.7121750.7382500.3794160.0002450.2225870.5414830.0002540.0000320.0051470.0845560.8855110.0013011.5545040.0178640.0194470.0757880.4531031.6030980.1333770.0006450.0182472.6017450.0027700.6650370.0096661.4718370.0024670.0012530.0014440.0190190.0031420.0022680.5298980.0537661.1192321.2816520.0012920.1826910.0127520.0016020.3887471.9109302.8800480.1312290.0001950.5797440.0002820.3859591.7627960.0015670.0024760.0001090.8438220.0004510.6092820.0932690.0338230.0025530.0011572.8067380.3961761.7394330.1370291.3091731.1314200.7954231.7295000.9184451.6391560.5782532.2775360.0023310.2903752.0938020.0008960.0097160.0035262.7754620.0011820.0024791.1594580.4811120.0017060.0020580.2780170.0002230.0205561.0336750.0012210.0000601.4969950.3479660.1327740.0000920.1246651.1513150.0045150.8186570.0003550.2548010.2876210.0001590.0014110.0011370.0009121.6875150.0142560.2652370.0610460.4640190.1084951.6252350.0336210.0000440.1735180.0001192.8879631.0191080.0004621.3235540.7175420.0007790.0006360.0010390.0011260.5918590.0007710.0000401.0173861.0111791.9090511.2225001.5153780.0242730.0032370.0021580.0071410.0020320.0037310.9289912.2814200.0023980.0216310.9671100.0071380.0216180.0089500.0000810.0010910.1023920.1515060.5448111.1033741.0433112.5142852.0121650.0618820.9662911.0946040.0052510.8638852.0398040.5391100.8660360.0023650.7042400.0003930.1292890.9210490.0004380.4094801.7762360.0009431.6758220.5027630.4471680.1447160.8722431.6807891.9115400.0008650.0141840.0000290.3417880.0001641.2774090.0005370.0192301.1367170.0004731.0531080.0286910.0337581.1202970.7508270.0011510.7818580.0003321.8079693.1381091.0538851.5973281.3480960.0006070.0011810.0001552.7209150.1854691.0955050.9950060.1961270.0000960.0022480.6950200.0002910.0221820.4609941.5550330.0090931.9368410.7908080.5508460.5015620.4403530.0003410.9906970.0004090.1732970.0001250.0112080.0023050.0000780.1315981.1591770.0088230.0005231.3534180.0007641.2508420.6876500.9804140.6040130.0015280.0374580.6176811.3928171.0813890.8963730.0011361.9549570.0010100.0007891.6656821.3108510.0438840.0051710.0000390.0054050.1774670.3194210.0049320.0589380.0292992.6013760.6958000.0306780.9597990.8984820.1236950.0000930.7043410.0023201.2164040.0025460.0007801.5128440.7725230.3486921.5150690.6842571.4472650.0024010.0031270.0001362.7096070.0026080.0245570.0014440.0014451.3686321.2859140.0032500.0015580.0000490.0013252.1188150.0032640.0014620.0077140.8879000.8489510.0071560.0041530.0159690.0016840.0001400.2473550.4868142.2780020.4150540.0001902.1435300.4042392.1094230.0247200.0005173.1712411.1848450.8140260.6536920.0049660.0140540.0122660.0000380.9210300.0031340.0026000.0039660.0052900.0000370.0047821.9151030.0011430.1165111.2228800.0440830.5642361.7608090.2800640.0001300.5778561.9505210.6742570.0876880.7898810.0042261.5025050.0028040.0000320.0033960.0001031.4673271.5132370.0724630.0034500.7083711.2793510.4586520.0112041.0591950.0004300.0000390.7735820.7134981.0072110.4528501.0648950.0005170.0000320.0013641.0544480.2958210.3460910.4552100.0005910.2305080.3127260.0057060.0001350.0000610.5921920.8658930.0017462.6996741.4193761.3901412.6780340.2280970.0031312.6630030.0078371.2526310.0017720.0000300.0050400.0021430.0025611.1548580.0029020.0056960.0012390.0029570.0001031.4580700.1464790.0007550.0002050.0006730.0726835.0893910.0041990.0019081.4379471.3142750.1049750.6114160.2213151.5181360.0086310.0013120.0011241.5992922.8215170.0023743.6235070.0023530.0013000.0040660.0020483.1239200.6636470.9290180.8851350.0123410.0061410.0003640.5094960.5705290.0948960.8439221.5365312.8804640.0014830.0004850.1488020.0026930.0034820.0083800.0265312.1800791.2310931.5860360.6856530.0030742.7657540.8604410.8098600.1731780.0001521.5766270.3018390.0993991.0503210.3004861.2222350.8838582.6066750.0038600.0045680.5641080.3551413.0152480.2806273.0442682.0750870.0027361.5827560.0005900.5131191.0767521.3684280.0005242.0417131.4926280.0026090.0025590.0000361.0140860.0154240.0004350.0717260.4860650.9717030.8674061.1018660.0004620.9982640.7961790.0512241.1575671.3581610.0110330.0193410.4869980.3664230.2629961.4182320.3355380.0559780.0705471.5944700.0005810.0017590.0033381.9699300.4701720.5339920.5030421.6600930.0006660.0022131.1847990.0117790.0042850.0410760.0028480.0248870.1736521.4743071.9550680.0029000.0022080.0000211.4314710.0835920.0016561.6521090.7141040.9363802.0479191.3388480.5026813.1643250.0011080.6760340.0075300.0028850.0067371.1105570.0027270.1370700.0535300.0048940.8726160.6841701.5963181.8945552.2452261.6046472.4400390.0053531.3976662.3180060.0082630.8270170.5342551.0675370.0003910.0101530.0297180.0183080.0100610.9835210.0394490.0000390.9283780.0193680.9451541.3339731.5184250.0032580.0001650.2452182.6547811.0774630.0073961.3138460.0015360.6579990.0029150.0000460.0000820.1405250.1137392.5134200.6622702.818983

*******************************************
EVALUATING PIPELINE 
Pipeline directory: /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_3fecf930_2020-02-15_03-37-121b3xitaa/
With following parameter combination: {'batch_size_seq_length': 1, 'lr': 1e-05, 'lr_type': 'cosine'}
EVALUATION OF CHECKPOINT /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_3fecf930_2020-02-15_03-37-121b3xitaa/outputs/checkpoint-3
-------------------------------------------------------------
|           |   agree   | disagree  |  discuss  | unrelated |
-------------------------------------------------------------
|   agree   |    698    |    97     |    164    |    26     |
-------------------------------------------------------------
| disagree  |    96     |    265    |    83     |    29     |
-------------------------------------------------------------
|  discuss  |    211    |    77     |   1480    |    89     |
-------------------------------------------------------------
| unrelated |    32     |    29     |    52     |   8470    |
-------------------------------------------------------------
Score: 8628.5 out of 9226.0	(93.5237372642532%)
Accuracy: 0.9172129769709195
F1 overall: 0.7631932714728524
F1 per class: [0.6904055390702275, 0.563230605738576, 0.8140814081408141, 0.9850555329417922]
*******************************************


*******************************************
EVALUATING PIPELINE 
{'batch_size_seq_length': 4, 'lr': 1e-05, 'lr_type': 'constant'}
INFO:__main__:Creating features from dataset file at /home/ubuntu/fnd_implementation/data/processed
  0%|                                                 | 0/11898 [00:00<?, ?it/s]  0%|                                       | 1/11898 [00:02<7:37:59,  2.31s/it]  4%|█▌                                   | 501/11898 [00:02<5:07:11,  1.62s/it] 38%|█████████████▌                      | 4501/11898 [00:02<2:19:33,  1.13s/it] 46%|████████████████▋                   | 5501/11898 [00:03<1:24:30,  1.26it/s] 52%|███████████████████▉                  | 6223/11898 [00:03<52:29,  1.80it/s]100%|███████████████████████████████████| 11898/11898 [00:03<00:00, 2996.76it/s]
  ******************************************* 
              Running Evaluation                
  *******************************************
 
  Length dataset evaluation: 11898
  Length dataloader evaluation: 372
  Number of epochs: 3
  Batch size: 32
  ******************************************* 
 
['/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_3333275a_2020-02-14_23-16-30la61ez_j/outputs/checkpoint-3']
INFO:__main__:Evaluate the following checkpoints: ['/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_3333275a_2020-02-14_23-16-30la61ez_j/outputs/checkpoint-3']
INFO:transformers.configuration_utils:loading configuration file /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_3333275a_2020-02-14_23-16-30la61ez_j/outputs/checkpoint-3/config.json
INFO:transformers.configuration_utils:Model config {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 28996
}

INFO:transformers.modeling_utils:loading weights file /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_3333275a_2020-02-14_23-16-30la61ez_j/outputs/checkpoint-3/pytorch_model.bin
HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=372.0, style=ProgressStyle(description_width='initial')), HTML(value='')))
0.1350350.1362590.1973480.1155790.0294670.0064370.0013930.6147600.2879630.3483831.0144450.3392800.0480260.1323280.6012290.0411030.0027250.8046920.0997900.1878740.0225620.1379920.0242910.0253880.1599380.0684930.0132720.4601410.0361360.0014090.0105650.0004970.1352150.2367390.0083390.1535170.2237810.0084630.0009470.0014140.1193190.0169520.0005580.0001820.0003070.0001850.0028800.0090880.0009720.0356140.0193780.3344440.0225950.0007740.0004350.1427830.2103910.2715150.0070890.0028110.1687770.2048980.0045260.0055980.0031120.0144680.0085500.0005630.0003550.0520720.1783110.2757410.0151560.0007830.0025960.0014560.0478120.0036330.0009670.4979480.2442810.2240150.5774150.7577690.3480010.4006060.0480620.9689840.0124010.0010410.0127250.3726870.3799990.0473030.2567310.0091210.0400090.0382450.0841751.1709310.2977360.2752200.4584010.0502380.1550850.0026480.6437400.1642670.7584780.5003990.2616880.2426650.1126450.0140380.9726192.1136210.4323510.0932000.3815010.0441040.2043470.0075260.0404770.0247960.4957240.1520990.2227560.0939480.0654940.4065000.7752700.8645650.2738760.0865450.1797520.2315250.2532300.0020840.1918980.0035530.0007330.3771010.1405650.9510471.1731040.0772760.2879330.0612480.0019520.0066540.1274730.3226720.0031950.0001800.0071800.9381980.9725561.0599060.2025920.6879880.1148920.0015340.1836300.2272040.0016990.0394900.2475800.0735230.0526730.0065850.2144651.9728570.1414570.0042120.1481280.4609470.7865460.5015250.2258460.0031660.0655990.0452500.1348970.3943200.6404390.1594440.0390290.2333940.4847730.2342330.5131181.0887350.8518580.0425880.0023210.0012040.3090620.5690140.1613970.0011270.1306230.0130340.0019450.0679700.0509640.9189610.4269501.0474360.3206660.3100910.2172000.0978240.0012780.0003171.4390530.7818470.2770980.1626630.0841571.4824830.3647510.0760870.6918010.2388850.0063840.0250580.1938110.1280161.3077550.6212790.1026360.1534690.2930930.4267550.5614270.5828270.8088370.0162940.0009871.4900050.8621170.0528920.1955880.0116070.0046650.0113810.0063720.0673520.0610090.0013830.2969620.2153060.2109990.0182600.1413630.1048960.0337650.0433590.7245540.7410530.6771100.4475330.3775370.1888480.3243580.3834800.2281380.5248100.0462620.0207310.6108050.2571060.2990060.1019120.0403100.0984840.0040000.2313040.0380261.1520250.1868690.0851000.0785520.3554870.3774560.3007520.3942200.2886300.2545850.3743240.6443070.5555590.3148190.4604140.4257950.4073800.6023610.6144270.2508190.5093480.3320650.3586910.1579010.3461270.4166820.5395700.6234850.1782640.3058570.2881300.2238490.3550620.2213940.3434550.2891260.1856210.6366680.5673970.5059080.5370670.2644980.4709380.6560470.5858100.5519370.4474860.2708850.3821360.3841020.1972830.5934990.3435400.3988770.2337650.2792840.3689180.9151070.2444770.2105350.4320900.3774590.3631030.3321190.7640110.4024020.8137310.2087630.2085920.5798510.5067210.8594820.2371170.4220960.4639540.5385620.6744511.0423870.4254270.3188820.4199350.4133710.4640210.2001880.3727560.5143160.3770160.9270530.7706430.2299790.2886230.4265810.423725

*******************************************
EVALUATING PIPELINE 
Pipeline directory: /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_3333275a_2020-02-14_23-16-30la61ez_j/
With following parameter combination: {'batch_size_seq_length': 4, 'lr': 1e-05, 'lr_type': 'constant'}
EVALUATION OF CHECKPOINT /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_3333275a_2020-02-14_23-16-30la61ez_j/outputs/checkpoint-3
-------------------------------------------------------------
|           |   agree   | disagree  |  discuss  | unrelated |
-------------------------------------------------------------
|   agree   |    621    |    65     |    147    |    19     |
-------------------------------------------------------------
| disagree  |    189    |    288    |    129    |    23     |
-------------------------------------------------------------
|  discuss  |    184    |    74     |   1423    |    78     |
-------------------------------------------------------------
| unrelated |    43     |    41     |    80     |   8494    |
-------------------------------------------------------------
Score: 8589.0 out of 9226.0	(93.09559939301973%)
Accuracy: 0.9099008236678433
F1 overall: 0.7426313943247898
F1 per class: [0.6574907358390683, 0.5250683682771194, 0.8044092707744488, 0.9835572024085225]
*******************************************


*******************************************
EVALUATING PIPELINE 
{'batch_size_seq_length': 1, 'lr': 1e-05, 'lr_type': 'constant'}
INFO:__main__:Creating features from dataset file at /home/ubuntu/fnd_implementation/data/processed
  0%|                                                 | 0/11898 [00:00<?, ?it/s]  0%|                                       | 1/11898 [00:02<8:40:18,  2.62s/it]  4%|█▌                                   | 501/11898 [00:02<5:48:56,  1.84s/it] 38%|█████████████▌                      | 4501/11898 [00:03<2:38:32,  1.29s/it] 46%|████████████████▋                   | 5501/11898 [00:03<1:36:00,  1.11it/s] 51%|██████████████████▌                 | 6120/11898 [00:04<1:00:42,  1.59it/s]100%|███████████████████████████████████| 11898/11898 [00:04<00:00, 2807.12it/s]
  ******************************************* 
              Running Evaluation                
  *******************************************
 
  Length dataset evaluation: 11898
  Length dataloader evaluation: 2975
  Number of epochs: 3
  Batch size: 4
  ******************************************* 
 
['/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_2b71f0fa_2020-02-14_21-09-28awnqa5gn/outputs/checkpoint-3']
INFO:__main__:Evaluate the following checkpoints: ['/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_2b71f0fa_2020-02-14_21-09-28awnqa5gn/outputs/checkpoint-3']
INFO:transformers.configuration_utils:loading configuration file /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_2b71f0fa_2020-02-14_21-09-28awnqa5gn/outputs/checkpoint-3/config.json
INFO:transformers.configuration_utils:Model config {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 28996
}

INFO:transformers.modeling_utils:loading weights file /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_2b71f0fa_2020-02-14_21-09-28awnqa5gn/outputs/checkpoint-3/pytorch_model.bin
HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=2975.0, style=ProgressStyle(description_width='initial')), HTML(value='')))
2.1574242.1574451.0787720.3600200.1149020.0231640.0040020.0005900.0001810.0000350.0000780.0001680.0002450.0000350.0000210.0000200.0000380.0000190.0205540.0010980.0000720.0000210.0000170.0000170.0000160.0000910.0000210.0044180.0001740.0000230.0000170.0003811.8190870.0551480.0016390.0000720.0000191.4307010.0376820.0013830.0001370.0000200.0000180.0000830.0000190.0000170.0000170.0000210.0000690.0000180.0000170.0000220.0000210.0000190.0000190.0000231.5236371.5970181.7024572.2277870.0372000.0006350.0000300.0037150.0000750.0000270.0000890.0006992.1956600.0318400.0004910.0000310.0000170.0013230.0000360.0000240.0000382.1761320.0279760.0003720.0568332.1480230.0262192.1477020.0293282.2348151.7393830.0200120.0003080.0000222.2907390.0251900.0004790.0008430.0000340.0000570.0041740.0000630.0000170.0000160.0000170.0000190.0000300.0000270.0032840.0000510.0000261.0868250.0101160.0001340.0000232.0623872.1456412.3764093.9353961.2946911.2556420.0109100.0001090.0000190.0000180.0000170.0000160.0001160.0000180.0004050.0000770.0000320.0000170.0000170.0000160.0000170.0000180.0000160.0000170.0000173.0676272.9404350.9945420.0071721.5315801.7763820.3178602.1413040.0184480.0016690.0000270.0000160.0005140.0000760.0000160.0000180.0002110.0000180.0001160.0001040.0001580.0134430.0001032.3755570.0148700.0001100.0000710.0000290.0000190.0000200.0007180.0000370.0000190.0001120.0000780.0000180.0001210.0007780.0000510.0000260.1751940.0010110.0000430.0000210.0000250.0000250.0000190.0000220.0000190.0000190.0000190.0000210.0000200.0001560.0057230.0002700.0001970.0400620.0005640.0001120.0000290.0000190.0000690.0001720.0001350.0000390.0000200.0004020.0000930.0001201.7849690.0086410.0000801.9445280.0093480.0000700.0000590.0000720.0000260.0000250.0000761.6269600.8335040.0047241.3033231.3223160.5778970.0026240.0000320.0000190.0000200.0000180.0000250.0001050.0037380.0000340.0000170.0000170.0000370.0000180.0000160.0000170.0000160.0000170.0135690.0000730.0000190.0000250.0000230.0000170.0000750.0000320.0000200.0000200.0000200.0000190.0000210.0000270.0000220.0000180.0000190.0000191.6616740.0064350.0000460.0012760.0010740.0000210.0001120.0000171.8863560.0071580.0005580.0001250.0004290.0000280.0000280.0001260.0000680.0018870.0000300.0000410.0000260.0000220.0005600.0012650.0000261.8357441.7451470.0061640.0000420.0000280.0000311.7436021.6881080.0058220.0000410.0000680.0000170.0000580.0000620.0004730.0000750.0000170.0000730.0004970.0000300.0014480.0000210.0000170.0001180.0005740.0000620.0000720.0000390.0001090.0000600.0000170.0000220.0012400.0000450.0000160.0003280.0004060.0001620.0006840.0000230.2491010.6429130.1397360.0004470.0003120.0000740.0001540.0006820.0000720.0000190.0000270.0000180.0000200.0000180.0000170.0000180.0000220.0000200.0000180.0000180.0000170.0000190.0000190.0000180.0000160.0000180.0000280.0000180.0000270.0000170.0001480.0000200.0000170.0001600.0000220.0000160.0000210.0000230.0000260.0000300.0000220.0000200.0000200.0000200.0000340.0000190.0000170.0000210.0000600.0000171.8415470.0049430.0000480.5340680.0014360.0000250.0000190.0000210.0000480.0000270.0000270.0000200.0000190.0000200.0000250.0000280.0000230.0021730.0000300.6817390.0018031.1153690.0028960.0011020.0000250.0005490.0000200.0000190.0000180.0000170.0000200.0004100.0013010.0001210.0001470.0048811.8613882.5745750.0063210.0004000.0000170.0000530.0000610.0020000.0001110.0000170.0027130.0001070.0002020.0000380.0000220.0002930.0000160.0000290.0000170.0000170.0000190.0000220.0000470.0000230.0003630.0000940.0000190.0000160.0000270.0000220.0000220.0000170.0000170.0001230.0000160.0000250.0049621.7300901.6511481.2277250.5318650.0019320.2660440.0007210.0012130.0000310.6755070.0165260.9471840.0020890.0000730.0000682.1926620.0048100.0000800.0000300.0000200.0016690.0011790.0000690.0000750.0002000.0000190.0000220.0000160.0000171.0862601.3969570.0029470.0000750.0000440.0000210.0000260.0002280.0000970.0001520.0001640.0750040.0001810.0000220.0000190.0000280.0000250.0000340.0000420.0032540.0081170.0000730.0003770.0002610.0004780.0002820.0000420.0000170.0000250.0000160.0004210.0000190.0009560.0000230.0000180.0007590.0000220.0000170.0000260.0000170.0000160.0001020.0000170.0004980.0005530.0000180.0000220.0001390.0073360.0000340.0010020.1087050.0002290.0000560.0106790.0003040.0013320.0000500.0020730.0000470.0000200.0000770.0000180.0000170.0000170.0000160.0000620.0000620.0000660.0000180.0000180.0000170.0000160.0000160.0001180.0000160.0000160.0000800.0001170.0000170.0000860.0000311.3339530.0028910.0000731.6743821.2328150.0037230.0000340.0000320.0000470.0002830.0000200.1999941.5207570.0026830.0002550.0000800.0000161.7288315.2178610.0096770.0004530.0014450.0001360.0000220.0000160.0001230.0203130.0000520.0000720.0000170.0000160.0000230.0002260.0001900.0000220.0000170.0005880.0005840.0006660.0001170.0000190.0005300.0000190.0000160.0000170.0003980.0000620.0000180.0016340.0000190.0000160.0001220.0000160.0000160.0000591.8384820.0039090.0000221.4551520.0024240.0000620.0000160.0000221.8947470.0030670.0000700.0000160.0000160.0000610.0002450.0000470.0000210.0000690.0000620.0000180.0000192.3255010.0036960.0003472.1462560.0034051.9100580.0030330.0000360.0000902.3304490.0036790.0000270.0000400.0000300.0000390.0000200.0000310.0000460.0000831.3307002.9164710.0073880.0015220.0008800.0000181.1907060.0043840.2290240.0351270.0011331.1258620.0064610.0001490.0017260.0001410.0003050.6132520.1377670.1427090.0003340.0000292.0255240.0030221.9824571.9309211.9139610.0028362.0096101.9217730.0028360.6585601.0723410.0015820.0000240.0079990.0049180.0001310.0001870.0000780.0004590.0002060.0000440.0001140.0016760.0034020.0036680.0005670.2148281.7607540.0026060.0000840.0000170.0000180.0000270.0003070.0000190.0000270.0002670.0000180.0000160.0000170.0000160.0003160.0000170.0000170.0002060.0000160.0000370.0000890.3428080.0007140.0000180.0000160.0005270.0002370.0000860.0000160.0000730.0000170.0000162.3608671.8530943.9911190.0054470.0000341.8980641.7328500.0023633.8104921.7588750.0034650.0000240.0822690.0003550.0027620.0000220.0000160.0018620.0000260.0000190.0000290.0000191.3916650.0063660.0000260.0008740.0000220.0004620.0000250.0000180.0000360.0000200.0004500.0000170.0000200.0000190.0006350.0000450.0547640.0010810.0000240.0000170.0002110.0009350.1779490.0030440.0002610.0001890.0000950.0001130.0000190.0000170.0168950.0013230.0001340.0000190.0000210.0189540.0000410.0001250.0000230.0001250.0001234.7500227.0933760.0092400.0001580.0002170.0001490.0000740.0012420.0001490.0002850.0001021.5832951.2380470.0018720.0002840.0020270.0003080.0002301.8328182.1830560.4824350.0011810.3508990.0097733.4719230.0042500.0000220.0000500.0000240.0001150.0033300.0000310.0501270.0015820.0000220.0000460.0017000.0044980.5359780.0006700.0020143.1184792.3743130.0028550.0009750.0000250.0002000.0005840.0001430.0000500.0000170.0009560.0008610.0000240.0000191.0660330.8679290.0027710.0017830.0003810.0004320.0020810.0051440.0002440.0001540.0002030.0032931.3797540.0029750.4620540.0005560.0002170.0397720.0009550.0000760.0109532.5917231.2249250.0015240.0000231.3687270.9732370.0011280.0000232.0216600.0035240.0021960.0007670.0001000.0001440.4669760.9994490.0014390.0007400.0036770.6852790.0008520.0150940.0000690.0000600.0000850.0001590.2923760.0005410.0000600.9155960.0010440.0000200.4952060.0005670.0004030.0000200.0000280.0000700.0000220.0000330.0000260.6169262.4646990.0028440.0000230.0000920.7519940.8051001.0251630.0091660.3653961.1945390.0015940.3703302.8876830.0038570.0001010.0011750.0012480.0002940.0000630.0001390.0000210.0001840.0004810.0051640.0001610.0001400.0001080.0000700.0005410.0001450.2328600.0003210.0014243.7144455.1159351.2244540.0502320.0001240.0000850.0000980.0000580.0000360.0002100.0001470.0001450.1073040.0001720.0000870.0013940.6350430.8932110.0013080.0002250.0001030.0000940.0001440.0012950.0003940.0007050.0000160.0000170.0000210.0015000.0000510.0000290.0000310.0000200.0000880.0000960.0000190.0000380.0014290.0000250.0006170.0000350.0007480.0012140.0007130.0009870.5901360.0007450.0000530.0000530.0003320.0000330.0003750.0005580.0005820.0002360.0013820.0000260.0009460.0034540.0000200.0000190.0000191.3717810.0013780.3033980.0009960.0003630.0001950.0001810.0010760.0007380.0011430.0000190.0013810.3480390.0003620.0009340.0109190.0025220.0013310.0002150.0002200.0001270.0001902.9293400.0029190.0000780.0000220.0000170.0000180.0001630.9470970.0017650.0003980.0004771.3607901.2704890.0023340.0013160.0000180.0015570.0022350.0000180.0000183.1178373.7026941.8192730.0018651.7899000.0081950.0115660.0066640.0011330.0010750.0001340.0000790.0014170.0002171.3496300.0049550.4027990.0377160.0008900.0060390.0000321.9258440.0077340.0000250.0007700.0000970.0000170.0015800.0035680.0002170.0002610.0000160.0000161.0136250.0022200.0000900.0000160.0018700.0001010.1315250.0031160.0000260.0000160.0000160.0000150.0001290.0000190.0000160.0000160.0000160.0000160.0000162.2760630.0020760.0000180.0000160.0000160.0000170.0000170.0000160.0000160.0000170.0000890.0028490.0004510.0000310.0006940.0003960.0005410.0023980.0003580.0000160.0000920.0000290.0001190.0000160.0001180.0000660.0000160.0012950.0001240.0000660.0003000.0000780.0000650.0001390.0001100.0012650.0001150.0000550.0033700.0366370.0023190.0676954.0735500.3864594.1345520.9136560.0008110.0020792.9417471.3372290.0232780.0004450.0124370.2450743.6547994.9235760.0042630.0054860.0051740.0000250.0044220.0002380.0002040.0000170.0000180.0000160.0000300.0004801.1837561.3558510.0017370.5372410.8814460.0008750.0000190.0001240.0000640.0002470.0157040.0031440.0001290.0002230.0002800.0001830.0001540.0001480.0001700.0000410.0001420.0002190.0000170.0000830.0026670.0006380.0000910.0003820.0000170.0000190.0007860.0008500.0015992.0100390.4645702.0122560.0018130.0001591.4161383.1227441.7870360.0063660.0000220.0000250.0000290.0000830.0176000.0000310.0000200.0000170.0000170.0001760.0000200.0000190.0000170.0000230.0000180.0000190.0000950.0000220.0000190.0000170.0017080.0000190.0000190.0000460.0000210.0025220.0109980.0001381.2290920.0024980.0016616.0284431.9191243.4920495.7007202.3283040.0029560.0005100.0004420.0004360.0000181.1844500.0011162.7684070.0023782.5360030.0021100.0001050.0001050.0000910.0000160.0002090.0001140.0000610.0000630.0001010.0000160.3960550.5357010.0157390.2408711.1646711.9342960.0035460.0014520.0068020.0038810.0364610.0018980.0003120.0001660.0000650.0001480.0000350.0000390.0001090.0002060.0000180.0000190.0000200.0000460.0000170.0000160.0004310.0000180.0000370.0056760.0006220.0000182.0186192.3079630.0019520.0000250.0000330.0000170.0000800.0000940.0000180.0000200.0000170.0000190.0001450.0001390.0000310.0000230.0000320.0000670.0000270.0013870.0000360.0063230.0000270.0131870.0013370.0000210.0177530.0075400.0002340.0001742.1835720.0019640.0003670.0000180.0006210.0000190.0000170.0010540.0000250.0001810.0000260.0000220.0008390.0003310.0000170.0000190.0006330.0010990.0019180.0001960.0005980.0003240.0028460.0006640.0008710.0007340.0002140.0000911.9727140.0040960.0002330.0001290.0005180.0007410.4480902.2326711.4485272.3287063.8387052.4819002.1054820.0025650.0005570.0023310.0044960.0021040.4074770.4670980.0004040.0018090.0002990.0001400.0010060.0005430.0000610.0000350.0008430.0000761.6062770.0390390.0014822.1966220.0016110.0006740.0001691.1357420.0036640.0332640.0020210.0018150.0449640.0566140.1158321.9604461.4059251.6426211.6293912.4179041.5831351.3358250.0013930.0002760.5911200.0006830.0007000.0002230.0017010.0031020.0001610.0000180.0000770.0000260.0002600.0022740.5064240.0003760.0010410.0000370.0001940.0000270.0000330.0006070.0000230.0000210.0011860.0007660.0002120.1259060.0001191.4725020.0010470.6894530.3806020.0002840.0000270.0000350.0000190.0000221.1472080.0008141.1556990.0015060.0000210.0000280.7170920.0006101.0194030.0007900.0000300.0000300.0003690.0000290.0238051.8422540.0013420.0001380.1058690.0356840.0006400.0002850.0000670.0005670.0002090.0002880.0003920.0000180.0128770.0143280.0127190.0089971.9227440.0585860.0000620.8246560.0005730.0000410.8337520.0005860.0000250.0000180.0000210.0000300.0000211.8700410.0012650.0001370.0000160.0000170.0001550.0000160.0000160.0000940.0000170.0002770.0003543.7822170.0027990.0003400.0000170.0001420.0003312.0379300.0013620.0000180.0000210.0011340.0013280.3390810.0053210.0058260.7835285.2873953.8684961.4246351.1130192.0100531.0599311.5210570.0010151.7542401.7886200.0011870.0001840.0000350.0000204.0857420.0026801.8777410.0012391.8409870.0012120.5787170.0003910.2950280.9800820.0006501.5557790.0056170.0001310.0001821.4101850.0010090.0000910.0004630.5919890.0005840.0002030.0000680.0002620.0000540.0001410.0000210.0001750.0001290.0001022.3011943.9988371.9421560.0013260.0001052.3097531.9651352.0376803.9490352.2125801.8495204.0879750.0026084.0731400.0027452.0549553.8842220.0024660.0000480.0000160.0000160.0003380.0000160.0000170.0000160.0000160.0000860.0000160.0000180.0000170.0001010.0000170.0000860.0373970.0000440.0000160.0000160.0000290.0000161.8050910.0011380.0000200.0002650.0000160.0000160.0221000.0000290.0000891.5066330.0009530.0000160.0000160.0000150.0000170.0000180.0000160.7628320.0005010.0000160.0000210.0000160.0000160.0000160.0002350.0002620.0002690.0002450.0003540.0022530.0013830.9544112.0840340.0029020.0001800.4733881.6540632.1009712.5241640.0851944.0860302.2321311.3769340.0124530.0002410.0002210.0002311.3249450.8462370.0022260.0006000.3740350.0022750.6318950.0013290.2220350.0012930.0000160.3656410.3846540.0002470.0000200.0001470.0000180.4885580.0003080.0000930.4027810.0003110.2297250.0001540.0015520.0000170.4885920.0019470.0000200.0042240.9226200.0010840.0015670.1980810.0162060.0006450.0000190.0017640.0000710.0000190.0000200.0000290.0002490.0002320.0002440.0001030.0000180.0000230.0000350.0000241.3087530.0007860.0000200.0000240.0000230.0000180.0000210.0000250.0000170.0000520.0002130.0001343.5961613.6615571.7805255.6486924.7588065.8645661.1147030.0009490.0030220.5741101.2362890.0009480.0001960.0016720.0001650.0001020.8381650.0008161.1826340.8147420.0019040.0000990.0000201.1191610.0026140.0005420.0007950.0010880.0004890.0289930.0002494.9144011.6878593.0957733.7100751.4217530.0009610.0018951.2985280.0027051.8315511.8898055.2942382.4160141.7069671.7773600.0014010.0008780.0004100.0009000.0004800.0004350.0000330.0000180.0002600.0002400.0002650.1236970.0004140.0003000.0002380.0003670.2694650.0004802.1051762.2543460.0015004.5017592.1748811.0758160.0007290.0002140.0000160.0000200.0002080.0000190.0001280.0000760.0001960.0000800.0000160.0001170.0000190.0108230.0000250.0006940.0000180.0012950.0000180.0007680.0008320.0000170.0000190.0000193.6659510.0035510.0007720.0124720.0005170.0223380.7680850.0040160.0000200.0000230.1325610.0001170.0020160.0000201.4423090.8160851.2438050.0007250.0000241.3274821.8965041.6787320.9360071.5427810.0008610.0000272.1460530.0019670.0000180.0004360.0000180.0000220.0014360.0029500.0022950.0002721.3587260.9454512.2366281.7160590.0011990.0871150.7257940.0224790.0001570.1717010.0002660.5552480.0021820.3117710.0046901.7064520.0222960.0000830.0009981.1697190.0007240.3190981.5701940.0024162.1486360.7622131.5285041.0622690.0005860.0000170.0000170.0000260.9442680.0005290.0000250.0000160.0000180.0000661.0614543.0215900.0016190.0000200.0000170.0000175.1643971.2275540.0329360.0000470.0000260.0040900.0000211.2909820.0009100.0014260.0023810.0009100.0009730.0001100.0000380.0013190.0002910.0004380.0003190.0000960.0011510.0013600.0001040.0018042.2286840.0268822.3743823.8215433.1865354.1407373.3301580.9818982.6833361.6060880.0059370.0090890.0000650.0000190.0000210.0001050.0000180.0016690.0004810.0003900.0000170.2453260.0001430.0006880.0012970.0000160.0000160.0000160.0010400.1138290.0006730.0000160.0000180.0050000.0000240.0006090.0000180.0000170.0000180.0000180.0000160.0000180.0000170.0000161.5006801.1136130.0005860.0000170.0000610.0116500.0001260.0000180.0000170.0000220.0000170.0001711.4689180.0007631.4566200.0007640.0000200.9587500.0005012.5446410.0150450.0000701.6307810.0010400.0003031.0931370.0021170.0000700.0030130.0000180.0007490.0000450.0000770.0000210.0000190.0002150.0001120.0000750.0001990.0023260.0001050.0000720.0001480.0000780.0002000.0000780.0000160.0001531.3229160.3564811.6207080.0008250.0000170.0000190.0000191.5183072.0866430.0010560.0000181.4375880.0007390.0000171.4375871.3194380.0006700.0000180.0000190.0000481.2225931.3484490.0007370.0000200.0000300.0000730.0000200.0000180.0052080.0001490.0000220.0000190.0000190.0001250.0000190.0006390.7904930.0005550.0000210.0021370.0000190.0000200.0000190.0012740.0000250.0000220.0000291.2400730.0006321.3751821.6152830.0008170.0000190.0000260.0001421.7200681.6831470.0009360.0002271.5080410.0007490.1143370.7982870.6755961.4482591.6293130.0009371.2484570.1758831.4955660.1176580.0006650.9685930.0004930.0388060.4026240.0556440.0014440.7936980.0011740.0011080.0013230.0005900.0005720.0009300.0002571.4993101.2953312.1728881.6153610.7317000.0003750.0000981.7680470.0847450.0000650.0016920.0091770.0010800.0000210.0017900.0000410.0000200.0019600.0013830.0000210.0000220.0002510.0003420.0005490.0006730.0007400.0008032.5024931.7510470.0021551.6038730.0032140.0000990.0001580.0000170.0000230.0001220.0000240.0000681.6595150.0008000.0006000.0040380.0000182.4744500.0019693.4916124.8281041.4435000.0007030.0000200.0000390.0000190.0000210.0022180.0000200.0059720.0022510.0000171.0319131.0310420.0005130.0000850.0000170.0023700.0000200.0000170.0001170.0000260.0000211.7263853.5678091.8154630.0023120.0022780.0020025.1422550.7713220.0004230.0003051.7518130.0008720.2138440.0002103.2552680.0023620.0000770.0000271.2346620.0030120.1061072.4036271.6322622.9949080.0014850.4623401.5769260.0007361.1462180.0007590.0002530.0004120.0000420.0002860.0000630.0030750.0023070.0006830.0006140.0005900.0024730.0024970.0010060.0000170.0030800.0103260.0003390.0002580.0003210.0001960.0003350.0000930.0001550.0001920.0002180.0005091.1895280.0008530.0007910.0004110.0003030.0002500.0049971.3736860.3464061.3956730.0008490.0001010.0055540.0005960.0000290.0001840.0000280.0008854.5408963.0996052.5465261.5134380.1804250.2206260.0001310.0075630.0019520.1941260.0015840.0001230.9883660.0006130.0004920.5119830.9147691.5013540.0013251.6449490.2340782.4265240.0012211.3808440.0012730.0001850.0980390.0022600.0007100.1828080.9384210.0005430.6630470.0004350.4382210.1025040.0048002.7899170.2617500.0003080.7648200.6375050.5016461.5805460.0008990.6032661.3957410.8635400.0004750.9773420.1587421.2797520.2376950.6416070.3481820.4283690.0034240.5064812.8695830.0023740.1506980.2877640.0033500.2975010.7873390.5143080.0107000.2466290.0214560.4921321.2645192.3938210.0239650.0020120.0051850.0006400.7278560.0041600.6736141.2745741.3412932.4167680.0059960.0039200.9885412.1645480.0275260.0000891.2482130.0020350.0001720.4414220.0038952.6803610.0058311.2230960.1103770.2877082.1209351.3382010.1944311.7156900.2321510.0002441.8191810.0015941.4792190.4985580.3371981.8069630.3037660.2859060.2197370.6921140.3692850.0003950.3352980.2567821.5001830.2666560.3579680.3373700.0081110.0005681.0209070.0005720.5778940.1021970.9107751.6242630.0059620.4481210.2927010.9066641.1334340.3742040.6312710.0008624.0725840.0020431.3307870.5302132.5060880.5079680.1798670.0003030.4579580.1113610.0001830.0001850.0115410.0481020.6968410.0018020.5105530.0030870.2480410.2581160.4240042.0210291.6194180.0009040.0957012.1595130.0157450.1865420.0243151.5434470.0026610.0014860.0016780.5413310.0214290.0572901.4321960.0009811.0045790.3042290.0007103.5498190.0037030.0009630.2460560.2401990.8550970.0764840.0001341.5868410.0008790.2262991.9037540.0008830.0025210.0003811.0424840.0007020.2416610.6324640.0146940.0052010.1850241.1701480.5462251.1752530.0011700.2882861.3410300.3896151.3728171.9799420.9777370.6308852.7687210.7207940.1760531.4095490.0008430.0298090.0077832.0130690.0008640.5148330.4287091.4348110.2014640.4386330.7928960.0004980.5329000.3667080.0008900.0001350.3612520.3255910.8958320.0005481.0410191.2926470.0038780.0110790.0002150.1436900.2311860.0001450.0022430.0012450.0020911.4637770.0056640.0033910.3451271.4570080.3066632.3269650.4929940.0004700.6398250.0004252.8083890.1586410.0008411.1129270.4787140.0026050.0014980.4331730.0148451.7848720.0026460.0001450.9127680.8605802.6595661.1932950.5231251.5789532.2947560.0245710.0124650.0159280.0493900.9108111.6727290.0010140.0132530.8310210.0224940.0601280.0095050.0000400.0007720.4361330.3030931.8984301.7746250.7342211.0463231.5963520.0012940.2879610.5944550.4047050.9434802.1581840.4092720.9208070.0098101.9013570.0009330.2248091.0534150.0006430.7079180.4972610.0003880.0938541.3288780.2068790.5543330.1658410.5085441.7724840.0024750.0151100.0001610.8461680.0003761.0107510.0005180.0819680.9631830.0005271.3517280.1472100.6816230.6005851.4995100.0917710.4479080.0002010.6753892.6920631.6648790.9360940.7195820.0003300.0018380.0003282.1342282.0010270.3450960.4432220.9044230.0004390.0057010.2981660.0001580.0123002.4513372.4774350.2978171.7838740.6003980.0053381.4870840.3392170.0009332.4080620.0009730.7394810.0003150.0281850.0139410.0011090.1459940.7100680.1029610.0001710.8817840.0005230.9625780.3697011.6022380.0037340.6682220.0037651.7770970.5947211.4735361.6648170.0026581.7407150.0008520.0032631.2343020.3586590.1730170.0002620.0004640.0263140.1133920.2596860.6358440.1806020.0473992.8443770.0015041.9286860.5383420.4264491.8937100.0010910.3038810.0026970.0021190.0063810.0005311.1625440.0022190.3453461.5493311.6909110.3595660.0027820.0054800.0022182.2800950.0030650.4526870.0020130.0024451.2239321.0617400.0052940.0022580.0000350.0044562.0114030.0050900.0026220.0132010.6363280.3515700.3248070.0037090.3400730.0069560.0097961.9953510.2439852.6538960.0157190.0001782.0121150.0064381.5477821.5531810.4922603.2579911.1502221.0845800.8920070.0022750.0019170.0022980.0006901.5201470.0046630.0007400.0022880.0018320.0001490.0012463.1845650.0015510.0151021.2305100.5766460.3033231.3584400.4049860.0003130.2516680.4979260.9944060.4305840.2954380.1691850.5400900.0900660.0001480.1826080.0001450.5204591.1765730.1800910.0091830.0087820.6264860.4834740.0331690.6801570.0004240.0000480.4340110.4083420.9502130.6827660.3574670.0004460.0002610.0127151.2408930.2968830.3662150.5126800.0027611.4626940.3441240.3432310.0002610.0005640.6310450.0929200.0062271.8759881.9395501.1318441.6581660.4540240.1628202.4341680.0030670.9444340.1285980.0001000.3484060.0424610.0005650.5794820.1498300.1910380.0050950.0149170.0013111.2087750.0730160.0008940.0002650.0007790.0007150.0253790.0054760.0676981.3295071.3258380.9525360.0065890.5947352.4693570.2035250.0045520.0052311.2932482.3384630.0040812.8195030.0062430.0021340.0069230.0043603.8350670.1155380.6570790.1698760.0207230.0199370.0010840.0117910.8748180.0270400.6322960.3167050.6498130.0630850.0014881.0559270.0108060.0054840.0053230.0006980.8260910.6298330.8283990.2167960.0211452.1534270.6392801.5213040.3436970.0004140.3476331.8921350.3384240.9342320.6969550.3969990.4756091.8544470.0202340.0511760.2255720.3423212.3599920.1864072.3203811.2924750.0061671.3508280.0006740.4358471.6249030.0304060.0002610.6688301.4322460.0072420.0130510.0000880.4352620.0441830.0009640.8077250.9134130.6531000.2132570.4855860.0010160.3322281.5458620.4010650.3258990.5896630.5764470.2579011.4960671.0658100.2206250.5253990.2999580.2944750.2895621.5294780.0006060.0131880.0163280.8463311.5374620.8522250.5060710.6521540.0004130.0053990.2149400.0020960.0145600.0058000.0049960.8420910.1850681.3187251.6913990.0016380.0443060.0000400.5590590.3203970.0108333.6812860.0057181.1309950.3851601.3896710.7467741.1828780.0004741.4603330.1706200.0047820.0199690.5280210.0081460.2741970.0196440.0038721.8408811.2191373.3093611.5643762.4457051.1946602.3408560.0145711.1527350.7078390.0031841.5583420.1436120.4475990.0002600.3225940.2515350.2550460.6800920.4457370.0006490.0001690.3122820.1897210.3600751.3054821.1475790.0542400.0000930.7812031.9825710.1605820.8179231.8946000.0027710.0035111.6480850.0005890.0002030.0127390.1102172.9261560.6942490.408219

*******************************************
EVALUATING PIPELINE 
Pipeline directory: /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_2b71f0fa_2020-02-14_21-09-28awnqa5gn/
With following parameter combination: {'batch_size_seq_length': 1, 'lr': 1e-05, 'lr_type': 'constant'}
EVALUATION OF CHECKPOINT /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_2b71f0fa_2020-02-14_21-09-28awnqa5gn/outputs/checkpoint-3
-------------------------------------------------------------
|           |   agree   | disagree  |  discuss  | unrelated |
-------------------------------------------------------------
|   agree   |    636    |    93     |    135    |    17     |
-------------------------------------------------------------
| disagree  |    65     |    233    |    53     |     3     |
-------------------------------------------------------------
|  discuss  |    279    |    88     |   1481    |    68     |
-------------------------------------------------------------
| unrelated |    57     |    54     |    110    |   8526    |
-------------------------------------------------------------
Score: 8604.75 out of 9226.0	(93.26631259484067%)
Accuracy: 0.9141032106236342
F1 overall: 0.753481525375225
F1 per class: [0.6631908237747653, 0.5669099756690997, 0.8016238159675236, 0.982201486089511]
*******************************************


real	21m48.581s
user	25m3.776s
sys	6m45.528s
ubuntu@run-gpu-mg:~/fnd_implementation$ 
ubuntu@run-gpu-mg:~/fnd_implementation$ exit
exit

Script done on 2020-02-15 09:31:18+0000
