Script started on 2020-02-19 05:16:28+0000
ubuntu@run-gpu-mg:~/fnd_implementation$ time python3 model_grid_search.py --modell=bert --model_type=bert-base-cased --dataset_name=fnc_arcM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C.py --model=[1PM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C.py --model=b[1PM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C.py --model=be[1PM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C.py --model=ber[1PM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C.py --model=bert[1PM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C.py --model=bert [1PM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C.py --model=bert -[C[1PM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C.py --model=bert --[1PM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C.py --model=bert --m[1PM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C.py --model=bert --mo[1PM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C.py --model=bert --mod[1PM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C.py --model=bert --mode[1PM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C.py --model=bert --model[1PM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C.py --model=bert --model_[1PM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C.py --model=bert --model_t[1PM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C.py --model=bert --model_ty[1PM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C.py --model=bert --model_typ[1PM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Ce.py --model=bert --model_ty[1@pM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Cv.py --model=bert --model_t[1@yM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Ca.py --model=bert --model_[1@tM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Cl.py --model=bert --model[1@_M[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C_.py --model=bert --mode[1@lM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Cs.py --model=bert --mod[1@eM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Ce.py --model=bert --mo[1@dM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Cp.py --model=bert --m[1@oM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Ca.py --model=bert --[1@mM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Cr.py --model=bert -[1@-M[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Ca.py --model=bert [C[1@-M[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Ct.py --model=bert[1@ M[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Ce.py --model=ber[1@tM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C

/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/home/ubuntu/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/ubuntu/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/ubuntu/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/ubuntu/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/ubuntu/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/ubuntu/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
There are 2 GPU(s) available.
The following GPU is used:  Tesla V100-PCIE-16GB
INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-config.json from cache at /home/ubuntu/.cache/torch/transformers/b945b69218e98b3e2c95acf911789741307dec43c698d35fad11c1ae28bda352.3d5adf10d3445c36ce131f4c6416aa62e9b58e1af56b97664773f4858a46286e
INFO:transformers.configuration_utils:Model config {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": "multi",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 28996
}

INFO:transformers.tokenization_utils:loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-vocab.txt from cache at /home/ubuntu/.cache/torch/transformers/5e8a2b4893d13790ed4150ca1906be5f7a03d6c4ddf62296c383f6db42814db2.e13dbb970cb325137104fb2e5f36fe865f27746c6b526f6352861b1980eb80b1
INFO:transformers.configuration_utils:loading configuration file /home/ubuntu/fnd_implementation/bert/model_pretrained/config.json
INFO:transformers.configuration_utils:Model config {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 28996
}

INFO:transformers.modeling_utils:loading weights file /home/ubuntu/fnd_implementation/bert/model_pretrained/pytorch_model.bin
INFO:__main__:Loading initialized pretrained model from /home/ubuntu/fnd_implementation/bert/model_pretrained
  ******************************************* 
           Freezing Embedding Layers          
  *******************************************
 
name:  bert.embeddings.word_embeddings.weight
param.requires_grad:  False
=====
name:  bert.embeddings.position_embeddings.weight
param.requires_grad:  False
=====
name:  bert.embeddings.token_type_embeddings.weight
param.requires_grad:  False
=====
name:  bert.embeddings.LayerNorm.weight
param.requires_grad:  False
=====
name:  bert.embeddings.LayerNorm.bias
param.requires_grad:  False
=====
name:  bert.encoder.layer.0.attention.self.query.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.0.attention.self.query.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.0.attention.self.key.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.0.attention.self.key.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.0.attention.self.value.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.0.attention.self.value.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.0.attention.output.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.0.attention.output.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.0.attention.output.LayerNorm.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.0.attention.output.LayerNorm.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.0.intermediate.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.0.intermediate.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.0.output.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.0.output.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.0.output.LayerNorm.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.0.output.LayerNorm.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.1.attention.self.query.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.1.attention.self.query.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.1.attention.self.key.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.1.attention.self.key.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.1.attention.self.value.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.1.attention.self.value.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.1.attention.output.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.1.attention.output.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.1.attention.output.LayerNorm.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.1.attention.output.LayerNorm.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.1.intermediate.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.1.intermediate.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.1.output.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.1.output.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.1.output.LayerNorm.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.1.output.LayerNorm.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.2.attention.self.query.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.2.attention.self.query.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.2.attention.self.key.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.2.attention.self.key.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.2.attention.self.value.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.2.attention.self.value.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.2.attention.output.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.2.attention.output.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.2.attention.output.LayerNorm.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.2.attention.output.LayerNorm.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.2.intermediate.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.2.intermediate.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.2.output.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.2.output.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.2.output.LayerNorm.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.2.output.LayerNorm.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.3.attention.self.query.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.3.attention.self.query.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.3.attention.self.key.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.3.attention.self.key.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.3.attention.self.value.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.3.attention.self.value.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.3.attention.output.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.3.attention.output.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.3.attention.output.LayerNorm.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.3.attention.output.LayerNorm.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.3.intermediate.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.3.intermediate.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.3.output.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.3.output.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.3.output.LayerNorm.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.3.output.LayerNorm.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.4.attention.self.query.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.4.attention.self.query.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.4.attention.self.key.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.4.attention.self.key.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.4.attention.self.value.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.4.attention.self.value.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.4.attention.output.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.4.attention.output.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.4.attention.output.LayerNorm.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.4.attention.output.LayerNorm.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.4.intermediate.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.4.intermediate.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.4.output.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.4.output.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.4.output.LayerNorm.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.4.output.LayerNorm.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.5.attention.self.query.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.5.attention.self.query.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.5.attention.self.key.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.5.attention.self.key.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.5.attention.self.value.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.5.attention.self.value.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.5.attention.output.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.5.attention.output.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.5.attention.output.LayerNorm.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.5.attention.output.LayerNorm.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.5.intermediate.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.5.intermediate.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.5.output.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.5.output.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.5.output.LayerNorm.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.5.output.LayerNorm.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.6.attention.self.query.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.6.attention.self.query.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.6.attention.self.key.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.6.attention.self.key.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.6.attention.self.value.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.6.attention.self.value.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.6.attention.output.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.6.attention.output.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.6.attention.output.LayerNorm.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.6.attention.output.LayerNorm.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.6.intermediate.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.6.intermediate.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.6.output.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.6.output.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.6.output.LayerNorm.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.6.output.LayerNorm.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.7.attention.self.query.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.7.attention.self.query.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.7.attention.self.key.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.7.attention.self.key.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.7.attention.self.value.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.7.attention.self.value.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.7.attention.output.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.7.attention.output.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.7.attention.output.LayerNorm.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.7.attention.output.LayerNorm.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.7.intermediate.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.7.intermediate.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.7.output.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.7.output.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.7.output.LayerNorm.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.7.output.LayerNorm.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.8.attention.self.query.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.8.attention.self.query.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.8.attention.self.key.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.8.attention.self.key.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.8.attention.self.value.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.8.attention.self.value.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.8.attention.output.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.8.attention.output.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.8.attention.output.LayerNorm.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.8.attention.output.LayerNorm.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.8.intermediate.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.8.intermediate.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.8.output.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.8.output.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.8.output.LayerNorm.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.8.output.LayerNorm.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.9.attention.self.query.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.9.attention.self.query.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.9.attention.self.key.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.9.attention.self.key.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.9.attention.self.value.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.9.attention.self.value.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.9.attention.output.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.9.attention.output.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.9.attention.output.LayerNorm.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.9.attention.output.LayerNorm.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.9.intermediate.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.9.intermediate.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.9.output.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.9.output.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.9.output.LayerNorm.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.9.output.LayerNorm.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.10.attention.self.query.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.10.attention.self.query.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.10.attention.self.key.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.10.attention.self.key.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.10.attention.self.value.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.10.attention.self.value.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.10.attention.output.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.10.attention.output.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.10.attention.output.LayerNorm.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.10.attention.output.LayerNorm.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.10.intermediate.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.10.intermediate.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.10.output.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.10.output.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.10.output.LayerNorm.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.10.output.LayerNorm.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.11.attention.self.query.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.11.attention.self.query.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.11.attention.self.key.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.11.attention.self.key.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.11.attention.self.value.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.11.attention.self.value.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.11.attention.output.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.11.attention.output.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.11.attention.output.LayerNorm.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.11.attention.output.LayerNorm.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.11.intermediate.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.11.intermediate.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.11.output.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.11.output.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.11.output.LayerNorm.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.11.output.LayerNorm.bias
param.requires_grad:  True
=====
name:  bert.pooler.dense.weight
param.requires_grad:  True
=====
name:  bert.pooler.dense.bias
param.requires_grad:  True
=====
name:  classifier.weight
param.requires_grad:  True
=====
name:  classifier.bias
param.requires_grad:  True
=====

*******************************************
Evaluating the following pipelines 
['/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_6f7e679c_2020-02-19_02-01-090kbf7hlt/', '/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_7b45b6f6_2020-02-18_14-32-245l4g06ly/', '/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_5d678db8_2020-02-18_21-13-00669ominy/', '/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_6d174fb4_2020-02-19_01-56-35p_4_ab_p/', '/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_62ecba9c_2020-02-18_23-02-56bwnagayw/', '/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_6a80fab6_2020-02-19_00-06-39y8r0zluh/', '/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_67fd4e52_2020-02-18_23-53-42t33u4sfb/', '/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_7645cfce_2020-02-18_12-24-14prdl64xd/', '/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_78b0bd82_2020-02-18_14-14-01g90xeutb/', '/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_739798ac_2020-02-18_12-24-10rij2za19/', '/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_658239e4_2020-02-18_23-20-25qzd_eea9/', '/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_6048b07a_2020-02-18_21-13-04wmo6dyla/']

*******************************************

*******************************************
EVALUATING PIPELINE 
{'batch_size_seq_length': 4, 'lr': 3e-05, 'lr_type': 'cosine'}
INFO:__main__:Creating features from dataset file at /home/ubuntu/fnd_implementation/data/processed
  0%|                                                 | 0/11898 [00:00<?, ?it/s]  0%|                                       | 1/11898 [00:02<7:29:41,  2.27s/it]  4%|â–ˆâ–Œ                                   | 501/11898 [00:02<5:01:37,  1.59s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                   | 5501/11898 [00:03<1:58:30,  1.11s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                 | 6001/11898 [00:03<1:16:30,  1.28it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11898/11898 [00:03<00:00, 3034.66it/s]
  ******************************************* 
              Running Evaluation                
  *******************************************
 
  Length dataset evaluation: 11898
  Length dataloader evaluation: 372
  Number of epochs: 3
  Batch size: 32
  ******************************************* 
 
['/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_6f7e679c_2020-02-19_02-01-090kbf7hlt/outputs/checkpoint-3']
INFO:__main__:Evaluate the following checkpoints: ['/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_6f7e679c_2020-02-19_02-01-090kbf7hlt/outputs/checkpoint-3']
INFO:transformers.configuration_utils:loading configuration file /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_6f7e679c_2020-02-19_02-01-090kbf7hlt/outputs/checkpoint-3/config.json
INFO:transformers.configuration_utils:Model config {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 28996
}

INFO:transformers.modeling_utils:loading weights file /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_6f7e679c_2020-02-19_02-01-090kbf7hlt/outputs/checkpoint-3/pytorch_model.bin
eval_separate.py:214: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0
Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`
  for batch in tqdm_notebook(eval_dataloader, desc="Evaluating"):
HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=372.0, style=ProgressStyle(description_width='initial')), HTML(value='')))
0.0854740.0859110.2248840.1918850.0484410.0098980.0017980.5128350.3042250.3025991.0505560.3420830.0339680.1460670.4999870.0339020.0022260.4297700.1648530.2494620.0126570.0303240.0016490.0008590.3669970.2179630.0094810.3961350.0160240.0006560.0066060.0003210.1531840.2414800.0076850.2885210.3564120.0116520.0006950.0005460.1166000.0045060.0002150.0001190.0002910.0001270.0056850.0010480.0008080.0057760.0144860.3435710.0075610.0003050.0002820.0584160.1295480.3130220.0084820.0612430.1466430.3563880.0062530.0081300.0006190.0148160.0046540.0003990.0001860.0362490.0698390.0876530.0054870.0003280.0007750.0005050.0642750.0303350.0006790.5977940.2383070.4509280.7190510.5559600.3953290.6798750.0112331.2740580.0149050.0003770.2932150.8038920.8312580.0798610.4754250.0094580.0052860.0071200.0287631.1929370.0132890.3130530.5615420.0180440.1523720.0018770.4570510.0716070.1343070.2323670.0352160.0923760.0144870.0363970.6600572.0605160.3015490.0031310.2477440.1230240.0782960.0260880.1431240.0095380.2709630.0198120.3033290.0709190.0555880.3194530.3193921.2988390.5722050.1759480.2221000.1953220.1311630.0011000.2574180.0075120.0215090.0475020.1182120.7179031.8645220.0831170.2285490.0059460.0005490.0039260.3061790.4957760.0037790.0001380.0008280.5344920.3009710.5681870.0097160.0866380.1400050.0011770.1849840.2172740.0016970.0218520.2569390.0034700.0112410.0014420.1470681.5037540.1642310.0019290.034694^B0.111956^B^B0.092502^B^B^B0.113820^B^B0.2965720.0021320.1813130.2578250.1743620.113117^B0.0071790.197892
0.0849660.1618920.3301260.2035690.2248480.7848860.7755580.0572230.0008920.0004581.3633711.9602220.4514600.0024760.0074620.0036000.0052410.0602330.0027651.2074370.4335981.3252580.1060770.0039300.1395420.1172210.0020850.0052291.5272390.9187430.2390740.0464360.4490690.4168840.0470050.1311040.9403980.3151860.0019790.0011650.3296130.0436281.5490260.7615110.0394450.0901110.2783940.9100490.9396460.6974211.0251490.0690920.0008031.0202680.5070200.0997890.1790530.0091870.2787250.1025850.6395420.9164540.0055330.0005030.0417430.1907150.1037900.0070640.1505670.1106980.0095200.0043410.4514190.3188260.2055910.1985470.1231840.0102100.1179840.1629970.2147981.2399090.0637210.0118830.5576710.3002560.3354100.2245710.0038770.0127020.0014310.0370630.1052511.3893810.2243490.0039380.0149470.4167260.4358700.2176440.4679800.3164720.2149400.3238350.6764670.6211260.3986310.4186580.5695600.4238770.5935920.4974730.2611500.6883720.3261360.2964220.2833080.2481360.3539490.5494790.8298470.1588910.1433530.3204820.2426110.3703930.2288510.4308390.3144260.1484160.6636780.6444450.2953310.5499890.3698280.4217740.8357830.4587110.5119990.3177270.2893010.3918780.3440950.2154110.5770150.3380260.4099640.1829230.4129850.4974120.9277950.2841460.1783640.5805620.4246040.4216470.3146830.5924110.2906980.9089060.2156230.1506070.5007160.3296350.8880550.2642220.3118040.4259130.6504510.5275731.0611020.4621800.3104190.6416680.3601870.4241940.1933970.4602430.4176430.3141870.9633620.7045230.1579960.2751940.5485180.597049

*******************************************
EVALUATING PIPELINE 
Pipeline directory: /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_6f7e679c_2020-02-19_02-01-090kbf7hlt/
With following parameter combination: {'batch_size_seq_length': 4, 'lr': 3e-05, 'lr_type': 'cosine'}
EVALUATION OF CHECKPOINT /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_6f7e679c_2020-02-19_02-01-090kbf7hlt/outputs/checkpoint-3
-------------------------------------------------------------
|           |   agree   | disagree  |  discuss  | unrelated |
-------------------------------------------------------------
|   agree   |    659    |    91     |    125    |    24     |
-------------------------------------------------------------
| disagree  |    107    |    267    |    76     |    13     |
-------------------------------------------------------------
|  discuss  |    232    |    76     |   1523    |    75     |
-------------------------------------------------------------
| unrelated |    39     |    34     |    55     |   8502    |
-------------------------------------------------------------
Score: 8672.75 out of 9226.0	(94.00336006936918%)
Accuracy: 0.9204067910573206
F1 overall: 0.7667595849618147
F1 per class: [0.6807851239669421, 0.5735767991407089, 0.8265943012211668, 0.9860821155184412]
*******************************************


*******************************************
EVALUATING PIPELINE 
{'batch_size_seq_length': 4, 'lr': 3e-05, 'lr_type': 'constant'}
INFO:__main__:Creating features from dataset file at /home/ubuntu/fnd_implementation/data/processed
  0%|                                                 | 0/11898 [00:00<?, ?it/s]  0%|                                       | 1/11898 [00:02<7:20:55,  2.22s/it]  4%|â–ˆâ–Œ                                   | 501/11898 [00:03<4:55:48,  1.56s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                   | 5501/11898 [00:03<1:56:13,  1.09s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž               | 6704/11898 [00:04<1:06:04,  1.31it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11898/11898 [00:04<00:00, 2903.39it/s]
  ******************************************* 
              Running Evaluation                
  *******************************************
 
  Length dataset evaluation: 11898
  Length dataloader evaluation: 372
  Number of epochs: 3
  Batch size: 32
  ******************************************* 
 
['/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_7b45b6f6_2020-02-18_14-32-245l4g06ly/outputs/checkpoint-3']
INFO:__main__:Evaluate the following checkpoints: ['/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_7b45b6f6_2020-02-18_14-32-245l4g06ly/outputs/checkpoint-3']
INFO:transformers.configuration_utils:loading configuration file /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_7b45b6f6_2020-02-18_14-32-245l4g06ly/outputs/checkpoint-3/config.json
INFO:transformers.configuration_utils:Model config {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 28996
}

INFO:transformers.modeling_utils:loading weights file /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_7b45b6f6_2020-02-18_14-32-245l4g06ly/outputs/checkpoint-3/pytorch_model.bin
HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=372.0, style=ProgressStyle(description_width='initial')), HTML(value='')))
0.1523690.1746970.2165370.1227760.0347100.0074410.0016250.1409210.1869190.2850081.2338560.3787670.0354300.1780240.8234040.0566220.0036890.3398960.1879480.2446890.0142950.0618190.0038020.0046660.0180510.0404110.0043530.5742530.0220160.0009670.0246790.0010550.0414110.3911300.0135410.0361690.3466770.0174860.0011020.0008880.2204460.0067610.0003710.0005870.0017090.0004120.0012170.0273290.0050510.0312160.0713130.2033520.0679400.0017230.0021650.3555560.2561480.3644210.0098560.0362950.0080820.0050960.0043290.0123010.0006610.0499680.0207840.0008090.0003730.1127630.3463430.2754410.0889090.0016470.0013990.0010760.4572740.2350470.0048400.6340470.2345670.6375070.3693290.3034860.7742950.7786810.0276871.4285720.0210480.0016350.0103810.3387870.3022860.0811740.2091010.0035990.0539870.0204750.2203991.0992600.0127580.1788380.5223160.0664050.1571200.0052070.0415470.0141390.0361240.4483880.1503110.4420350.2408530.1866211.0630751.5086590.2221010.0043350.0434360.0418160.1242850.0237290.0326310.0037690.2075310.0265820.1457760.0257010.0412850.1949660.0754051.1554670.1831950.2452450.1379020.1328900.0849140.0012800.0026290.0065800.0010610.2002970.1102970.5998330.4944480.1996670.1651890.1394330.0017030.0139310.3203400.5142850.0043700.0003140.0005760.1321620.0820950.5557150.0330920.1224930.0211280.0007850.1510230.2213090.0016880.0189620.2544360.0175830.0637810.0254600.2520782.5464320.0238440.0140550.0333690.0335340.0980530.0838430.0523580.0040650.0819420.2423130.1058240.0427050.0715780.2329020.0574800.1049050.2063630.1462940.1662321.0524520.7790240.0283440.0052610.0063610.6951360.4913790.1463910.0011110.1161950.1691110.0778330.0961550.0074001.5600300.6270010.0241470.1482630.1173530.3987010.2833020.0047070.0286531.7458951.1181820.0286400.0743401.5424030.3890240.1123380.0705740.8988200.2776330.0019150.0011860.1743590.0375891.2663820.6631220.2395070.4938260.2289700.2959720.5810840.7335480.6379980.1850870.0187040.9705060.2880780.0028740.0308210.0006220.2436220.1566000.2239630.4062040.0028500.0006870.3223600.4534510.2144120.1229140.1084670.2479500.0081340.0462270.5525260.1964400.0096280.5575660.1069090.0083050.1719390.2376660.1578740.5234920.0752550.0882620.5188500.4939570.7173700.5384360.0066210.3129680.0023190.0045680.0395250.7126190.2177580.0149730.0219960.3280240.5828760.3082370.9805720.4293180.3891960.3058310.6948310.4501190.2316270.4020240.4288080.2677730.4285400.5397680.3948290.6377170.3934030.2532640.4485030.4833560.8429690.4460090.6869670.1740300.3545700.3115850.2908160.3928500.2645020.6930010.5703780.2404580.4938940.4959720.2479890.6192260.2948790.7556010.9928190.4442500.8437800.3112530.3803320.3699640.4035830.2147510.4115180.3677800.3591030.2283980.3198090.3070090.7366340.1916140.2206440.4473650.3794840.5092370.2758380.2774370.2579700.8438240.2559400.3427730.2726110.3666840.6049300.2899310.3157530.4155850.4249770.6445560.7986490.4631450.4205670.3330940.3849990.3641830.1852960.3740050.5243740.4352740.9068940.6084290.2377450.3684450.4175610.422258

*******************************************
EVALUATING PIPELINE 
Pipeline directory: /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_7b45b6f6_2020-02-18_14-32-245l4g06ly/
With following parameter combination: {'batch_size_seq_length': 4, 'lr': 3e-05, 'lr_type': 'constant'}
EVALUATION OF CHECKPOINT /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_7b45b6f6_2020-02-18_14-32-245l4g06ly/outputs/checkpoint-3
-------------------------------------------------------------
|           |   agree   | disagree  |  discuss  | unrelated |
-------------------------------------------------------------
|   agree   |    659    |    81     |    120    |    13     |
-------------------------------------------------------------
| disagree  |    148    |    295    |    94     |    30     |
-------------------------------------------------------------
|  discuss  |    186    |    56     |   1489    |    72     |
-------------------------------------------------------------
| unrelated |    44     |    36     |    76     |   8499    |
-------------------------------------------------------------
Score: 8659.0 out of 9226.0	(93.85432473444612%)
Accuracy: 0.9196503614052782
F1 overall: 0.7689467307431865
F1 per class: [0.6900523560209424, 0.5700483091787439, 0.8313791178112786, 0.9843071399617812]
*******************************************


*******************************************
EVALUATING PIPELINE 
{'batch_size_seq_length': 1, 'lr': 3e-05, 'lr_type': 'linear'}
INFO:__main__:Creating features from dataset file at /home/ubuntu/fnd_implementation/data/processed
  0%|                                                 | 0/11898 [00:00<?, ?it/s]  0%|                                       | 1/11898 [00:02<8:37:32,  2.61s/it]  4%|â–ˆâ–Œ                                   | 501/11898 [00:04<5:47:12,  1.83s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                   | 5501/11898 [00:04<2:16:25,  1.28s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š               | 6860/11898 [00:04<1:15:12,  1.12it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11898/11898 [00:04<00:00, 2741.93it/s]
  ******************************************* 
              Running Evaluation                
  *******************************************
 
  Length dataset evaluation: 11898
  Length dataloader evaluation: 2975
  Number of epochs: 3
  Batch size: 4
  ******************************************* 
 
['/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_5d678db8_2020-02-18_21-13-00669ominy/outputs/checkpoint-3']
INFO:__main__:Evaluate the following checkpoints: ['/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_5d678db8_2020-02-18_21-13-00669ominy/outputs/checkpoint-3']
INFO:transformers.configuration_utils:loading configuration file /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_5d678db8_2020-02-18_21-13-00669ominy/outputs/checkpoint-3/config.json
INFO:transformers.configuration_utils:Model config {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 28996
}

INFO:transformers.modeling_utils:loading weights file /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_5d678db8_2020-02-18_21-13-00669ominy/outputs/checkpoint-3/pytorch_model.bin
HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=2975.0, style=ProgressStyle(description_width='initial')), HTML(value='')))
2.1285772.1285961.0643160.3556230.8823790.1764940.0304940.0043750.0005660.0000810.0000280.0001010.3677860.0283100.0020410.0001540.0000280.0000200.0005180.0000450.0000200.0000190.0000190.0000190.0000190.0001000.0000220.0078250.0002960.0000270.0000170.0003030.9981400.0302680.0009100.0000460.0000190.5712860.0150540.0004200.0001060.0000220.0000190.0000900.0000200.0000190.0000190.0000190.0001010.0000210.0000190.0000200.0000190.0000190.0000180.0000180.9892630.9259411.1235282.1043080.0351590.0005940.0000280.0261740.0004270.0000251.9644040.0298661.9510310.0282930.0004240.0000280.0000180.0000400.0000190.0000180.0004262.2710140.0291480.0003871.7525082.3627650.0288322.3415372.1825202.3796021.0525510.0121160.0002250.0000202.2348940.0245770.0003140.0013770.0000330.0000200.0055040.0000760.0000190.0000180.0000180.0000180.0000190.0000190.0001430.0000190.0000180.0000810.0000240.0000190.0000190.8425101.1771601.3370012.8938011.3580521.5921130.0136810.0001350.0000200.0000190.0000190.0000190.0000240.0000200.0000200.0001240.0000210.0000200.0000200.0000200.0000200.0000190.0000190.0000190.0000192.1955262.5164252.3582840.0169841.4968000.0114210.0001260.0001200.6976191.2028270.0082570.0000750.0000210.0000210.0000190.0000190.0000360.0000190.0000900.0001110.0000220.0169660.0001262.3102170.0144570.0001080.0360130.0002390.0000210.0000181.7579910.0105480.0000801.2011050.0070890.0000591.8822221.8585440.0107000.0000781.8760390.0106170.0000780.0000180.0000190.0000280.0000180.0000200.0000180.0000190.0000170.0000180.0000190.0000250.0016152.2788540.0118872.2745420.0117731.9616820.0100370.0001300.0000260.0002070.0001600.0000420.0000280.0002310.0001160.0000190.0008250.0000220.0000180.0010410.0000840.0000170.0000170.0000180.0000180.0000170.0000170.0006960.4327330.0023132.0837460.2370280.0014800.0000250.0000180.0000170.0000170.0000170.0000170.0000170.0036040.0000330.0000180.0000180.0000170.0000170.0000180.0000180.0000180.0000180.8728740.0036390.0000320.0000180.0000170.0000180.0000170.0000180.0000170.0000170.0000170.0000170.0000170.0000180.0000170.0000170.0000170.0000170.0415530.0001790.0000190.0009600.0010640.0000220.0001430.0000182.1936820.0083590.0000920.0000940.0001610.0000690.0000280.0000340.0000310.0014230.0000220.0000170.0000160.0000170.0006550.0013650.0000221.4543571.4436970.0050830.0000340.0000180.0000171.5100791.6152900.0055680.0000370.0000860.0000180.0000820.0000810.0000290.0000830.0000180.0000790.0001210.0000180.0000180.0000180.0000180.0001430.0001420.0000800.0000790.0000180.0001460.0000800.0000180.0000200.0001800.0000210.0000190.0007320.0001021.7470440.0069090.0000570.3739430.0336390.0111970.0000560.0001720.0001080.0002661.4551050.0044760.0000320.0000180.0000180.0000180.0000190.0000180.0000180.0000190.0000180.0000180.0000180.0000180.0000180.0000180.0000180.0000180.0000190.0000180.0000180.0000190.0000180.0000200.0000180.0000180.0001010.0000190.0000180.0000180.0000190.0000230.0000180.0000180.0000180.0000180.0000190.0000180.0000180.0000180.0000200.0001040.0000181.1040130.0029690.0000250.9039320.0024150.0000230.0000170.0000190.0000190.0000170.0000200.0000180.0000170.0000170.0000170.0000170.0000170.0003640.0000190.0001440.0000870.0003980.0000860.0030270.0000250.0016200.0000210.0000170.0000170.0000170.0000170.0002030.0001990.0000860.0002051.2472410.1893600.0039220.0000860.0003610.0001040.0000790.0000781.3307320.0040120.0000300.0017911.9270790.0046560.0000320.0000200.0001250.0000200.0000240.0000200.0000170.0000170.0000170.0000170.0000180.7933670.0019060.0000220.0000180.0000180.0000180.0000180.0000170.0000170.0000170.0000180.0000170.0126571.2570191.9079721.0068391.0409420.0023370.0001030.0007810.0000260.0000280.7053900.0056241.0739960.0023630.0000880.0000201.8008100.0039810.0000880.0000190.0000180.0014690.0000520.0000180.0000820.0002050.0000180.0000180.0000180.0000180.0034800.0001990.0000180.0000840.0000190.0000180.0000170.0001350.0001120.0001730.0000761.9996870.0041250.0000270.0000180.0000180.0000180.0000220.0000221.7276472.4624620.0049890.0003020.0001200.0001670.0001680.0000180.0000180.0000170.0000180.0001060.0000180.0068000.0000310.0000170.0009460.0000190.0000170.0000180.0000180.0000180.0000290.0000170.0006010.0006100.0000200.0002870.0001390.0131880.0000420.0002160.0191560.0000540.0000180.0000190.0000500.0000440.0000210.0099360.0000450.0000170.0000850.0000180.0000180.0000170.0000180.0000840.0000870.0000860.0000180.0000180.0000180.0000170.0000190.0001570.0000170.0000180.0000830.0000200.0000180.0000940.0000181.4135210.0025590.0000221.3651862.8100122.0991610.0040210.0000250.0000180.0001790.0000182.0904430.8665170.0015380.0001290.0000980.0000182.1470166.1402370.0114110.0007650.0021690.0000770.0000300.0000190.0000980.0000450.0000200.0001400.0000190.0000190.0000290.0001700.0000880.0000180.0000170.0037590.0081550.0045030.0000910.0000170.0009630.0000220.0000190.0000190.0006050.0000210.0000180.0006230.0000210.0000180.0001370.0000190.0000180.0000782.0886530.0034250.0000232.1568280.0035800.0000820.0000180.0000182.1745930.0035190.0000870.0000180.0000180.0000770.0000190.0000180.0000170.0000770.0000790.0000180.0000182.2535770.0035960.0000302.2062770.0034822.1520530.0033880.0000240.0000902.2409650.0035040.0000240.0000180.0000180.0001020.0000190.0000180.0000210.0001190.0040790.0045210.0007080.0007040.0006830.0000191.4266891.9372921.3837840.0033230.0003020.0003440.0003520.0001730.0008250.0001472.0292690.0247712.0203721.3129840.0020890.0000231.5929190.0023771.0829841.3029781.5791380.0023430.9827481.1049760.0016387.8066183.9432310.0057730.0000260.0021440.0059090.0001110.0000910.0000980.0001210.0001730.0000320.0001630.0000930.0002710.0002730.0003040.9313930.0400920.0001500.0000200.0000190.0000200.0000210.0005850.0000230.0000240.0005840.0000200.0000190.0000190.0000190.0005760.0000190.0000190.0000190.0000180.0000200.0000910.0001620.0001290.0000210.0000180.0001280.0001990.0000860.0000180.0001230.0000190.0000222.0581651.8941772.8143350.0038420.0000231.9211612.0713600.0028183.2440941.8149310.0042440.0000231.3654100.0025570.0018390.0000200.0000170.0015050.0000200.0000170.0000170.0000205.4549920.0073630.0000270.0013700.0000190.0013570.0000190.0000180.0000170.0000180.0006410.0000190.0000180.0000180.0001610.0000180.0065460.0039750.0000220.0000170.0000240.0000170.0098300.0085540.0000860.0000830.0000770.0000800.0000180.0000170.0000800.0020660.0001110.0000180.0000171.0057930.0012880.0000870.0000170.0000820.0001054.4933466.7606930.0089430.0001530.0000930.0002260.0000960.0002952.3593910.0031150.0002470.0002320.0006290.0003340.0002690.0002790.0002820.0002170.0002901.6254814.0124570.0056830.0031930.0040902.5555270.0031300.0000200.0000170.0000160.0000170.0013820.0000190.1310770.0017430.0000190.0000170.0034670.0013951.1293090.0013690.0016511.5727240.6145720.0007520.0000840.0000210.0001050.2267520.0003510.0000180.0000170.0002300.0004120.0000180.0000170.7600082.1253640.0034260.0069990.0004440.0002870.0013150.0038420.0003020.0002150.0002810.0142790.6777560.0067010.1399640.0001790.0002251.6779930.7776790.0009720.0044993.8633511.0628180.0012340.0000491.5093801.3900140.0016010.0000730.0005980.0062160.6409501.7992610.0021800.0000860.0002140.0015470.0001560.2237080.0040900.0013050.0000910.0008710.0000950.0000870.0000980.0002240.0003110.0002270.0000870.0001730.0000210.0000192.1751720.0024220.0001000.0000180.0000190.0000210.0000190.0000200.0000372.1841933.9854500.0045130.0000240.0000862.1823202.1627780.0027100.0005341.0082873.0091710.0034661.1293662.7700570.0068120.0000860.0018130.0019280.0003070.0000910.0002630.0000190.0007540.0004450.0000300.0002780.0003150.0001950.0001140.0000260.0005520.0015150.0004000.0021302.7248245.4126041.2554732.1152150.0022420.0000200.0000180.0000170.0000180.0001700.0000180.0000801.6292010.0017140.0000190.0018470.9098640.0396060.0003450.0003310.0000880.0000820.0000970.0003330.0002580.0002770.0000180.0000170.0000170.6248640.0006580.0000190.0000180.0000220.0000170.0001120.0000180.0000230.0009840.0000180.0001050.0000190.0000890.0020730.0013410.0000331.2890460.0013750.0000210.0000450.0000250.0000180.0001990.0010440.0011630.0000200.0014270.0000220.0014060.0105110.0000280.0000230.0000180.8399310.0008500.3786443.0684891.3619690.0013600.0001910.0051440.0017490.0049570.0000231.3794400.0060180.0000252.4609661.5480350.9362311.3832990.0016200.0002760.0002050.0002761.5915770.0016480.0000870.0000180.0000180.0000180.0001392.8397930.0035690.0002850.0002580.0003930.2392920.0017600.0015590.0000180.0009040.0014840.0000180.0000170.0031021.9446850.0039030.0001070.0367420.0093390.0087180.0016790.0016084.7979900.0046910.0000960.0003660.0001540.0016800.0030021.2452860.0134710.0008030.0024930.0000231.4965770.0025380.0000200.0010730.0000830.0000200.0026840.9277820.0009340.0000770.0000180.0000181.1577880.2835400.0003360.0000180.1308890.0001962.1013680.4087260.0003920.0000180.0000190.0000180.0000910.0000190.0000180.0000180.0000180.0000190.0000182.1012530.0019200.0000200.0000180.0000190.0000180.0000180.0000180.0000180.0000180.0001830.0004390.0016340.0000190.0013730.0001360.7437710.7780770.0008700.0000180.0000840.0000170.0001750.0000190.0072750.0001020.0000191.5535270.0015620.0000950.0002630.0001180.0001151.3122350.0033180.0016620.0000980.0028530.0038361.3572810.0119761.6386320.7095820.0227703.6346381.3488830.0011900.0000870.9152381.0300280.2983530.0005850.0113411.1195071.2723201.4848390.0012970.0023310.0020810.0000190.9071420.0009990.0003080.0000190.0000180.0000180.0000180.0001092.5813681.4210000.0014861.2520220.7299350.0008080.0000190.0001030.0000940.0001860.0005660.0002460.0000200.0001480.0003410.0001470.0001670.0001670.0002370.0000180.0001610.0001230.0000170.0000180.0164800.0017780.0000800.0000840.0000180.0000171.9635480.0032511.7448352.7589391.8361742.2486240.0020820.0002302.0059904.3215052.3997360.0027560.0000200.0000170.0000170.0000210.0008010.0000180.0000180.0000170.0000180.0013030.0000180.0000170.0000170.0000190.0000170.0000170.0000200.0000180.0000170.0000170.0007310.0000190.0000170.0000180.0000170.0007010.0008100.0000180.0032360.0022390.0265494.3392071.4163612.4590654.1193882.9766530.0023990.0007450.0006810.0006530.0000181.8271500.0017064.5326770.0038526.2245240.0050850.0001660.0001520.0000980.0000180.0001650.0001680.0000900.0000860.0001570.0000183.8891472.8123530.4906920.0006260.0004430.0004551.9775300.6718932.8557702.7259561.6369291.0772100.0011510.0002570.0000892.0412580.0016070.0000230.0002130.0003800.0000200.0000210.0000200.0000200.0000180.0000180.0000260.0000180.0000210.0000210.0000360.0000182.0929142.2626140.0019100.0000210.0000180.0000190.0000990.0000960.0000190.0000180.0000190.0000180.0007140.0002590.0000190.0000180.0000180.0000900.0000180.0010810.0000180.0042390.0000200.0084010.0013360.0000190.0075751.1351860.0010070.0000192.2627220.0019860.0002300.0000200.0000850.0000190.0000180.0004570.0000180.0001170.0000210.0000320.0002120.0001480.0000180.0000190.0002630.0002270.0010550.0000880.0001020.0002260.0003320.0004070.0003630.0003280.0002290.0000832.1354040.0018210.0001750.0001050.0001550.0002300.0812152.8182942.6178623.9505273.9364355.3521212.4754100.0032240.0008810.0014900.0018790.0001220.0008830.0024840.0000930.0003410.0000230.0002330.0008830.0000950.0000890.0000200.0002380.0000830.0921580.5129050.0045510.5884920.0004400.0002340.0000900.0051120.0103360.0095270.0024910.0025321.4091703.1160573.0547772.6182771.5357031.1330701.0616752.3116921.1018722.5282802.5065532.3203341.7273631.8479712.3140810.2598340.8583472.4454440.1481370.0001220.0000840.0000180.9802211.3284811.1659070.0008440.0011110.0000310.0000540.0000450.0000230.0013280.0000280.0000270.0011620.0000790.0000530.0009190.0000190.6514880.0004690.4148050.0112970.0000250.0000170.0000170.0000170.0000171.2851270.0009021.3417990.0027930.0000190.0000170.9762730.0006871.1010900.0007750.0000180.0000171.2738200.0008872.6695911.5966060.0011700.0001360.0049351.5947310.0013730.0001020.0000780.0002200.0004410.0001740.0001760.0000180.0146120.0206060.0217190.0232080.8897860.4037450.0002892.3651450.0016070.0000191.3322770.0009120.0000180.0000170.0000170.0000180.0000191.9571770.0013260.0000960.0000180.0000180.0000180.0000190.0000180.0000860.0000180.0000950.0004094.8729380.0032490.0013090.0000190.0000190.0001032.1361130.0014290.0000200.0000190.0047130.0049340.1200020.0178890.6497550.0015150.0080290.0045610.0014160.0043721.9748571.9511601.9949830.0013212.0450571.8670300.0012350.0000190.0000170.0000182.2934750.0015081.8824160.0012392.0191820.0013260.0068710.0000220.0182890.0093000.0000230.0000960.0000170.0000170.0001380.0000780.0002560.0000820.0001500.0000180.0002160.0000830.0000780.0002680.0000180.0003950.0000180.0001690.0051560.0008821.0436741.8325690.9743920.0007040.0002330.9087340.9805242.1400372.1162701.0979691.8965122.2006930.0014112.1651760.0018350.6974142.1484620.0013730.0000180.0000170.0000171.1119440.0007170.0000180.0000170.0000170.0000870.0000170.0000170.0000170.0000830.0000170.0000841.5446270.0009810.0000170.0000180.0000190.0000171.5876140.0010040.0000251.3967360.0008840.0000181.4880650.0009390.0000831.5557700.0009790.0000180.0000170.0000170.0000170.0000180.0000171.3770510.0008670.0000170.0000170.0000170.0000170.0000170.0003990.0003720.0003740.0003970.0003750.0012680.0009590.0008550.0029990.0018820.0000850.0160551.9283691.5932112.9382970.4497152.0184200.9602021.0967660.0204100.0003380.0004760.0004612.3053154.5496726.2142281.7865473.1024222.1492981.0268852.0640651.6919013.9322980.0023811.4429171.2824580.0007860.0000180.0000180.0000172.9190410.0017650.0000282.3805190.0014392.8118130.0016940.0000870.0000171.4546451.5257670.0009250.0426260.9950140.0029000.0043111.4085500.4493640.0018760.0000190.0017480.0001100.0000190.0000180.0000190.0000930.0005520.0001620.0001570.0000180.0000180.0000210.0000190.0003820.0000230.0000180.0000190.0000180.0000440.0000190.0000200.0000180.0000190.0000210.0000953.0889713.5355161.4194084.6690481.5603273.9202770.0110160.0000890.0140860.0125480.0025240.0000770.0000210.0050040.0001460.2943900.0025820.0000810.0062130.0022390.0006640.0000200.0000180.0044520.0003010.0004660.0004640.0003070.0010210.0005730.0002910.0543780.0048050.0204810.0094430.0007370.0001960.0016121.6606340.0024482.1370452.1723505.9275272.5864192.0736851.9591500.0020070.0022290.0007880.0016390.0008130.0009810.0000190.0000180.0003500.0004040.0003360.1183490.0003930.0003310.0003360.0003910.0002990.0003761.6849072.2020110.0015873.9208472.0644601.3923770.0009490.0002760.0000190.0000190.0004050.0000190.0006740.0002080.0013500.0000980.0000190.0001860.0000180.0008910.0000180.0008260.0000190.0016230.0000190.0008870.0008290.0000180.0000180.0000192.5984270.0963870.0009250.0014210.0011650.0198151.9768070.0011100.0000220.0000210.0069950.0000210.0011540.0000180.7259121.6638550.4074210.0002420.0000181.0375650.9273951.1471690.4584941.8685090.0010400.0000211.6160260.0015600.0000200.0006770.0000180.0000190.0013560.0013680.0013480.0002152.3572970.9515373.1199922.4701920.0016182.1896202.6999052.9247890.0017290.0233910.0001691.5637811.9232551.5469711.6272741.9233191.3138340.0007870.0001160.3821490.0002820.5248580.4746970.0018551.4365673.7132344.4898460.7707800.0004290.0000180.0000170.0000170.9876180.0005430.0000170.0000180.0000170.0000760.7683833.2992890.0017670.0000180.0000170.0000175.5379401.3321481.2289710.0006660.0000170.0041280.0000190.0001520.0000220.0001040.0003690.0000840.0040740.0000260.0000200.0000860.0001040.0001940.0000190.0000230.0000840.0001600.0000190.0000412.1199320.0014612.3073683.9999823.2628964.3343694.3160892.1874104.3618392.2177050.0086400.0077500.0000240.0000210.0000190.0004830.0000220.0003270.0001170.0000950.0000200.0023910.0000200.0009600.0018030.0000180.0000170.0000170.0009512.3423840.0021580.0000190.0000170.0011380.0000180.0009540.0000390.0000180.0000170.0000180.0000170.0000170.0000170.0000182.0893202.0060240.0010410.0000180.0000222.0001740.0011820.0000180.0001090.0000200.0000320.0000751.9521080.0010102.0645710.0010640.0000181.9060770.0009823.2563322.1187500.0011672.4583990.0015940.0004501.3418010.0029430.0000180.0045480.0000190.0023330.0000180.0000980.0000180.0000180.0002090.0000910.0000930.0002500.0000180.0000880.0000790.0001700.0000860.0002630.0000850.0000180.0001841.2030330.0014820.3808580.0002070.0000180.0000170.0000171.3941601.2983760.0006620.0000171.1886200.0006070.0000181.1886190.9526710.0004890.0000170.0000170.0000350.9958920.3131480.0001720.0000170.0000180.0001130.0000170.0000170.3321060.0001830.0000170.0000170.0000170.0000170.0000170.0000180.0037660.0000190.0000170.0146960.0000240.0000170.0000170.0024900.0000190.0000170.0000170.0027910.0000190.0021710.0033400.0000190.0000170.0000170.0000750.0077250.0026460.0000181.1753471.4566100.0007225.0534778.1770614.9931996.8343816.3691240.0032230.0014450.0007680.0007980.0003980.0002760.0003810.0000270.0008930.0007570.0008420.0042491.4712040.0022300.0027000.0033820.0021380.0016890.0018160.0004442.0782380.6666820.8953330.0005792.7655740.0013360.0000820.0015831.5426820.0007520.0012370.0015820.0013730.0000180.0013540.0000200.0000170.0015800.0012720.0000180.0000180.0002640.0003330.0002730.0023600.0006970.0002671.6539130.0010820.0222302.3502220.0015040.0001020.0001100.0000180.0000200.0001020.0000200.0001242.0968280.0010020.0013370.0025390.0000192.4044570.0013890.0036521.3285080.0102100.0000240.0000170.0000190.0000170.0000280.0028600.0000190.0867090.0023540.0000180.5310320.5294120.0002650.0000180.0000170.0019940.0000180.0000170.0000170.0000170.0000171.5099173.0986011.8492490.0037080.0027830.0027530.0008860.0002100.0000850.0001390.9878120.0005360.0001120.0001600.0003850.0000780.0000920.0000180.0001640.0000780.0000380.0007590.0001920.0001650.0000180.0001930.0004020.0000180.0002800.0001360.0000780.0000750.0000180.0000820.0001010.0018570.0023470.0007110.0003680.0007281.8811891.5747952.2773260.0010493.1406631.7781800.0011420.1092710.0003850.0001650.0002510.0000830.0001710.0002540.0001930.0003550.0024160.0003480.0011580.0002700.0003410.0002590.0026510.0022220.0027370.0073400.0007430.0008102.1041110.0022920.0002340.0001620.0000220.0012043.7171002.7365283.6902871.8223250.1444110.1235100.0000790.0310690.0073570.0050810.0015270.0001890.0022520.0002870.0009240.2178250.0010140.0035060.0013630.0027940.0008610.0024300.0002341.2973300.0024560.0002670.0055920.0021900.0012760.1757751.0913980.0006200.6768800.0005270.9042711.3534940.0071242.1254810.3257020.0001781.6495281.1654850.6564880.5658550.0005870.2335550.9484490.4119210.0002360.6962100.4845972.5152890.7108150.6069501.9816460.4064361.7570200.9581451.3213930.0007670.4526741.1204350.0176790.9912372.6399430.4049370.3970010.4072620.6973191.6915330.0893121.5023620.5034130.0055820.0099690.0000490.0052610.0066161.7036560.0059051.0981662.8514420.0055530.0120681.5446542.6550530.0159610.0002600.9389300.0004900.0003580.9233030.0058842.5800610.0032020.5028820.4842430.9793420.9816510.1581690.2754581.7496271.9531350.0008640.6389770.0011130.3223950.5717140.1119062.2747390.1322470.1966930.2814490.4079610.3109190.0001500.1991370.5661943.9063152.2699751.5927020.4039900.0068750.0002740.6398420.0006740.0225691.0180640.6340011.0605680.0090460.4834420.0239570.0432611.4918150.0092660.0085600.4540193.5515300.0015830.7462030.0695842.0211950.6313030.0923680.0004490.0218720.0737370.0000510.0000200.0224350.0192510.7392820.0061030.9125861.3699690.0104120.1228121.0872660.2821852.8405370.0013001.0446001.6127560.0166321.9511340.0130821.1186950.0053850.0062470.0080860.0046610.0093880.0087011.3001100.0123991.0435450.3194570.0014391.8761020.0010390.0003290.0610260.3382561.6094830.1975820.0001340.0008370.0001031.2172871.6957330.0009340.0101670.0000321.3015740.0007530.0181920.4245730.0055240.0088060.0009730.3529171.0513101.0051840.0026691.1799791.4739690.0024251.6114201.9797891.7708350.0025050.5317110.0011310.7234790.9133730.0009190.0068140.5776271.9692870.0008450.0081780.4530330.3934260.0174200.0101400.2914300.0002060.3059820.7974060.0019030.0000580.8450770.9885780.3092190.0001530.2961461.4870260.0037730.4041050.0001860.2942060.5785850.0002570.0090220.0048920.0061621.1745140.0116050.2088990.0180650.5342940.2026341.3364980.1738200.0001920.3161150.0001781.0880940.2084990.0001560.7778581.2818680.0066180.0111220.0055760.0006530.8012720.0016110.0001161.6267070.6285271.5737712.8120662.2569700.0805190.0072780.0066910.0233020.0073900.0052991.1492452.0759070.0026840.6745570.7753840.0112750.0331480.0170850.0001340.0010060.2081070.1301461.3706600.5188700.9958420.7360942.2573760.0067880.0246091.1455610.5208380.0176182.0183691.1684721.3017060.0101060.4689080.0006020.6869840.9658080.0004490.0312891.0749470.0007781.1325160.5346610.2703310.3738010.0813862.3385571.5662550.0006650.0068110.0000250.0196110.0000521.0999190.0004590.0068981.0514530.0004640.7366790.0256850.0363970.7501340.0306320.0023330.0222700.0000291.3492892.2596410.3050181.0618580.6770940.0002970.0041740.0012332.4396772.4555550.9652000.3343930.5091490.0002160.0065260.5193300.0002350.0241391.2702170.5211050.0323960.3486190.5180740.0018240.7822840.2489530.0001313.3366650.0013590.5373230.0002280.0090660.0125750.0000501.9162211.3435880.0113600.0000611.1237330.0004770.5329780.4632840.4513600.6011720.0085620.1591890.1831600.5077790.3504150.6779361.2652172.6452900.3660870.0070921.0571151.0356100.1911180.0001850.0000920.1325040.5896550.5671870.4579520.4744500.1201642.6815270.0098250.2380970.4699660.3065293.4808540.0014560.1367380.0062120.0054910.0110190.0000321.2781610.0082601.1772051.1748490.0095371.2243370.0058510.0093860.0000422.3771380.0056000.4179240.0047740.0050091.1504491.1686370.0101510.0046050.0000220.0047591.8129480.0107750.0049210.4131360.9228980.5934930.4617230.0010410.0857990.0141150.0002400.4636960.8693252.1781340.3931980.0001792.2489950.9974162.3445201.7235350.3304263.5058891.0918221.0978090.0472530.0051800.0196410.0121780.0000551.1131760.0066890.0063720.0064820.0062420.0000220.0066522.2172920.7816180.2078530.6263040.1508220.3393220.8750710.2615340.0001190.2325432.0336780.7940820.8198930.7420230.0265161.6109540.0423040.0001790.0228640.0000731.0280342.3373280.1826270.0086030.0234490.9470480.8379740.0121870.8614440.0003380.0000611.3879861.2031871.3387950.4679151.4315370.0007180.0000840.0065771.4599290.3694780.6248970.7464720.0004180.5178090.3245620.2910560.0001330.0005150.5515740.1043550.0055672.0520852.6727331.8594521.9391881.3015140.0069882.9597310.0017271.0933960.0037580.0000210.0215970.0052720.0003920.9348750.0198850.0005880.0057440.0079770.0002731.1107741.0997330.0077020.0000310.0031970.0023923.0874290.0136150.0071831.0804501.3363120.0154130.9420850.7938290.9468870.1292830.0062480.0061391.0979522.8796100.0071843.2333540.0079900.0063580.0060360.0071653.2376520.9487070.9861620.9124610.0125440.0089860.5686980.0944391.0256270.0110841.0120620.3038471.1613150.0174350.0000740.1855870.0116430.0091350.4931730.4033131.9255320.7326520.8349330.0604270.0158593.1374020.0117030.7785560.1315630.0001941.4876200.5238200.0096530.2020650.5821481.9440160.9129263.0169540.0041000.0061840.3147180.3861602.9503990.4898283.0345531.3891930.0095022.7689260.0010010.3974671.1606900.3816220.0003481.5555620.6135290.2808250.0147280.0000510.2575840.0049960.0047790.0219901.3448282.0899530.9290180.5907840.0003090.2676690.6408380.0015110.5745340.5909270.0058290.0174610.4570261.3772360.0239161.2844540.5011020.0091160.3131281.4550800.0005340.0442050.0145271.8138480.4464360.5028590.3076400.3237470.0002210.0069181.1318250.0060590.0060490.0064162.5705910.0546500.3300751.1092031.6029090.0008410.0241770.0000390.9355510.5157370.0052240.5303930.0063971.1517561.6480011.1247560.1407652.4878040.0008731.0549550.0120700.0066380.0077511.1198740.0064120.8602670.0075980.0077540.2565821.0067542.3370582.9044642.8488352.9671072.6660440.0070460.9781522.7107700.0016251.4634581.2757200.0240280.0000450.0071550.0005920.0168670.0068330.9015990.0133510.0000280.2706910.0022650.2520791.2486091.1069670.0084170.0003001.3412662.1216410.2055670.5352960.2530510.0058190.6041840.0101490.0000230.0000300.0073500.0052953.2420010.9624961.871778

*******************************************
EVALUATING PIPELINE 
Pipeline directory: /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_5d678db8_2020-02-18_21-13-00669ominy/
With following parameter combination: {'batch_size_seq_length': 1, 'lr': 3e-05, 'lr_type': 'linear'}
EVALUATION OF CHECKPOINT /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_5d678db8_2020-02-18_21-13-00669ominy/outputs/checkpoint-3
-------------------------------------------------------------
|           |   agree   | disagree  |  discuss  | unrelated |
-------------------------------------------------------------
|   agree   |    683    |    132    |    171    |    34     |
-------------------------------------------------------------
| disagree  |    90     |    225    |    93     |    17     |
-------------------------------------------------------------
|  discuss  |    240    |    75     |   1465    |    72     |
-------------------------------------------------------------
| unrelated |    24     |    36     |    50     |   8491    |
-------------------------------------------------------------
Score: 8600.0 out of 9226.0	(93.21482766095816%)
Accuracy: 0.9130946377542444
F1 overall: 0.7403496989166771
F1 per class: [0.664073894020418, 0.503919372900336, 0.8069402368493528, 0.9864652918966018]
*******************************************


*******************************************
EVALUATING PIPELINE 
{'batch_size_seq_length': 3, 'lr': 3e-05, 'lr_type': 'cosine'}
INFO:__main__:Creating features from dataset file at /home/ubuntu/fnd_implementation/data/processed
  0%|                                                 | 0/11898 [00:00<?, ?it/s]  0%|                                       | 1/11898 [00:02<7:23:10,  2.24s/it]  4%|â–ˆâ–Œ                                   | 501/11898 [00:02<4:57:16,  1.56s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                   | 5501/11898 [00:03<1:56:48,  1.10s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                 | 6001/11898 [00:03<1:15:23,  1.30it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11898/11898 [00:03<00:00, 2975.84it/s]
  ******************************************* 
              Running Evaluation                
  *******************************************
 
  Length dataset evaluation: 11898
  Length dataloader evaluation: 744
  Number of epochs: 3
  Batch size: 16
  ******************************************* 
 
['/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_6d174fb4_2020-02-19_01-56-35p_4_ab_p/outputs/checkpoint-3']
INFO:__main__:Evaluate the following checkpoints: ['/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_6d174fb4_2020-02-19_01-56-35p_4_ab_p/outputs/checkpoint-3']
INFO:transformers.configuration_utils:loading configuration file /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_6d174fb4_2020-02-19_01-56-35p_4_ab_p/outputs/checkpoint-3/config.json
INFO:transformers.configuration_utils:Model config {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 28996
}

INFO:transformers.modeling_utils:loading weights file /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_6d174fb4_2020-02-19_01-56-35p_4_ab_p/outputs/checkpoint-3/pytorch_model.bin
HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=744.0, style=ProgressStyle(description_width='initial')), HTML(value='')))
0.4428020.5368960.2687320.0990180.2510800.0502750.0382750.0056840.0007740.0001540.0003250.0000860.0023700.0002410.8667790.2542220.0245030.4630050.0259450.4951551.0641401.0302250.5500710.0242150.0050480.0002610.0284730.3815351.6494360.0716220.0024950.0003130.0000680.0000600.0213111.1856250.0640150.0018020.0002280.4798460.0120570.4164310.0099840.3944970.4289330.0095900.0002660.0262250.4829420.0100420.0004850.0051520.0006100.0001760.2889410.8933430.0160100.0015690.0000840.0000610.1385140.0023270.0000940.0000590.0015910.0009840.4267830.0064880.0010910.0000750.3859910.2575100.9414670.0130280.0009750.0013280.0003280.0002080.0023500.0395850.0111870.0388000.2931780.0035900.0001000.0000580.0000580.0000600.0000600.0001100.0000610.0000600.0001060.0000800.0013680.0000910.0000650.0002720.0004760.0031240.0000970.0043830.7688460.0078530.0007480.0001870.0001510.0000600.0002600.0000590.0000560.0338030.0314940.6629620.2223660.5872340.0057660.0002880.0005500.0017710.0003180.0124750.0001580.1198630.0018800.0001950.0925860.0009180.0000620.0003250.0107480.0024330.0401210.0027530.0001320.0002230.0000590.0004060.0001790.3356860.5941970.0043160.6741740.1554110.0030510.1956880.0014350.0002020.0008580.0003460.0001600.0001690.0001711.3519040.0089030.4359610.0028880.0285630.4630830.7106370.4649840.0029450.0001220.0997990.2153460.5641690.5550520.0972760.1107690.6298890.5735720.0164590.0023360.0002900.3658842.0076030.0115580.0002180.0001580.0000580.4589450.2332010.0014450.9892500.3061590.7136190.0070180.0009090.8580670.0378340.0352590.0005620.0246530.0046510.0122200.0002630.0008650.0008430.0001972.3852810.0122890.0006920.0009450.2409300.4128600.6279740.0037070.0271010.0437730.9712420.1426910.0009690.4342051.0672770.0063450.0557330.4867500.2246130.1195220.6541140.0058120.0646900.3097320.3170020.2668380.2631130.4404660.0020001.1295550.8735201.7111713.2678160.6103610.0031250.0009320.0007120.0640130.7897620.0033750.2909650.0443740.0752990.0018710.0009100.1935580.0008930.0006470.0024300.4835630.0020040.0091300.0470660.3165140.0317580.0099090.1792840.0314400.0008160.4377930.2360250.0817230.3079770.0099422.2347270.4541530.9190990.4254800.0263360.3111140.0058390.0048770.4413170.1016990.0028820.0001140.0000590.4863560.0018130.0003120.0005430.0005790.0002250.3543350.0019600.0364380.0117370.0418051.4945271.1942950.4370120.0058290.0041700.0076050.8026520.1678400.0009580.0002880.0004060.0002340.0080650.0079751.2738371.0067910.4319910.0015910.0000750.0000580.0000630.0001590.0001650.0020642.3407341.9293770.4646471.2005790.0041980.0003080.3049970.0971130.0141720.0460500.0004880.0004080.0000600.0001080.1296130.4197390.0014840.0002220.0001940.0003000.0035130.6856730.5605980.0020100.0051440.0270460.0033530.0355230.0008580.3021040.0028022.9099882.2645280.0384730.1603360.0010640.0003940.1542370.3993910.0820850.0669320.0492310.0043140.3077500.4665400.5841040.0027340.0001760.0004260.1036640.7745120.4523510.4491510.5921240.1553040.0610470.0233510.0003790.0125150.1833170.1703720.1493960.0004590.2093550.0006150.0002260.0197220.4837320.0036730.1177950.2304291.1189600.7590720.9197390.7452890.2275100.0023620.0002970.0002620.0004130.0003541.1717190.6093282.0760640.8388140.6718890.0019190.0001150.0001580.0002540.0002470.0001930.0003420.0001640.0000570.0002300.0015040.2840400.0017850.6909152.3848560.3295360.9239330.1320350.0060950.0114820.0010480.0012530.0006660.0370160.0765360.1380530.0004200.0681900.0002190.0003380.0000650.0001023.4393472.3219500.2395230.5394570.3153790.5780460.0841990.8141961.5420170.3332410.4418700.3560810.1478270.1010110.5866570.0020791.7345660.7663980.0019850.0005180.0007560.0010140.0006280.3194600.0932020.1221750.0308351.6204441.5574080.9722110.5574190.0018840.2026310.0422710.0530740.5971390.2224810.1980270.4181871.1478400.2190590.0005551.4400591.6173420.0075200.2725890.0010190.0002920.0001210.3565480.9303240.4004940.0026270.0010440.0808350.0018290.1123680.0088950.0002930.0000610.0004840.0002510.0001180.0003420.0186030.0029990.0765670.0013790.0005010.0003320.0004830.0011050.1449250.1662360.0655090.1158830.1949640.0273920.0001580.0279890.0001160.0065440.1803250.0067100.0151230.0007960.1039250.1780250.3246300.0014170.0004880.0011410.0014690.0012911.1637120.3511000.0079730.0022350.0021050.0006350.3902410.1111690.0005190.3701990.0017462.2065370.6128030.0022000.0177540.0007810.0013451.0578210.0259431.0121330.4797730.6595191.0209770.4250930.6652600.0014040.0018640.0239670.0578030.0011400.0006030.0011690.4170200.2512910.1379680.0005671.9815580.0503770.0054480.0080300.0021650.0008500.0010470.3230440.3639930.6701490.4825140.4210130.1628680.7586090.4418830.1575750.2697600.3901740.1847220.0669860.4010740.5519540.3717380.8661210.9970880.5226780.3340710.7874120.3345020.5761880.2677910.4546170.3647490.4749430.8849631.2452450.2983530.0968030.5397900.5640391.1976360.5109730.0097150.1415030.2602040.1380770.3968420.3373200.2540370.1598090.5738280.6242030.8048150.5332510.7719620.2549810.0623690.2509610.1215120.3689300.1175840.3895070.2209590.0866320.5811890.3805470.3015340.3968590.9007940.4564710.5372270.2250610.1204400.4858420.6654891.2366430.4742410.1842640.3708820.7014150.7731710.3248760.1432700.4002860.3307141.3266970.2817880.9682090.0830180.9568040.6925680.4431690.1813550.3069130.2774750.7587880.2163350.8330580.2623330.0785230.0932270.8802190.5214440.1414020.4393590.8565170.2850710.2682720.2014770.4518770.2640540.0418510.7190731.4241610.8611620.2370180.2292920.0247320.4599800.6219690.4121650.5619500.3366900.7054100.3117370.1452400.6994640.1954071.0071090.4816180.2378680.9921341.1933960.1900960.0761880.3214700.1608750.2854300.4887590.6498910.3614241.2714610.6065420.2405500.2624740.4208600.0615100.3149660.4871430.7389620.5362090.5921730.5433861.3500220.7534110.5226810.4741430.1211970.3740470.3124100.6890060.2767300.3517780.7261690.5470610.3593780.0130060.5889420.1171210.4511110.5668320.4554180.1765890.2818331.3271690.8264360.6620450.1076120.1554620.2642450.3453831.0478440.1310190.0369781.448948

*******************************************
EVALUATING PIPELINE 
Pipeline directory: /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_6d174fb4_2020-02-19_01-56-35p_4_ab_p/
With following parameter combination: {'batch_size_seq_length': 3, 'lr': 3e-05, 'lr_type': 'cosine'}
EVALUATION OF CHECKPOINT /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_6d174fb4_2020-02-19_01-56-35p_4_ab_p/outputs/checkpoint-3
-------------------------------------------------------------
|           |   agree   | disagree  |  discuss  | unrelated |
-------------------------------------------------------------
|   agree   |    702    |    87     |    136    |    18     |
-------------------------------------------------------------
| disagree  |    105    |    289    |    67     |    12     |
-------------------------------------------------------------
|  discuss  |    202    |    62     |   1504    |    80     |
-------------------------------------------------------------
| unrelated |    28     |    30     |    72     |   8504    |
-------------------------------------------------------------
Score: 8686.75 out of 9226.0	(94.15510513765446%)
Accuracy: 0.9244410825348798
F1 overall: 0.7846879903409872
F1 per class: [0.7090909090909091, 0.614240170031881, 0.8293355390129584, 0.9860853432282004]
*******************************************


*******************************************
EVALUATING PIPELINE 
{'batch_size_seq_length': 3, 'lr': 3e-05, 'lr_type': 'linear'}
INFO:__main__:Creating features from dataset file at /home/ubuntu/fnd_implementation/data/processed
  0%|                                                 | 0/11898 [00:00<?, ?it/s]  0%|                                       | 1/11898 [00:02<7:16:09,  2.20s/it]  4%|â–ˆâ–Œ                                   | 501/11898 [00:03<4:52:35,  1.54s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                   | 5501/11898 [00:03<1:54:57,  1.08s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                 | 6001/11898 [00:04<1:14:12,  1.32it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11898/11898 [00:04<00:00, 2935.96it/s]
  ******************************************* 
              Running Evaluation                
  *******************************************
 
  Length dataset evaluation: 11898
  Length dataloader evaluation: 744
  Number of epochs: 3
  Batch size: 16
  ******************************************* 
 
['/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_62ecba9c_2020-02-18_23-02-56bwnagayw/outputs/checkpoint-3']
INFO:__main__:Evaluate the following checkpoints: ['/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_62ecba9c_2020-02-18_23-02-56bwnagayw/outputs/checkpoint-3']
INFO:transformers.configuration_utils:loading configuration file /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_62ecba9c_2020-02-18_23-02-56bwnagayw/outputs/checkpoint-3/config.json
INFO:transformers.configuration_utils:Model config {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 28996
}

INFO:transformers.modeling_utils:loading weights file /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_62ecba9c_2020-02-18_23-02-56bwnagayw/outputs/checkpoint-3/pytorch_model.bin
HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=744.0, style=ProgressStyle(description_width='initial')), HTML(value='')))
0.5382440.5973350.2996860.1011490.2625740.0525840.0093170.0015600.0002640.1990670.0200400.0018900.0002610.0000891.6148330.1077680.0068120.2382090.0133060.5116101.3614520.9676950.5231060.0231290.0023530.0001720.0002460.3663691.8841400.2866550.0097200.0005340.0000860.0000720.2694080.8011460.0235420.0007110.0001690.3604990.0090820.0002970.0000810.0000770.0000830.0000730.0000710.0014840.0001990.3453860.3660400.0074940.0004770.0000970.1147500.9484790.0170050.0020010.0001040.0000710.1272840.0021590.0001030.0000720.4316700.0491100.5016930.0080970.0024050.0001060.3942180.0210910.9166920.0126860.0003150.0004020.0001880.0001870.0001840.0004500.0069480.0428890.0131080.0002300.0000730.0000710.0000710.0000750.0000730.0001550.0000730.0000720.0001010.0074910.0018860.0000980.0000730.0008600.0005110.0007120.0000750.0018391.6650560.0163060.0146780.0002760.0002410.0000710.0003220.0000780.0000680.0440250.4683330.0655700.1890260.4634690.0044940.0042050.0031570.2601010.0055090.1858940.0015920.6544040.0066780.0002460.0000730.0002140.0000690.0003120.0018110.0017400.0004430.0022720.0001130.0001420.0000700.0001280.0001420.5193840.5062490.0036940.4703260.0083480.0037510.0746170.0006090.0001660.0006360.0005400.0001870.0002470.0001490.9130810.0060470.4901940.0032570.0001700.5086000.9686980.5084410.0032280.0001250.0022260.3336991.0189040.0282950.1318680.1207860.6499610.9752030.0395380.0022290.0002500.3718082.7809840.0160250.0002630.0001810.0000700.1125760.0055750.0001671.4319330.6700230.8371220.0123100.0004610.4547970.0030970.0005820.0002240.0037790.0033380.0319400.0003380.0003990.0015880.0001762.7829840.0142410.0004250.4137170.2897990.2920830.4284610.3094050.3067511.0109271.6320220.4317520.0023590.4256870.3084760.0031140.1041480.3167160.3800420.9873760.6907930.0055400.0005940.3727530.0549220.0135520.0382450.4896830.0022281.5311991.0260602.1289152.8386890.6296950.0244880.0037790.0010460.0094590.3905350.0017130.2442252.2727490.5544240.0035770.0006290.0010700.0000770.0022070.0071610.3790130.0016400.0049080.0173870.2327100.5477640.0060850.2476380.3622320.0018330.4449030.1991900.0020210.0632580.4639241.2914500.1506060.6996690.1295920.3885780.6068390.3903660.3267580.7246671.0141910.6056370.0023200.0000770.4844450.0018210.0095430.0042010.0003380.0002000.0004920.2770850.0089060.0058960.0573611.3487821.1176160.8101300.0696600.1632220.0480120.4092870.2593050.0012150.0002430.0002460.0001790.0012730.0023591.2268461.1912400.4828400.0026140.0000830.0000850.0000760.0006120.0004460.0023352.4488081.9848460.0593770.2143930.0009320.0002100.3995150.4869920.0338720.0152100.0002920.0002580.0000710.0001310.2145590.5034060.0016660.0001320.0001200.0002760.0037110.2265240.5145180.0017250.0004920.0005710.0009610.0007140.0007390.3837570.0382403.0004992.2715740.1635540.2052010.0036360.1704380.0064150.0227080.0029760.7727020.5943600.0154230.0232530.0014540.0091740.0007500.0004570.0003790.1288230.5609220.3364070.3989290.6441240.0018750.1354660.0114310.0004780.0135770.1760140.1402510.1807700.0005590.3276430.0009430.0001680.5722550.4563760.0057840.4460410.7597711.5502450.9818851.0547421.0039490.8311850.0022740.0002570.0002080.0003450.0002200.8378990.8455031.2671170.5458460.3830100.0904040.0003260.0001260.0408190.0805790.0005310.1505740.0022290.0000730.1002550.0005720.0024230.0096180.4226741.8389100.0919210.7983023.2950902.3894080.2204280.2608020.5476320.0495740.2562630.1336270.0356580.0001770.0010830.0000700.0001010.0000680.0000953.1722452.6994500.9860310.0169220.6189830.1910200.0245721.3528472.5962910.3047062.7539182.4960691.9523890.0047530.0007150.0009571.7689460.7961220.0019980.0003260.0003890.0004320.0003220.4486520.0971630.1060130.0012651.7296821.4280890.9434060.4737600.0015690.2866390.2908900.0527440.1276240.4194000.0802020.0275100.4943390.0916500.0002941.4260951.1929020.0349700.0021990.0003430.0003170.0000770.4859962.6521020.9307740.0054270.0033960.2960100.0011310.0274800.0005810.0002070.0000690.0351930.1010170.0003130.0865770.1949830.1820010.4143700.0024280.0009540.0003260.0002680.0004630.9525840.5275601.5395250.3137770.5107190.2572160.0006130.1231150.0003140.0145680.2693500.0411730.0081200.0003510.0022110.0022030.3967170.0028240.0011630.0029920.0739660.0020410.8887310.1471880.3209330.0341390.0074290.0006351.2640130.6510180.0016220.4130860.0017040.2291510.4834620.0018360.0036670.0006900.0010890.9617170.0038100.5844620.0690070.5681380.8613740.5328050.3857590.0008730.0031650.5321910.3227840.0012900.0046220.0010390.0006980.0028070.0046540.0002632.2999500.0850100.0238160.0013370.0010150.0009140.0010960.1038560.3373690.8356170.6744620.2100820.1258250.4240060.2534710.1414000.1475280.5827030.0517540.1479490.6363571.0690970.5857810.8231100.5773870.1409530.3699320.7862030.2915500.7072980.2868480.3966480.2585830.2871890.8635580.9520790.1791980.0822970.4884910.6395900.5137170.5581440.0368640.1555120.4840540.0509710.1361280.2582850.2031910.1181200.5418900.7127160.5450170.3731710.9340560.1493710.0509390.1385810.2232310.3785110.1779560.3725950.1001870.1558150.4482460.2359490.1524460.6678620.7448940.0426440.6716870.2542440.1019540.4617460.9029010.7822050.5130280.1123100.6652630.9328460.9202480.4817070.1499240.3915270.3047222.3167190.3466450.9410690.1417530.4747250.2750510.4842720.2198920.5198340.3194130.5362240.1906580.6772320.2883690.0320610.1745060.6424670.5998550.1565640.0349460.4797090.4669610.5839100.1974020.3685930.2470070.0614680.6496681.1071980.6313520.3512180.2417590.0259950.3311990.6531020.3867370.6786540.2299360.5970810.4254130.0944830.6236750.3277320.4383850.1447000.2679961.2605781.4282890.1847030.1683260.4586130.2363160.6133720.3519360.4399650.3603251.2259810.4655470.1811490.3915440.7256060.0728870.4937490.4813390.9608790.4378180.4964480.5834671.4918550.7718330.3822700.5864630.0349260.4499300.4219950.3798400.3316890.4629890.3847110.5810860.2577080.0323770.6674070.2780380.5198570.5996320.5833110.2115520.1968051.6608200.9548830.5595840.1217250.0953790.1427350.3173410.7192030.1098990.1718781.430692

*******************************************
EVALUATING PIPELINE 
Pipeline directory: /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_62ecba9c_2020-02-18_23-02-56bwnagayw/
With following parameter combination: {'batch_size_seq_length': 3, 'lr': 3e-05, 'lr_type': 'linear'}
EVALUATION OF CHECKPOINT /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_62ecba9c_2020-02-18_23-02-56bwnagayw/outputs/checkpoint-3
-------------------------------------------------------------
|           |   agree   | disagree  |  discuss  | unrelated |
-------------------------------------------------------------
|   agree   |    668    |    83     |    139    |    19     |
-------------------------------------------------------------
| disagree  |    103    |    298    |    80     |    19     |
-------------------------------------------------------------
|  discuss  |    240    |    56     |   1494    |    65     |
-------------------------------------------------------------
| unrelated |    26     |    31     |    66     |   8511    |
-------------------------------------------------------------
Score: 8684.5 out of 9226.0	(94.13071753739432%)
Accuracy: 0.9220877458396369
F1 overall: 0.777842612092606
F1 per class: [0.6865364850976362, 0.6157024793388429, 0.8222344523940561, 0.9868970315398887]
*******************************************


*******************************************
EVALUATING PIPELINE 
{'batch_size_seq_length': 2, 'lr': 3e-05, 'lr_type': 'cosine'}
INFO:__main__:Creating features from dataset file at /home/ubuntu/fnd_implementation/data/processed
  0%|                                                 | 0/11898 [00:00<?, ?it/s]  0%|                                       | 1/11898 [00:02<8:10:37,  2.47s/it]  4%|â–ˆâ–Œ                                   | 501/11898 [00:03<5:29:06,  1.73s/it] 17%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                              | 2001/11898 [00:03<3:20:03,  1.21s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                   | 5501/11898 [00:03<1:30:31,  1.18it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                  | 6141/11898 [00:04<57:02,  1.68it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11898/11898 [00:04<00:00, 2848.23it/s]
  ******************************************* 
              Running Evaluation                
  *******************************************
 
  Length dataset evaluation: 11898
  Length dataloader evaluation: 1488
  Number of epochs: 3
  Batch size: 8
  ******************************************* 
 
['/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_6a80fab6_2020-02-19_00-06-39y8r0zluh/outputs/checkpoint-3']
INFO:__main__:Evaluate the following checkpoints: ['/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_6a80fab6_2020-02-19_00-06-39y8r0zluh/outputs/checkpoint-3']
INFO:transformers.configuration_utils:loading configuration file /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_6a80fab6_2020-02-19_00-06-39y8r0zluh/outputs/checkpoint-3/config.json
INFO:transformers.configuration_utils:Model config {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 28996
}

INFO:transformers.modeling_utils:loading weights file /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_6a80fab6_2020-02-19_00-06-39y8r0zluh/outputs/checkpoint-3/pytorch_model.bin
HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=1488.0, style=ProgressStyle(description_width='initial')), HTML(value='')))
0.9200870.9203310.4695680.1567110.0392360.0091060.1375270.0196770.0024900.7755820.0775880.0070840.0006870.0143160.0010530.0003030.9634900.0567080.0031900.9516820.0476790.0024180.0001400.0000370.0001290.0000360.0000330.0000310.7136161.0602910.0354390.0106720.0003650.0191111.0047680.0287440.8924270.0241681.9906250.0511901.0207431.0419371.9557110.5970170.0136711.0672150.0237370.0005360.0050760.0001340.0000360.0000320.0001380.0000930.0000450.8695971.7483711.7379700.4612710.0078490.0001610.0000490.0001070.0001450.0000330.0000310.0000310.0000310.0870820.2970680.7646530.0108510.5708310.0078510.0001760.0000330.0001370.0001830.0272251.0892430.0136470.0002010.0000330.0001910.0000340.0000330.3503170.0040560.0000820.0000350.0000320.0000310.0000310.0000300.0000800.1767540.0019320.0013760.0000500.0001960.0001660.0001020.0000990.0007760.0016980.0001140.0000370.0006740.0005380.0424360.5284710.0050960.0000750.0000300.0000300.0535860.0004920.0000340.0000310.0000300.0785200.0006790.0000440.0000370.0000300.0000300.0001630.0000310.0000300.9556110.0079740.0003740.0001320.9966730.0075340.0001020.0000330.0022420.0000460.0000300.0005630.0004750.0007510.0000350.3877340.8843100.0061380.0001240.0002100.0000840.0005480.0006880.0000360.0002350.0001280.0001290.0000790.0004020.0000330.0002580.2340680.0155060.7435290.0047320.0003080.0003020.0000320.0000300.0000300.0000300.0000300.0000300.0000300.0000300.0000300.0000300.0000330.0000300.0004960.0000330.0000300.0000300.0000300.0000310.0000300.0000990.8054400.0043380.0027690.0000460.0000310.0000300.0000310.0000310.0000310.0007440.0008260.0006170.0015520.0013030.0000370.0000300.0155150.0004161.5386051.5180670.0074130.0001800.4947710.0254150.0002660.0000330.0004440.0000340.0000300.0000330.0001280.0000930.0000300.0000320.0000300.0000310.0048711.1854691.3569900.0451060.0002630.2941790.4728550.0021511.1130060.0049630.0000520.0005600.0001690.0007420.0000340.0006730.0003850.0000950.0000300.0003090.0009930.0188270.0001130.0000370.0000380.2688650.0013660.0003260.0001940.0000310.0000650.0001690.0000310.0002640.0000310.0000300.0000360.0005280.0000370.0229740.0005750.1678560.0047310.0019810.0057650.0000630.0000930.0000320.0000900.0001440.0000320.0000320.0001590.0000320.0000880.0001100.5414520.2361751.3859350.4360430.0015770.0001021.1165340.0041940.0002322.5406100.0092870.0018860.0000390.0008350.0001020.0000310.0001880.0001100.0009080.0018960.0000910.0007280.0000330.0002060.0003350.0000320.0001320.0000860.8778370.7914750.0027010.0000420.8624030.0028560.0000920.0000340.0000820.0000821.0177620.0032560.9524420.8167630.0026701.0083670.0031620.0000480.0000310.0000950.0025760.0006180.0003050.2063000.4207950.7875990.0036160.2674570.0058921.1992720.0037160.8726520.9788400.6686391.9655290.3382550.0140630.0052040.0048950.0001690.0002730.0001960.0004330.0006080.0007050.0001160.0000310.0002190.0000310.0002140.0000310.0002180.0000310.0000310.0001770.0006150.0000360.0009370.0001720.0000990.5500611.5090010.0041310.9090510.5060230.5176260.0035210.0021700.0000350.0017520.0000341.0046000.0030550.1057030.0080680.0000510.0002710.0000310.0000510.0003260.0017320.0000360.0004090.0040710.0002300.0000930.0001080.0009820.0000330.0071440.0001140.0001775.3832500.0140050.0003660.0005941.0008490.0130140.8347410.9334050.0026791.2468490.8663540.2891481.2770190.0031370.0000370.0008530.0137210.0000640.0027970.1477091.2326701.4141590.0039520.0002680.0001200.0001670.0001190.8621321.4357770.2389880.0014210.0013650.0004580.3186090.3007480.0010680.6147881.1424410.0059600.0000461.4334990.0033530.0007050.0021720.0002160.0006140.0023180.6520270.3041040.0008440.0002940.6564670.3100230.0007221.0225580.0023590.0000380.0000331.0691902.1358790.0047502.1177570.0049242.3412400.8073681.6497850.0041780.0023430.0076220.0002430.0006320.0007940.0002840.0002860.0005060.4616011.4527270.8135580.0017420.0000350.0001720.0428600.0001230.1321040.0300960.0032240.0001850.0004960.0002400.0000310.0001570.0000310.0000320.0000350.0007020.0000870.0001200.0028620.9192040.0019210.0000490.0000320.0050940.0004430.0004060.0012830.0001060.0280060.5373050.0015390.0010700.0015030.0005950.0048690.0024380.0022550.0005440.0004580.8846660.0018000.0000330.7388210.0022070.0567500.6571110.1808580.6958550.0013570.7005170.3280310.1555110.0191020.0012220.0002180.0242360.0014680.4866500.0020740.7025440.0018740.0006450.0008460.0160980.0002060.2966710.0028820.0037760.3900200.0055580.0000410.0001230.0000310.0000310.0000310.9951270.0018310.0000350.0000310.0000310.0026110.0008410.0002030.0003540.0001790.0000940.0003170.5043360.1100630.0006500.8919210.3668920.0030930.0000370.1248690.0029280.1009943.2767470.0058532.3417010.0083600.2381811.0524420.0047460.0520280.2442150.0007630.0000320.0018411.9715780.6331920.1649120.0003690.0002180.0002500.0001520.0002240.0002690.0001100.0002480.0000501.1192860.0021480.0000340.5567002.3967282.1294410.0039043.1200591.1283750.0018890.0009080.0006350.0000300.0000900.0000290.0000320.0000460.0015500.0000320.0003870.0005080.0002980.0309210.0387421.1033191.7305141.1520430.0023070.0004050.3006251.0419432.0388980.0034990.0002060.0001430.0002110.0002000.0251600.0033270.0010960.5904561.4022372.2428220.0069510.0003580.6387490.0011770.0003340.0000320.0000310.0000470.0000310.0000340.8105670.9504590.0014870.0001660.0001700.0000310.0004060.0002470.0000310.0002180.0012820.0012610.2936060.0101101.4665790.9599960.0020110.0001030.0000300.0002580.0001500.0002600.0001530.0002910.0004910.0001870.0005280.0006910.0005480.9363620.0017910.0001880.0028983.0092404.2830695.5890010.0089090.0606700.0135550.0005410.0006810.3027830.0005870.0002150.0006670.0051590.0015000.0003260.0190960.1970120.2986182.4678110.2057560.0091860.0288230.0205080.0003760.0914190.0007150.6462480.0009910.0002931.3545080.0029070.0174000.0000540.0002260.0002300.0000920.0002310.2121890.4462080.0006460.0000300.1930060.4935860.0011090.3021340.3481850.0005070.0065350.0024000.7954640.0069730.3422250.0006520.0007410.0003950.0062880.0316840.8762460.0487430.4241670.4666140.0006570.0000310.0000300.6876960.0015430.0000330.0000310.0001570.0002951.5742550.0021390.0003610.6054010.0008290.0023130.0110730.0040710.0063680.4849671.9315791.0440202.0303170.0026780.0000341.9966241.0310461.0645440.2065481.2971090.0018080.0000960.7966870.0011820.7960890.0011710.0002700.0001570.0001540.0002392.5846170.9136060.3817310.6219682.2568172.2787751.7137050.0040741.2416830.0015960.0001860.0000310.0000310.0000950.0000310.0001180.0002550.0000310.0000310.0002840.0000320.0002200.0001710.0000980.0001750.0000310.0000310.0000310.0001750.0000310.0000310.0005800.0007430.0319110.0010010.0013480.0008540.8536615.5634831.6762921.5456560.2425150.0014472.2422730.7673351.1847970.6623000.5749290.0013250.2592960.0003690.4834470.0006650.5292460.0024510.0001330.0010490.0119340.2391630.0341670.0254380.0009320.0001300.0000300.0016980.0004980.0000310.0000300.0004360.0000310.0000310.0000310.0000330.0001333.1657013.2609621.6594360.2126750.0103540.0008960.0009090.8903090.0071180.0019490.0303270.0034890.8612300.7376730.9163671.8630601.9666981.3423210.0047940.7189611.9224353.7676053.3564851.9324872.3443461.6261930.0018720.0006290.3077690.0009240.0005490.0010221.8196301.6948721.7537830.0022910.0000340.0002110.0002120.0002730.0001510.0003370.0002810.0004480.0002630.0003220.0000310.2209880.0011380.0010210.0666350.0001080.0865810.0026942.0941680.4458051.0917142.1682092.1477130.0023771.0908300.0013970.0000330.0012170.0007401.4142071.3562290.0202180.8578480.0132850.4828140.0053450.7199570.2943751.0126640.0521140.6853040.1600471.8277050.0019800.0000320.5923880.0006600.0000873.1596360.0033800.0000334.1086960.4136020.0361320.0002190.0001030.0001260.0001660.0001130.0001120.0000320.0000600.0000561.5793332.3468912.0954610.5090110.1076270.0078950.0000390.0004410.0019210.0005030.0232470.0003720.0004950.0000310.6884120.0009900.0006540.0002820.0000360.0000310.0000300.0000310.0032070.0000330.0003780.0001500.0000320.0001030.0056640.0011660.0004610.7591920.0013230.1613680.3875740.0020340.0043520.0017490.0000930.0002240.0001700.0002300.0001680.0002360.0003810.0001740.7684140.7796700.0008060.1116471.6332190.6780670.0007071.2639660.0012810.0000321.3038720.0013170.0004510.0000330.0069980.0000370.0000300.0001820.0037310.0059230.0000360.0015470.0000340.0023960.0013570.0012040.0000320.4212180.0016230.4312210.0022010.0274480.6202500.0011670.0005060.0003240.0002900.0004320.0047150.0027200.0069200.0044810.0025151.6406331.1140020.8312700.0040350.0043650.0039120.0016680.0047510.0019870.0641050.0003590.0005590.0020861.1175230.0018161.9758010.0022730.0000330.0001690.3828010.0007890.0008850.8108422.8083490.5567130.0005500.0000300.0028310.0123260.2338160.2320630.0002450.0727430.0001010.0000302.5435910.8961640.0020111.8147230.0018710.4510340.0011991.2932990.0012710.6386871.3649930.7263830.0029820.7004960.1985210.0003250.0000850.0006570.0011530.0005980.0049970.0010780.0030350.0005350.0004920.0003380.0003760.0004990.0012270.0004690.0005410.0013210.0018050.0002220.0006810.0001350.0004483.6302302.9696000.1094180.0042940.0053910.0005170.0019350.6028820.9155980.0017860.0010520.0005740.0007110.0034770.2264040.4790410.5630131.0874150.4979660.2921100.6058570.4205590.4247500.5075330.0131101.1159051.0233340.9088870.4217300.2614330.4392510.2426291.2563250.0121790.9694950.7046870.2402390.0043060.0126150.5667201.5207540.2567341.7867810.0072660.7671800.7307851.0344740.1525940.6617380.8677730.1549570.4639360.3385070.6053590.8420440.7039680.4370440.1437370.3359640.9727850.5640970.0360420.3547740.6220930.4569760.0141380.0590180.6689070.0212171.2878720.5846261.3015980.1120760.2665450.0006400.1275800.3991200.5192200.2648401.0643790.4431701.2159660.6613620.5988830.0510080.3409660.0098050.0608180.5893810.0382510.0056360.3039810.8860660.0037980.2510030.5800970.0016100.6141201.1876370.6828191.2427161.0648290.2519700.6422101.3617500.4525810.2586190.9441470.0084611.3017420.1113260.3838530.0111510.1906860.3854500.0035330.0656900.0962440.9324320.0956370.0745540.0809120.0038100.7561320.3023700.1828630.7804020.0579500.0684710.9802350.4529260.3977340.0028770.5927540.0007710.6712830.9477570.6296470.0112150.0092760.5266580.7748410.3226150.0524080.0190540.1341100.6484591.0908531.2062430.3757640.5056301.5680320.7728370.3026310.3555570.3583980.2723010.3449960.5023030.2092591.4120340.2190261.3217010.4727130.0398880.4307430.3486760.5184320.2401240.2133552.4287000.8102760.9099700.0071061.8909120.3486100.0089030.3502920.0089911.2789321.0924900.0511640.6407071.0683730.3636790.4392210.0049411.3321800.0126820.6254200.8957220.7868120.0076190.8333090.6641290.9300420.0218821.0200960.0267650.0074290.3521790.4321721.2935470.6366920.6072251.1163910.2553040.0191790.7307730.0021250.6889850.4844950.2533601.2265510.0905340.2684590.2169670.0034420.8493470.0100340.7370540.3138340.0055660.0027451.7270541.1675091.4248390.7033340.8751521.9698910.9898860.0464420.0085610.6732440.0276220.0081450.9830520.0691350.6953890.6059020.0431740.5651770.9559190.4921460.5531990.1069460.5311290.7585300.4825330.9286490.6349270.0005071.0762861.6086050.5494890.0021890.9617950.3378160.2376730.1087650.0003290.9258540.9454131.2688900.8855981.1142440.5228300.1283610.0110690.4589610.0054380.0085150.6059760.0849360.0006021.6567430.0414721.0973280.0144060.9987370.0244030.6254141.2978651.4762010.0092941.5459580.5476760.3670460.0115680.5106750.4608030.6494230.0346690.0316280.0499481.1747500.7960480.1862140.9644050.2125280.6559840.4324880.4680430.5100090.8864360.2825201.1387261.5592320.8921521.1187421.0070970.0212971.3000440.0083940.4144310.0165160.4300301.9108520.3463120.8519900.4647460.3560940.4815650.3974720.7111660.0199620.6620480.1488970.6488770.6134660.3229650.5066310.0059870.0075400.1780160.6118250.0157270.3895420.2536600.5678541.2933250.4735031.1874960.2210490.0067060.5201250.0782620.6400761.1205052.5851912.0786080.4731691.4768660.2333440.0037410.0135450.0280510.2274190.3765470.3307521.3424020.0035201.2882400.3221760.8024070.5292020.0005430.3098731.8154581.737170

*******************************************
EVALUATING PIPELINE 
Pipeline directory: /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_6a80fab6_2020-02-19_00-06-39y8r0zluh/
With following parameter combination: {'batch_size_seq_length': 2, 'lr': 3e-05, 'lr_type': 'cosine'}
EVALUATION OF CHECKPOINT /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_6a80fab6_2020-02-19_00-06-39y8r0zluh/outputs/checkpoint-3
-------------------------------------------------------------
|           |   agree   | disagree  |  discuss  | unrelated |
-------------------------------------------------------------
|   agree   |    704    |    101    |    135    |    14     |
-------------------------------------------------------------
| disagree  |    99     |    256    |    74     |    14     |
-------------------------------------------------------------
|  discuss  |    210    |    84     |   1512    |    78     |
-------------------------------------------------------------
| unrelated |    24     |    27     |    58     |   8508    |
-------------------------------------------------------------
Score: 8676.75 out of 9226.0	(94.04671580316497%)
Accuracy: 0.9228441754916793
F1 overall: 0.7705693482600123
F1 per class: [0.7071823204419889, 0.562019758507135, 0.8255528255528255, 0.9875224885381]
*******************************************


*******************************************
EVALUATING PIPELINE 
{'batch_size_seq_length': 1, 'lr': 3e-05, 'lr_type': 'cosine'}
INFO:__main__:Creating features from dataset file at /home/ubuntu/fnd_implementation/data/processed
  0%|                                                 | 0/11898 [00:00<?, ?it/s]  0%|                                       | 1/11898 [00:02<7:55:59,  2.40s/it]  4%|â–ˆâ–Œ                                   | 501/11898 [00:03<5:19:16,  1.68s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                   | 5501/11898 [00:03<2:05:26,  1.18s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                 | 6001/11898 [00:04<1:20:58,  1.21it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11898/11898 [00:04<00:00, 2858.31it/s]
  ******************************************* 
              Running Evaluation                
  *******************************************
 
  Length dataset evaluation: 11898
  Length dataloader evaluation: 2975
  Number of epochs: 3
  Batch size: 4
  ******************************************* 
 
['/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_67fd4e52_2020-02-18_23-53-42t33u4sfb/outputs/checkpoint-3']
INFO:__main__:Evaluate the following checkpoints: ['/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_67fd4e52_2020-02-18_23-53-42t33u4sfb/outputs/checkpoint-3']
INFO:transformers.configuration_utils:loading configuration file /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_67fd4e52_2020-02-18_23-53-42t33u4sfb/outputs/checkpoint-3/config.json
INFO:transformers.configuration_utils:Model config {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 28996
}

INFO:transformers.modeling_utils:loading weights file /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_67fd4e52_2020-02-18_23-53-42t33u4sfb/outputs/checkpoint-3/pytorch_model.bin
HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=2975.0, style=ProgressStyle(description_width='initial')), HTML(value='')))
2.2868852.2869031.1434700.3815780.1083340.0216870.0037320.0005510.0000880.0000290.0000230.0000951.0169920.0782480.0056070.0003920.0000420.0000201.4723000.0775080.0038930.0002030.0000270.0000190.0000180.0003160.0000300.0147190.0005440.0000370.0000190.0001980.0003030.0000280.0000190.0000210.0000290.0000480.0000200.1329620.0033980.0001020.0000210.0000790.0000200.0000190.0000190.0000190.0000820.0000210.0000190.0000190.0000190.0000190.0000190.0000181.2970180.6316201.3657902.3158970.0386740.0006630.0004601.9823020.0310890.0004980.6977480.0145812.2577930.0327430.0004920.0000260.0000202.2165970.0299740.0004262.1236622.2875922.0233760.0256312.0536892.3167180.0282742.2917592.2030472.2775681.2771480.0147060.0002520.0010322.3239810.0255580.0013220.3079540.0033070.0000610.0199010.0002230.0000210.0000190.0000190.0000190.0000190.0002412.2072120.0210400.0002171.6097980.0149960.0001560.0000190.7474581.6463881.8198032.4922601.4886441.2553390.0107490.0001100.0000210.0000200.0000200.0000200.0000190.0000190.0000190.0000850.0000200.0000190.0000200.0000200.0000200.0000200.0000190.0000200.0000200.0013370.0012421.2896050.0092960.8258480.7558570.0054650.7483120.0063761.6416960.0112640.0000950.0000190.0000180.0000190.0000190.0000200.0000980.0000780.0000800.0001580.2109290.0013561.5444510.0096780.0000780.0000200.0000190.0000190.0000190.0055940.0000630.0000190.0000240.0000190.0000180.0000210.0000230.0000190.0000180.0004450.0000210.0000200.0000210.0000180.0001320.0000190.0000200.0000190.0000240.0000180.0000200.0000200.0000190.0013160.0004090.0000210.0258000.0002450.0000290.0000910.0000190.0000180.0001540.0001370.0000190.0000180.0019800.0000890.0000210.0012850.0000240.0000180.0006740.0003180.0000200.0001310.0000190.0000180.0000170.0000180.0052750.2985180.0024801.4090461.2000560.0153900.0000880.0000190.0000190.0000180.0000180.0000210.0000190.5099150.0022250.0000270.0000180.0000170.0000170.0000170.0000170.0000180.0000170.0197610.0001000.0000190.0000180.0000200.0000180.0000180.0000330.0000180.0000180.0000180.0000180.0000180.0000240.0000190.0000190.0000180.0000180.0036720.0000340.0000210.0011470.0009430.0000230.0001310.0000202.3276580.0088480.0000560.0000780.0000390.0001400.0000230.0000200.0000210.0032380.0000310.0000180.0000190.0000190.0003520.0006740.0000201.0733061.2773540.0045500.0000330.0000180.0000171.6830021.7505270.0060330.0000390.0000750.0000190.0000740.0000730.0000190.0000780.0000200.0000730.0001860.0000210.0000230.0000190.0000200.0001380.0001500.0000750.0000780.0000190.0001870.0000930.0000200.0000180.0004250.0000190.0000260.0003600.0000420.0004230.0007300.0000280.8072780.0172230.0003910.0000200.0001430.0000770.0001931.6707140.0051270.0000360.0000200.0000210.0000200.0000210.0000210.0000200.0000200.0000200.0000210.0000200.0000210.0000200.0000200.0000200.0000200.0000200.0000200.0000210.0000190.0000210.0000200.0000210.0000210.0000800.0000200.0000210.0000200.0000210.0000200.0000200.0000200.0000200.0000200.0000200.0000200.0000200.0000200.0000200.0000800.0000200.1703900.0004730.0000190.4646330.0012500.0000210.0000180.0000180.0000170.0000180.0000180.0000170.0000180.0000180.0000190.0000180.0000180.0012480.0000210.0004940.0001700.0011020.0001890.0157050.0000570.0077960.0000370.0000170.0000170.0000170.0000170.0008210.0035120.0001820.0001542.0719431.7694661.0335240.0028380.0000980.0000220.0002820.0003720.9205990.0024970.0000240.0135160.0007070.0000210.0000190.0000190.0000860.0000200.0000200.0000190.0000210.0000210.0000200.0000200.0000200.0002430.0000770.0000200.0000200.0000200.0000200.0000210.0000210.0000200.0000200.0000210.0000190.0031300.9798801.4155010.7851330.5107190.0012020.0005690.0000660.0000350.0000190.1796700.0041941.1560140.0026000.0000800.0000192.4046190.0052800.0000880.0000180.0000180.0016640.0000240.0000180.0002640.0004630.0000180.0000180.0000170.0000170.0013050.0003030.0000190.0000880.0000180.0000180.0000180.0000910.0000890.0002040.0000751.6342550.0033770.0000270.0000200.0000200.0000210.0000210.0000231.5365162.1975880.0044510.0001910.0001280.0001360.0001470.0000240.0000180.0000180.0000170.0001510.0000190.0001760.0000200.0000300.0004240.0000190.0000180.0000180.0000180.0000180.0001320.0000180.0006990.0006740.0000180.0000180.0003451.1912180.0022970.0013730.3641030.0007200.0000420.0001140.0000420.0043610.0000380.0019430.0001850.0000180.0000750.0000210.0000210.0000210.0000210.0000760.0000780.0000760.0000210.0000210.0000210.0000220.0000200.0001310.0000210.0000210.0000850.0000190.0000190.0003150.0000191.4563050.0027100.0000231.4102922.1176001.5054930.0026920.0000230.0000180.0003790.0000201.5339741.6856340.0029760.0000930.0000850.0000201.7827565.1075790.0100500.0007530.0039460.0008050.0000200.0000190.0002090.0007080.0000190.0000750.0000190.0000180.0000190.0001510.0000780.0000190.0000180.0009890.0009240.0009360.0001080.0000180.0005780.0000190.0000180.0000180.0004180.0000190.0000180.0005920.0000200.0000200.0002350.0000210.0000220.0000831.8091520.0029710.0000271.9610020.0032730.0000840.0000220.0000211.7894690.0029020.0002760.0000220.0000210.0000850.0000210.0000750.0000200.0003270.0002280.0000210.0000202.1481810.0034080.0000241.8804930.0029711.3192370.0020820.0000220.0001462.1238150.0033220.0000230.0000180.0000180.0000960.0000190.0000190.0000190.0000890.0014700.0017880.0027890.0006120.0004560.0000180.7997511.3551731.3838730.0054591.8017260.0030470.0012460.0001750.1083880.0003140.0029060.0389681.5211643.0084900.0047160.0000251.6877060.0025171.5294931.3493041.6284850.0024161.7366961.3379690.0019790.0452771.0087500.0014910.0000200.3240850.6221380.0010230.0000850.0000780.0001160.0003400.0001490.0001370.0000790.0004030.0004000.0002710.0002900.0002610.0000830.0000190.0000190.0000180.0000190.0005770.0000180.0000180.0004110.0000180.0000180.0000180.0000180.0005450.0000180.0000200.0000190.0000190.0000180.0001170.0002590.0057940.0000280.0000190.0003870.0007730.0003450.0000190.0001250.0000190.0000181.1769530.6518081.7812080.0024380.0000211.1933341.6572140.0022571.2748971.1362310.0017660.0000201.2161650.1628060.0037350.0000230.0000170.0027960.0000210.0000170.0000170.0000184.8563730.0068930.0000270.0006380.0000180.0008030.0000190.0000180.0000180.0000180.0004380.0000180.0000180.0000180.0000250.0000180.0057080.0009340.0000200.0000180.0000510.0000400.0065050.0073240.0003620.0002520.0002570.0002790.0000180.0000170.0023380.0013070.0002710.0000180.0000181.4081900.0017980.0003420.0000190.0003900.0003624.6151416.9437090.0089610.0001380.0001980.0004790.0001700.0003920.0001090.0001331.3772031.2207810.0017120.0002490.0000942.0048470.0026750.0002311.2721921.9548003.7032740.0133490.2745210.0176162.1149460.0026040.0000210.0000170.0000190.0000180.0070260.0001160.0534910.0034700.0000230.0002740.0904670.0046981.5041310.0018220.0188202.5544442.7826460.0033390.2685740.0003400.0000770.0018600.0001240.0000180.0000190.0001490.0000790.0000200.0000192.0003796.3066190.0082661.3374640.0018460.0002640.0006500.0013540.0002590.0001940.0002500.0078061.7432810.0048072.1697150.0025240.0003620.0014150.0037100.0000770.8417191.2393230.0042550.0002260.0000301.6032381.4639770.0016870.0000300.9505310.0024640.0045040.0007120.0001510.0001180.0002260.0003030.0002370.0012890.0027140.0050030.0001850.0040250.0001540.0002060.0001780.0005220.0039180.0004840.0001800.0007480.0000200.0000191.9333620.0021550.0001740.0000190.0000190.0000190.0000190.0000180.0000181.9144283.6755970.0042430.0000240.0001272.0484772.0854660.0024030.0009591.0439111.0378170.0014641.1964261.5130720.0016620.0002030.0025370.0015020.0003320.0000810.0002430.0000190.0001980.0004390.0000200.0004010.0001910.0001910.0001160.0000190.0003030.0132030.0000430.0024610.9026653.3401790.5421941.5947550.0016960.0000200.0000190.0000180.0000190.0001390.0000190.0000730.9437940.0010020.0000190.0079701.7253800.2444230.0005880.0003770.0001300.0000880.0003010.0003590.0006020.0003910.0000210.0000210.0000200.0002840.0000180.0000190.0000190.0000180.0000180.0000640.0000180.0000201.6460730.0016870.0006370.0000190.0003023.4569201.7571300.0018442.1558160.0021880.0000200.0000190.0000200.0000190.0000181.5559361.7339450.0018210.0011410.0000220.0009590.0482570.0000660.0000220.0000192.0305100.0020270.0028330.0027790.0002410.0000280.0001190.2397800.6263500.0600770.0000770.5684810.3589460.0003681.8474760.9246690.1182780.8848270.0010570.0001940.0001430.0001992.0559370.0020680.0002620.0000220.0000200.0000190.0338142.9706800.0034750.0002610.0002800.0003230.0008380.0020240.0011520.0000190.0029300.0185500.0000350.0000214.4798324.4985562.2706040.0022372.2027240.7474290.0069850.0026860.0012560.4718290.0005700.0000730.0055660.0001300.0019991.3616530.2037010.0547310.0023110.0017620.0000201.6757910.0023880.0000200.0006070.0002460.0000200.0016541.7021260.0016550.0000920.0000190.0000192.0088731.5975660.0015550.0000211.5637240.0015153.5161823.2896430.0030300.0000230.0000190.0000200.0000830.0000200.0000200.0000210.0000200.0000200.0000202.1729170.0019860.0000220.0000200.0000200.0000190.0000200.0000200.0000200.0000200.0000850.0004460.0002620.0000200.0008740.0004500.0003150.0259460.0003240.0000200.0000760.0000190.0001610.0000180.0001840.0000810.0000180.0001100.0001400.0001000.0002600.0000860.0000801.3754880.0014780.0007630.0001620.0001480.0013241.7140700.1831962.0389521.6135260.2499523.6637161.7655900.0015530.0004573.0172034.7721974.6214650.0043930.2600941.2530801.1373992.1116430.0018380.0007070.0007460.0000181.9172230.0019850.0002120.0000180.0000180.0000180.0000181.1134292.6224341.1612520.0019090.1935560.0059990.0001430.0000200.0000920.0000810.0001360.0001320.0001760.0000190.0001430.0001290.0001390.0001790.0001390.0001410.0000180.0001480.0001470.0000180.0000440.0023000.0006270.0000800.0026610.0000210.0000180.0006170.0005680.0007990.4021150.1815110.4393920.0011220.0005091.2371301.5819160.4670580.0013910.0000210.0000190.0000190.0002050.0005990.0000180.0000180.0000170.0000180.0002520.0000180.0000290.0000170.0000200.0000170.0002230.0000270.0001980.0000180.0000170.0008600.0000200.0000300.0000810.0000180.0010160.0011350.0000190.0025640.0016120.0021385.2124821.7451613.3167505.1825503.4941530.0028150.0003680.0003880.0003720.0000180.7193810.0011693.6637960.0038895.3392340.0045430.0001340.0001310.0000750.0000190.0001330.0001320.0000750.0000750.0001290.0000190.0059750.2177750.0007710.0003610.0134010.0004461.8304701.2692583.1189914.0852641.5661911.2403190.0015050.0002560.0000770.0001420.0000180.0000180.0001750.0003430.0000180.0000180.0000180.0000180.0000180.0000190.0000180.0000180.0000180.0000180.0000840.0000182.2439422.3006260.0018980.0000200.0000180.0000180.0000770.0000790.0000180.0000180.0000170.0000180.0002530.0005740.0000180.0000180.0000180.0000820.0000180.0013020.0000200.0018110.0000200.8334850.0042430.0000210.0050100.0019660.0001360.0000192.3367000.0019960.0004490.0000180.0001880.0000180.0000180.0004320.0000180.0002450.0000180.0000180.0004480.0002100.0000180.0000180.0006910.0004490.0003830.0001710.0015380.0002550.0007210.0004710.0005320.0005600.0002070.0000742.0028770.0016610.0001960.0000750.0000780.0001880.4562420.7193561.2534032.4527940.0211280.8033700.0031840.0013670.0009820.0025460.3226690.0003570.0014440.0013400.0000790.0003720.0000210.0001850.7225590.0005970.0000770.0000190.0001890.0000780.0045890.0068890.0048160.0045740.0000210.0010230.0002400.0045840.0035860.7379450.0024500.0020691.3059763.7630572.8822191.2357641.3614520.0067130.0076210.0189090.0067531.2001651.6116650.9562220.5152890.8747430.4433630.0032780.9782220.9430950.0868330.0000790.0003930.0000181.2928811.4480381.3873260.0009890.0013840.0000220.0008080.0000210.0000220.0004080.0000180.0000180.0004580.0002460.0000200.0004460.0000180.3342930.0002501.0221880.8714900.0006210.0000190.0000190.0000180.0000180.9347970.0006621.1876200.0012250.0000190.0000191.0918270.0007730.0812440.0000800.0000180.0000180.0192720.0000323.2890113.0495340.0021570.0001811.5353761.6444220.0037210.0005900.0001911.3858740.2175420.0005060.0052520.0000231.8389850.1833270.1459231.4553043.2260543.7336180.0025320.0712640.0000660.0000211.6054580.0010950.0000180.0000170.0000180.0000180.0000191.7952870.0012170.0003300.0000180.0000170.0000180.0000170.0000170.0002130.0000170.0003160.0000683.9294730.0026220.0000250.0000170.0000180.0003091.8463790.0012360.0000180.0000170.0038180.0037340.4241010.0353280.0232530.8911824.4504052.5179600.0189351.7978200.9896911.3977561.4763140.0009821.4476061.1749190.0007840.0000180.0000180.0000181.8917210.0012830.3279260.0002311.3262260.0008770.8360560.0005590.2730851.5598230.0010290.0002240.0000190.0000190.0001390.0156700.0001520.0000760.0001420.0003780.0001200.0000790.0000780.0003060.0000190.0003270.0000190.0001720.0632220.0004500.7736761.6739650.8378410.0009540.0002921.3091370.8918770.8712360.9778731.6264481.1425142.0269190.0013011.5816720.0013790.4873942.5913420.0016560.0000200.0000190.0000210.0291970.0000380.0000200.0000190.0000210.0000840.0000190.0000180.0000210.0000800.0000190.0000820.0003070.0000200.0000200.0000190.0001450.0000191.5550530.0009870.0000200.0340950.0000400.0000200.0119620.0000260.0000760.2918040.0002000.0000190.0000190.0000200.0000200.0000190.0000181.1883010.0007570.0000200.0000190.0000190.0000210.0000220.0004480.0007670.0004780.0006310.0008441.7826180.0015380.0004520.9244120.0035220.0001520.6267592.3978975.5816234.8365271.0477653.5347211.0570291.8216050.7328880.0008330.0005640.0002841.0358391.1498360.0020000.0004370.0021050.0009040.0005570.0009200.0004600.0008250.0000190.0285681.3104080.0008040.0000190.0000200.0000171.8283810.0011120.0000190.7198690.0004481.3195800.0008050.0003710.0000180.0012901.0363710.0006350.0371941.1068450.0047670.0299790.6973770.0647770.0064820.0000280.0099870.0000970.0000180.0000180.0000180.0000810.0002380.0001320.0000850.0000180.0000180.0000180.0000180.0001710.0000180.0000180.0000180.0000180.0000180.0000180.0000180.0000180.0000180.0000180.0000833.2944864.0478901.7056125.4210513.3221103.1031080.0051620.0002290.0006870.0031430.0010020.0001800.0000190.0009460.0004402.2766550.0026990.0001920.0013380.0007030.0138030.0000360.0000180.0019070.7261780.0028680.0036440.0011140.0042340.0036250.0008380.2050250.0271950.0365961.2054410.0474760.0002560.0011901.7184190.0021801.5436432.1412544.2253472.0813121.4808891.8626350.0015200.0008210.0003930.0008950.0005720.0005910.0000210.0000190.0002410.0006970.0002431.4314480.0010450.0002440.0002370.0003870.0002410.0003041.1021871.7577200.0018453.3358281.7051620.3730360.0003430.0001900.0000190.0000190.0002050.0000190.0001380.0000770.0002080.0000750.0000200.0001370.0000170.0014480.0000180.0009730.0000180.0017860.0000190.0007650.0005810.0000180.0000170.0000190.8819530.0014200.0019210.6148680.0021400.0027160.0031170.0002010.0000260.0000260.0086940.0000230.0046650.0000212.1542901.7634341.6423510.0009170.0000182.3271392.3074622.2582932.0686872.3279740.0012870.0000182.3065960.0017610.0000190.0003470.0000180.0000180.0010130.0012500.0008320.0005843.0714741.5539453.0092922.0177450.0020102.8583362.9252153.2066010.0019101.6166010.0011051.9709411.6108661.5322861.6338451.8352391.5338070.0011010.0009011.5244570.0010660.5357060.0043910.0012040.3048660.3189961.8352041.7806220.0009680.0000180.0000180.0000181.8418400.0010060.0000190.0000180.0000180.0001041.7796414.6912470.0025060.0000190.0000190.0000196.8012242.8066501.5747520.0008520.0000220.0007240.0000200.0011230.0000190.0000850.0000200.0000900.0000830.0000190.0000190.0000860.0001570.0000190.0000180.0000180.0000190.0000190.0000180.0000181.4056020.0010021.9508195.3131095.0188175.9491334.3539592.2452723.8742572.2527240.0031100.0111370.0000240.0000180.0000180.0046400.0000200.0007520.0000790.0000760.0000180.0857540.0000620.0010230.0020040.0000190.0000170.0000170.0010371.7263710.0018160.0000180.0000180.0920350.0000650.0009282.0899360.0010900.0000180.0000190.0000190.0000180.0000190.0000203.7711381.7331230.0009020.0000180.0001420.9192541.9542320.0010121.5495940.0011681.8416410.0010271.7851940.0009251.5337230.0007960.0000191.7052260.0008825.2137563.3952060.0017905.9407820.0032710.0003110.7667110.0020400.0000200.0037700.0000200.0029130.0000190.0000780.0000180.0000180.0002000.0002280.0000870.0002280.0000180.0001670.0000820.0002510.0000820.0004390.0001990.0000190.0002031.3132790.1409280.6967700.0003640.0000180.0000180.0000181.3512222.3979310.0012080.0000181.5377400.0007800.0000181.5377411.3571870.0006890.0000180.0000170.0000321.5174791.4511100.0007330.0000180.0000180.0004260.0000180.0000180.0069520.0000230.0000180.0000170.0000180.0000180.0000180.0000710.0014760.0000180.0000180.0045210.0000200.0000180.0000170.6203630.0003210.0000180.0000180.0022260.0000190.0034680.0035760.0000190.0000180.0000170.0010000.0855490.0032340.0000190.0153970.0687490.0000513.1935674.2070803.1503234.6504095.1917530.0033610.0013560.0004730.0009560.0004050.0005000.0004730.0003640.0019790.0011400.0014550.0049871.0961550.0029610.0058490.0037300.0038000.0019270.0023320.0005380.1501461.3029842.9147540.0018251.4703590.0007190.0002090.0034291.4646690.0007240.0021471.2762880.0023170.0000270.0036300.0000310.0000240.0445710.0038050.0000310.0000260.0004250.0004080.0004860.0005621.8406230.0015000.9333430.0009120.0009761.8849790.0014370.0000960.0001070.0000180.0000180.0000900.0000180.0000861.9895240.0009520.0013960.0029540.0000190.0051570.1164720.0051131.0881560.0221120.0000270.0000180.0000180.0000170.0000170.0026250.0000180.0036540.0026260.0000191.1893141.1879940.0005710.0000170.0000170.0016290.0000180.0000180.0000180.0000170.0000171.5242492.8847001.7720850.0020510.0014080.0012441.9166750.0053630.0003180.0006631.1058110.0008330.0007810.0029170.7849130.0006820.0004040.0000180.2818260.0005550.0000180.8174240.0060960.5129990.0002520.0082371.0343760.0004900.0014300.0006030.0003240.0002830.0000180.0003620.0002600.0018890.0035360.0003110.0002720.0002553.1015573.2124133.0220940.0013883.2982400.0150210.0002510.0001920.0002440.0001310.0001860.0000820.0001280.0001920.0001300.0002631.4540390.0008960.0001350.0002080.0002450.0001910.0017530.0011210.0018600.0074780.0030440.0001090.0010790.0015280.0000190.0002610.0000180.0009322.9501611.6230243.7287531.7423421.1084730.0980600.0000670.0031380.0007530.0008080.0005010.0001590.0008950.0002320.0006540.4360800.0006710.6186420.0006420.0011430.0003700.0010050.0002890.0008620.0006890.0003230.0009050.0008860.0004680.0124241.6861990.0008360.5467370.0015191.2693620.0591900.0030223.2174752.1847340.0009940.4698650.0520332.9431401.7933250.0008250.5913130.4758250.5288730.0002670.0462680.4420502.1424011.2899231.7079771.8594301.5277180.0010160.1060462.1932070.0011911.9823410.2448330.0133370.4197170.7521790.0065440.0094310.0167230.0134161.2170862.4827220.5757380.2942670.0115880.0300620.5912690.0040610.0896491.9454260.0036001.5256192.8696160.0057280.0044713.1640492.0048070.3887950.0012960.9792450.0005370.0005170.5016650.0025532.6097390.0020892.6639190.2336510.2591091.3441050.1764630.3888521.4198720.6478720.0003180.4279390.0003002.2644040.4013270.2333592.6013370.9296110.3201460.1586850.6780980.3775140.0001940.3922690.2226742.6146180.0099382.3395150.3683710.0492050.0002320.5245170.0002820.0187320.3229231.0766001.3047340.0052020.1342700.0129580.3296001.1065670.2054220.2036070.0007603.7043680.0018031.5535910.1606982.0457140.6609720.3704700.0006080.2478890.1844530.0001090.0000210.0415690.1089950.8478560.0030241.2545460.0035220.0458310.9517960.5552102.4801002.0116250.0017270.4785351.5463400.0052361.2335710.0072081.6752150.0030300.0022600.0020180.0065830.0028420.0772690.3600390.0005451.3916660.0008690.0031991.8591530.0011730.0004370.2933131.2707531.7559530.1600880.0001220.8351490.0006030.1386471.2293380.0005760.0035850.0001051.2666190.0006120.1195150.5648120.0046870.0044110.0004391.3439430.4937251.3039120.0008950.2056451.7946620.0010671.4990300.5700801.8479310.0141792.0846470.0008730.4349481.0851230.0005170.0060351.4018842.5040760.0015960.0500150.3820010.3600140.0030470.0074730.4850390.0002611.9186932.2556240.0018710.0001240.1373051.8566100.2294700.0001430.1355471.2732500.0079910.8170210.0010711.4138070.3674370.0001960.0041190.0031160.0137661.2636510.0064140.0037060.0105760.4966970.2286640.4855390.0066560.0000700.0079130.0000652.2667021.1095070.0004741.4798801.3928110.0034090.0019560.0037510.0007080.4442410.0014990.0000310.2278222.9465493.1736581.1277960.7151451.6394122.3379650.0041060.0113800.0027380.0047601.2031982.2238760.0016110.0100361.0682020.0074630.0170250.0078320.0000580.0002170.2868440.1421620.1155180.8422601.7946141.1103872.7607980.0011640.2832510.8514140.2481980.0547151.9993990.5640651.2290250.0048960.5301090.0003500.0454570.2004590.0001730.0831521.0159600.0006081.4641980.4568830.4577480.2785370.2504031.3092162.0199230.0008910.9183630.0004421.0590720.0004650.7672360.0003480.3873661.0006240.0004640.9312130.0132340.7689070.0105671.0760870.0027020.6914650.0002981.3234783.0963441.0993161.1356560.8834950.0003720.0025960.0003992.0974852.1423901.0233880.1638480.1352910.0000800.0060580.3265070.0001760.5186431.3749831.3933230.9091662.1121370.5492650.0003081.1569870.4661160.0002123.4700880.0013651.7108530.0007560.0038770.0034830.0002131.5916781.7116950.0062830.0005771.4758920.0295911.1990981.2696190.4281840.0003100.0590480.0004740.2170260.4618180.4061160.4132190.6676511.9321650.0218910.0045541.1845320.8802990.1124980.0000990.0000620.1109570.1737440.2233510.2597160.7087410.1283202.4270200.0013410.1991900.3775500.3038952.2376240.0009960.2854020.0266390.5179900.0926430.0002861.4960160.0026670.9014101.5485991.2950350.6740600.0036791.9971600.0018582.2774230.0039230.2043820.0030530.0035070.6093311.1633770.0064370.0038610.0000940.0048241.9271270.0063950.0036040.0118300.7303860.7334760.3853840.0041570.0048900.0039770.0008731.8760491.0120921.9661540.5246820.0012362.3686172.2661741.8378021.4011680.0006581.9923771.0925941.0588391.0741350.0058030.0153200.0102850.0000970.7364940.0058070.0059950.0057180.0048400.0000770.0053312.0659880.0014550.0113520.8688680.3346220.3985701.5416780.4330420.0001940.2983861.6907661.0815271.0420611.5157150.5070144.2945890.1194790.0001430.0138310.0000341.2517471.6720230.1205600.0069861.2071591.2442670.4167750.0025170.9447220.0004910.0000291.2275720.3816392.6202241.5978941.1276500.0008130.0002000.0046590.7315940.8043000.1187570.7813100.0023670.5408080.5534930.0072310.0007910.0005481.6944150.2315690.0040422.4834872.4198881.3636932.2270841.0551860.1494422.5816720.0027190.9970830.0045450.0000620.0095650.0063610.0011651.1636840.0048240.0002220.0041890.0045890.0003101.1265630.3867460.0602550.0000660.0051460.0149560.0865890.0028850.4931520.4918911.0087840.1076930.6584720.9308740.6560210.2510770.0028680.0032111.4815812.4359800.0034083.1018800.0039620.0026430.0098650.0034583.0278640.9792600.2250961.6363550.0061680.0161770.0010860.0051441.1181990.0943740.6213802.0291400.4371440.3746580.0002350.0620570.0033680.0032060.0046190.0655731.0269241.0728010.8939790.3901080.0085623.2473920.5696470.2631180.3092650.0002651.5365540.3037600.3438150.8348500.0096430.5448510.9767782.7231980.0034150.0080300.2645821.1040222.7873651.4646082.4290751.6397760.0043242.0722110.0010730.7095801.7258330.5133890.0003781.3670491.4047520.0051610.0053280.0001980.3776050.2635950.0029470.0071720.9517462.9273301.2705460.4994670.0006710.4052880.3640300.1056100.3957072.7132110.0086680.0120060.7284811.5027870.0243190.7127821.7109920.0072751.2208351.4086010.0005450.0093140.0051211.0549140.3732671.3198160.4185101.8572400.0007470.0028460.2883590.0067670.0053120.0052210.4871440.1632710.3270061.0186041.9428210.0205800.0598590.0000490.3583320.3948300.0028031.4896450.0094461.1372670.3674311.3091720.6645762.4690470.0008980.8863260.0094940.0395950.0054470.4250030.0057420.2897670.0164060.0041451.7598530.5552461.3916232.6596132.6040770.8593892.6648840.0080941.4139962.0227850.0037930.4386320.5903170.6118070.0002350.0036350.5868260.0099710.0517450.2484300.0001240.0000370.3748980.0002610.4511011.3619901.4171680.0037750.0000511.2588622.0524290.4604071.1459760.5262840.0028490.0253370.0061260.0000320.0000510.0821540.2232573.3591190.4368440.858442

*******************************************
EVALUATING PIPELINE 
Pipeline directory: /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_67fd4e52_2020-02-18_23-53-42t33u4sfb/
With following parameter combination: {'batch_size_seq_length': 1, 'lr': 3e-05, 'lr_type': 'cosine'}
EVALUATION OF CHECKPOINT /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_67fd4e52_2020-02-18_23-53-42t33u4sfb/outputs/checkpoint-3
-------------------------------------------------------------
|           |   agree   | disagree  |  discuss  | unrelated |
-------------------------------------------------------------
|   agree   |    642    |    118    |    151    |    15     |
-------------------------------------------------------------
| disagree  |    87     |    207    |    62     |     8     |
-------------------------------------------------------------
|  discuss  |    266    |    101    |   1499    |    78     |
-------------------------------------------------------------
| unrelated |    42     |    42     |    67     |   8513    |
-------------------------------------------------------------
Score: 8608.0 out of 9226.0	(93.30153912854975%)
Accuracy: 0.9128424945368969
F1 overall: 0.7355941425087729
F1 per class: [0.6541008660213958, 0.49759615384615385, 0.8052645715820574, 0.9854149785854844]
*******************************************


*******************************************
EVALUATING PIPELINE 
{'batch_size_seq_length': 2, 'lr': 3e-05, 'lr_type': 'constant'}
INFO:__main__:Creating features from dataset file at /home/ubuntu/fnd_implementation/data/processed
  0%|                                                 | 0/11898 [00:00<?, ?it/s]  0%|                                       | 1/11898 [00:02<8:11:24,  2.48s/it]  4%|â–ˆâ–Œ                                   | 501/11898 [00:03<5:29:35,  1.74s/it] 38%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                      | 4501/11898 [00:03<2:29:44,  1.21s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                   | 5534/11898 [00:04<1:30:12,  1.18it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                  | 6293/11898 [00:04<55:37,  1.68it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11898/11898 [00:04<00:00, 2800.48it/s]
  ******************************************* 
              Running Evaluation                
  *******************************************
 
  Length dataset evaluation: 11898
  Length dataloader evaluation: 1488
  Number of epochs: 3
  Batch size: 8
  ******************************************* 
 
['/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_7645cfce_2020-02-18_12-24-14prdl64xd/outputs/checkpoint-3']
INFO:__main__:Evaluate the following checkpoints: ['/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_7645cfce_2020-02-18_12-24-14prdl64xd/outputs/checkpoint-3']
INFO:transformers.configuration_utils:loading configuration file /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_7645cfce_2020-02-18_12-24-14prdl64xd/outputs/checkpoint-3/config.json
INFO:transformers.configuration_utils:Model config {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 28996
}

INFO:transformers.modeling_utils:loading weights file /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_7645cfce_2020-02-18_12-24-14prdl64xd/outputs/checkpoint-3/pytorch_model.bin
HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=1488.0, style=ProgressStyle(description_width='initial')), HTML(value='')))
0.8687500.8732910.6850890.2287710.0573430.0120800.0074690.0012190.0003050.5356800.0537210.0050350.0007440.0175500.0014030.0008420.9082510.0535760.9132400.0485370.0027410.0004700.0001700.0001560.0003190.0001620.0001550.0001541.3121471.2602840.0423200.9010150.0283100.8680240.9167610.0263470.0008940.0001811.7446530.0449211.8098340.9521441.8297290.0503570.0014560.9065501.7077210.0364890.0101890.0003570.0001560.0001530.0005340.0003580.0001570.4924500.9998501.6506930.6056130.0104150.0003240.0001700.0001540.0003980.0001570.0001530.0001530.0001532.3987541.5820721.5974520.8653790.9107580.0126250.0003200.0001530.0001510.0004870.0144360.9135810.0115710.0002940.0001540.7000580.0084850.0002510.0001540.0001530.0001630.0001530.0001530.0001520.0001520.0001520.0001690.0117260.0002800.0001563.4273933.6210382.7119401.8400370.0183570.0220710.0799350.0010650.0002270.0001600.0528030.0335830.0356671.0847830.0098350.0002360.0001550.1775190.0016800.0001640.0001510.0001510.2811210.0024760.0001750.0001560.0001560.0001570.0001550.0001560.0001570.0101260.0076280.0077730.0005180.8988330.0070640.0004250.0001890.0066770.0002000.0001540.0126090.6332370.6464340.0046700.6026510.6113320.0045020.0003340.0003200.0003060.0005010.0001530.0001500.0008810.0004890.0004700.0003080.0005740.0001560.0040640.8332810.3660950.0257330.0007120.0008190.4394720.0027970.0001660.0001510.0001500.0001500.0001500.0001520.0001530.0001500.0001500.0001560.0001500.0003420.0001510.0001510.0001500.0001510.0001510.0001500.0003390.8673630.0047910.0102500.0002070.0001520.0001530.0001530.0001530.0001530.0002570.0022850.1677970.0096310.0077180.0001900.0001530.0012050.0006361.7174370.7903730.0039870.0005060.0007720.0006980.0005070.0001510.0004740.0001520.0001500.0001510.0003910.0003180.0001510.0001510.0001510.0001510.0010470.7829930.7111000.0036160.0002430.0204610.3735350.0019470.9030150.0044730.0001690.0123070.0004090.0003760.0001510.0008340.0007760.0003190.0001510.0008300.0006790.6981260.0030190.0001690.0002191.7126530.0077260.0011970.0010500.0001590.0002480.0001580.0001550.0044780.0001710.0001550.0001550.0083750.0001831.0912530.0043270.3083800.0018550.0003190.0054640.0001870.0003170.0001500.0003250.0004890.0001510.0001500.0004920.0001510.0003240.0003610.2496470.0010651.0382240.3005440.0012170.0003871.3585780.0056240.0003762.2538760.0230700.0133310.0001960.0006910.0003110.0001510.0005190.0003650.0061180.0102610.0003390.0047800.0001700.0033450.0034140.0001650.0004780.0210980.0119970.0094740.0005660.0001560.0106520.0003620.0003170.0001680.0003500.0003200.9153210.0035330.8349330.7984900.0028290.9226270.0030180.0001640.0001490.0003133.2171211.2747111.2429100.4320700.1966680.5532960.4770480.4415470.0261370.2446260.0011860.4071161.0853670.5906991.3188453.0355411.4377710.0162180.0163490.0006410.0006930.0005230.0014170.0025820.0016770.0003610.0001570.0036290.0001720.0035000.0001630.0032900.0001620.0001510.0003750.0007180.0001510.0008160.0003280.0003130.9455272.5384650.0070501.6636491.7424121.6244090.3945930.0166010.0001990.0084950.0001762.0749010.0059790.0042390.0042220.0001630.0036500.0001600.0001530.0044580.0157070.0001950.1725800.0319850.0006110.0003490.0003190.0092880.0001780.3779190.0013450.0005104.6509200.0130130.0007300.0007260.0006790.0006370.7588590.0027840.0008080.7641812.6163171.4218011.0509000.0027070.0001570.0066860.6909080.0018150.0171810.3081271.9417381.6352200.0040520.3543340.0011680.0005020.0003300.9023532.8963770.6227470.0089840.0177060.0015060.9269520.8337270.0025060.0014930.0013940.7656990.0019040.7145860.0017800.0083440.6062790.0020070.0007710.0089380.3555050.0816130.0006510.0008180.4200430.0021880.0001740.5476060.0015400.0001540.0001520.5801171.4689090.0035371.2842830.0043050.8810740.6466530.2619700.0111320.0116360.0007500.0005950.0006820.0012450.0008170.0007920.8444401.5155621.6038160.8690580.0019800.0001580.0004720.7324260.0016790.3956010.8612820.0027900.0007190.0016170.5073030.0011910.5604740.0013060.0001540.0001550.7164710.0018730.0003821.3903770.8847880.0019370.0002120.0001560.5068650.0083140.0076040.0114980.0001751.1373820.0164910.0010360.0184650.0290680.2309350.0101651.2161550.6474290.0024020.0009750.8980420.0020550.0001560.7532980.0072900.0022060.0102400.0075050.0164650.0001833.5520410.8468231.2359630.7083960.6216930.0018120.0009320.6094002.9684140.6459930.5563550.0502650.0058500.0106930.6365770.0015250.9243350.5992380.6242821.5808741.2710620.0024730.0003340.0001500.0001490.0001510.9061580.0017890.0001530.0001490.0001500.0005920.0007850.0008980.0021470.0006740.0003380.0005070.0006670.0002530.0006910.0007740.9575880.0085810.0001690.4289501.2329512.0914352.6949240.0053042.3953470.8489920.3649652.5359830.0160500.0108460.5290280.0022130.0001570.8929990.0054610.1627460.0014110.0003280.0006390.0008350.0005070.0007090.0008320.0003450.0006620.0001521.2706720.0029420.0001561.3722982.3881501.7716740.0041702.6844730.9724560.0017560.0006810.0077350.0001650.0001600.0001530.0001970.0001550.0001730.0001540.0081070.0002950.0086760.0096430.0247480.9254771.2566811.7330860.0060900.0070740.8047971.5801902.0890380.0041960.0006650.0005270.0006940.0006930.0322730.0450250.0025250.8475711.6525731.4437220.4590070.0016100.0004890.0005850.0009170.0001520.0001490.0001490.0001500.0001500.6536510.8905720.0015130.0003160.0003280.0001500.0004500.0003420.0001510.0003290.0046500.0043200.4108160.0089981.1278480.8853340.0028530.0003610.0001530.0009580.0003570.0007050.0004980.0009540.8085490.0018780.0014270.0016820.0014180.8594980.0022880.0005220.0321143.7757353.1084803.8690080.0183931.4440620.8603220.2896480.0009220.0013420.0005890.0006620.0012340.6727130.5286160.0016130.0208290.3240921.1258092.5797981.4183270.9955191.5639880.0062050.7590050.0601270.0011890.0014710.0003220.0192851.1653460.0087130.0004970.0001520.0065160.0059030.0001710.0067260.0130420.7911570.0012440.0001530.3821090.3831100.0006860.4261830.0111220.0001650.0001511.5468592.3802410.6349630.8759060.0017000.0009060.0008960.2543410.0548701.3073330.6676630.3317400.3423010.0006100.0001510.0010910.6420380.0013170.0001530.0001500.0005070.0006811.9708770.0027640.0004270.7125150.0010900.0154380.4939460.1420494.4717451.2835822.0177600.8821001.7210050.0023930.0001551.8097530.8881350.8787070.4886641.3999520.0021240.0006690.0010310.0007190.8580040.0017820.0011220.0009080.0005530.0005302.5717000.8058250.8909281.7265092.6443063.3219541.7312260.7413471.6683370.0022540.3925970.0006440.0001530.0003150.0001520.0003150.3233720.0005550.0001510.5745760.0008660.0110740.5266240.0009650.5424030.0008220.0001520.0001520.5343910.0008070.0001520.0009220.0018740.0022580.0141520.0270500.4810500.7556772.6373071.3435031.8289080.0132150.0016001.1152900.4794790.6331360.7305760.0749070.5074610.4279480.0006640.5455830.0008010.7140610.9663700.0032720.4395220.4942740.3784150.5044250.7208760.0101910.0003310.0001510.0004860.0005150.0001510.0001510.0020780.0001530.0001510.0001510.0001510.0003221.5918832.0995202.0025140.0204050.0221030.0340250.0075340.0005350.0117120.0206700.0005410.0110610.6313910.6043280.4454912.3765212.3069432.3887320.0161380.4370741.6734913.2786761.6045040.0230900.0486960.0115690.0001650.0016031.1294650.0028460.0016170.8009641.7322531.7618141.5501830.0032440.0001530.0008870.8301910.0020310.0007000.0058640.0052480.0113800.0049550.0057100.0001571.6967350.0108570.0126660.0064540.0001580.0094520.0004831.6995910.3203810.9177001.3717771.6170340.0019120.9162530.0055140.0001581.1558990.0115170.4256520.4333750.0178610.0313310.0210490.5614130.0172920.9270600.0122120.6490540.2981180.6656722.9669712.6902220.0030220.0001540.3606730.0005350.0004761.6579440.0019100.0001532.2456890.2769470.0113280.5308580.0009040.0003390.9326040.0013180.0003810.0001490.0001630.0001500.9106303.6068374.2334632.7103592.6145100.4199500.0005890.0003610.0007560.0005010.0411350.0064310.0133410.0001641.0382900.0084980.0064500.0074440.0002200.0001560.0001540.0001510.0114540.0001640.0061330.8772720.0011080.3147350.0069340.0068340.0061620.0118590.0061380.8691670.6732500.0081640.0152120.0078320.0003220.0006770.0005540.0007340.0005560.0007500.0013400.0006370.4765880.4507110.0005990.3952500.9258110.5099220.0006560.9835980.0011230.0001530.9856350.0011240.0022270.0001540.0234400.0001750.0001520.0001520.0142030.0099950.0001620.0100760.0001620.0144630.0130470.0296610.0001810.2765290.0124620.4090010.9855772.0919193.7676900.0053060.0019680.0012720.0010080.0018020.0204010.4014930.0290050.0469130.0077730.4623950.3144100.9004860.0108410.2614310.4591370.0089930.0105170.0090020.0112180.0008241.1056810.7796420.0031940.0021290.4590370.0009320.0001520.0003310.8380030.0082950.0140911.0947075.9213190.9249350.0010130.0001510.0103070.0234430.3426920.3319020.0004580.7717700.0008660.0001511.6166900.5599350.0250100.6001420.0011950.1481670.3191990.3572480.0006520.3703601.2206750.0890030.3844420.0763480.0024160.8037370.0014270.0122950.0177880.0028781.6046010.4861150.9704060.0021660.0012730.0009360.0009600.0012660.0017300.0011230.0013050.0267950.0233240.0013860.0011650.0003220.0009412.9274562.1307440.3604130.0101990.0196010.0038730.0100880.0209370.8995170.0168580.0135750.0052870.0061450.0170750.0159500.4706760.4852610.7364421.2493590.7099020.8841801.1926570.0251110.4642100.2045251.2072841.1424481.7766440.3528540.8267941.1479640.1172660.8836630.0188151.3094361.1558390.8206410.5240800.0226141.1974451.3850490.0283393.7360070.5033120.3837311.6116431.3299230.1452711.6703840.8527390.4635141.0444340.4592271.4580351.2198460.0807200.2135790.0373110.3068820.7425591.4639000.0116600.4334630.0091312.1035190.0025060.4818030.5198400.0750211.7321731.1691632.3693640.0152750.3778250.0004700.0425910.4790580.8580470.2214921.4688920.9594250.8283982.0549670.7681540.0158270.0153610.0189420.5887901.0615120.5459920.0016680.5583430.3347430.8269030.3472550.7040210.0101641.6327110.8804570.0684131.1413991.8142730.1515000.6590950.5623041.4522180.8858420.7962880.8167231.0054520.0893200.7092760.0302770.1860860.4116250.0052480.2808650.4125410.6280500.6147910.1155630.0278500.5081030.4116190.0238530.7628891.3510930.2494230.2040760.9290320.3455640.0391940.0172770.3481570.0090720.8180741.6050231.1055850.4258700.0167240.4922650.7824370.6138900.2836460.0117310.1944700.1676480.6757100.8880270.0438530.4321851.6818670.6811430.5956411.2354410.2533330.5400630.0533821.0672861.6395560.8897560.0689491.3125760.1720920.0730720.2968760.1251300.6574651.3004970.9843642.0479383.4183121.3191610.0131092.4271500.0911220.1783570.1618860.0098150.0436890.6312060.1033060.4339101.5675440.1082330.0186490.0088701.4239070.0201180.3914360.8101410.8685390.3407961.6713541.8859512.6365840.6089900.4962831.2113070.0099860.7170490.0182650.9442530.2480151.2123331.1396140.4862790.0418180.4985331.8912880.5155140.4303550.0156530.8505520.0164380.4322990.4353480.0083650.6227260.0233480.3193340.3714470.0185550.0099020.2477660.3940221.2166371.7000760.6592601.0792350.4483480.0389180.5742321.3104260.0197140.0084460.8200861.1238500.4942721.2225650.1458231.2701440.6402410.7056261.8482960.0249120.3177301.2092350.0306090.7871800.6452250.0006290.9987702.2331190.8754700.0084562.3399980.5962020.1845440.5377610.0005481.2816241.1808191.6921751.5684931.4362230.5142100.2844920.6104090.2484200.3935540.0535570.2842660.0190710.0131531.2661820.0166570.9748090.3434690.5413000.0670170.5052241.1783401.3042180.8414881.6863921.6236721.0118170.0088820.4465880.4329741.2495520.0133950.8658640.3575990.8312221.2157600.8471931.0954840.5210070.2816760.2955340.5977351.5876701.3000810.0231521.6627211.5760961.0192771.0403820.8197610.5520331.2688350.0280110.7669280.0183630.3189441.5309460.3774810.8116170.1322280.3139851.2477461.1266911.2108340.0437841.5985690.1233250.3773740.9727820.0090960.4894420.0192790.0172830.1709841.7243740.0154700.1893120.2243951.3021311.2257030.4948820.9926230.3792110.0177140.4418130.6268791.3888501.6905002.6610442.3844470.3571581.3153251.2916910.0625540.3426060.6096380.4155231.2941671.2912831.2405270.0082680.1630780.4997310.4771660.5567450.0005260.0207211.3330900.740453

*******************************************
EVALUATING PIPELINE 
Pipeline directory: /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_7645cfce_2020-02-18_12-24-14prdl64xd/
With following parameter combination: {'batch_size_seq_length': 2, 'lr': 3e-05, 'lr_type': 'constant'}
EVALUATION OF CHECKPOINT /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_7645cfce_2020-02-18_12-24-14prdl64xd/outputs/checkpoint-3
-------------------------------------------------------------
|           |   agree   | disagree  |  discuss  | unrelated |
-------------------------------------------------------------
|   agree   |    678    |    162    |    212    |    34     |
-------------------------------------------------------------
| disagree  |    51     |    196    |    45     |    32     |
-------------------------------------------------------------
|  discuss  |    251    |    76     |   1439    |    68     |
-------------------------------------------------------------
| unrelated |    57     |    34     |    83     |   8480    |
-------------------------------------------------------------
Score: 8533.25 out of 9226.0	(92.49132885324084%)
Accuracy: 0.9071272482770214
F1 overall: 0.728099944419129
F1 per class: [0.6387187941592086, 0.494949494949495, 0.7965679490727927, 0.9821635394950197]
*******************************************


*******************************************
EVALUATING PIPELINE 
{'batch_size_seq_length': 3, 'lr': 3e-05, 'lr_type': 'constant'}
INFO:__main__:Creating features from dataset file at /home/ubuntu/fnd_implementation/data/processed
  0%|                                                 | 0/11898 [00:00<?, ?it/s]  0%|                                       | 1/11898 [00:02<7:39:57,  2.32s/it]  4%|â–ˆâ–Œ                                   | 501/11898 [00:02<5:08:29,  1.62s/it] 17%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                              | 2001/11898 [00:02<3:07:31,  1.14s/it] 38%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                      | 4501/11898 [00:03<1:38:06,  1.26it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                    | 5501/11898 [00:03<59:24,  1.79it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                  | 6169/11898 [00:04<37:15,  2.56it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11898/11898 [00:04<00:00, 2945.79it/s]
  ******************************************* 
              Running Evaluation                
  *******************************************
 
  Length dataset evaluation: 11898
  Length dataloader evaluation: 744
  Number of epochs: 3
  Batch size: 16
  ******************************************* 
 
['/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_78b0bd82_2020-02-18_14-14-01g90xeutb/outputs/checkpoint-3']
INFO:__main__:Evaluate the following checkpoints: ['/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_78b0bd82_2020-02-18_14-14-01g90xeutb/outputs/checkpoint-3']
INFO:transformers.configuration_utils:loading configuration file /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_78b0bd82_2020-02-18_14-14-01g90xeutb/outputs/checkpoint-3/config.json
INFO:transformers.configuration_utils:Model config {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 28996
}

INFO:transformers.modeling_utils:loading weights file /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_78b0bd82_2020-02-18_14-14-01g90xeutb/outputs/checkpoint-3/pytorch_model.bin
HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=744.0, style=ProgressStyle(description_width='initial')), HTML(value='')))
0.2729330.2737820.1370900.1743760.3673290.0735700.0132080.0021760.0006230.0130120.0017450.0002180.0002010.0000850.5418730.4045850.2355890.4961530.0315910.5775841.2977841.4596640.7133960.0325010.0020050.0004790.0009200.4016881.9259660.3764560.0126250.0005380.0000910.0000582.1292511.9103240.4963190.0134810.0005680.4593820.0115610.0031050.0001730.3751300.3385220.0078100.0002440.0007540.1436840.6465010.6664580.0138910.0012880.0018210.4157821.2469380.0223180.0008380.0001130.0000960.0010070.0001270.0000780.0001280.0011850.0257730.4308720.3886840.0062640.0001610.3171600.6396750.5277430.0077410.0003140.0002540.0003660.0002980.0003170.0010740.1567290.0033690.0008460.0000780.0000670.0000660.0000590.0001010.0000650.0002100.0001060.0000750.0001440.0920940.0044240.0002470.0000750.0085080.0008880.0008130.0000610.0016620.8382860.0084520.0007040.0002100.0008420.0001480.1301620.0012680.0000840.0400540.0034790.1895340.3564340.5452000.0055800.0004010.0013520.0003700.0002430.0007940.0001330.0095640.0018520.0006650.3048720.0028390.0000770.0005810.0476680.0475460.0005330.0644620.0007130.0002320.0001880.0001940.0003090.3198140.7410560.0056300.5356560.0052260.0022660.0878500.0007210.0006060.0092080.0008620.0003150.0004010.0003411.0328550.0069020.3603550.0026460.0003950.9885220.8717430.4091200.3829600.0026260.0034970.0164280.8858161.5670830.1511080.2749271.0658660.7233680.0064970.0027320.0008770.0759791.0086250.0062430.0010320.0002860.0000880.2645940.0067400.0004991.2564730.5513260.7305620.0154240.0004790.0304640.0923250.0093560.0028710.0333650.0009320.0271700.0004360.0173490.0079830.0002972.3373980.0123820.3374380.8430280.9317940.7494580.5795980.0108190.0661290.0957831.3876030.0072590.0008390.3512060.3499550.0078850.0209430.0620310.6370910.2924600.6628670.0160740.0060780.4066400.7230890.3963840.2969850.1329250.0006850.5807660.4386620.6640832.7058100.6789940.0036350.0010170.0009490.3989610.9950010.0042620.0036920.0191480.0451430.0008680.0005980.0070360.0011640.4305650.0063110.9545040.2860880.1605030.0026030.0252010.0024070.0672590.0153050.3646350.0021720.3488940.0781630.0884850.7482850.4496840.1713150.0196800.1733620.2239670.1438300.0480580.0033240.0021810.3361940.3217110.0065150.0002850.0000620.5091670.0019030.0003930.0025630.0386530.0004080.3267100.0017670.0192130.0053550.2217180.9863600.2241290.7406410.0092920.3454970.2474260.9466960.0344500.0009340.0004330.0005100.0005420.0113580.0095970.3900160.2515710.2952660.0594260.0004200.0002260.0061980.0006940.0010630.2387420.9659590.5099950.0027780.0103860.0004850.0003390.0317500.3613710.0102640.0102530.0007230.0005770.0001540.0002150.3574300.4053000.0015550.2885700.0011780.0012240.0809500.0076660.5003950.0016370.0003610.0012850.0006520.0006950.0010360.2520790.0061480.7519850.5008590.4781390.4585120.0029330.0194410.0106420.0303030.3086381.1900151.7462220.0078980.0008570.0005180.1252930.0013120.0005770.0012390.1311330.5136070.3806440.3445050.5411350.0016890.4929550.0587680.0018920.0011270.0054740.0267050.0418520.0015480.0057490.0000680.0002980.3364660.0055740.0056380.0053770.0391860.6426170.4842300.6050160.3354770.5360490.0016800.0005300.0004460.0005380.0004501.6336061.4490872.4675041.3016490.7240510.0020680.0001450.0002860.0002970.0002970.0004270.0003260.0001660.0000650.0004670.0007200.0014730.0026270.1833461.8687040.0133650.8390220.3301610.4138370.0200930.0012740.0026090.0033140.0086600.2121460.0353740.0002990.0003780.0001170.0001770.0025530.0002032.6581182.2933930.0083840.1529010.0061110.0108391.6679051.2692981.0358360.3198390.2847990.0044590.0038590.0005820.0013110.0013001.6236940.5973290.0018310.0008210.0008270.0016100.0010210.2528410.0025890.0010910.0034470.8614201.3735080.8578860.4795480.0028300.2477610.4097290.2306430.0029900.0448400.0954290.0256340.6849940.4389170.0010731.4171031.0921320.0046810.0005370.5025500.0035520.3620050.5565790.3610410.0120280.0183730.0005520.0023600.0016460.0047100.0011170.0009420.0000720.0051550.0023190.0014590.0031880.1641970.2139800.2081650.0014940.0005150.0004430.0004810.3606890.2838560.0227870.8206660.1104290.2526090.2382230.0030900.0025270.0005890.0045290.0022440.0008640.2265880.0008530.0007180.0322310.5807880.0026860.0009120.0022640.0034410.0055610.7645110.2921850.0046210.0046320.0030290.0012010.0039860.2928280.0010650.4345920.0028880.3645080.0400610.0006030.0014550.0004620.0005611.0848310.0220401.1247720.6623320.6488011.4341640.9241350.9260760.0020800.0058310.3171990.8760850.0934170.0008530.5815010.4829990.3118860.7107520.1654603.1720910.0084110.0214160.3934570.0699130.0556270.0039930.0880890.4428040.5632910.3737600.2500710.2115550.5983850.5380780.6512390.3033290.6482040.6456590.2188610.3724890.8373350.5150880.2352950.4082150.6608390.6776910.3250470.2419570.3716960.4122780.4125130.6035260.4055640.5013750.9330410.5685850.0925200.5003830.5302130.7505200.6162720.0521340.5320900.9067510.4748470.4676680.3487890.3531470.2294700.5662040.3556150.9234520.5341150.5411170.1938970.3366350.4989500.2006650.5098240.1302800.2127000.1885680.2318970.3336310.1504320.4010320.4130420.7535650.2092560.6779010.2973340.1887730.4536770.6988970.7577950.5408640.1439030.3956890.5816810.4172200.3991280.2630380.9329880.1180140.7923320.3505870.7496950.2011190.7449570.6274500.4799400.1485450.6364930.2896790.4655410.2548900.2583060.6205350.2205840.2675460.5991760.3486380.3418180.2875660.3146250.4733460.3914730.2786840.3926460.3952870.2412390.9472100.5868150.6961050.2503600.2071220.0882460.5685630.5400880.4556490.3507130.2482890.6568190.2662370.1689290.4478910.1142680.6067080.2362860.3362811.0653580.7162370.2560990.4212450.5378600.1461840.8766860.3799750.4119880.4010340.6650760.2309570.2513730.1312930.4278020.3171610.6625350.5641740.3912170.2751490.4017560.3256440.9648820.7845380.3769060.3003900.1016780.4780630.4142710.3860090.3146970.6179390.6072270.9321880.6361310.3017760.4166740.3641920.3029840.6769380.8458600.2810640.8472211.0091220.5859270.4182170.2513530.2248180.0909810.3183850.9555920.1661090.0751520.803022

*******************************************
EVALUATING PIPELINE 
Pipeline directory: /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_78b0bd82_2020-02-18_14-14-01g90xeutb/
With following parameter combination: {'batch_size_seq_length': 3, 'lr': 3e-05, 'lr_type': 'constant'}
EVALUATION OF CHECKPOINT /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_78b0bd82_2020-02-18_14-14-01g90xeutb/outputs/checkpoint-3
-------------------------------------------------------------
|           |   agree   | disagree  |  discuss  | unrelated |
-------------------------------------------------------------
|   agree   |    815    |    111    |    186    |    41     |
-------------------------------------------------------------
| disagree  |    70     |    282    |    60     |    31     |
-------------------------------------------------------------
|  discuss  |    135    |    63     |   1493    |    160    |
-------------------------------------------------------------
| unrelated |    17     |    12     |    40     |   8382    |
-------------------------------------------------------------
Score: 8625.25 out of 9226.0	(93.48851073054412%)
Accuracy: 0.9221717935787528
F1 overall: 0.7920858045249626
F1 per class: [0.7442922374429224, 0.6190998902305159, 0.8225895316804408, 0.9823615587459713]
*******************************************


*******************************************
EVALUATING PIPELINE 
{'batch_size_seq_length': 1, 'lr': 3e-05, 'lr_type': 'constant'}
INFO:__main__:Creating features from dataset file at /home/ubuntu/fnd_implementation/data/processed
  0%|                                                 | 0/11898 [00:00<?, ?it/s]  0%|                                       | 1/11898 [00:02<8:14:14,  2.49s/it]  4%|â–ˆâ–Œ                                   | 501/11898 [00:02<5:31:28,  1.75s/it] 38%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                      | 4501/11898 [00:03<2:30:35,  1.22s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                   | 5501/11898 [00:03<1:31:11,  1.17it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                  | 6051/11898 [00:04<58:22,  1.67it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11898/11898 [00:04<00:00, 2824.16it/s]
  ******************************************* 
              Running Evaluation                
  *******************************************
 
  Length dataset evaluation: 11898
  Length dataloader evaluation: 2975
  Number of epochs: 3
  Batch size: 4
  ******************************************* 
 
['/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_739798ac_2020-02-18_12-24-10rij2za19/outputs/checkpoint-3']
INFO:__main__:Evaluate the following checkpoints: ['/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_739798ac_2020-02-18_12-24-10rij2za19/outputs/checkpoint-3']
INFO:transformers.configuration_utils:loading configuration file /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_739798ac_2020-02-18_12-24-10rij2za19/outputs/checkpoint-3/config.json
INFO:transformers.configuration_utils:Model config {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 28996
}

INFO:transformers.modeling_utils:loading weights file /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_739798ac_2020-02-18_12-24-10rij2za19/outputs/checkpoint-3/pytorch_model.bin
HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=2975.0, style=ProgressStyle(description_width='initial')), HTML(value='')))
1.4138341.4149750.7086070.2517330.5120060.1034850.0224640.0066050.0158580.0029250.0079610.0035430.0047930.0016510.0017470.0037510.0060990.0021480.7342570.0401250.0035480.0054820.0048250.0014300.0012850.0038220.0016701.4427060.0526060.0029010.0011750.0062170.0013450.0027510.0012150.0011500.0011591.0033470.0275210.0091880.0030600.0012020.0012370.0041170.0012670.0015020.0012860.0013650.9435710.0204610.0016800.0011630.0019160.0018260.0011540.6851441.4323280.4619120.4565372.9602880.0521710.0020060.0011751.4852000.0243630.0015180.0029970.0149561.4771470.0225660.0014820.0011710.0011741.4769940.0211170.0014230.0129641.4770950.0201020.0014150.0028501.4769750.0191591.4788341.4945381.4948751.4942220.0183350.0030250.0011961.4769630.0173840.0204930.4543210.0058600.0011550.4402940.0057010.0011790.0011410.0011280.0011280.0011280.0022120.0045120.0011770.0011261.8146960.0179300.0013020.0011360.0055270.0028920.0030020.0045210.1290550.5594620.0059180.0011940.0011420.0012530.0011470.0011490.0021410.0011500.0021640.0028450.0011640.0011500.0011520.0011490.0011470.0011540.0011550.0011570.0011510.0051450.0041691.4105560.0112830.0069010.0241300.0013030.0033300.0088171.4083520.0107750.0012280.0024720.0011680.0011670.0011390.0032960.0011750.0028730.0028500.0097691.1078680.0080941.3964750.0097620.0011240.0011160.0011120.0010950.0010731.2434560.0085030.0011380.0010570.0010880.0010910.0019490.0616360.0013850.0010900.0075420.0016460.0011030.0010600.0010820.0817760.0015170.0011000.0010950.0010630.0011120.0010670.0011200.0082330.0151880.0117030.6207040.0047500.0104350.0016090.0012810.0216100.0123630.0130660.0051160.0242800.0111431.4777640.0100550.0011701.0947110.0066800.0011461.4075470.0097900.0014030.0010930.0013500.0011170.0012200.0011180.0357100.8944590.0119451.4083000.0468500.9494610.0058090.0012590.0010910.0011060.0011130.0034060.0011200.0290720.0012390.0010700.0011270.0010730.0010450.0010760.0010830.0011220.0010620.8590270.0046690.0010700.0010900.0010950.0010870.0143060.0011170.0010590.0010650.0010600.0010900.0010770.0010670.0010870.0010780.0011050.0011161.5182060.0069040.0012140.0786430.0204650.0012250.0045560.0011661.4083150.0099000.0011810.0028321.4772140.0066020.0011750.0011760.0055880.0179100.0011340.0010380.0010390.0010770.0147900.0282710.0012270.0028150.0028270.0011370.0011300.0011240.0011190.0028230.9214610.0042820.0011530.0028020.0011500.0034500.0028340.0015950.0028200.0011360.0034550.7802800.0037390.0054710.0013610.0011780.0045010.0050640.0029160.0028330.0011560.0045060.0028360.0040450.0014650.0044980.0011390.0011140.0191200.0012090.0010440.0293041.3599970.1539630.8781140.0088850.0011760.0045080.0028400.0061920.8668680.0054600.0011640.0011700.0011510.0011710.0011630.0011490.0011600.0011320.0011650.0011340.0011520.0011580.0011670.0011360.0011550.0011500.0012100.0011390.0011660.0014360.0011420.0016210.0011400.0011580.0032950.0013920.0011630.0011670.0011490.0011670.0015360.0011590.0011540.0014950.0011880.0011350.0011370.0011610.0011480.0028450.0011630.0109140.0020850.0013980.4368200.0028210.0015320.0014270.0174600.0027560.0082530.0013350.0014820.0010330.0013100.0118500.0021480.0015600.0166080.0011280.0045170.0028490.0078670.0028550.4368310.0021680.4369180.0021800.0012420.0010570.0010780.0010670.0061760.0045180.0028320.0045130.0016211.4100451.4134610.0062730.0014870.0011380.0028230.0028310.0028260.0028200.0011520.0045070.0045200.0011530.0011540.0011560.0031620.0011580.0011410.0011410.0011540.0011450.0011380.0011440.0011520.2225430.0033400.0011580.0011450.0012240.0011570.0038140.0011400.0011410.0011540.0011570.0011590.0170930.4686760.0241220.0214150.1190040.0013610.0057660.0120490.0039670.0015370.0758300.0240100.8211280.0029500.0028380.0011561.4783290.0060310.0028440.0011490.0011560.0300160.0013480.0011460.0028260.0028290.0011400.0011430.0011410.0011520.0061790.0045130.0011590.0028080.0011760.0011310.0011550.0028340.0028340.0044900.0028141.4083590.0040050.0011220.0011150.0011200.0011240.0011320.0011371.4083561.6289460.0089330.0047760.0028380.0052670.0045090.0143040.0010910.0011030.0011550.0177570.0011240.0010730.0012020.0010560.0163710.0011060.0011140.0011260.0011220.0011520.0010820.0010660.2154750.0160270.0011760.0011850.0044910.8028970.0026250.0063490.6959330.0023930.0010440.0015080.0011260.0028080.0021650.8622310.0051590.0010640.0028130.0011750.0011610.0011590.0011690.0028380.0028520.0028490.0011730.0011700.0011610.0011730.0011620.0045190.0011740.0011710.0028450.0011780.0011661.4777740.0038221.4099111.1272130.0076570.2700843.0522020.3357990.0017270.0011560.0070800.0030420.0011321.4082100.0458150.0012330.0029491.6929330.0041101.4099634.2267250.0268960.0197090.4858620.0036160.0012150.0011360.0028141.4765370.0036790.0028350.0011520.0011480.0011470.0045000.0028340.0058900.0054510.0218240.0208540.0216360.0145690.0089570.0257760.0010980.0010360.0042830.0143180.0157860.0010940.0156730.0010710.0010830.0044980.0011690.0011220.0028371.4083290.0038360.0011551.4083360.0051080.0028230.0011440.0011481.4100140.0034090.0028240.0011300.0011800.0028200.0011970.0011590.0011480.0028270.0028370.0011390.0011291.4083120.0033610.0011441.4082900.0033411.4083250.0034090.0011350.0028321.4083190.0033200.0011320.0011340.0011560.0011570.0011440.0011600.0011510.0028340.0346880.0580110.8519370.0190810.8369510.0023850.0169420.9061870.0373320.3852792.3765470.0114461.3659180.0065551.1153480.0062110.0078690.4862431.0133101.4883980.0067150.0011721.4110220.0032361.4099871.4103671.4103610.0032121.4086061.4103730.0032101.9566541.6055090.0034680.0011300.0235441.9163650.0179090.0100130.0227110.0128051.4699651.4893730.0066561.4864390.0083170.0078720.0078720.0078720.0078720.0028030.0011200.0010340.0010680.0011180.0149640.0011040.0010530.4277890.0017270.0011210.0011240.0010901.4146910.0031060.0011220.0139240.0011700.0011690.0028390.6894660.3486400.0016500.0011550.0029190.0075880.3872760.0016880.0028210.0011620.0011601.6244050.4378022.0617910.0039330.0020440.4371291.4178100.0030503.0314520.4410340.0034130.0011341.6242650.7687251.4093910.0030180.0011551.4082780.0035750.0011580.0011710.0012154.2242230.0100910.0011040.2397630.0013990.0210820.0011550.0011250.0010990.0011460.0143740.0011200.0011290.0011380.0021860.0011711.6245681.4103560.0029520.0011380.0012230.0013431.2560781.4584830.0046980.0028290.0028210.0028280.0011410.0011481.4658201.4101540.0046090.0011540.0011451.4453670.0029620.0028290.0011850.0028160.0028252.8187984.2277820.0131580.0045170.0028130.0045020.0028151.4800650.0046520.0045270.0055480.0057412.6288970.0111100.9636010.0102170.0069300.0080021.1933323.0561702.9595331.8364053.0907241.5191422.0872510.0036070.0010950.0010640.0010300.0010640.4368620.0015850.1087180.4369690.0015780.0010410.8729270.4378860.1092090.0011650.4386390.5735200.0353550.0011870.0011690.0011330.0027980.0028170.0028190.0012110.0011540.0045060.0028350.0011570.0011551.6260965.8479780.0147151.4134140.0095130.0078710.0214470.0571320.0079510.0061950.0078690.4025221.7339701.2386351.6856730.0042420.0118500.0045220.0045100.0028290.0045040.8072340.0043140.0010960.0010570.8831070.8832750.0020860.0010770.0134022.8325121.8356521.4120040.0061000.0130650.0028460.0028210.0217420.0173080.0582040.0187700.0028400.0178270.0028350.0113540.0031630.0061770.0028400.0061780.0028320.0044890.0040380.0011401.4083480.0026970.0028200.0011460.0011330.0011410.0011380.0011590.0011411.4083592.8170420.0099090.0011390.0028081.4083381.4140091.3172820.0042251.4076800.1932980.0046581.4074670.1473380.0036660.0027800.0418510.0405260.0045460.0028270.0028340.0011560.0028220.0045090.0011580.0061880.0028270.0045060.0028350.0011440.0045101.4123360.0026132.1643591.8478823.4368650.1268480.0210910.0039260.0014790.0013650.0011710.0011180.0044660.0013370.0028020.4419050.0030100.0012450.4539761.8454250.6551490.0085380.0166720.0032050.0028260.0028280.0061860.0061890.0065620.0011210.0011240.0030190.0029000.0040930.0192561.1908670.0115310.0339442.7162810.0275211.4726020.0200980.0041191.4846811.4800561.4820500.0345161.2648822.7194390.0183731.2628550.6937861.1841932.9535651.2447340.0198650.0316920.0193192.1292200.0298770.0010850.0272970.0211470.0011360.0012990.0114491.2735050.0023290.2109650.0080680.0061891.4864010.0045380.0461300.0544580.0383820.0014110.6667940.0336190.0053921.3426721.3995710.7502751.8661250.0079920.0061840.0044930.0061831.8886450.0046510.0028830.0011410.0010880.0011180.0028223.2475920.0246040.0078830.0078671.4396401.9107220.0185280.0154500.0011030.0191990.0166280.0011370.0010522.8156114.2909681.4141280.0041911.4100700.8151180.5353070.0395260.0383460.0078970.0045040.0028260.0201610.0045140.0061800.0374810.9048280.3794750.0237281.4330270.0032110.9294792.8844880.0089171.4174400.0043400.0027031.4305461.4130350.0041120.0028230.0011220.0011341.6243951.4098430.0040990.0011281.4083540.0041063.0333532.8183560.0037280.0011570.0011530.0011351.2801980.0023070.0011560.0011400.0011480.0011430.0011530.0034160.0011500.0011460.0011600.0011560.0014020.0011550.0011710.0011310.0011530.0028350.0028350.0061660.0051850.0028050.0028100.0028190.0044940.0045010.0011290.0028170.0011330.0045030.0011550.0045370.0028370.0011631.4769240.0058120.0028340.0045140.0028260.0028340.9057530.0102471.4077640.0033460.0022331.4174852.3729082.7178974.8750784.6607943.0410663.1709301.6305130.0025590.9702232.8179874.4412134.2282710.0115202.8390461.0018501.3723130.8085280.0017730.1374690.0189420.0010780.6802380.0067690.8979590.0019180.0011560.0011300.0011430.0012110.0045050.0078640.0078670.0078670.0045090.0045090.0011410.0028360.0028280.0054100.0028030.0045030.0011220.0044931.6042580.0058430.0044920.0045030.0028160.0011380.0044970.0028220.0010930.0020250.0152120.0157250.0027600.8551690.0017880.0011000.0166410.0146690.0155401.6395861.4113101.6289350.0075300.0061891.4116553.0359231.6319200.0187670.0011140.0010230.0010740.0797890.0189030.0011140.0011060.0011110.0032090.0147010.0011040.0011230.0010900.0173910.0010960.0010510.0018450.0017080.0010910.0010790.0167730.0010650.0010670.0139800.0010540.0174651.4925180.0048440.0804130.0396740.0535372.8085650.9364031.8128722.7855931.8747460.0026650.0170110.0144290.0188490.0010731.6260270.0091553.2508750.0104454.1699570.0078160.0045390.0045090.0028300.0011500.0051160.0045040.0028230.0028270.0045110.0010920.0514610.0514280.0241130.5217681.0590291.2717621.6304841.4146313.0360764.2266801.6327731.4146180.0089620.9841530.0035700.0121950.0011390.0011380.0044980.2011710.0012760.0011330.0011230.0041270.0011690.0011660.0011520.0011400.0011700.0011390.0011620.0011601.4099601.4110980.0055890.0011390.0013810.0011640.0028380.0028450.0011910.0011630.0011490.0011650.0028330.0028390.0011730.0011580.0011640.0028370.0010890.0183110.0010630.0180120.0010560.8530200.0191920.0010920.0490001.1446370.8926920.0017193.2082222.6750001.8070250.0025060.0028160.0011610.0011510.0061980.0011570.0028290.0014810.0011560.0092731.6854360.0024060.0011760.0045090.0061860.0061870.0028330.0028350.0061870.0078630.0078650.0078640.0078650.0061750.0028231.4752010.0072550.0044990.0027960.0057400.0061805.2086263.3696531.0914810.5466181.8851131.0899151.1084080.0331150.0213540.0062040.0061820.0028210.0061830.0078650.0028370.0045100.0011550.0061890.0061860.0028190.0028230.0011540.0061820.0028350.6859760.9535521.4106500.9080710.0017120.0061560.0029300.0937970.0333650.7291271.4495421.4512851.6407982.2266791.6735160.0056840.0272280.0135050.3105000.0047250.0078631.7894200.0057630.5566710.6863160.5571070.3024110.0030210.5674310.5694500.5548580.0015370.0028250.0011400.0061690.0063190.9023390.0016760.0162860.0038310.0039610.0010430.0013270.0159220.0010700.0013200.0163400.0064950.0011770.0280970.0058270.0191840.0010770.7443770.1088860.0011780.0011490.2343030.0012310.0010780.1082170.0011640.8222950.0183500.0011060.0011320.8217220.0016100.4395310.0013880.0010690.0010610.0011190.0010952.8153942.8214530.0048280.0054560.0896671.4082910.0071310.0028250.0028160.0061830.0028250.0045020.0045030.0011351.9647971.3239641.3236551.9559532.2817320.6595860.0152010.8230200.0019090.0130011.2842500.0019310.0011170.0052400.0063350.0022340.0011711.4083600.0020960.0028260.0011530.0011410.0011430.0011510.0011440.0028290.0011520.0028280.0033193.2477320.0032970.0011480.0011540.0011450.0028291.1878260.0019470.0011550.0011550.4312510.4316840.6539891.5336562.3799451.4149015.6306014.2279801.4161120.0087881.4115711.4091771.4091850.0020311.4082280.5678380.0015180.0107250.0011370.0011292.8840020.0054110.9452400.0017241.4082460.0020190.6869700.0015970.0045060.0028410.0011390.0028180.0025040.0011410.0045011.4786580.0038110.0030240.0045051.4769771.7163920.0039230.0028260.0061850.0012870.0045270.0011400.0045040.5551740.0033240.1086820.8722890.4370950.0030901.0187061.6264160.1094801.1818020.5451480.4372001.2553000.8729200.0016350.8734650.0033160.1087410.8721140.0017040.0011370.0011580.0011440.0028330.0011540.0011510.0011560.0011530.0028300.0011520.0011620.0011560.0028300.0011550.0028290.0028380.0011510.0011500.0080920.0011560.0011070.0028360.0011470.0011580.0045080.0011560.0011490.0028280.0011510.0028390.0028310.0011540.0011540.0011560.0011560.0011590.0011530.0011510.0028280.0011600.0011370.0011270.0011450.0011630.0011520.0045300.0078620.0078650.0078670.0078650.0307820.0293610.0227281.5044212.8173790.0044700.1087561.0880820.0085220.1484090.5725901.0085741.3315171.0979890.4407440.0081270.0078650.0078652.2527553.7666383.0708811.1370510.2145882.2054371.7727331.2888361.1793951.8408400.0022280.0055380.0059900.0012190.0012730.0060890.0016681.4802440.0036470.0121280.0046830.0101960.0054470.0014580.0028060.0013090.0048620.0085540.0013061.0986250.5451140.4369900.4573280.7247491.0053790.4378090.0013080.4379090.0030880.0014000.0011350.0011380.0130410.0029830.0028890.0028180.0013230.0011400.0025150.0011490.0167330.0017650.0136780.0011980.0076550.0256890.0011540.0066250.0065950.0097710.0044330.0028221.8144552.7724581.4440722.7978233.4569361.9190191.8168960.0038610.3430371.4102041.4090620.0036410.0017480.0243110.0055460.0011730.4703550.0052450.0363691.4083440.0053120.0011550.0011291.4096240.0161610.0078700.0078640.0078650.0078650.0078650.0078654.2241302.0380632.8198363.1565430.0096670.0065540.0598030.9447650.1649091.4280641.4141404.2250851.6318811.4142481.8698630.0290240.2370090.0144141.4535841.4093601.4087060.0019080.0011290.0078600.0078630.0078641.8832810.0089211.2967840.0085890.0078640.0078640.0078641.4167332.3203942.1760951.9930371.4321840.7870280.0049350.0061770.0011180.0011450.0061830.0011311.0089140.0033670.0061790.0028250.0011400.0045020.0010990.5001130.0013070.0180790.0010830.0353210.0011090.0149150.0288810.0010670.0010450.0010492.4425980.0231680.0333370.0195680.0200840.0349670.0208150.0073350.0011420.0015890.0302920.0010550.0330030.0010821.4734410.9212520.7090590.0015290.0011761.3118491.6251161.4643301.2611931.6251080.0021210.0011341.3739350.0166590.0011380.0170550.0010970.0010630.5356591.7388420.0324770.0061693.0349411.4149742.8195621.6310270.0087422.8187992.8186984.1508600.0067661.4099290.0052491.6259131.4108451.4107111.4089881.4109361.4124850.0035830.0148172.8154660.0043951.4099741.4107110.5040000.8930810.0764422.5637261.6258060.0020080.0011440.0011520.0011531.6245950.0029970.0011720.0011440.0011530.0028281.6244443.3366220.0029170.0011870.0011530.0011556.5920183.4728020.1351630.0011390.0010380.4410320.0013020.0172180.0012600.0028240.0011400.0037850.0028300.0129420.0011510.0028160.0028180.0147600.0011270.0058220.0120470.0011480.0011360.0080941.4784540.0086331.6294473.9304984.2872542.6723551.4304461.4089091.4288230.0258190.0630481.4259540.0018970.0011580.0011560.0028290.0011510.0057930.0028270.0028310.0011172.4536600.0023830.0177810.0335160.0011400.0011200.0010880.0147331.6385350.0169300.0011240.0011090.0198010.0011510.0161051.2164120.0017220.0010580.0010880.0010950.0010800.0010950.0010520.0547540.0744510.0011330.0010830.0084070.0149711.3719630.0017781.4765090.0209020.0178560.0027840.8603730.0021620.0161090.0011120.0010400.0314900.0011260.0751460.3624410.0029571.4134450.0068670.0078632.1736650.0153070.0010410.0292330.0010591.4081440.0018050.0028260.0011490.0011540.0061830.0028360.0028280.0061880.0019520.0028250.0028280.0045130.0131920.0061880.0028250.0011490.0044900.9702160.7389350.9226980.0015340.0010750.0011270.0010670.8222201.9237320.0020140.0010640.8745530.0014970.0010660.8744860.5576480.0016710.0011200.0010920.0010650.2815730.8711960.0015050.0010450.0010540.0027700.0011140.0010750.0459360.0010820.0015220.0010800.0011120.0010460.0010820.0010740.0231840.0011490.0010670.0306470.0010950.0010570.0011130.0206290.0010970.0010890.0011250.0363800.0011500.0628761.4099530.0018850.0011430.0011150.0028131.4076220.0522940.0011450.0028111.4081870.0018193.2658475.8473303.2539084.6581414.6588001.0223130.0066820.0090190.0078660.0045180.0045200.0061900.0011850.0045090.0061870.0061900.0410680.9110110.0161470.0284880.0343530.0160310.0270570.0168470.0078670.0078630.7480592.7687950.4596410.7699810.0014630.0028060.3400010.8902550.0015480.0160520.8884540.0162560.0011350.0152840.0011200.0011180.0165510.0154770.0011050.0010980.0078610.0078640.0078641.0158580.9727190.0083190.0078790.0078640.0078630.3472161.3320360.0034610.0028210.0011400.0011750.0028160.0022220.0084461.4803070.0018380.3453452.1944250.0021350.0568450.5995931.4911723.5675971.4641330.0018190.0010990.0011380.0012050.0011070.1235760.0011720.0796690.0395020.0011200.6187800.6126020.0013890.0011130.0011000.0415540.0011180.0011310.0010890.0010960.0010910.8568813.1481331.3859370.0289600.0404720.0329250.0164470.0045090.0028330.0046210.0028220.0028360.0056480.0044910.0061870.0032360.0028220.0011400.0118680.0028240.0102170.0061880.0056820.0175540.0011420.0045080.0045020.0011461.0035330.0049550.0028140.0028310.0012430.0029960.0029540.4656410.0563865.1474515.1111426.0328411.6517201.6592791.5721800.0018311.5969921.4800300.0085300.6937960.0081740.0045091.3388180.0034330.0045030.0061860.0051620.0078621.0337840.0083271.0400840.0074480.0078640.0061880.0561610.8733260.0554190.0307270.0029240.0033211.0288850.0066790.0080080.0045750.0023360.0066612.3237171.5149902.8473180.9473490.5462290.4556690.0012570.0310460.0205030.0273600.0299580.0044920.0603790.0061770.0183170.9788920.0194200.9277100.0161650.0456470.0181961.4263860.0050830.0224590.1981450.0064760.5377260.0358280.0206500.0285140.0508330.0016681.8271290.0018591.1607351.2246520.1092531.2308621.0298890.0168931.6766030.1091670.7455850.7659820.0013900.4378240.5588850.4372360.0012290.1098700.1110631.9163570.4379441.1180281.4172420.4374240.0306930.8495221.2252530.0303510.5719111.3528980.4521770.9911960.5602910.1089670.1087690.1146750.1089240.7839751.2612831.8525822.1791580.1096411.4068410.0126271.3053741.3612010.1097591.6673501.7996450.6978630.8648381.1205690.8881502.2160051.4260330.7139892.9747330.0025220.0034321.2613800.0237313.0264920.0176842.1156951.4758430.5605511.2315271.2328540.1094640.9949131.0411470.0015041.0389480.0171860.4534500.5566010.4398751.9114800.4508030.4372720.1085391.2298270.4373080.0104720.4370160.5569951.5690371.0513821.8600860.0431160.0384480.0021690.5834220.0036861.3302330.5540920.8372650.6976890.0224590.5560000.1362980.3637071.2260080.1091950.1091410.0172932.3991690.0077081.0676212.3496361.5714920.7782990.9308380.0014601.4390770.9249100.0024550.0010300.5060370.5659531.0067990.1135531.7282981.4387840.1090500.1587630.4412850.9930441.6676320.0024030.5528301.4573650.0286763.0161110.2312610.8649670.6838570.7249680.1187450.1200451.2669151.2613061.1106320.0019011.1013100.0245740.0011012.5800170.0046530.0138370.8583570.8360081.2856600.4373860.0023170.6783410.0069960.5551271.2315280.0098690.4371310.0016072.0049770.0146171.5064110.2525150.4373170.4373280.0082741.2468421.0049150.1138220.0224850.5733741.7682060.0336781.4269310.8731420.7055770.0248731.3758450.0156320.3827733.0850880.0096910.2721621.9231601.3446040.0161070.1219220.7197670.8781610.1242001.3600671.3785660.0016990.5551572.5417800.0023540.0027710.5556781.3237500.5573770.0034840.5557030.8389340.0350950.0324510.0028021.9201010.4526040.0177750.3784461.6348090.6777030.2349340.3777260.1088550.7657630.4385380.8373560.8859170.4371740.0013070.4405100.0088190.6725500.5557650.0019510.1089350.8778210.0205120.0192780.4383150.0161761.3269470.0183550.0038461.5418311.2199781.4163780.8322770.6806030.9008200.8636950.9275710.1232120.1088080.0267400.8436131.5956510.0171870.0443901.4993300.0301050.2821430.0751720.0142820.0164810.1087040.4369381.0203211.2173710.0691261.4505381.9988330.0018400.4521680.5656880.1245351.1126251.9568011.8296060.2171650.1088910.2225550.0011650.1195100.5552620.0012520.1086250.4685910.0168400.0012682.2514590.5578500.9238361.5261771.3390021.5434080.0179290.1256460.0011171.3491590.0024610.4405530.0017831.5083331.3528530.0020660.6610980.1174930.8775740.0247610.4369060.0194180.4510030.0012310.8673641.0641921.2838770.1094010.5446650.0113670.4366530.0011991.4236641.2849251.1260670.4373170.5563430.0014680.4373910.1183940.0010810.4367671.7119531.7029131.1176980.4372621.3524710.0128711.4189011.1131650.0057610.2803610.0012290.1086720.0010920.0278920.0257500.0176831.5650080.9443710.0459130.0137480.8269480.0032470.7595090.8107450.9355540.0016940.1086670.0010831.8985090.9130841.0531100.4422940.0034411.3862540.0018740.1243400.5447500.5553310.6632540.0014910.0010380.1087140.1247340.5904670.1089330.1120090.1380260.9483290.0360700.5551950.4371070.4374200.6786830.0164630.6630020.1094410.1112700.2296640.0099680.8970820.6773461.9717180.5559191.4199350.4393451.2333880.2168280.0149950.8726260.1090450.1239990.1087661.1005850.5448280.4479081.3398000.1257830.0025780.1374690.6768041.3418270.1092150.0092290.6990710.6240160.4402790.0031590.4367700.4401500.0012341.2949690.8484781.9149861.9191640.0219522.1780830.0151780.3046131.8434070.0147742.2661450.8736451.7889710.0310231.3111940.3245300.2210940.0020323.0484941.4613180.1092411.2384430.1091820.0121260.1169790.8808200.6940250.1193860.7563750.4393181.7499360.9922580.4373030.0012280.5574110.6635730.1166220.1086590.8394530.6915320.6633510.1091670.0010781.3323770.0304290.5568100.9099060.5560480.4370770.4375170.5607631.2131540.0559870.8200700.0013470.0010620.5549320.5566421.7127061.0015031.5706020.0078910.0012450.1096430.0476470.4766830.2958680.7132440.6470530.6880640.4284430.2293130.0107740.0038150.0603720.5605630.1089361.8638531.0456670.8717371.3167850.9913320.4373062.2421730.0062190.5444340.4688280.0013500.8725490.4371760.0165280.5444370.4370510.0230140.0401870.4369980.0016630.5554690.0031280.0224440.0010470.0562350.0311792.1954612.2214661.6144122.3443990.5559050.1091730.0177830.5552071.3803230.5451910.1093230.1090180.5573451.8092930.2609752.2165190.3042460.5067110.1084470.1095723.0826310.5587450.5703480.5675310.1086730.1089640.0284790.0162990.4370730.1087490.4389441.1055030.8826260.0186130.0017080.2362270.1215320.1176790.6644490.0170401.2305560.3911860.6766300.1852850.7129480.8629010.6774261.1927310.9558050.0197731.0321090.8713540.8887800.4372340.1105642.2057250.5455651.7639170.0238940.0396260.4479161.2620482.3082430.8249282.2046501.0988920.0513872.1059520.0017700.5575211.2110081.3592980.0046050.8506820.6725590.1099180.1086440.0010961.1128820.4371760.0340911.5595480.9040411.7407170.8997480.6342040.0218400.4512541.1473780.0319610.8989832.1105670.0312520.0211622.8447951.9221770.1139101.1741781.9290130.1182450.4369911.3587100.0015090.1090420.1114360.6275850.2818161.3723520.8529670.1090150.0011470.1181740.5552560.1114110.7846880.1089930.1091600.4491290.5553350.1234141.2827700.0157500.4368520.0011790.9913390.8803020.1087981.1100980.1360180.8806900.8234111.7896950.4396580.6695000.0017870.4548930.2165020.1088330.1264370.5447491.2807550.6633491.9032020.1093550.6094930.5446881.2315702.5168811.9597902.9861551.9190890.0220641.2619941.3240570.0133641.4311620.8126270.0502300.0010521.2250410.6860380.8923030.1090000.1158320.0268210.0014800.0238860.0149390.0234640.5663150.5705740.1089300.6767171.3553431.2554240.6767570.2168300.5553780.1091750.7842990.1097730.0090890.0010311.0103600.0198781.1141520.4372061.135638

*******************************************
EVALUATING PIPELINE 
Pipeline directory: /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_739798ac_2020-02-18_12-24-10rij2za19/
With following parameter combination: {'batch_size_seq_length': 1, 'lr': 3e-05, 'lr_type': 'constant'}
EVALUATION OF CHECKPOINT /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_739798ac_2020-02-18_12-24-10rij2za19/outputs/checkpoint-3
-------------------------------------------------------------
|           |   agree   | disagree  |  discuss  | unrelated |
-------------------------------------------------------------
|   agree   |    479    |    74     |    120    |    29     |
-------------------------------------------------------------
| disagree  |    216    |    235    |    115    |    58     |
-------------------------------------------------------------
|  discuss  |    233    |    71     |   1416    |    56     |
-------------------------------------------------------------
| unrelated |    109    |    88     |    128    |   8471    |
-------------------------------------------------------------
Score: 8451.0 out of 9226.0	(91.59982657706482%)
Accuracy: 0.8909900823667843
F1 overall: 0.6877594042527648
F1 per class: [0.5508913168487637, 0.43040293040293043, 0.7966244725738396, 0.9731188971855256]
*******************************************


*******************************************
EVALUATING PIPELINE 
{'batch_size_seq_length': 4, 'lr': 3e-05, 'lr_type': 'linear'}
INFO:__main__:Creating features from dataset file at /home/ubuntu/fnd_implementation/data/processed
  0%|                                                 | 0/11898 [00:00<?, ?it/s]  0%|                                       | 1/11898 [00:02<8:05:02,  2.45s/it]  4%|â–ˆâ–Œ                                   | 501/11898 [00:02<5:25:18,  1.71s/it] 17%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                              | 2001/11898 [00:03<3:17:45,  1.20s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                   | 5501/11898 [00:03<1:29:28,  1.19it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                  | 6249/11898 [00:04<55:19,  1.70it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11898/11898 [00:04<00:00, 2927.09it/s]
  ******************************************* 
              Running Evaluation                
  *******************************************
 
  Length dataset evaluation: 11898
  Length dataloader evaluation: 372
  Number of epochs: 3
  Batch size: 32
  ******************************************* 
 
['/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_658239e4_2020-02-18_23-20-25qzd_eea9/outputs/checkpoint-3']
INFO:__main__:Evaluate the following checkpoints: ['/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_658239e4_2020-02-18_23-20-25qzd_eea9/outputs/checkpoint-3']
INFO:transformers.configuration_utils:loading configuration file /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_658239e4_2020-02-18_23-20-25qzd_eea9/outputs/checkpoint-3/config.json
INFO:transformers.configuration_utils:Model config {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 28996
}

INFO:transformers.modeling_utils:loading weights file /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_658239e4_2020-02-18_23-20-25qzd_eea9/outputs/checkpoint-3/pytorch_model.bin
HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=372.0, style=ProgressStyle(description_width='initial')), HTML(value='')))
0.1098280.2526720.2950980.2519540.0633700.0128650.0022800.8628740.3718960.3301861.0538230.3747810.0352920.1480700.8418510.0563970.0036360.4657650.0531100.1582170.0080890.0005710.0002550.0006570.2456510.2918590.0119400.4498740.0167650.0006890.0532430.0018280.0038310.2319370.0130190.2540780.3216310.0091670.0004880.0005830.0603490.0078940.0002990.0001240.0001790.0001170.0023880.0009640.0001860.0118770.0066720.4622680.2276310.0044690.0002930.0150580.1473120.2881960.0061920.1497910.1705010.3445070.0067260.0584930.0013390.0122420.0078070.0005110.0002560.0565040.1539490.3934950.0068480.0002820.0011110.0006360.3937030.2432810.0033290.7037570.2492750.4058880.7425770.7322430.2645761.5830890.0225690.9449450.0112700.0004430.0500270.5938730.5981370.1339630.3116320.0038910.0091840.0059010.0020511.3318410.1404290.1447580.4120580.0163550.1246500.0024070.2277830.0629660.4854470.8157830.2368370.3675640.2766380.2475191.2487332.6916640.3275840.0033680.3138450.0150800.0493930.0200720.0430480.0068070.1839590.0495190.2601660.0841140.0126200.3005180.3890150.9939470.2296010.0386370.1140580.2313620.1192760.0010110.2263170.0022160.0003710.2441000.0427990.6323920.8555090.1358250.3892540.0700550.0007810.0008310.3273230.5381630.0043680.0001690.0010170.6439120.7329090.3821350.0198050.3361370.0175120.0003470.0830760.2560640.0017820.0029270.3264030.1313230.1800640.1512070.2209691.9690640.4452070.0130050.0747570.3110120.1570460.1627530.2461560.0023750.1525310.1934740.2121750.2779310.0061060.2005370.0991110.1950260.4660190.1431230.0658711.2833060.9612570.1339620.0010210.0003620.7037911.0807320.4730040.0025480.3339360.1792610.1701180.1600600.1108951.4012470.4475740.3337520.1672110.1276530.1606550.1106880.0045060.0006261.5272760.9894290.3439880.0937690.2810331.1956930.3890820.0024440.7111850.2907400.0023780.0018120.1680560.0282561.5616640.8039700.0875650.3732490.8291500.2329640.2748190.5284440.6342220.0692170.0088790.9354881.0409630.1110590.1921010.0042110.0988230.0059800.2218950.4093120.0061220.0003450.2141620.4148870.3501700.0795600.0867840.1142920.0497250.0032210.3738031.1921230.7337010.3699020.2125620.0036770.6450140.4176450.2096921.8942040.0279200.0033970.5617350.7777910.7037640.7256030.0123190.1278040.0025900.0071110.2811771.1317210.0938860.0117610.0027640.2366230.5355090.2850690.4783500.2896540.2401330.3187690.4699030.5346230.4513810.3000040.4262340.2631030.5686500.5894600.3073150.6445700.2275050.2675770.2303800.2452330.3179240.5985640.7823210.1830420.1896490.2471600.2330040.4548770.3364420.6676090.2776660.1382890.5553600.5032180.3632180.4146080.2993810.4546890.7564800.5859100.5381770.3344340.2398980.4362060.5084640.2122910.7341400.3536960.3882430.2067920.3578560.3634920.8163850.3088900.1750660.4968490.3277280.4849540.3430140.2961920.2800380.9029850.1948470.2217790.4342570.3696890.9237330.3173120.3470320.4483500.6341750.6212641.1266260.5221340.2801250.3776470.3386700.4368930.1433270.4387870.4405170.3769441.0167160.8462000.2793710.2912280.5081420.557052

*******************************************
EVALUATING PIPELINE 
Pipeline directory: /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_658239e4_2020-02-18_23-20-25qzd_eea9/
With following parameter combination: {'batch_size_seq_length': 4, 'lr': 3e-05, 'lr_type': 'linear'}
EVALUATION OF CHECKPOINT /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_658239e4_2020-02-18_23-20-25qzd_eea9/outputs/checkpoint-3
-------------------------------------------------------------
|           |   agree   | disagree  |  discuss  | unrelated |
-------------------------------------------------------------
|   agree   |    706    |    102    |    189    |    16     |
-------------------------------------------------------------
| disagree  |    87     |    272    |    81     |    15     |
-------------------------------------------------------------
|  discuss  |    209    |    59     |   1438    |    63     |
-------------------------------------------------------------
| unrelated |    35     |    35     |    71     |   8520    |
-------------------------------------------------------------
Score: 8634.75 out of 9226.0	(93.59148059830913%)
Accuracy: 0.9191460749705833
F1 overall: 0.7687892457111185
F1 per class: [0.688780487804878, 0.5893824485373781, 0.8105975197294251, 0.9863965267727931]
*******************************************


*******************************************
EVALUATING PIPELINE 
{'batch_size_seq_length': 2, 'lr': 3e-05, 'lr_type': 'linear'}
INFO:__main__:Creating features from dataset file at /home/ubuntu/fnd_implementation/data/processed
  0%|                                                 | 0/11898 [00:00<?, ?it/s]  0%|                                       | 1/11898 [00:02<7:37:45,  2.31s/it]  4%|â–ˆâ–Œ                                   | 501/11898 [00:02<5:07:01,  1.62s/it] 17%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                              | 2001/11898 [00:03<3:06:38,  1.13s/it] 38%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                      | 4501/11898 [00:03<1:37:38,  1.26it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                    | 5501/11898 [00:04<59:09,  1.80it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11898/11898 [00:04<00:00, 2688.85it/s]
  ******************************************* 
              Running Evaluation                
  *******************************************
 
  Length dataset evaluation: 11898
  Length dataloader evaluation: 1488
  Number of epochs: 3
  Batch size: 8
  ******************************************* 
 
['/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_6048b07a_2020-02-18_21-13-04wmo6dyla/outputs/checkpoint-3']
INFO:__main__:Evaluate the following checkpoints: ['/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_6048b07a_2020-02-18_21-13-04wmo6dyla/outputs/checkpoint-3']
INFO:transformers.configuration_utils:loading configuration file /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_6048b07a_2020-02-18_21-13-04wmo6dyla/outputs/checkpoint-3/config.json
INFO:transformers.configuration_utils:Model config {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 28996
}

INFO:transformers.modeling_utils:loading weights file /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_6048b07a_2020-02-18_21-13-04wmo6dyla/outputs/checkpoint-3/pytorch_model.bin
HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=1488.0, style=ProgressStyle(description_width='initial')), HTML(value='')))
0.9445210.9451270.4756930.1586360.0396850.0080410.0863280.0123570.0015690.3452250.0345510.0031650.0003610.7165860.0512090.0035661.0104430.0594820.0033290.0004770.0000880.0000750.0000290.0000270.0000630.0000280.0000270.0000271.5090001.8408980.0614220.9662510.0302200.0038851.1337610.0324200.0014760.0000661.1653670.0299091.1783961.2036302.2499901.1849640.0269911.1709210.0263690.0005960.0090060.0002090.0000290.0000260.0001260.0000810.0000260.9244751.8693952.3940380.6877780.0116840.0002220.0000320.0000280.0000760.0000280.0000270.0000270.0000270.9536650.8722990.5655570.0549960.9200100.0126280.0001970.0000280.0000270.0001070.0173231.0261420.0128530.0001840.0000260.7501460.0089570.0001300.0000370.0000290.9446100.0106390.0001450.0000290.0000270.0000250.0000250.0007840.9597960.0104820.0001370.0001940.0001010.0185260.0002420.0026260.0006060.0000730.0000280.0000270.0004290.0825931.4032330.0130710.0001410.0000250.0000250.0017930.0000390.0000240.0000240.0000240.0336860.0003040.0000290.0000270.0000260.0000270.0000270.0000260.0000260.0019040.0005980.0006500.0000931.0073040.0075990.0094100.0001100.1340570.0009960.0000310.0008770.7135410.7228620.0050790.7730760.7805130.0054010.0000940.0000590.0000580.0001030.0000260.0000240.0001680.0000880.0000890.0000570.0002210.0000290.0006260.8899790.0091240.6834930.0043260.0001970.0002070.0000270.0000260.0000250.0000260.0000260.0000250.0000260.0000250.0000260.0000260.0000260.0000250.0000700.0000260.0000260.0000260.0000320.0000260.0000260.0000610.0000290.0000240.0008250.0000290.0000260.0000280.0000240.0000240.0000240.0008250.0002450.0003820.0009920.0006150.0000270.0000240.0002910.0001360.8698390.8365980.0040940.0001090.0001140.0001280.0000970.0000320.0000870.0000410.0000250.0000250.0627460.0003510.0000260.0000250.0000250.0000250.0009650.0038930.5008510.0022920.0003070.0162790.2255150.0010491.1697850.0051620.0000470.0007290.0000660.0001410.0000250.0003890.0006110.0000610.0000240.0001990.0001540.0914750.0004040.0000300.0000290.5070250.0022050.0001680.0001830.0000240.0000311.1255930.0044730.0004900.0000250.0000240.0000250.0009510.0000280.0020900.0000740.0014680.0000370.0000540.0023690.0000390.0000600.0000250.0000600.0000910.0000420.0000250.0000900.0000250.0000620.0000630.6853960.0041701.5603530.6574090.0023550.0000991.1089060.0040880.0000850.0070780.0015110.0015380.0000300.0007730.0000600.0000240.0000910.0000600.0034030.0110700.0001160.0026370.0000330.0002810.0002870.0000250.0000880.0000560.9948370.8106750.0027180.0000340.8755120.0028710.0000670.0000270.0000560.0000551.0105010.0032201.0162310.7670370.0024630.9742610.0030510.0000350.0000250.0000610.0043160.0017560.0012030.0307560.0142080.8410890.0134700.0011740.2493760.5254100.0016540.9553611.8012010.9877271.9120470.0102980.0051230.0015050.0028140.0001220.0001280.0000900.0002370.0004120.0004910.0002640.0000260.0002980.0000260.0002890.0000260.0003050.0000260.0000260.0026510.2497580.0007170.2356440.0007850.0001271.0749472.8511830.0077721.7560710.7348380.8824170.0031800.0026740.0000310.0020460.0000292.2357440.0060570.2260790.0243660.0000890.0043420.0000360.0002910.0111530.0008080.0000290.0115580.0028770.0001110.0000590.0000680.0009390.0000280.0037430.0000720.0001245.4914720.0140520.0001810.0002420.8068970.0026890.0052630.6677540.0018201.0671281.8806240.1855581.1160580.0027400.0000310.0006730.0056280.0000380.0021210.0127541.3781271.5390370.0037840.0001480.0000630.0001280.0000741.0952121.5184890.3510130.0017220.0022660.0003040.4556040.5678300.0014990.5502080.0051490.0029200.0000381.4200790.0032710.0019340.0018500.0001360.0005810.0111920.6536410.8466750.0020100.0002030.6603220.7572320.0017060.3967890.0009370.0000260.0000240.6551430.0076820.0001141.4548730.3472191.5464510.0392912.0480240.0052290.0011600.0002760.0003170.0003810.0005940.0002330.0002700.9959640.8738010.0222760.9472370.0020160.0000300.0000950.7499320.0015890.6761870.1356450.0004690.0001260.0003560.0003980.0000240.0038380.0001530.0000280.7002380.0024840.0049710.0001060.0035071.8881640.0038650.8935440.0018860.0301320.0031970.0007570.0030950.0000390.1545880.0042850.0001820.0021390.0026390.0100850.0201770.0031740.0057790.0002520.0002011.1054000.0022880.0000290.0804460.0009490.0016100.0090810.0032130.0059650.0000390.8961510.0031960.0802530.0028311.6676860.0032660.0010150.0018080.0071500.0018530.4782320.0013610.0005720.0007180.0160570.0001001.0667400.0142410.0055970.7596510.0240880.0000710.0000640.0000270.0000270.0000271.1304910.0020710.0000310.0000270.0000270.0020550.0002480.0002920.0006640.0001830.0000670.0001000.0005980.7459830.0014710.0001800.0151940.0012180.0000480.0045930.0038340.6095023.0455280.0053852.4838990.0243400.4472363.6305590.0312370.0122850.0007560.0001730.0000300.2755461.9260550.0046060.5738070.0010530.0001560.0001460.0000990.0001900.0001530.0001680.0002180.0000531.2623380.0022350.0000280.9071061.5455611.5654630.0028671.2759830.9055330.0015190.0002920.0005510.0000250.0000310.0000240.0000260.0000260.0000290.0000240.0004820.0000300.0006270.0006920.0038071.9574142.2132883.3215870.0056380.0006560.0037140.8419351.6982630.0028560.0001530.0000980.0001280.0001270.9615061.3364940.0030320.0045080.6968102.1952070.4474410.0008580.0000960.0000960.0001680.0000240.0000250.0000270.0000260.0000290.8285331.0617210.0016510.0000730.0000640.0000240.0001200.0000900.0000240.0000720.0006150.0007830.0069420.0012890.1932361.2049370.0021110.0000740.0000260.0001630.0000910.0001120.0001040.0001930.0002590.0001620.0003630.0004070.0003620.9766470.0016630.0002270.0091472.7759143.7991044.0909120.0078260.6449360.3147260.0008680.0000990.0002280.0000990.0001250.0006500.0026540.0011110.0002370.4762130.0040420.0785201.1405460.0062820.2173780.0022280.0003930.0002960.0002710.0001480.0002000.0000600.0001660.0099790.0004440.0000260.0000270.0003580.0003550.0011780.0004230.5012261.4792840.0020700.0000280.7846850.7389570.0011030.8148690.4060070.0005960.0117390.0613490.6689950.0627200.6947180.0011450.0002580.0002330.0060360.0063560.6212340.0151400.9311180.5051430.0007030.0000250.0000270.4045450.0006900.0000250.0000240.0000620.0002180.2914710.0004400.0001000.9067090.0012200.0025870.0518980.0027700.5879830.5233151.7246940.9517681.8260190.0024070.0000292.1664460.9872200.9235940.3338950.7665720.0010600.0000290.8465050.0012201.1065930.0015400.0001960.0001600.0001030.0001142.3603720.8117560.6552201.3508572.1042672.2275291.6716880.9743311.4502030.0018540.0000860.0000250.0000250.0000560.0000250.0000610.0001170.0000250.0000290.0000880.0000250.0001020.0000790.0000590.0000730.0000250.0000250.0000260.0000830.0000250.0000250.0003620.0003680.0006290.0011180.0018400.0014410.0555003.9292260.1516930.5586370.3590980.0008733.9207650.0072640.0038290.9611460.0025850.0002890.0004100.0000630.0037910.0000370.0029320.0003530.0000670.0006300.0074250.0807220.0268000.1350190.0015120.0000730.0000250.0002280.0001700.0000250.0000250.2845590.0003580.0000250.0000250.0000240.0000893.3302733.3901312.1611721.2750291.6821790.3550160.2729681.1570180.1042610.5241120.0010300.1677650.0020670.0034200.2220941.4254841.4855022.1606600.0036250.7889241.3949371.5447981.7896960.6994741.4934300.0323730.0001190.0002940.0040700.0003290.0003430.0003273.0756701.9913001.6442330.0020780.0000280.0001500.0001470.0001870.0001040.0042000.0012830.0030090.0033270.0020650.0000260.6923070.0024600.0010660.0005430.0000500.0038550.0021672.1125920.9239791.1271132.1437872.0792330.0022921.1624460.0016100.0000280.0019380.0009262.2169172.2885051.5010331.6060630.0194520.6517210.0027060.0052430.0019761.5527340.2813220.1331490.1263391.6823760.0018190.0000261.1046220.0011990.0000613.6400800.0038840.0000284.4688020.0067440.0085330.0000950.0000670.0003301.1155590.0012330.0000920.0000270.0000350.0002671.1408652.7212813.2034482.6615812.5339740.0080590.0000340.0000760.0001010.0001210.0102590.0010560.0029120.0000270.3354660.0017040.0004990.0013600.0000900.0000270.0000260.0000260.7632550.0008070.0007770.9337500.0009880.0003990.0012760.0011050.0007390.0018770.0008000.0016310.0021380.0008420.0033440.0007710.0000600.0001290.0001210.0001410.0001070.8898160.0011820.0001311.0516160.9298190.0009490.4337771.5794240.7443260.0007620.8948200.0009090.0000261.0059360.0010250.0002370.0000260.0053800.0000430.0000840.0001090.0029380.0054910.0000480.0016330.0000370.0059580.0007170.0026800.0000270.0308360.0038100.0050870.0022750.2588770.0453440.0022070.0065000.0010940.0026940.0173260.0031660.0011270.0022540.0011830.0010321.5571941.6870711.3544121.1079200.2191380.0665420.0013700.0018450.0025480.0019120.0001950.0004341.1047141.7306380.0043071.2541510.0013160.0000300.0000710.6729160.0016870.0023121.5417413.2440730.2476100.0002550.0000240.0010710.0030670.0024150.0013500.0000250.0017500.0000260.0000252.0440480.2987410.0016850.5478780.0006380.3489010.0007450.7654130.0007590.0040050.6634310.6198450.0011750.7186090.0013520.0000980.0000570.0014460.0065290.0012831.5993950.2841641.8008510.0019090.0002730.0001960.0001960.0002410.0004210.0012320.0002740.0018550.0028860.0001280.0004150.0000670.0001922.5882262.3011270.0139250.0011540.0024960.8568950.0021000.0014280.0012870.0012750.0010280.0013640.0004960.0017270.0116140.0758060.3176190.5094241.1139280.5880150.4631980.4088390.3804390.4766190.0093791.1314070.5461980.7912850.0544320.3645440.7537310.1257020.9317730.3612070.7874480.2063340.0057860.7049820.0071470.6824851.9219530.0346011.3282070.0145900.5433180.6456161.3810490.2298710.5433931.0207850.1096390.0578070.2011950.4996390.9035720.4910530.5848990.2221850.4059021.0543110.7867670.0165900.4788830.1723190.5917290.0101350.1694300.6631670.0126491.0937641.1715171.2243400.0103030.3623880.0003450.2531190.4540581.2119670.3869661.2486791.3055961.0432850.4510250.6151580.0079910.0114140.0161920.3459930.5421690.6680770.0012220.1992110.4461800.5653500.5019940.6183120.0028910.6197660.6476790.2897650.6296181.1226790.1813850.1680721.4036151.1010160.9457750.4206790.0041781.2219680.0336040.3854560.0092310.2048470.2701180.0006790.0405900.1699900.5765230.0576010.0455330.1341940.0085700.5629910.0216570.2183170.6864090.1098250.1292380.9631760.2287210.2917840.0040070.7072710.0021160.6774600.8958030.3913540.0189270.0194680.2898930.9443840.7421310.0403850.0229900.0885830.8250751.1387441.6517380.1536190.6350721.2117480.7161070.7393510.1942330.0960120.5877190.5178610.8437330.2685631.5204440.0205900.1123500.3882500.0443420.3367980.6920170.4344570.1512830.1173542.1762281.4092230.6327510.0039161.9594890.8023760.0037040.4077020.0103881.4166570.6826700.3235700.4253410.8565310.6221470.0587660.0021181.2904120.0071460.6004690.9940120.6449020.0116340.3345430.6392750.0849470.0090260.7608710.5126590.0110180.0609090.0153821.1808290.3993660.5782020.1859090.3210300.0194930.6260420.0070960.5428830.3420870.0145150.5629600.0171040.4073440.3650140.0065880.9968600.0225350.3438880.3283710.0595470.0042511.4010730.9457831.4437510.8664980.2960271.5859240.8557720.0307450.0148870.4122770.0139720.0109610.8610530.2821100.7482570.7578610.1036940.5132190.7406230.2269230.4101950.0120310.6374421.0461380.0966930.6907110.3757820.0003280.8790230.6223390.0111370.0018850.6288600.6889490.7571350.2481390.0010950.5264500.9909871.3688421.3894910.9172990.6331280.0039970.0059240.5622140.0058130.0035790.4401240.1317610.0043750.5980510.0878870.6905710.0163341.2986500.0115990.5910571.2996731.5007590.0193281.6225650.8208200.4293640.0065800.4964610.4718151.5042050.0067140.1427170.0110031.3122750.9685620.3314461.4561880.2721350.6508320.2604920.4826110.5295361.4356900.5234351.6990972.9479800.7427321.1701910.9477540.1128831.2521320.0134750.5530300.0076570.3109370.9910790.3509660.0825910.2618650.9431880.3236560.4732141.0161350.1708600.8424510.0114540.8675640.3660180.0248080.5544720.0071920.0064910.1907191.3585720.0799030.1654320.2162750.7739380.5366290.6862051.0052100.3687580.0119270.4135230.2490860.1625621.1320102.6468961.7457160.4630080.9310560.2385590.0218600.0081920.0350220.3242330.2171910.2770030.9419810.0033921.2475430.6225620.6099410.0943240.0001330.0192131.2216160.650919

*******************************************
EVALUATING PIPELINE 
Pipeline directory: /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_6048b07a_2020-02-18_21-13-04wmo6dyla/
With following parameter combination: {'batch_size_seq_length': 2, 'lr': 3e-05, 'lr_type': 'linear'}
EVALUATION OF CHECKPOINT /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_6048b07a_2020-02-18_21-13-04wmo6dyla/outputs/checkpoint-3
-------------------------------------------------------------
|           |   agree   | disagree  |  discuss  | unrelated |
-------------------------------------------------------------
|   agree   |    701    |    78     |    129    |    26     |
-------------------------------------------------------------
| disagree  |    94     |    298    |    75     |    11     |
-------------------------------------------------------------
|  discuss  |    221    |    65     |   1519    |    72     |
-------------------------------------------------------------
| unrelated |    21     |    27     |    56     |   8505    |
-------------------------------------------------------------
Score: 8711.75 out of 9226.0	(94.42607847387816%)
Accuracy: 0.9264582282736594
F1 overall: 0.7899827032216515
F1 per class: [0.7113140537798072, 0.6300211416490487, 0.8309628008752735, 0.9876328165824769]
*******************************************


real	23m21.915s
user	26m36.329s
sys	8m31.435s
ubuntu@run-gpu-mg:~/fnd_implementation$ 
ubuntu@run-gpu-mg:~/fnd_implementation$ exit
exit

Script done on 2020-02-19 08:15:29+0000
