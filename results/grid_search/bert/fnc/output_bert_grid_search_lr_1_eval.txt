Script started on 2020-02-07 19:13:43+0000
ubuntu@run-gpu-mg:~/fnd_implementation$ time python3 eval_separate.py
/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/home/ubuntu/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/ubuntu/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/ubuntu/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/ubuntu/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/ubuntu/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/ubuntu/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
There are 2 GPU(s) available.
The following GPU is used:  Tesla V100-PCIE-16GB
INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-config.json from cache at /home/ubuntu/.cache/torch/transformers/b945b69218e98b3e2c95acf911789741307dec43c698d35fad11c1ae28bda352.3d5adf10d3445c36ce131f4c6416aa62e9b58e1af56b97664773f4858a46286e
INFO:transformers.configuration_utils:Model config {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": "multi",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 28996
}

INFO:transformers.tokenization_utils:loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-vocab.txt from cache at /home/ubuntu/.cache/torch/transformers/5e8a2b4893d13790ed4150ca1906be5f7a03d6c4ddf62296c383f6db42814db2.e13dbb970cb325137104fb2e5f36fe865f27746c6b526f6352861b1980eb80b1
INFO:transformers.configuration_utils:loading configuration file /home/ubuntu/fnd_implementation/bert/model_pretrained/config.json
INFO:transformers.configuration_utils:Model config {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 28996
}

INFO:transformers.modeling_utils:loading weights file /home/ubuntu/fnd_implementation/bert/model_pretrained/pytorch_model.bin
INFO:__main__:Loading initialized pretrained model from /home/ubuntu/fnd_implementation/bert/model_pretrained
  ******************************************* 
           Freezing Embedding Layers          
  *******************************************
 
name:  bert.embeddings.word_embeddings.weight
param.requires_grad:  False
=====
name:  bert.embeddings.position_embeddings.weight
param.requires_grad:  False
=====
name:  bert.embeddings.token_type_embeddings.weight
param.requires_grad:  False
=====
name:  bert.embeddings.LayerNorm.weight
param.requires_grad:  False
=====
name:  bert.embeddings.LayerNorm.bias
param.requires_grad:  False
=====
name:  bert.encoder.layer.0.attention.self.query.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.0.attention.self.query.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.0.attention.self.key.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.0.attention.self.key.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.0.attention.self.value.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.0.attention.self.value.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.0.attention.output.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.0.attention.output.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.0.attention.output.LayerNorm.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.0.attention.output.LayerNorm.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.0.intermediate.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.0.intermediate.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.0.output.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.0.output.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.0.output.LayerNorm.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.0.output.LayerNorm.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.1.attention.self.query.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.1.attention.self.query.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.1.attention.self.key.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.1.attention.self.key.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.1.attention.self.value.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.1.attention.self.value.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.1.attention.output.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.1.attention.output.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.1.attention.output.LayerNorm.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.1.attention.output.LayerNorm.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.1.intermediate.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.1.intermediate.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.1.output.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.1.output.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.1.output.LayerNorm.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.1.output.LayerNorm.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.2.attention.self.query.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.2.attention.self.query.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.2.attention.self.key.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.2.attention.self.key.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.2.attention.self.value.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.2.attention.self.value.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.2.attention.output.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.2.attention.output.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.2.attention.output.LayerNorm.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.2.attention.output.LayerNorm.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.2.intermediate.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.2.intermediate.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.2.output.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.2.output.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.2.output.LayerNorm.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.2.output.LayerNorm.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.3.attention.self.query.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.3.attention.self.query.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.3.attention.self.key.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.3.attention.self.key.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.3.attention.self.value.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.3.attention.self.value.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.3.attention.output.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.3.attention.output.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.3.attention.output.LayerNorm.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.3.attention.output.LayerNorm.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.3.intermediate.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.3.intermediate.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.3.output.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.3.output.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.3.output.LayerNorm.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.3.output.LayerNorm.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.4.attention.self.query.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.4.attention.self.query.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.4.attention.self.key.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.4.attention.self.key.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.4.attention.self.value.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.4.attention.self.value.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.4.attention.output.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.4.attention.output.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.4.attention.output.LayerNorm.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.4.attention.output.LayerNorm.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.4.intermediate.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.4.intermediate.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.4.output.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.4.output.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.4.output.LayerNorm.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.4.output.LayerNorm.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.5.attention.self.query.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.5.attention.self.query.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.5.attention.self.key.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.5.attention.self.key.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.5.attention.self.value.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.5.attention.self.value.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.5.attention.output.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.5.attention.output.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.5.attention.output.LayerNorm.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.5.attention.output.LayerNorm.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.5.intermediate.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.5.intermediate.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.5.output.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.5.output.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.5.output.LayerNorm.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.5.output.LayerNorm.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.6.attention.self.query.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.6.attention.self.query.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.6.attention.self.key.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.6.attention.self.key.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.6.attention.self.value.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.6.attention.self.value.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.6.attention.output.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.6.attention.output.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.6.attention.output.LayerNorm.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.6.attention.output.LayerNorm.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.6.intermediate.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.6.intermediate.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.6.output.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.6.output.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.6.output.LayerNorm.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.6.output.LayerNorm.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.7.attention.self.query.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.7.attention.self.query.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.7.attention.self.key.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.7.attention.self.key.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.7.attention.self.value.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.7.attention.self.value.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.7.attention.output.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.7.attention.output.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.7.attention.output.LayerNorm.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.7.attention.output.LayerNorm.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.7.intermediate.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.7.intermediate.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.7.output.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.7.output.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.7.output.LayerNorm.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.7.output.LayerNorm.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.8.attention.self.query.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.8.attention.self.query.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.8.attention.self.key.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.8.attention.self.key.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.8.attention.self.value.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.8.attention.self.value.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.8.attention.output.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.8.attention.output.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.8.attention.output.LayerNorm.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.8.attention.output.LayerNorm.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.8.intermediate.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.8.intermediate.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.8.output.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.8.output.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.8.output.LayerNorm.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.8.output.LayerNorm.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.9.attention.self.query.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.9.attention.self.query.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.9.attention.self.key.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.9.attention.self.key.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.9.attention.self.value.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.9.attention.self.value.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.9.attention.output.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.9.attention.output.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.9.attention.output.LayerNorm.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.9.attention.output.LayerNorm.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.9.intermediate.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.9.intermediate.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.9.output.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.9.output.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.9.output.LayerNorm.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.9.output.LayerNorm.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.10.attention.self.query.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.10.attention.self.query.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.10.attention.self.key.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.10.attention.self.key.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.10.attention.self.value.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.10.attention.self.value.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.10.attention.output.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.10.attention.output.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.10.attention.output.LayerNorm.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.10.attention.output.LayerNorm.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.10.intermediate.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.10.intermediate.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.10.output.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.10.output.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.10.output.LayerNorm.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.10.output.LayerNorm.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.11.attention.self.query.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.11.attention.self.query.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.11.attention.self.key.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.11.attention.self.key.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.11.attention.self.value.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.11.attention.self.value.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.11.attention.output.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.11.attention.output.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.11.attention.output.LayerNorm.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.11.attention.output.LayerNorm.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.11.intermediate.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.11.intermediate.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.11.output.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.11.output.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.11.output.LayerNorm.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.11.output.LayerNorm.bias
param.requires_grad:  True
=====
name:  bert.pooler.dense.weight
param.requires_grad:  True
=====
name:  bert.pooler.dense.bias
param.requires_grad:  True
=====
name:  classifier.weight
param.requires_grad:  True
=====
name:  classifier.bias
param.requires_grad:  True
=====

*******************************************
Evaluating the following pipelines 
['/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_3da0d128_2020-02-07_09-08-07fr323k61/', '/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_cd99c91a_2020-02-07_15-36-28gr4x2kfm/', '/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_4a470038_2020-02-07_13-11-05b1jw5ym_/', '/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_cb2aa6cc_2020-02-07_15-23-23_ccg10pw/', '/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_d75370dc_2020-02-07_18-22-52it4jdf2d/', '/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_42fc7d8e_2020-02-07_10-33-20nlwf2m67/', '/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_c638d148_2020-02-07_13-57-585i1el58q/', '/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_d00ea8be_2020-02-07_16-02-58gxuqrd5c/', '/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_c8cc1a0a_2020-02-07_13-58-02figzuq9u/', '/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_d4e06774_2020-02-07_17-43-15295o0x47/', '/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_405507e0_2020-02-07_09-08-120r2sp91s/', '/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_d2701b24_2020-02-07_16-12-30nku9tara/']

*******************************************

*******************************************
EVALUATING PIPELINE 
{'batch_size_seq_length': 1, 'lr': 1e-05, 'lr_type': 'constant'}
INFO:__main__:Creating features from dataset file at /home/ubuntu/fnd_implementation/data/processed
  0%|                                                  | 0/9622 [00:00<?, ?it/s]  0%|                                        | 1/9622 [00:02<7:22:25,  2.76s/it] 21%|███████▋                             | 2001/9622 [00:03<4:05:20,  1.93s/it] 78%|██████████████████████████████▍        | 7501/9622 [00:03<47:47,  1.35s/it]100%|█████████████████████████████████████| 9622/9622 [00:03<00:00, 2465.64it/s]
  ******************************************* 
              Running Evaluation                
  *******************************************
 
  Length dataset evaluation: 9622
  Length dataloader evaluation: 2406
  Number of epochs: 3
  Batch size: 4
  ******************************************* 
 
['/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_3da0d128_2020-02-07_09-08-07fr323k61/outputs/checkpoint-3']
INFO:__main__:Evaluate the following checkpoints: ['/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_3da0d128_2020-02-07_09-08-07fr323k61/outputs/checkpoint-3']
INFO:transformers.configuration_utils:loading configuration file /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_3da0d128_2020-02-07_09-08-07fr323k61/outputs/checkpoint-3/config.json
INFO:transformers.configuration_utils:Model config {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 28996
}

INFO:transformers.modeling_utils:loading weights file /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_3da0d128_2020-02-07_09-08-07fr323k61/outputs/checkpoint-3/pytorch_model.bin
eval_separate.py:214: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0
Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`
  for batch in tqdm_notebook(eval_dataloader, desc="Evaluating"):
HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=2406.0, style=ProgressStyle(description_width='initial')), HTML(value='')))
0.0001450.0003090.0001610.0000660.0000800.0000220.0000100.0000080.0000110.0000070.0000070.0000070.0000080.0000400.0001420.0000180.0000090.0002200.0000180.0000080.0001470.0000130.0001750.0000150.0003721.1082000.0426440.0015861.6962260.0587750.0019660.0000690.0000080.0000060.0000090.0000070.0003540.0000160.0000090.0000060.0000780.0001050.0000160.0000061.6341390.0363200.0009150.0000250.0002470.0000112.2289700.0455750.0008820.0000220.0000060.0000060.0000060.0002850.0001820.0000090.0003080.0000120.0000070.0000130.0000060.0000190.0000110.0000060.0012780.0000310.0000070.0000070.0000060.0000060.0000060.0000060.0000060.0000060.0000070.0000060.0000360.0000150.0000480.0000070.0000070.0000300.0000080.0001460.0002030.0000110.0000380.0000430.0001080.0000970.0006190.0000120.0003980.0003980.0000120.0001340.0003520.0000140.0002110.0003730.0000950.0000110.0000340.0000170.0008820.0013581.9307740.0174000.0001610.0000080.0000060.0000140.0000060.0876580.0007490.0000120.0000060.0002960.0000080.0000060.0000060.0001620.0000070.0000060.0000070.0000060.0000060.0000060.0006080.0003920.0005680.0001910.0000260.0000060.0000090.0012530.0015870.0001550.0000120.0001450.1524730.0010580.0000130.0000380.0000060.0001030.0000320.0000060.2806923.8229211.6349270.0105540.0000740.0000060.0000060.0000110.0000240.0002970.0003310.0000090.0000060.0110960.0000730.0000190.0000060.0000110.0001360.1189730.0016610.0007300.0000500.4425551.8690690.0105650.0001800.0000100.0000060.0000072.3495850.0128480.0003940.0000083.8064192.0895820.0111210.0000740.8091340.0061090.0001842.2179900.0119310.0000670.0000070.0000060.0000060.0000070.0000360.0347390.0001780.0000070.0000060.0000060.0012860.0000120.0000060.0000090.0151770.0000780.0000060.0000060.0000060.0000060.0000070.0000060.0000060.0000060.0000060.0000060.0001550.0000160.0003280.0000190.0000140.0002120.0000070.0000061.7521550.0077280.0037880.0000220.0001580.0000060.0000420.0000060.0000160.0001480.0000070.0000060.0000060.0008860.0000100.0000060.0000060.0000060.0000061.9644480.0078640.0000370.0001370.0001550.0000070.0000060.0000201.6087220.0062510.0002920.0006620.0000080.0000060.0000061.5969621.2668621.8343570.0068760.0000320.0000070.0000060.0000060.0000370.0084420.0002401.8094930.0067200.0000300.0000060.0000060.0000060.0000060.0000070.0000060.0000070.0000060.0000060.0000060.0000060.0009360.0000090.0006500.0000100.0000060.0000062.1933282.1571410.0072760.0000310.0000070.0000062.2353442.1894550.0072320.0000300.8517630.0068470.0000290.0000060.0002360.0000070.0000060.0000060.0000060.0000060.0000060.0000060.0000060.0011210.0000100.0000060.0073920.0000292.0465570.0063220.0002020.0000070.0000100.0001870.0002722.0053320.0071660.0000271.5788150.0048620.0003310.0001360.0001390.0000140.0002710.0001380.0001130.0000060.0000060.0000060.0000060.0000060.0000060.0000060.0000060.0000060.0000060.0000060.0000060.0000060.0000060.0000060.0000060.0000060.0000060.0000060.0000060.0000060.0000060.0000060.0000060.0002480.0002340.0000060.0000060.0000060.0000060.0000060.0000060.0000060.0000060.0000100.0000060.0000060.0000060.0000060.0000070.0001970.0000070.0005930.0007260.0000080.0000060.0003140.0012170.0000090.0002600.0000070.0000060.0000110.0001660.0001070.0000060.0000060.0000060.0000340.0000080.0002960.0000070.0000090.0000060.0000060.0001810.0000750.0000560.1736200.0004290.3293730.0008031.8704460.0045140.0000170.0018690.0979060.0002390.0983410.0011110.0001671.6396451.6416770.0038750.0001900.0000070.0000060.0000060.0000080.0000080.0000060.0005770.0000080.0000060.0003050.0000070.0000060.0000060.0000070.0000470.0000060.0000080.0101700.3880810.0016330.0000100.0003620.0000104.1335560.0094050.0003160.0000080.0000200.0002610.0000070.0000110.0000090.0000060.0000060.0000060.0000060.0000080.0001290.0000920.0000060.0019160.0004920.0000070.0000060.0001230.0001111.0682400.0026460.0000120.0001330.0002030.0000070.0000060.0000060.0000060.0001371.0295290.0040571.8159031.7399860.0036840.0056890.8520540.2724810.0014800.0002080.0001410.0000060.0000060.0015340.0000090.0000060.0000060.0000060.0002780.0007160.0000070.0000140.0000060.0000060.0000060.0013670.0000090.0000060.0002680.0000070.0013890.0015650.0000090.0000060.0006450.0024330.0015690.0000090.0002490.0006940.0000110.0000061.3827440.0026430.0001442.8143700.0053260.0002900.0000650.0000070.0002010.0001422.9844490.0055740.8490750.0172041.7245440.0032000.0000410.0000060.0001190.0034251.1213561.0994770.0031480.0000110.0001620.0005010.0000070.0000060.0003090.0005850.0000090.0007320.0087300.0011680.0000080.0000060.0003780.0000070.0004840.0002360.0001550.0001530.0000080.0000060.0000060.0000060.0001490.0001410.0000060.0003020.0000061.7569930.0030511.8220521.8421920.0031821.8752940.0036620.0000131.9095240.0032700.0057480.0001940.0001360.0001340.0001750.0000060.0001460.0000070.0331290.0004200.0000070.0000060.0002551.9429910.0065270.0003790.6133280.0029300.0003000.0001590.0001000.0002130.0001550.0007700.0003423.8285320.0064130.0002810.0015960.0006430.0001440.0001520.0000070.0001421.7514310.0029670.0000101.7565490.0029750.0000110.0001400.0000061.8612480.0029650.0001560.0000060.0000060.0001520.0000060.0003610.0000060.0002470.0001500.0000060.0004541.0560952.0812610.8145700.0017870.0007580.0002130.0000070.0004210.0000070.0004070.0002560.0000070.0004060.0001420.0000100.0001430.0004880.0007470.0008520.0193160.0002800.0171630.0490440.1186570.0001840.0374030.0000620.0296010.0000500.0031930.0001550.0000060.0000060.0000060.0002100.0008390.0008070.0008030.0003280.0000070.0000060.0000060.0000060.0000060.0002230.0000070.0003660.0000060.0000060.0000070.0000060.0000060.0000060.0000060.0000060.0001630.0000070.0001470.0001510.0000070.0002180.0000060.0001510.0001840.0001840.0000060.0004180.0002630.0001420.0001500.0003060.0000430.0091630.0000190.0004460.0000081.9212150.0026820.0000101.3886491.0319430.0014360.0000080.0001500.0000060.0001340.0001780.0056290.0993621.7405020.0031440.0015361.1254023.6988270.0051730.0000130.0001480.0001651.3866870.0021270.6069382.9697642.6407830.0038280.0012880.0000190.0000060.0008480.0002420.0000360.0000060.0013220.0010741.7843910.0023693.6652430.0048480.0000120.0000064.8034340.0063200.0000140.0000760.0000060.0002430.0000060.0000060.0003140.0000190.0005540.0005660.0005810.0005670.0005650.0006050.0001950.0001710.0000060.0000060.0012650.0000070.0000060.0000120.0000060.0003370.0001490.0003660.0003200.0001840.1737970.0773450.0001031.3124220.0019500.0001900.0073110.0001640.0003741.3513170.0022101.9017240.0385890.2870940.0003631.7514421.7349460.0021561.9193441.8166891.7006410.0021061.7620340.0023410.0000143.7027080.0045462.1410180.0028700.0000320.0000082.0680123.7262314.0330400.0049001.2074050.0014682.2599090.0027370.0003070.0004330.0001380.0002660.0003160.0007120.0006690.0005030.0000060.0005130.0015900.0000160.0005670.0000060.0000060.0000060.0001590.0003030.0002630.0000080.0003230.0008150.0000090.0000060.0000060.0017610.0008970.0005180.0000070.0000060.0000060.0000100.0000060.0000060.0000060.0002560.0000060.0000060.0000060.0000060.0000060.0000060.0000060.0000060.0000060.0000060.0000060.0000060.0000060.0000060.0000060.0000060.0001530.0005530.6306920.0024650.0000090.0013770.0013240.0006770.0007150.0000070.0000070.0000061.8572241.8739090.0020991.9447720.0021752.4810063.3638900.0039310.0003380.0013360.0006100.0002940.0002230.0000070.0005990.0003515.7589203.5473940.0039960.0001680.0000470.0005360.0024950.0002000.0003890.0167470.0004560.8357720.0010361.5660871.5791581.2468610.0016232.8856180.0034160.7742880.0830380.3310190.0006150.0000420.0002560.6230180.0008510.0003690.1213590.0005340.0002090.0000070.0000060.0006970.0000070.0000060.0000060.0000060.0001960.0003420.0000070.0000060.0000060.0000060.0001410.0002170.0000061.5495520.0016260.0000081.9733650.0022100.0001692.1022230.0021890.0000080.0005140.0000060.0004590.0000060.0000060.0000060.0004690.0000150.0000060.0007121.1674630.7420350.0363220.0533740.2533701.7723191.9296530.0025900.0002820.0001870.0000060.0000060.0000060.0000060.0000270.0000060.0000060.0000060.0005230.0000060.0000060.0004250.0004560.0000070.0005300.0000060.0000060.0000060.0000070.0096550.0000160.0000060.0000060.0000880.0001810.0000060.0000060.0000950.0003130.0000090.0004390.0000060.0000070.0000060.0000060.0000060.0000060.0001325.4054753.7486950.0045910.0000110.0000060.0000070.0005580.0001520.0001790.0001640.0001270.0000071.0795081.4584421.8850610.0019860.0010670.0010290.0009900.0000070.0032240.0146310.0063340.0000240.0003490.0000061.1087420.2742250.0002670.1251901.7369840.0016540.0000080.0000060.0064450.0000120.0644010.0019001.4128981.1436260.0010820.0000070.0915480.0003250.0000060.0012380.0000070.0000060.2877030.0010470.0000070.0004300.0000061.7158310.7920730.0007412.6486591.3622473.3925583.0752080.0036342.6555050.0093880.0004150.0002670.0008121.9319112.4442630.0026490.0002300.0004060.0002670.0004150.0004290.0001160.0001360.0000671.7451121.7285030.0017511.7337683.5049270.0037790.0000090.0015560.0015940.0014121.9247280.0025090.0000080.0000080.0000180.0000061.9275511.9156493.9075820.0036430.0000090.0001860.0000060.0000121.8577430.0016580.0000080.0000060.0000060.0001860.0000080.0000060.0002340.0000180.0001900.0001900.0000060.0000060.0000060.0000060.0000060.0059250.0000110.0000060.0000060.0000340.0604170.0017990.2231000.0033660.0003620.0008252.4965250.0022700.0001810.0001412.5800881.7940672.9303310.0029320.0001611.1280071.7739160.0018430.0001480.0000070.0000060.0000060.0000060.0005060.0000080.0604570.0000581.4644260.0014940.0002770.0002530.0000060.2679350.0002331.2225400.0010491.4770680.0012550.0002710.0000060.0000080.0000060.0000080.0000060.0000060.0000060.0005430.0000060.0000060.0000060.0000640.0029210.0000090.0002420.0000060.0000060.0000060.0011260.0006291.0070540.0016550.0000210.0000060.0000120.0000070.0003300.0007280.0000250.0000060.0000430.0001800.0006750.0014026.8237575.7186943.7328850.0033490.0003990.0003530.0003300.0001620.0001610.0000120.0004780.0003160.0005450.0006150.0000070.0000060.0000100.0000070.0001240.0004570.0000130.0000060.0011970.0016540.0004800.0001750.0000060.0000310.0000060.0004310.0000110.0000060.0000060.0002850.0000060.0000060.0000060.0000060.0000060.0003290.0000060.0000070.0002990.0003670.0000060.0001960.0000060.0000060.0000060.0000060.0001180.0000890.0000060.0001150.0000170.0001300.0000070.0000122.5471670.0031700.0013290.0010350.0010033.4974085.6357191.8366163.7018561.9779760.6781970.0010190.0057370.0005220.0016744.5578384.4947740.0040110.0005750.0005440.0005640.0062450.0007380.0009190.0011090.0006460.0001410.0004360.0003080.0004480.0003840.0003440.0002720.0007670.0013991.2161241.2622962.6304401.0110140.0019200.0000070.0000060.0000060.0000060.0136310.0000160.0000060.0002960.0003550.0000060.0413830.0053420.0107950.0036640.0447990.0008070.0010230.0003800.0000070.0002270.0000740.0002230.0000090.0001850.0043010.0000090.0015610.0000070.0000060.0005690.0000090.0000060.0001780.0005690.0000060.0000060.0000070.0000060.0000060.0008220.0005440.0018980.0013111.3809490.0010200.0006230.0000060.0001210.0042760.0000090.0001240.0018360.0000490.0000060.0000061.7524770.0017590.0000070.0000500.0000060.0127680.0000150.0006060.0014930.0000070.0001200.0001050.0000060.0000060.0000080.0001320.0000060.0000060.0000360.0000061.4359720.0013150.0010390.0244040.0003290.0008020.0003170.0008750.0010980.0003200.0002240.0004880.0006800.0001831.7075830.0021020.0015715.9625005.7052037.7845430.0056540.0001130.0001440.0002550.0000060.0001210.0000080.0002760.0000071.8816330.0014540.0000070.0004330.0005730.0002910.0004630.0004670.0002900.0005090.0004160.0004500.0003090.0004470.0005240.0001620.0004330.0001680.0079400.0008811.8457510.0060300.0005370.0023510.0002602.0190930.0016340.0000480.0004533.5399120.9136520.8989382.2359781.8839050.0013071.2384640.0019600.0059840.0005150.0005130.4708040.2487751.6852494.5778370.0037920.0006730.0005810.0006080.0005660.0011600.0000070.0001340.0006040.0000060.0002890.0000060.0000060.0001040.0003270.0000070.0000130.0002970.0000060.0026450.0003410.0000060.0001810.0000060.0000090.0000060.0011252.1489590.0017040.0005424.2171534.2765954.2552512.1600211.8422404.2771005.4099444.3386044.3398892.0914460.0026350.0040090.0010510.0002470.1345610.5217900.0005820.0011810.9242870.0009751.3589991.3084000.0012310.0003730.0004890.0005010.0003820.0006010.0004360.0004130.0004832.7980563.4660960.0030611.5669260.0010301.4668250.0013840.0000170.0000060.0000070.0000060.0000060.0000060.0000060.0002610.0001581.7097840.0011182.1226670.0013801.7551110.0011410.0001510.0003720.0011971.8684551.7982560.0013641.7716853.5598400.0032000.0010000.0007440.0000070.0000260.0003580.0003360.0001840.0000070.0000150.0001640.0003310.0002600.0004440.0002960.0010540.0002740.0004071.8268120.0012960.0002760.0006120.0002880.0002670.0005290.0001480.0035740.0037620.9219460.0008590.0001311.8676570.0014570.0001292.3614250.0017512.3432154.2426680.0029721.8513391.8716810.0013031.9323610.0013405.2279073.0600441.4537312.2077880.7246881.4824560.5067280.0005940.0003260.0000060.0003410.0004050.0002510.0000060.0284000.0002140.0002260.0000060.0002230.0001680.0001660.0000071.8494050.0011483.6929092.0130660.0012441.9226811.9034686.3336925.1045266.4523695.2792934.6005970.0032730.0005680.0001930.0004320.0001630.0000060.0003350.0000850.0001480.0000060.0000060.0000161.4082420.0008610.0005521.5727960.0009590.0000060.0000060.0000070.0000110.0003007.4145997.0305662.0405410.0022222.0601760.0012470.2423620.0001520.0000060.0479611.4418963.3637931.9486181.7306014.0163762.0522426.0195535.9254403.9814960.0023830.0000430.0001231.7071250.0010241.8847940.0011270.0000060.0005350.0033720.0000080.0000060.0000060.0000780.0000060.0000060.0003660.0003150.0002240.0008200.0003480.0002750.0005530.0001840.0003380.0005310.0002960.0002700.0005350.0000060.0006270.0001630.0004231.4080750.0009623.5176780.0025441.8867130.3448480.0002090.0097041.7820331.4358910.0010950.0000430.0000150.0000060.0004521.8947600.0014160.0002790.0003550.0003250.0004420.0004480.0003040.0005710.0001520.0002830.0001440.0001670.0000280.0001451.6958120.0009810.0002960.0002850.0001480.0001650.0002920.0001520.0001480.0001590.0000060.0002770.0001480.0013870.0000072.8555670.0019050.0002840.0000060.0002770.0000280.0003530.0000060.0013490.0000060.0000110.0004310.0001530.0000100.0006020.0000060.0001470.0001310.0000070.0001590.0000060.0000060.0003060.0002740.0001660.0001552.3426030.0013220.0000070.0000100.0000070.0000060.0000060.0000070.0000060.0000940.0003990.0001850.0000070.0000070.0000060.0000060.0000800.0001020.0000060.0000840.0000060.0000060.0000060.0002000.0004340.0001480.0007820.0004150.0001681.7613513.5412911.6810130.0022970.0024412.3014510.0027490.0002880.0002530.0004460.0000870.0002410.0002740.0003970.0003860.0002200.0001860.1036850.0004580.0000070.0002660.0002550.0003190.0002930.0001240.0002870.0007950.0009580.0007680.0007925.5883091.9340091.9170543.5628021.1526321.8715851.7538181.5786140.0023850.0106840.0028560.0017050.0002410.0004780.0009210.0002630.0004490.0008460.0006790.0004810.0007820.0002810.0008520.0002980.0005810.0002220.0000060.0000060.0000060.0002070.0005070.0002770.0001780.0000070.0000060.0000060.0000060.0004680.0000060.0000060.0000060.0000060.0000060.0000060.0000100.0000060.0000070.0000080.0001610.0000062.7896070.0014830.0000070.0001980.0004500.0004200.0004060.0017040.0004160.0001870.0003590.0004210.0001760.0004930.0000061.5831000.0025380.0004730.0031310.0014272.5180314.3488291.3571483.4569291.3577710.0160030.0008580.0002530.0002050.0002490.0000070.0027470.0000080.0000060.0000071.6140000.0009340.0001430.0002210.0000110.0001370.0203450.0088590.0001030.0000080.0007680.0003350.0001120.0020330.0042360.0006130.1556860.0008320.0007920.0004150.0006340.0000080.0007060.0008200.0007930.0010471.7305681.9145710.0017873.6941731.9772240.1103530.4224010.7596650.3831320.0006490.0001450.0001580.0002050.0004530.0002990.0004340.0021730.0004520.0004190.0004190.1077950.0033640.0003160.0002660.0002910.0001570.0006540.0000070.0083940.0000100.0000100.0000060.0000060.0000060.0000060.0000060.4420610.0005630.0000070.0000060.0000060.0000060.8961600.0014030.0004461.4288140.0007220.0000070.0001500.0019300.0039460.0005760.0010870.0013700.0017700.0006050.0003000.0002220.0000070.0002660.0002760.0005771.7829240.0011380.0002970.0001520.0002230.0000460.0002480.0000060.0000060.0004240.0004540.0004120.0004370.0005610.0000060.0000060.0000061.0953690.0013440.0105290.0273190.0034790.9079530.0014080.0007530.0003092.5322412.0945730.0010330.0000071.5328860.3016630.0001542.0469391.7072330.0008410.0000061.0529080.0006850.0004430.0000060.0000060.0000072.1539970.0010540.0003480.0000060.0004540.0001760.0000060.0000060.0007790.0002350.0012880.0002420.0000060.0002420.0000063.9108863.0335930.0019771.7155590.6190480.0008151.2161011.9250490.6784600.0005860.0004870.0009900.0005460.0002091.3579661.5288170.0007393.2166830.0017370.0042880.0006460.0010912.2946240.0016810.0007522.0983590.3117020.0120530.0009711.3848920.0041600.0009740.4578040.0002240.0046980.0001970.0000080.0000100.0149260.0000130.0000330.0000230.0215410.0095591.5944270.0290150.2111410.0001060.0023130.3582301.0791060.0005151.5294741.0410441.3571631.4129981.8492230.0009981.6602411.4037421.5650451.7908355.1697450.0024311.6905570.8942962.0609050.2332483.7106281.4503011.3937240.0010600.0001310.0004380.0000330.8789321.7033140.0011910.0002582.6310760.0024080.0019930.0016790.0003790.0006980.0013180.0011290.0001370.0003850.0002040.0000060.0004540.0007640.2664070.0001540.0001420.0000060.0003180.0001450.0005820.0001380.0007820.0006960.0001510.0002960.0002850.0368500.0012140.0000070.0000060.0006940.0007150.0003930.0004620.0004050.0001980.0002840.0004790.0002230.0000060.0000060.0000060.0003400.0000060.0000070.0007080.0000070.0000060.0000060.0000060.0000060.0000060.0000070.0003020.0000070.0000060.0799340.0000430.0000060.0003420.0003150.0000060.0000060.0006200.0005930.0001950.0000060.0000070.0000170.0000070.0001800.0000070.0004280.0000060.0001590.0000060.0000060.0000060.0000060.0000060.0000060.0001430.0000060.0003930.0000060.0013720.0001730.0000060.0000060.0000060.0004620.0008500.0000430.0000061.8239290.0008190.0000790.0003290.0010370.0008970.0011720.0005900.0006810.0006670.0003540.0008440.0007031.9208063.8676117.8760945.8258870.0032300.0001470.0000060.0003850.0002480.0001030.0001230.0003610.0006220.0005690.0000070.0009500.0002850.0001810.0004130.0000070.0062300.0000090.0000060.0002570.0001381.6446180.0007280.0005240.0005521.4750850.0007890.0001340.0001372.4528790.0014271.5500510.0008140.0003940.0003360.0001641.0306410.0006840.0000080.0001530.0003210.0000080.0002010.0001920.0011250.0000060.0002541.8090560.0007900.0002590.0000060.0014310.0000070.0002360.0000070.0000060.4000330.0004340.5561220.0004850.0001430.8503720.0003720.0000060.0944080.0000460.0005610.0001360.0005240.0005480.0027800.0021830.0002790.0716830.0001740.0001380.1530710.0000710.4593560.0002130.0182470.0000140.0010530.0001721.7887780.0013901.6957130.0014390.0000060.0015872.9395840.0015890.0006850.0003200.0026650.0649460.0006510.0003190.0026200.0001720.0004440.0067690.0008460.0000780.2585501.0289240.0014070.0015510.0008190.0011497.7105197.3976237.4741141.7897950.0013990.0013220.0010040.0004280.0000060.0002910.0002500.0002450.0002870.0003320.0001620.0006950.0003060.0003780.0001390.0004740.0003780.0004350.0001450.0001050.0002980.0000060.0000120.0001420.0001880.0000830.0000060.0001890.0000060.0001810.0001160.000006

*******************************************
EVALUATING PIPELINE 
Pipeline directory: /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_3da0d128_2020-02-07_09-08-07fr323k61/
With following parameter combination: {'batch_size_seq_length': 1, 'lr': 1e-05, 'lr_type': 'constant'}
EVALUATION OF CHECKPOINT /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_3da0d128_2020-02-07_09-08-07fr323k61/outputs/checkpoint-3
-------------------------------------------------------------
|           |   agree   | disagree  |  discuss  | unrelated |
-------------------------------------------------------------
|   agree   |    538    |    37     |    114    |     7     |
-------------------------------------------------------------
| disagree  |     9     |    68     |    36     |     1     |
-------------------------------------------------------------
|  discuss  |    209    |    53     |   1630    |    31     |
-------------------------------------------------------------
| unrelated |     6     |     4     |    20     |   6859    |
-------------------------------------------------------------
Score: 7225.75 out of 7516.5	(96.13184327812147%)
Accuracy: 0.9452296819787986
F1 overall: 0.7753460228803536
F1 per class: [0.7379972565157751, 0.4927536231884058, 0.8756379264034381, 0.9949952854137956]
*******************************************


*******************************************
EVALUATING PIPELINE 
{'batch_size_seq_length': 4, 'lr': 1e-05, 'lr_type': 'linear'}
INFO:__main__:Creating features from dataset file at /home/ubuntu/fnd_implementation/data/processed
  0%|                                                  | 0/9622 [00:00<?, ?it/s]  0%|                                        | 1/9622 [00:02<6:55:29,  2.59s/it] 21%|███████▋                             | 2001/9622 [00:03<3:50:23,  1.81s/it] 78%|██████████████████████████████▍        | 7501/9622 [00:03<44:53,  1.27s/it]100%|█████████████████████████████████████| 9622/9622 [00:03<00:00, 2612.84it/s]
  ******************************************* 
              Running Evaluation                
  *******************************************
 
  Length dataset evaluation: 9622
  Length dataloader evaluation: 301
  Number of epochs: 3
  Batch size: 32
  ******************************************* 
 
['/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_cd99c91a_2020-02-07_15-36-28gr4x2kfm/outputs/checkpoint-3']
INFO:__main__:Evaluate the following checkpoints: ['/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_cd99c91a_2020-02-07_15-36-28gr4x2kfm/outputs/checkpoint-3']
INFO:transformers.configuration_utils:loading configuration file /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_cd99c91a_2020-02-07_15-36-28gr4x2kfm/outputs/checkpoint-3/config.json
INFO:transformers.configuration_utils:Model config {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 28996
}

INFO:transformers.modeling_utils:loading weights file /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_cd99c91a_2020-02-07_15-36-28gr4x2kfm/outputs/checkpoint-3/pytorch_model.bin
HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=301.0, style=ProgressStyle(description_width='initial')), HTML(value='')))
0.0027140.0032850.0031510.2885180.0732030.0968760.0727820.012099
0.0027440.0010650.0019600.0074480.0470680.0642810.0054140.0023190.1543270.0136580.0699950.2995010.0360100.3085780.2833350.5580800.0655930.0321580.0188450.0014000.0053340.0655910.0456660.0059200.0573220.1241860.1528620.0047570.2054120.4129220.0928210.0061440.0126860.0899280.0757330.0021440.0004350.0007280.0004590.0007500.0156740.0099640.0005170.0056240.1384960.1716960.0053560.0792980.2029760.0038990.0870750.0909690.3180030.3287150.0088750.0017570.0098780.0925490.3096690.2153170.1405740.0082760.0063550.0017320.3467610.1647910.1701470.0683950.2249370.2298820.0519960.0024090.4573220.0494000.2165180.6380430.1215330.0147770.0262070.0033720.1676760.3031730.0681071.3126130.1407100.1255850.1322610.1146810.0086470.0039110.1588770.0861570.2225940.2427010.4467760.0425310.1060980.0085270.0060200.0008980.1335450.0015330.0688720.1220950.0377740.2190700.0111600.1681130.0993460.0924250.0015480.2071370.1711230.0654070.3151440.0032390.0205770.0007650.0086160.4644390.4311150.0783580.0549240.1320430.1257590.0598130.2030181.0466880.5655220.2674970.1453070.2909910.0189610.0202720.0182220.1089270.4013100.0881000.4499750.2670190.0657820.0920020.0889660.0033990.8732970.0193690.1581610.1823500.0023760.0019350.0020210.3683201.1318990.1103930.0241790.0228200.2645970.0951930.0684430.0332050.0092070.3436870.0342990.0005870.0021760.0011230.3123120.3663971.2275010.0484130.0224670.0423940.2917770.1407271.3050780.4468960.0179610.0159090.0245240.2720190.2864260.2790270.0161750.0042100.1044140.1717580.2178720.0963620.0093190.1183100.4032481.0279290.4591620.1050410.1452611.0339880.1921980.0763700.2186610.4070100.7830110.6627460.1743400.3091580.0219310.2554720.4406860.0057470.0051080.0030130.0074700.0024320.0233950.0025290.1063170.0051570.0023710.0681160.3521590.2144610.3477200.0140350.0231100.7590770.4774560.0039690.0011930.0007680.0952470.0039750.9738400.1577480.0909230.2771820.4212200.5302860.8342730.1256500.2035490.0046860.0988040.2068220.2212570.3430220.0062620.2410650.7905030.5829110.1718860.1861850.3650710.4444140.3756740.8674200.5915440.0254740.2353020.0310310.3470990.4371170.3289830.4204570.1397650.0072010.0105450.0044840.0885070.1999240.0596090.0045170.0003020.0347040.0281790.0336910.6924710.0459650.0093450.0757300.3101530.0176340.2116510.0241790.0154630.0167900.0112660.6802470.3181310.3372610.3811780.0065850.0082850.0067120.005585

*******************************************
EVALUATING PIPELINE 
Pipeline directory: /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_cd99c91a_2020-02-07_15-36-28gr4x2kfm/
With following parameter combination: {'batch_size_seq_length': 4, 'lr': 1e-05, 'lr_type': 'linear'}
EVALUATION OF CHECKPOINT /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_cd99c91a_2020-02-07_15-36-28gr4x2kfm/outputs/checkpoint-3
-------------------------------------------------------------
|           |   agree   | disagree  |  discuss  | unrelated |
-------------------------------------------------------------
|   agree   |    535    |    65     |    160    |     3     |
-------------------------------------------------------------
| disagree  |    30     |    44     |    14     |     0     |
-------------------------------------------------------------
|  discuss  |    194    |    53     |   1599    |    19     |
-------------------------------------------------------------
| unrelated |     3     |     0     |    27     |   6876    |
-------------------------------------------------------------
Score: 7196.5 out of 7516.5	(95.74269939466507%)
Accuracy: 0.9409686135938474
F1 overall: 0.730612691239727
F1 per class: [0.7016393442622951, 0.352, 0.8725784447476126, 0.9962329759490003]
*******************************************


*******************************************
EVALUATING PIPELINE 
{'batch_size_seq_length': 4, 'lr': 1e-05, 'lr_type': 'constant'}
INFO:__main__:Creating features from dataset file at /home/ubuntu/fnd_implementation/data/processed
  0%|                                                  | 0/9622 [00:00<?, ?it/s]  0%|                                        | 1/9622 [00:02<6:51:18,  2.57s/it]  5%|█▉                                    | 501/9622 [00:02<4:32:57,  1.80s/it] 21%|███████▋                             | 2001/9622 [00:03<2:39:39,  1.26s/it] 52%|███████████████████▏                 | 5001/9622 [00:03<1:07:46,  1.14it/s] 78%|██████████████████████████████▍        | 7501/9622 [00:03<21:46,  1.62it/s]100%|█████████████████████████████████████| 9622/9622 [00:03<00:00, 2626.65it/s]
  ******************************************* 
              Running Evaluation                
  *******************************************
 
  Length dataset evaluation: 9622
  Length dataloader evaluation: 301
  Number of epochs: 3
  Batch size: 32
  ******************************************* 
 
['/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_4a470038_2020-02-07_13-11-05b1jw5ym_/outputs/checkpoint-3']
INFO:__main__:Evaluate the following checkpoints: ['/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_4a470038_2020-02-07_13-11-05b1jw5ym_/outputs/checkpoint-3']
INFO:transformers.configuration_utils:loading configuration file /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_4a470038_2020-02-07_13-11-05b1jw5ym_/outputs/checkpoint-3/config.json
INFO:transformers.configuration_utils:Model config {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 28996
}

INFO:transformers.modeling_utils:loading weights file /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_4a470038_2020-02-07_13-11-05b1jw5ym_/outputs/checkpoint-3/pytorch_model.bin
HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=301.0, style=ProgressStyle(description_width='initial')), HTML(value='')))
0.0008210.0010000.0008850.2972450.0747850.0728950.1188760.0178100.0964580.0114000.0024420.0015520.0040730.0025980.0005120.0004790.1432590.0542430.0212950.1111970.0065510.4402710.3280520.6527620.0474920.0028390.0006180.0003070.0007520.0010020.0003510.0021670.0075310.4449480.1929520.0056720.1438410.3236090.0280740.0014940.0074110.0134850.0443650.0011490.0001450.0002930.0001360.0002610.0417710.0016980.0001680.0010310.0483010.0196640.1326930.1595480.2334710.0042850.0024450.0134940.8844930.3306580.0097110.0031400.0092810.0339940.4543340.3893940.3622800.0886980.0076590.0005810.6961950.2029620.2843160.0162040.5425040.3098110.1246090.0023490.1723770.0353240.3625950.8392360.0121250.0011400.0003690.0010880.0023210.0224000.0784710.8813110.0607500.0168520.3828170.3198990.0058530.0014490.0027560.1527990.6256410.1691680.1679230.0251890.0624130.0036660.0028890.0002290.1675180.0016430.2391810.2320390.0117520.7014550.0081940.2341620.5315180.2510580.0025020.1685140.1722120.1237431.1124060.0092880.0500460.0005670.0045040.3443540.2094400.2190570.0140440.2147140.0887810.0096600.3039080.9757660.3871020.1606900.2630820.5403350.1027200.3932500.2129220.1148540.2022700.0715810.4466160.2516340.0037270.0593470.0197160.0008410.7102060.0108640.0058110.0073610.0006750.0008820.0004640.2901601.5574270.1166500.0053590.0039330.4064100.0943680.0782340.0564270.0025670.2192800.0280530.0003280.0611980.0156210.0329240.5384241.8429070.0226290.0050880.0126270.2516130.0963520.6850180.1469990.0036420.0068420.4578731.4769440.9044580.3613020.1375100.0021200.1565220.3794570.2581170.1229770.0027040.0203150.4481710.9915370.4532750.0124830.1584970.9748950.2065350.1224140.2295300.2429740.3346690.1810450.0973370.0149970.0277760.2725390.4713480.0034940.0018690.0010430.0016030.0007770.0010720.0006460.0016500.0011600.0015310.0211300.3427910.0084460.0783260.0212520.0501810.1279640.2985570.0020680.0004220.0007970.2183690.0021891.4007220.1583700.0309130.1099730.1360870.5214350.6070740.0076490.0118430.0014520.0238310.3257030.2060710.1993250.0156380.0766440.6181360.7457560.2698580.0039430.4697760.1357240.3655741.1771260.4990120.0237690.4708520.0047290.0826760.2713090.3172770.3656700.0479750.0635980.0032810.0017340.0097340.1713530.0259770.0036570.0001970.0035320.0063800.0173841.5471280.0100010.0263200.0112540.1692440.0026650.4130500.2329600.0086180.0355250.0316640.3709110.0544960.3357200.4046570.0039200.0026750.0020950.001846

*******************************************
EVALUATING PIPELINE 
Pipeline directory: /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_4a470038_2020-02-07_13-11-05b1jw5ym_/
With following parameter combination: {'batch_size_seq_length': 4, 'lr': 1e-05, 'lr_type': 'constant'}
EVALUATION OF CHECKPOINT /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_4a470038_2020-02-07_13-11-05b1jw5ym_/outputs/checkpoint-3
-------------------------------------------------------------
|           |   agree   | disagree  |  discuss  | unrelated |
-------------------------------------------------------------
|   agree   |    562    |    47     |    114    |     2     |
-------------------------------------------------------------
| disagree  |     5     |    55     |    16     |     1     |
-------------------------------------------------------------
|  discuss  |    192    |    55     |   1653    |    26     |
-------------------------------------------------------------
| unrelated |     3     |     5     |    17     |   6869    |
-------------------------------------------------------------
Score: 7248.0 out of 7516.5	(96.42785871083616%)
Accuracy: 0.9498025358553316
F1 overall: 0.7748746616495805
F1 per class: [0.7558843308675185, 0.4602510460251046, 0.8872785829307569, 0.996084686774942]
*******************************************


*******************************************
EVALUATING PIPELINE 
{'batch_size_seq_length': 3, 'lr': 1e-05, 'lr_type': 'linear'}
INFO:__main__:Creating features from dataset file at /home/ubuntu/fnd_implementation/data/processed
  0%|                                                  | 0/9622 [00:00<?, ?it/s]  0%|                                        | 1/9622 [00:02<7:03:45,  2.64s/it] 21%|███████▋                             | 2001/9622 [00:03<3:54:58,  1.85s/it] 52%|███████████████████▏                 | 5001/9622 [00:03<1:39:44,  1.29s/it] 78%|██████████████████████████████▍        | 7501/9622 [00:03<32:02,  1.10it/s]100%|█████████████████████████████████████| 9622/9622 [00:03<00:00, 2631.19it/s]
  ******************************************* 
              Running Evaluation                
  *******************************************
 
  Length dataset evaluation: 9622
  Length dataloader evaluation: 602
  Number of epochs: 3
  Batch size: 16
  ******************************************* 
 
['/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_cb2aa6cc_2020-02-07_15-23-23_ccg10pw/outputs/checkpoint-3']
INFO:__main__:Evaluate the following checkpoints: ['/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_cb2aa6cc_2020-02-07_15-23-23_ccg10pw/outputs/checkpoint-3']
INFO:transformers.configuration_utils:loading configuration file /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_cb2aa6cc_2020-02-07_15-23-23_ccg10pw/outputs/checkpoint-3/config.json
INFO:transformers.configuration_utils:Model config {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 28996
}

INFO:transformers.modeling_utils:loading weights file /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_cb2aa6cc_2020-02-07_15-23-23_ccg10pw/outputs/checkpoint-3/pytorch_model.bin
HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=602.0, style=ProgressStyle(description_width='initial')), HTML(value='')))
0.0006940.0008260.0005320.0003250.0002450.0003770.4560950.4911880.0615760.0071990.0014810.0013130.0968110.0076130.0008270.0005740.0002170.0004760.0002280.0003850.0077870.0006740.0002450.0009280.0060040.0008470.0001380.2353120.0085380.0005010.0009720.0002480.0001250.3670820.0109030.0010240.2348420.0504331.0861600.0279480.0012120.0008180.6893300.9275470.0218670.6024231.3948030.0443690.0240640.0006050.0027660.0001990.0015130.0001420.0001350.0002390.0004340.0005270.0111980.0004030.0245760.0004990.3112730.0053940.0005980.0014191.0605170.0159290.3855040.0062070.0001820.0001220.0293440.1268280.0784590.7056300.0726430.0013490.0001170.0006670.0175150.0004920.0093910.0153460.0007290.3827380.0045590.0001630.0001020.0001020.0001030.0002100.0001050.0001230.0001130.0002620.0002990.0021380.0002260.0008140.0000920.0000770.0002650.0009910.0014450.4997690.2928820.0028590.0002490.0238630.0144290.0820820.4953400.0048360.0001450.0001280.0013610.0008470.0592460.0009720.0961141.4514211.2618260.0118870.0003920.0005580.0000960.0006600.0017300.0017930.0004690.2876320.8113100.3092890.6353990.0053431.0014450.0641900.3106030.5193190.1628170.0015810.0002600.0003950.5359440.3559480.3585090.0867090.0030750.4752910.0084820.0029250.1117910.9460390.0065520.2988500.0023330.0153440.0003320.0004231.8495210.0133500.0148090.0006280.0016310.6779071.1005610.6270010.0040740.0026960.0001130.0006850.2844010.0017540.0007000.0003590.0004730.0014910.0006540.3521910.0778770.0011071.3244621.7232200.1432820.5542680.0974950.0051610.2860400.1761790.3298560.0030680.0013360.0016720.0002200.0008480.0005700.0379200.0035650.0568120.2646760.0053010.0009330.6735880.3278690.8060410.0122460.0020120.0017790.0029000.0011350.1098020.0011080.0013700.0002310.0000880.3873360.0018770.0001010.0000870.2496100.0053000.0009910.6744550.0072990.0044260.0010171.9158110.0102410.0012850.0026920.1709810.4472250.1064450.1047500.0014750.0002640.0001100.0002670.4789290.3125460.0023890.0006270.4322721.7288101.0588920.0045180.0001390.0831590.0186500.0001760.0001300.0015630.1019500.0005270.9274520.9757000.0153860.2364570.2741060.0023940.0014560.1313140.0933670.0827700.1175180.0076500.0062570.0019510.4002670.2943702.4859531.0358660.3280870.7688080.0055050.0031850.3532730.0013740.5771440.0023050.0118640.0004450.0011530.0001340.3956110.0219090.0787370.0519171.5256330.3366930.0014110.3813920.2413180.1111120.2233510.0013680.0001290.0006300.3064750.0071340.1037030.0028860.0026250.9321681.5730180.0069970.0011990.3065760.0021710.1154680.0006330.0003490.0002040.0003250.0002560.0001940.0003860.0006111.1415281.8144861.6223880.1968780.0131860.0022270.0027260.0194040.0045631.0470390.0037570.4382180.0033330.0784510.0052840.0119030.0015710.0003160.0003910.0001050.4008730.0107430.0901110.0003930.0001070.0002900.0013110.0005150.0001040.3906990.0728660.4023890.7041793.8807670.0123940.0017180.0354070.0024280.0012760.0013500.0129470.6045540.3706270.5472520.1598672.3955662.0468510.7768450.0032210.0012530.0004860.0005150.0019590.0002501.0116011.1447672.1702551.1036241.1545471.0209170.3892820.0027660.0317740.0019900.0004930.0001350.3905180.7907230.0041560.2856460.0661290.0135570.0022400.0025470.0009960.0022050.0296700.5635860.4360741.6571830.8289210.8922380.0103000.0007780.2093820.0012480.4490871.8231581.2957580.7120990.0021560.0004600.3073970.7349320.0036150.1010930.4801761.2243960.7883340.6526160.2537450.1482550.3246990.0010540.6928620.0860800.0145450.0017470.7380741.0236450.4005520.0014580.0009030.0012040.0005930.0003850.0009320.0009490.0030450.0005360.0003730.0177130.0013780.0003300.0006720.3333360.0008740.0000900.0007860.0002930.0005720.0017190.0246380.7671160.3102190.0025180.0551160.1443190.0022250.0018660.0024370.0048810.0152110.0041380.4376380.3902930.7146040.0017990.0005320.0004170.0001390.0001340.0002300.0231140.0126770.0016980.0003700.3933123.6323830.4322230.0014350.0004100.1132690.2871920.1620620.1518070.1105670.1420581.1972791.4967210.3072460.0164410.0046920.5941290.0049600.0005990.0000950.2125480.0011340.1821471.0740221.2883360.1500330.8963340.0945370.0004700.0016770.0004060.5202482.0313190.8952630.5160250.8727710.3892770.3542770.0029590.0307520.0010870.9255310.8574970.3973360.3650710.5822871.2606520.8439650.6346100.2209200.0243630.0545960.0640170.4577450.0018580.0027970.0216580.1411890.8343640.0050640.1928200.4655900.5355010.0050600.4290900.0013420.0008000.0013290.0006950.0012260.0007870.0004150.0025340.0001250.0051940.1008950.0016280.0141660.0007100.0014310.0001070.0000870.0052610.0003010.0036050.0008230.0019870.0018463.5442820.1574040.0019960.0163030.0038160.0018590.0042810.0507690.3511990.0086510.0018650.0007650.4901340.2495500.0006640.3242860.0020690.0017230.0165310.0304470.0037540.0113901.0470850.1315390.1263950.1538250.2048730.5113720.3578300.4530780.0032410.0008510.0012420.0011850.0011250.0012500.0010770.000665

*******************************************
EVALUATING PIPELINE 
Pipeline directory: /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_cb2aa6cc_2020-02-07_15-23-23_ccg10pw/
With following parameter combination: {'batch_size_seq_length': 3, 'lr': 1e-05, 'lr_type': 'linear'}
EVALUATION OF CHECKPOINT /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_cb2aa6cc_2020-02-07_15-23-23_ccg10pw/outputs/checkpoint-3
-------------------------------------------------------------
|           |   agree   | disagree  |  discuss  | unrelated |
-------------------------------------------------------------
|   agree   |    551    |    29     |    134    |     2     |
-------------------------------------------------------------
| disagree  |    18     |    65     |    22     |     0     |
-------------------------------------------------------------
|  discuss  |    190    |    66     |   1619    |    29     |
-------------------------------------------------------------
| unrelated |     3     |     2     |    25     |   6867    |
-------------------------------------------------------------
Score: 7224.5 out of 7516.5	(96.11521319763187%)
Accuracy: 0.9459571814591561
F1 overall: 0.775565430915178
F1 per class: [0.7456021650879567, 0.4868913857677903, 0.8741900647948164, 0.9955781080101486]
*******************************************


*******************************************
EVALUATING PIPELINE 
{'batch_size_seq_length': 4, 'lr': 1e-05, 'lr_type': 'cosine'}
INFO:__main__:Creating features from dataset file at /home/ubuntu/fnd_implementation/data/processed
  0%|                                                  | 0/9622 [00:00<?, ?it/s]  0%|                                        | 1/9622 [00:02<7:32:42,  2.82s/it] 21%|███████▋                             | 2001/9622 [00:03<4:11:01,  1.98s/it] 78%|██████████████████████████████▍        | 7501/9622 [00:03<48:54,  1.38s/it]100%|█████████████████████████████████████| 9622/9622 [00:03<00:00, 2611.98it/s]
  ******************************************* 
              Running Evaluation                
  *******************************************
 
  Length dataset evaluation: 9622
  Length dataloader evaluation: 301
  Number of epochs: 3
  Batch size: 32
  ******************************************* 
 
['/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_d75370dc_2020-02-07_18-22-52it4jdf2d/outputs/checkpoint-3']
INFO:__main__:Evaluate the following checkpoints: ['/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_d75370dc_2020-02-07_18-22-52it4jdf2d/outputs/checkpoint-3']
INFO:transformers.configuration_utils:loading configuration file /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_d75370dc_2020-02-07_18-22-52it4jdf2d/outputs/checkpoint-3/config.json
INFO:transformers.configuration_utils:Model config {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 28996
}

INFO:transformers.modeling_utils:loading weights file /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_d75370dc_2020-02-07_18-22-52it4jdf2d/outputs/checkpoint-3/pytorch_model.bin
HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=301.0, style=ProgressStyle(description_width='initial')), HTML(value='')))
0.0032350.0038050.0031820.2821240.0716850.0905810.2460570.0459090.0067620.0016230.0081140.0061110.0216270.0561800.0050870.0023240.1268070.0113000.0271430.2265850.0149310.2468080.2782320.5218740.0716860.0069310.0117320.0011750.0034780.0819810.0171100.0132790.0267560.2310270.1523210.0047790.1090740.1496720.0918860.0060720.0398660.0414370.1232930.0031610.0003670.0007060.0003660.0006610.0062380.0054200.0004750.0053280.0738250.1247570.0034550.0894960.2111960.0041080.0971380.0795100.6084250.2925430.0069680.0017890.0040090.0380970.2854080.1082040.1229420.0291260.1342880.0034210.4186570.1731900.2115990.0359400.2670960.1936350.0826700.0026950.3438940.0296460.1741870.4603530.0428110.0265020.0257510.0039850.0304430.1505140.1916021.1616360.1563640.0700270.1457980.1434120.0104890.0207500.0478080.1077510.1929360.2571720.3719040.0270950.1139940.0164470.0084980.0008220.1285110.0014530.3032130.1616970.0445430.2915120.0269170.4309730.1105280.0424760.0009980.2339780.1543930.1679600.5647790.0052820.0903240.0011350.0097000.4565910.3992410.0777540.0161990.1749150.2232330.0698860.1844751.0779710.6725860.4556860.0620960.1545530.0111870.0171270.1360910.1637000.5998780.1554550.4061310.2708060.0078170.0617040.0829990.0039760.9335090.0174000.0046630.1518720.0020460.0012270.0016090.1568311.4370750.1251000.0139420.0095540.3702150.0922860.0785010.0330630.0162350.2800570.0447730.0007270.0030700.0015020.3454880.2735781.2204830.0535900.0286090.0114770.4140400.1012260.9835310.3257810.0065410.0095840.2805820.8919670.4024230.3597270.0178180.0037480.0688990.1868640.1799280.0506600.0122960.1282250.4027690.9323900.4334110.0868550.1476031.1402170.2784200.1019940.3589340.5071630.7952640.6916400.1598490.1445530.0180370.2905570.5110720.0063520.0054330.0033230.0048890.0026700.0053530.0021890.1175030.0063710.0049550.0336780.4062730.0983930.1490550.0161950.0256960.4805900.3574150.0036860.0011140.0010360.0864340.0036751.4092180.1549900.0469380.2429540.3162930.3896700.8512660.0315440.0334230.0022600.1445860.1078250.1236480.1234410.0056740.0432000.6103760.3897410.1873340.0714540.5247130.6794470.2683300.9148400.3587080.0161060.1397990.0684090.5109910.5127640.4374440.1899990.0393890.0053760.0077640.0042320.0195230.0871840.0127260.0102330.0003340.0187410.0612040.1208690.7963150.0439920.0885720.0585230.2475900.0090350.2243230.0643730.0105760.0117370.0089920.5539700.3439600.3416280.2539800.0079570.0074460.0092730.008237

*******************************************
EVALUATING PIPELINE 
Pipeline directory: /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_d75370dc_2020-02-07_18-22-52it4jdf2d/
With following parameter combination: {'batch_size_seq_length': 4, 'lr': 1e-05, 'lr_type': 'cosine'}
EVALUATION OF CHECKPOINT /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_d75370dc_2020-02-07_18-22-52it4jdf2d/outputs/checkpoint-3
-------------------------------------------------------------
|           |   agree   | disagree  |  discuss  | unrelated |
-------------------------------------------------------------
|   agree   |    557    |    79     |    163    |     3     |
-------------------------------------------------------------
| disagree  |    19     |    34     |    19     |     1     |
-------------------------------------------------------------
|  discuss  |    182    |    49     |   1600    |    28     |
-------------------------------------------------------------
| unrelated |     4     |     0     |    18     |   6866    |
-------------------------------------------------------------
Score: 7189.75 out of 7516.5	(95.65289696002128%)
Accuracy: 0.9412803990854293
F1 overall: 0.7180691973212118
F1 per class: [0.7122762148337596, 0.28936170212765955, 0.8745558895873189, 0.9960829827361091]
*******************************************


*******************************************
EVALUATING PIPELINE 
{'batch_size_seq_length': 3, 'lr': 1e-05, 'lr_type': 'constant'}
INFO:__main__:Creating features from dataset file at /home/ubuntu/fnd_implementation/data/processed
  0%|                                                  | 0/9622 [00:00<?, ?it/s]  0%|                                        | 1/9622 [00:02<6:58:24,  2.61s/it] 21%|███████▋                             | 2001/9622 [00:03<3:52:00,  1.83s/it] 52%|███████████████████▏                 | 5001/9622 [00:03<1:38:28,  1.28s/it] 78%|██████████████████████████████▍        | 7501/9622 [00:03<31:38,  1.12it/s]100%|█████████████████████████████████████| 9622/9622 [00:03<00:00, 2641.00it/s]
  ******************************************* 
              Running Evaluation                
  *******************************************
 
  Length dataset evaluation: 9622
  Length dataloader evaluation: 602
  Number of epochs: 3
  Batch size: 16
  ******************************************* 
 
['/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_42fc7d8e_2020-02-07_10-33-20nlwf2m67/outputs/checkpoint-3']
INFO:__main__:Evaluate the following checkpoints: ['/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_42fc7d8e_2020-02-07_10-33-20nlwf2m67/outputs/checkpoint-3']
INFO:transformers.configuration_utils:loading configuration file /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_42fc7d8e_2020-02-07_10-33-20nlwf2m67/outputs/checkpoint-3/config.json
INFO:transformers.configuration_utils:Model config {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 28996
}

INFO:transformers.modeling_utils:loading weights file /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_42fc7d8e_2020-02-07_10-33-20nlwf2m67/outputs/checkpoint-3/pytorch_model.bin
HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=602.0, style=ProgressStyle(description_width='initial')), HTML(value='')))
0.0002330.0729780.0365320.0122350.0030990.0007360.4535850.5223000.0653270.0073860.0009600.0010740.3334940.0257010.0019720.0003460.0006130.0004790.0000800.0000680.0001090.0001050.0001100.0004400.1250080.0051320.0002820.4544120.0162700.0006390.0001110.0000980.0000440.4026610.0118810.0021320.0024000.0001130.7000630.0180010.0006260.0001850.0025710.1214760.1736200.4611431.7876500.3176930.0108300.0002580.0814920.0016360.0013200.0000580.0000340.0000670.0001720.0015360.2189240.0037760.3151860.0052020.0004810.5508980.0094400.4122820.0105350.0001940.3677090.0055450.0001270.0000370.0366760.4244960.3405930.9385400.0481000.0007100.0000440.0003660.0006900.0001010.0006660.0004860.0001600.0279360.0003710.0000450.0000430.0000450.0000420.0000950.0000450.0000430.0000480.0000750.0544580.0009780.0000790.0002410.0000460.0000420.0000410.0452340.0143660.0358350.0017170.0000580.0001480.0000420.5429030.0060150.6093290.0055700.0000890.0000380.0008410.0003330.0009560.0001750.0389990.6080290.2124930.0020430.0001150.0001940.0000370.0001750.0002110.0003260.0001670.3905650.8266490.3660421.2840260.0096180.8354870.4824440.4849830.8722290.0073570.0002120.0000720.0001211.3028800.5089870.4923780.0035160.0004500.5677420.0052880.0009690.3756860.0067020.0001860.3312460.0022580.2371820.0015720.0011410.0197650.0011020.4255620.0027890.1722860.1463150.0580530.1005070.0006720.0009250.0000500.0006760.0000520.0000380.0002180.0002020.0003580.0002530.0001630.1026770.5303900.4714084.8229951.3024500.0146390.0055450.0079510.0004510.4162780.4568280.7096970.0040800.0003550.0005580.0000950.0005780.0002250.1345470.0046740.0225260.4038000.0024010.0002090.1882110.0074780.0288360.0009330.0008280.4643040.5187650.0026330.0001790.0002640.0022960.0001250.0000410.1606210.0007780.0000430.0000381.7948890.4223930.0022270.8087990.0045440.0028120.0048820.0051620.0011020.0021671.7448011.4646711.2321350.4777280.2875880.0226240.0001680.0000500.0002000.4754930.4750240.0025680.0003040.3802040.9790151.5130960.0062240.0000690.3072590.6386970.0025910.0000660.0005830.0005950.0000520.7854040.4076030.3685050.2620020.5628070.0033260.1499200.4870960.3686070.1303150.2185370.0013600.0004840.0003300.3783510.4618280.9923390.0044600.0004670.0006390.6425280.6551810.3063870.0011401.0206480.0037320.0621240.0004340.0005910.0000530.0014040.0113240.0018330.0740170.7157710.0983140.0004160.7830980.4814690.3341160.6342020.6460760.0022180.0002850.0012890.0005790.0018460.0152860.0021291.9006492.4567050.0095230.0008180.0000490.0005650.6255330.0021040.0000890.0000940.0002420.0000920.0000890.0001400.0001702.0108212.7185722.3455670.3457300.0042720.0007610.0013480.0003990.3018650.1644700.0828410.4001340.1403280.3285430.0019460.0007000.0050540.0001370.0001560.0000340.2803470.0617710.0004690.0000610.0000620.0001110.0002260.0001480.0000480.0025680.0085510.0005840.8901115.3306990.0156510.0004190.0018230.0018980.0003910.0015430.0002140.2776130.2691500.2359080.2107510.7000860.4499540.6183630.0020700.0023380.0435020.0013120.0835210.0002721.3193822.1726243.3399601.9476931.4668960.5858150.0353400.0005980.4384220.0020430.0001530.0000330.4036460.7989780.0866140.0680320.2352390.0014530.0001940.0003240.0002780.0010190.0031940.3803860.5063461.8191280.4355371.8058920.7391250.0134990.0038250.0002350.4352491.8004342.0601570.6529850.0017300.0001610.2499290.3811580.0010710.0074170.4224090.8953130.7574760.3413710.3535440.2799180.0034620.0001110.4493380.5443270.2594040.0028100.9711151.3330170.7719210.0019340.0002920.0003930.0001910.0000840.0003230.0004640.0003300.0001690.0001090.1550640.0007700.0000990.0002220.0067300.0000560.0000360.0005580.0001580.0003290.0007460.0299791.9111300.5703800.0019730.0006530.0010990.0007320.0005630.0010400.0136320.0011210.0221240.9495471.0853620.9291430.0021130.0004770.4785330.0010570.0000450.0002540.2256510.0007880.0002870.0001470.4151672.3244380.3213650.0037520.0011150.0009380.2971580.0019200.0014390.0018160.0008000.8703461.1127110.0047950.0010240.0011320.0011980.0010130.0005410.0000490.2649820.0009050.2067191.4884501.3602650.0053030.4209570.0016970.0729750.3098990.0955280.6991662.7786390.8753540.5715070.6769720.3628710.4066720.0014350.0004680.0203010.4005280.0732710.0094590.0042320.3189991.2576100.8820200.5502900.1394520.0005230.0001350.0258060.0011480.0013880.0512391.3883080.0609200.4235300.0012330.3492020.7604900.1823820.0026910.3252050.0007760.0002580.0002670.0002310.0004030.0002520.0013960.0007970.0000370.0007680.0004370.0002310.0003970.0002680.0003260.0000360.0000520.0008620.0016900.0460810.0004490.0009450.0006663.2720440.0230080.0007390.0993890.0010390.0009320.0020490.0007910.3512540.0022520.0006490.0003541.0090250.3406800.0006660.5807380.0013200.0005880.0171340.0077120.0008340.0642482.0421370.3303500.1071970.0022390.0106920.0073840.3861520.9943240.0048750.0040080.0011120.0009080.0003340.0003600.0003290.000196

*******************************************
EVALUATING PIPELINE 
Pipeline directory: /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_42fc7d8e_2020-02-07_10-33-20nlwf2m67/
With following parameter combination: {'batch_size_seq_length': 3, 'lr': 1e-05, 'lr_type': 'constant'}
EVALUATION OF CHECKPOINT /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_42fc7d8e_2020-02-07_10-33-20nlwf2m67/outputs/checkpoint-3
-------------------------------------------------------------
|           |   agree   | disagree  |  discuss  | unrelated |
-------------------------------------------------------------
|   agree   |    656    |    49     |    197    |     5     |
-------------------------------------------------------------
| disagree  |     5     |    78     |    39     |     1     |
-------------------------------------------------------------
|  discuss  |    97     |    34     |   1533    |    18     |
-------------------------------------------------------------
| unrelated |     4     |     1     |    31     |   6874    |
-------------------------------------------------------------
Score: 7199.75 out of 7516.5	(95.78593760393801%)
Accuracy: 0.9500103928497194
F1 overall: 0.8024127516687194
F1 per class: [0.7860994607549431, 0.5473684210526316, 0.8805284319356692, 0.9956546929316339]
*******************************************


*******************************************
EVALUATING PIPELINE 
{'batch_size_seq_length': 1, 'lr': 1e-05, 'lr_type': 'linear'}
INFO:__main__:Creating features from dataset file at /home/ubuntu/fnd_implementation/data/processed
  0%|                                                  | 0/9622 [00:00<?, ?it/s]  0%|                                        | 1/9622 [00:02<7:15:17,  2.71s/it] 21%|███████▋                             | 2001/9622 [00:03<4:01:22,  1.90s/it] 78%|██████████████████████████████▍        | 7501/9622 [00:03<47:01,  1.33s/it]100%|█████████████████████████████████████| 9622/9622 [00:03<00:00, 2567.61it/s]
  ******************************************* 
              Running Evaluation                
  *******************************************
 
  Length dataset evaluation: 9622
  Length dataloader evaluation: 2406
  Number of epochs: 3
  Batch size: 4
  ******************************************* 
 
['/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_c638d148_2020-02-07_13-57-585i1el58q/outputs/checkpoint-3']
INFO:__main__:Evaluate the following checkpoints: ['/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_c638d148_2020-02-07_13-57-585i1el58q/outputs/checkpoint-3']
INFO:transformers.configuration_utils:loading configuration file /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_c638d148_2020-02-07_13-57-585i1el58q/outputs/checkpoint-3/config.json
INFO:transformers.configuration_utils:Model config {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 28996
}

INFO:transformers.modeling_utils:loading weights file /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_c638d148_2020-02-07_13-57-585i1el58q/outputs/checkpoint-3/pytorch_model.bin
HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=2406.0, style=ProgressStyle(description_width='initial')), HTML(value='')))
0.0000930.0001420.0000820.0000440.0000230.0000140.0000110.0000110.0000100.0000090.0000100.0000100.0000090.0000120.0000130.0000100.0000090.0000210.0000100.0000100.0000440.0000120.0000610.0000120.0000981.3708350.0527350.0019622.2196270.0766300.0025620.0000910.0000110.0000080.0000080.0000080.0000880.0000100.0000080.0000100.0022140.0585780.0014040.0000410.0345090.0007760.0003150.0000150.0001770.0000120.9982912.0826370.0400590.0007640.0000230.0000090.0000090.0000110.0000460.0000130.0001230.0000130.0000130.0086600.0001450.0019190.0000500.0000110.0037150.0002310.0000150.0000770.0000160.0000090.0000120.0000240.0000110.0000090.0000100.0000100.0000110.0001420.0112130.0001470.0000130.0000100.0000110.0000430.0001760.0000150.0000100.0000470.0000160.0000120.0012570.0000220.0012940.0002960.0000140.0000160.0000840.0000170.0000090.0001950.0000130.0000090.0001610.0000110.1814641.3057270.0151970.0001450.0000100.0000080.0000090.0004000.0000110.0002440.0000100.0000090.0000090.0000610.0000080.0000080.0000080.0000470.0000080.0000080.0000080.0000090.0000080.0000090.0002300.0001260.0000710.0003320.0000120.0000100.0000110.0000090.3041510.0022090.0000250.0000480.0000810.0000100.0000100.0000090.0001350.0001580.0342140.0002370.0001544.0573212.2609640.0145950.0001020.0000090.0000080.0000120.0000640.0001320.0001330.0000100.0000080.0147090.0000970.0000090.0000090.0000170.0000462.5673131.3605500.5696950.0032931.7654281.7615040.0099610.0001130.0000110.0000080.0000132.5383120.0138790.0001570.0000104.7607832.4494360.0130380.0000840.0022950.0002950.0002910.1071770.0008600.0000140.0000130.0000080.0000090.0000080.0151381.5548460.0077060.0000470.0000100.0000090.0000690.0000100.0000080.0000110.0268120.0001370.0000090.0000090.0000100.0000080.0000110.0000080.0000090.0000080.0000100.0000080.0000470.0000080.0000840.0000080.0346420.0002000.0000100.0000090.0000920.0000491.5213260.0065380.0000890.0000090.0000100.0000080.0000120.0000490.0000080.0000090.0000090.0064400.0000350.0000080.0000080.0000080.0000082.5271910.0101350.0000490.0000440.0000540.0000090.0000090.0000842.3268010.0090270.0001421.4128460.0054210.0000290.0000081.8761264.2526661.7864990.0066990.0000340.0000090.0000090.0000080.0000110.0023090.0000551.3421040.0050550.0000270.0000090.0000080.0000120.0000100.0000090.0000090.0000080.0000080.0000090.0000090.0000090.0011500.0000120.2273380.0013310.0000130.0000102.1492722.0200700.0068160.0000310.0000130.0000102.2264812.1592740.0071350.0000320.0117590.0289330.0001020.0000080.0003440.0000090.0000080.0000080.0000080.0000080.0000080.0000080.0000080.0002730.0000100.0000100.0004920.0000101.7194130.0053150.0000600.0000090.0000100.0000460.0001061.0839330.0041720.0000200.0002530.0000420.0001330.0000430.0000420.0000090.0000760.0000421.5437540.0045220.0000220.0000080.0000080.0000080.0000090.0000080.0000080.0000080.0000080.0000080.0000080.0000080.0000090.0000080.0000080.0000090.0000090.0000080.0000080.0000170.0000080.0000080.0000090.0001330.0000530.0000090.0000080.0000090.0000090.0000080.0000110.0000080.0000080.0000130.0000080.0000080.0000080.0000080.0000080.0000460.0000080.9642971.8480540.0047960.0000210.0000790.0000130.0000090.0001700.0000090.0000080.0000090.0000150.0003010.0000100.0000090.0000080.0000130.0000100.0000100.0000120.0000080.0000090.0000090.0000090.0000150.0000090.0034310.0000170.0185490.0000540.0074510.0000270.0000090.0359370.0038810.0000190.0039090.0013740.0000501.6276601.4556810.0034700.0000690.0000090.0000080.0000090.0000090.0000090.0000080.0000530.0000080.0000080.0000260.0000080.0000080.0000080.0000090.0020430.0000150.0000090.0003850.0012920.0003660.0000090.0001480.0000102.5877820.0058470.0001160.0000100.0000090.0001010.0000090.0000090.0000100.0000090.0000080.0000090.0000080.0000270.0000480.0000520.0000080.0008510.0005090.0000320.0000110.0106860.0000880.0036720.0010600.0001000.0000550.0000520.0000140.0000120.0000090.0000770.0001860.0125640.6152680.5467620.0187640.5725790.5303340.2209891.4032820.8487930.0020930.0011020.0000130.0000090.0007320.0000100.0000080.0000090.0000090.0016770.0001740.0000090.0000100.0000090.0000090.0000090.0001960.0000090.0000090.0001810.0000210.0001670.0004350.0000090.0000080.0002750.0001390.0008130.0000100.0000490.0003150.0000100.0000092.0371100.0038840.0000573.8791160.0073420.0002900.0000120.0000090.0000570.0000481.8936520.0035982.1448841.8999024.2483990.0078840.0000280.0001000.0001060.0000122.0766372.1813310.0048290.0000200.0000401.7657540.0032740.0000151.1249270.0038990.0000150.0076121.8494150.0068620.0000210.0000110.0107930.0000280.0002450.0000500.0000440.0000530.0000090.0000090.0000090.0000090.0000470.0000420.0000080.0000890.0000080.5415810.0009470.3011811.4173940.0024520.8390210.0022210.0000131.1060560.0018990.0136450.0001050.0000450.0000490.0001160.0000090.0000910.0000080.0001490.0001080.0000120.0000080.0000572.1102680.0037390.0000680.0002520.0019660.0001450.0002930.0001050.0002200.0000520.0001850.0002221.5418060.0025860.0031981.1240921.6424150.0027080.0000460.0000090.0000431.9108480.0030890.0000140.7664550.0012700.0000100.0000420.0000091.5089060.0024080.0000470.0000090.0000090.0000430.0000090.0002070.0000090.0000470.0000430.0000080.0024213.3995833.5652601.6870170.0027630.0002920.0005220.0000100.0032860.0000130.0001080.0000840.0000080.0001180.0000540.0000080.0359580.0001760.0001920.0001750.0014600.0000610.0006330.0029870.4311910.0006570.0233360.0000430.0077220.0000200.5480470.0008660.0000090.0000080.0000080.0000583.4162891.1086691.5960120.0429990.0000720.0000080.0000080.0000090.0000090.0000120.0000080.0000790.0000090.0000090.0000550.0000080.0000090.0000090.0000090.0000090.0000600.0000080.0000590.0000410.0000110.0000880.0000090.0000500.0000620.0000440.0000090.0012730.0000800.0000450.0000480.0003520.0000160.0024870.0001110.0000490.0000101.2189840.0017060.0000130.0014120.1778830.0002560.0000100.0000500.0000080.0000460.0000581.4063773.0360601.6138861.0960752.0702810.0108182.0545770.0028850.0000130.0000850.0000411.3664210.0018940.0000670.8514132.8676510.0039320.9962620.0013880.0000110.0000970.0016450.0000150.0000080.0091960.0025680.2063910.0002820.0032720.0000130.0000090.0000080.4422570.0005900.0000090.0003540.0000080.0016730.0000110.0000080.0000590.0000080.0001440.0001510.0001460.0001460.0001440.0001510.0000440.0016720.0000110.0000090.0002280.0000090.0000090.0000090.0000080.0000960.0000440.0006990.0000860.0000962.0653881.8711040.0023753.8511040.0049530.0000591.8549660.0024100.0022573.0553881.9052452.8922910.7709691.5620730.0019510.0005620.0009950.0000100.0000690.0007760.0001100.0000090.0005190.0000450.0000080.0417410.0000600.0936000.0002100.0000090.0000090.1078963.4065835.4049840.0065670.0007150.0000090.0420850.0000590.0002080.0001640.0000420.0000770.0000980.0002540.0002240.0003280.0000082.5759080.0032690.0000120.0002970.0000090.0000080.0000080.0000080.0000600.0000670.0000380.0000980.0025000.0000120.0000080.0000090.0198220.0002550.0000820.0000090.0000080.0000080.0000080.0000080.0000080.0000080.9729410.0011330.0000100.0000080.0000080.0000080.0000080.0000080.0000080.0000080.0000080.0000080.0000080.0000080.0000080.0000080.0000080.3597590.0007800.0043370.0005500.0000080.0001960.0007470.0001740.0001780.0000100.0000090.0000081.8444981.9629040.0022040.0009280.0000090.0000630.0000590.0001770.0001590.0001070.0061310.0000870.0001570.0000090.0002000.0001561.6868191.4057190.0016780.0001130.0000590.7502892.0365760.0102240.0001640.0917610.1071200.0003580.0000100.0018600.0005570.7952810.0009350.0014970.0000791.6870260.7890621.4288530.0016100.0000100.0000851.5828060.0019340.0001290.9653250.0011470.0001720.0000190.0000110.0002060.0000080.0000080.0000080.0000080.0000520.0000110.0000080.0000080.0000080.0000150.0001380.0000490.0000082.2224820.0023310.0000111.9706840.0021050.0000552.2841380.0023800.0000110.0012500.0000100.0002510.0000090.0000090.0000090.0005470.0000110.0000090.0000570.5608190.2110280.3935940.1349430.0108140.5233962.0033050.0022830.0002160.0000430.0000080.0000080.0000090.0000090.0000090.0000090.0000090.0000090.0783580.0000870.0000080.0083340.0093350.0000180.0054340.0000140.0000090.0000090.0000090.0003150.0000090.0000080.0000090.0000780.0001680.0000090.0000090.0000800.0001550.0000320.0032330.0000130.0000100.0000090.0000090.0000090.0000100.0000436.0751974.2386831.7638340.0017270.0000100.0000080.4221450.0004890.0002190.0001070.0001070.0000271.1960941.0499491.6633420.0016520.0002080.0002620.0002920.0000110.0002540.0016340.0000900.0000240.0000560.0000080.1757160.0393940.0000450.0856401.4478200.0013820.0000100.0000080.1231940.0001250.0402260.3937480.0008240.1144640.0001160.0000080.0994900.0001410.0000080.0297260.0000360.0000090.0088460.0000710.0000080.0224980.0000290.2808421.4847940.0013870.1262560.0661590.9200291.7259530.0017773.8811000.0049370.0003790.0000790.0003052.5477180.6938060.0009780.0001840.0001140.0000560.0001090.1245740.0001390.0001670.0000770.0002240.0002070.0000440.0001860.0003860.0021780.0000100.0001710.0001780.0001622.1136110.2180230.0002060.0000090.0000110.0000101.9593442.0496973.6169980.0032760.0000130.0000440.0000080.0000092.0059010.0017920.0000100.0000080.0000090.0000580.0000090.0000090.0000680.0000090.0000670.0000660.0000090.0000090.0000080.0000090.0000080.0001680.0000090.0000090.0000090.0001330.0003350.0006190.0013540.0008370.0001780.0003212.4174430.0022140.0001810.0000253.2826042.2404943.1681440.0028270.0001351.7800470.6439320.0006480.0000420.0000090.0000080.0000080.0000090.0000150.0000083.4225110.0029311.7692970.0015490.0000720.0000510.0000081.4636170.0012511.1968560.0010231.6583970.0014110.0000580.0000090.0000110.0000080.0000100.0000090.0000080.0000080.0004730.0000100.0000110.0000090.0000091.4874520.0012520.0003330.0000090.0000090.0000090.0008960.0005280.0004550.0004500.0000090.0000100.0000100.0000090.0001950.0002610.0000140.0000150.0000200.0000510.0002050.0003494.4960294.9428672.0578580.0017760.0008950.0001070.0000940.0001000.0000900.0000150.0001750.0000900.0000580.0030610.0000120.0000110.0000100.0000100.0000150.0001910.0000120.0000220.0009810.0007230.0004180.0000480.0000080.0000170.0000090.0000790.0000410.0000080.0000100.0000950.0000080.0000090.0000090.0000090.0000090.0000850.0000080.0000090.0000980.0000370.0000090.0000500.0000080.0000090.0000090.0000080.0002240.0000080.0000090.0001230.0000090.0001360.0000080.0000353.1078780.0063800.0034020.0007110.0010593.9644864.3132411.4332722.5024412.8800552.6313860.0021921.2694130.0012181.2720833.4290814.0097890.0032480.0005500.0015200.0006710.0004120.0001630.0003770.0002931.4470440.0011610.0001750.0010600.6945570.9771650.0009880.0001170.9615941.0162870.0112760.0025281.3312970.0023800.0002940.0000090.0000090.0000090.0000091.6858210.0012840.0000090.0003730.0005790.0000082.1428751.8144941.8859120.0472710.0005560.0002510.0003110.0001740.0000090.0002110.0000770.0000990.0000100.0000800.0122610.0000180.0010830.0000090.0001290.0002000.0000120.0000080.0000460.0001990.0000080.0000090.0000090.0000080.0000080.0488540.0988740.0167210.0153120.0063690.0000140.0000090.0000090.0000520.0091590.0000170.0000590.0000110.0001050.0000080.0000080.0010880.0000890.0000090.0000090.0000090.0009610.0000090.0000100.0000120.0000090.0000570.0001240.0000100.0000090.0000100.0000650.0000080.0000090.0000110.0000080.0001300.0001050.0007130.0004700.0002260.0003840.0001430.0001990.7333330.0006090.0000470.0001180.0001640.0000461.4421990.0015910.0011216.1429096.2149427.8989340.0057370.0001230.0002750.0002030.0000090.0036860.0000120.0063030.0000131.1983040.0024710.0000320.0987560.0002270.0000810.0001160.0001190.0000780.0001450.0001220.0001120.0000970.0001220.0001540.0000500.0001140.0000610.0000440.0408722.0116590.0050990.0000660.0001600.0001081.9326590.0014110.0001380.0001282.7350270.0021130.0002630.1294790.0233250.0000263.7357580.9940840.0702480.1571091.5906371.7067670.0885414.0659584.9371310.0035700.0002180.0001610.0001860.0001460.0002990.0000090.0000460.0001450.0000080.0000670.0000080.0000080.0000090.0000870.0000080.0000120.0000840.0000080.0001820.0000880.0000100.0000470.0000080.0000750.0000080.0000102.1822540.0055440.0001584.2647254.4872484.3388652.2676380.1453664.3808795.2148944.4427724.3396872.2378890.0319111.8436360.0015520.0000442.3957773.4432220.0023251.3413281.6967860.0012061.8937043.4171080.0025070.0001070.0007830.0001400.0002360.0005690.0001730.0002460.0003930.0006000.0004170.0000620.0001790.0000080.0002030.0000870.0000090.0000080.0000080.0000080.0000080.0000080.0000090.0000090.0000430.1132970.0000820.7268170.0004791.3933230.0009090.0000540.0001930.0005752.1193162.0123750.0013581.5045075.1988760.5230923.2287353.6819050.0023700.0000300.0001570.0001580.0000910.0000100.0000260.0000940.0000660.0000810.0002670.0000810.0001490.0000790.0001130.0000940.0000470.0000830.0005120.0000820.0001270.0001940.0000630.0135630.0026890.0033620.0000870.0000492.1488440.0014300.0000422.2721640.0015032.3140744.4741230.0028942.2007612.0204770.0013092.3059360.0014844.5423900.1410090.0007870.1314722.0389910.9997010.0017760.0000470.0001020.0000080.0001000.0000930.0002330.0000090.0044220.0002080.0003870.0000090.0000490.0000440.0000540.0000092.1447350.0013313.9033122.3327790.0014642.1164632.1576667.6375456.8365918.5474916.1563546.2252030.0039520.5625150.0004020.0001780.0000460.0000080.0000860.0000110.0000460.0000080.0000090.0000080.3244110.0002050.0000111.4077680.0008880.0000090.0000090.0000110.0000090.0000643.1755953.6090051.3288620.0010281.8617600.0011320.0203830.0020770.0000141.6163931.0540902.8339631.5356090.6832403.9436331.8728175.2161395.8734313.2525740.0019500.0000130.0008021.8364890.0011021.6483930.0009890.0000090.0017181.2770100.0007670.0000090.0000090.0000080.0000090.0000090.0006520.0015410.0001040.0001160.0005610.0000780.0002060.0001110.0002000.0002680.0000800.0000750.0001950.0000120.0002010.0000450.0001091.4486460.0009051.2099360.0010781.9634190.7499700.0005613.6676940.8328260.8954720.0006680.0000140.0000100.0000090.0001600.0000150.0000790.0000780.0001870.0001140.0001920.0002310.0001160.0002040.0000450.0000770.0000460.0000500.0000250.1058240.0025580.0000100.0000810.0000840.0000500.0001060.0000810.0000460.0000470.0000670.0000090.0000760.0000430.0041880.0000170.0000470.0000770.0000910.0000090.0000780.0000100.0000100.0000090.0188000.0000260.0000110.0001180.0001020.0000080.0001830.0000170.0000420.0000460.0000170.0000710.0000250.0000090.0000820.0001360.0000470.0000422.4273010.0013720.0000090.0000300.0000090.0000090.0000090.0000130.0000080.0000780.0000150.0001640.0000080.0000100.0000080.0000090.0000650.0000700.0000080.0000550.0000090.0000090.0000080.0000640.0001740.0000840.0003250.0034300.0003714.3718604.1067950.0063610.0014720.0044580.0041620.0001470.0001280.0002050.0002620.0000930.0001220.0001420.0002820.0016570.0001660.0001990.2310150.0003280.0000310.0002160.0002000.0000880.0001310.0000840.0003410.0001990.0002060.0001650.0001674.6154850.1462092.9875652.4460680.4717550.0008711.3425830.0246740.0007980.0766640.0056950.0016270.0000620.0039690.0015140.0000810.0312430.0002120.0002660.0002400.0004490.0000910.0003400.0000840.0002640.0000550.0000090.0000110.0000090.0000500.0002660.0001700.0000460.0000090.0000080.0000090.0000090.0000990.0000080.0000080.0000080.0000080.0000090.0000090.0000590.0000080.0000270.0000110.0000470.0000082.4573410.0013090.0000090.0000860.0000590.0001060.0002080.0002060.0000910.0000450.0000870.0001150.0000490.0001440.0000080.0000330.0000720.0000842.1459190.0014054.0550036.2957702.1459976.1784521.8809650.0010870.0001020.0000430.0000420.0000460.0000080.0001420.0000080.0000090.0000080.3112990.2592800.0001430.0000590.0000090.0000470.0041970.1544340.3317170.0001800.1503390.0003761.3411450.0011340.0003850.0003300.0040230.0006690.0006970.0004170.0009850.0000090.1537220.0002970.0002310.0005322.5578852.3376920.0014703.8072272.0205100.0016170.1014380.0040050.9026160.0015700.0001170.0000540.0001900.0002560.0000890.0002810.0001130.0002430.0002300.0001740.0002090.0002260.0000920.0001360.0001790.0001400.0001180.0000080.0001290.0000080.0000090.0000080.0000080.0000080.0000080.0000080.0015940.0152280.0000160.0000090.0000090.0000090.0001320.0000661.4459990.0009520.0000090.0000090.0000561.0109120.9028430.0006120.0039020.2351070.2461740.2552500.0223660.0095170.0000270.1402120.0025130.1003651.2291050.0088030.0609840.0000750.0000530.0000090.0000510.0000080.0000080.0000920.0000930.0000860.0001450.0000900.0000080.0000080.0000081.7882941.2056092.1696984.8751202.1169740.0573520.0017040.0002360.3857983.2762160.7928320.0003970.0000092.0772571.7225300.0008512.5055081.7276150.0008530.0000082.2647470.0011140.0001780.0000100.0000090.0000142.0743300.0010190.0004070.0000090.0001950.0000530.0000100.0000090.0001880.0001280.0000140.0001080.0000090.0001650.0000081.4825943.0967210.0016561.7384460.6764050.0004710.5338502.1706640.0052880.0002830.0002760.0003180.0002040.0003540.9240411.3010520.0006332.0812600.0010561.6583722.0468120.0011853.7642720.0019690.0001882.5015002.0588501.0772381.7106930.0373740.1582800.0002700.0096950.0000130.0003730.0001460.0000100.0000381.7740650.0008520.0000110.0000130.0003701.6650170.5255851.0375390.0006310.0000090.0004930.4808581.8230650.0008690.1105640.0002360.2013160.0005031.6314800.0008090.0001940.8028750.9752342.0675564.1074320.0019350.0018081.0963121.4597360.0028092.0262391.6255751.2181010.0007060.0000430.0002890.0000100.1803040.3633070.0002770.0000742.1935530.0013320.0011910.0002630.0263040.8872171.5226310.1324430.0001100.2356540.0001660.0000090.0001220.0002192.1450460.0010010.0000450.0000090.0000830.0000870.0001120.0000420.0000970.0000550.0000420.0000530.0000780.0001140.0001170.0000090.0000100.0001390.0001430.0000910.0000900.0000940.0000590.0000580.0003270.0000460.0000110.0000080.0000090.0000540.0000080.0000080.1091280.0000590.0000090.0000100.0000090.0000100.0000090.0002200.0019280.0000100.0000090.8443230.0003910.0000090.0000080.0008940.0000090.0000090.0001300.0001830.0002450.0000090.0000080.0000090.0000110.0002910.0000090.0005840.0000090.0002140.0000080.0000080.0000090.0000110.0000090.0000100.0000170.0000090.0005140.0000080.0005110.0000500.0000080.0000090.0000080.0001980.0006750.0000120.0000090.0095090.0000130.0040250.0000750.0002320.0001330.0001520.0001050.0001040.0001120.0000830.0001910.0001181.0789251.6021343.8670281.7384880.0140370.0001290.0000080.0002510.0001430.0000710.0001110.0001310.0001580.0001140.0000100.0015660.0000960.0000500.0001060.0000100.0027020.0000100.0000090.0001610.0000460.0012000.0000360.0004740.0003680.0004660.0000520.0000500.0000461.9967840.0013630.0004770.0000521.1277090.0005930.0000530.0000720.0024690.0015660.0000580.0000870.0000200.0000830.0000610.0002110.0000080.0000591.7952990.0007860.0000590.0000081.5064080.0006600.0000720.0000080.0000091.9949530.0009360.0003790.0000690.0000430.0005760.0000100.0000100.0002970.0000090.0008270.0000420.0002060.0002880.0003240.0004510.0000760.0027690.0000430.0000430.0006880.0000090.0014090.0000100.0015650.0000090.0006340.0000615.8585750.0029961.9646240.0067130.0000101.1740660.0009850.0003050.0007760.0003701.5793220.0046070.0006760.0003500.0005682.7827131.1932970.0117020.0006720.0000151.3460761.3804510.0010930.2821630.0003470.0002362.3103140.1029971.9355060.0058610.0012410.0002930.0005190.0001000.0000080.0003870.0000550.0000470.0000780.0000870.0000520.0006360.0000920.0000850.0000440.0001930.0003470.0001250.0000530.0000540.0022010.0000100.0000090.0000540.0000880.0000460.0000090.0000900.0000080.0000850.0000440.000009

*******************************************
EVALUATING PIPELINE 
Pipeline directory: /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_c638d148_2020-02-07_13-57-585i1el58q/
With following parameter combination: {'batch_size_seq_length': 1, 'lr': 1e-05, 'lr_type': 'linear'}
EVALUATION OF CHECKPOINT /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_c638d148_2020-02-07_13-57-585i1el58q/outputs/checkpoint-3
-------------------------------------------------------------
|           |   agree   | disagree  |  discuss  | unrelated |
-------------------------------------------------------------
|   agree   |    562    |    40     |    145    |     3     |
-------------------------------------------------------------
| disagree  |    24     |    70     |    36     |    10     |
-------------------------------------------------------------
|  discuss  |    171    |    49     |   1604    |    21     |
-------------------------------------------------------------
| unrelated |     5     |     3     |    15     |   6864    |
-------------------------------------------------------------
Score: 7219.25 out of 7516.5	(96.0453668595756%)
Accuracy: 0.9457493244647682
F1 overall: 0.7707343031061732
F1 per class: [0.7433862433862434, 0.46357615894039733, 0.8801097393689986, 0.9958650707290533]
*******************************************


*******************************************
EVALUATING PIPELINE 
{'batch_size_seq_length': 1, 'lr': 1e-05, 'lr_type': 'cosine'}
INFO:__main__:Creating features from dataset file at /home/ubuntu/fnd_implementation/data/processed
  0%|                                                  | 0/9622 [00:00<?, ?it/s]  0%|                                        | 1/9622 [00:02<6:55:55,  2.59s/it]  5%|█▉                                    | 501/9622 [00:02<4:36:02,  1.82s/it] 21%|███████▋                             | 2001/9622 [00:03<2:41:27,  1.27s/it] 78%|██████████████████████████████▍        | 7501/9622 [00:03<31:27,  1.12it/s]100%|█████████████████████████████████████| 9622/9622 [00:03<00:00, 2591.77it/s]
  ******************************************* 
              Running Evaluation                
  *******************************************
 
  Length dataset evaluation: 9622
  Length dataloader evaluation: 2406
  Number of epochs: 3
  Batch size: 4
  ******************************************* 
 
['/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_d00ea8be_2020-02-07_16-02-58gxuqrd5c/outputs/checkpoint-3']
INFO:__main__:Evaluate the following checkpoints: ['/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_d00ea8be_2020-02-07_16-02-58gxuqrd5c/outputs/checkpoint-3']
INFO:transformers.configuration_utils:loading configuration file /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_d00ea8be_2020-02-07_16-02-58gxuqrd5c/outputs/checkpoint-3/config.json
INFO:transformers.configuration_utils:Model config {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 28996
}

INFO:transformers.modeling_utils:loading weights file /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_d00ea8be_2020-02-07_16-02-58gxuqrd5c/outputs/checkpoint-3/pytorch_model.bin
HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=2406.0, style=ProgressStyle(description_width='initial')), HTML(value='')))
0.0003540.0004320.0002310.0000930.0000470.0000210.0000140.0000120.0000120.0000120.0000120.0000110.0000130.0000310.0000220.0000120.0000120.0000190.0000110.0000170.0000760.0000140.0000940.0000170.0002751.3726610.0528070.0019672.0870420.0720750.0024120.0000870.0000120.0000100.0000100.0000100.0002240.0000160.0000110.0000150.0002280.0172290.0004210.0000192.0219830.0449420.0051100.0001180.0058760.0001291.3622891.7775380.0341930.0006550.0000220.0000100.0000110.0000120.0001820.0000180.0002230.0000180.0000120.0000220.0000110.0005790.0000230.0000130.0024590.0001170.0000130.0000200.0000120.0000110.0000140.0000120.0000110.0000100.0000110.0000120.0000120.0000150.0002910.0000370.0000130.0000110.0000170.0000720.0000180.0000160.0000110.0000140.0000110.0000900.0138630.0001550.0007960.0010380.0000210.0000140.0000230.0000120.0000120.0005240.0000190.0000100.0000130.0000101.8745330.0175531.7722360.0159760.0001520.0000110.0000110.0000130.0000100.0001370.0000110.0000100.0000100.0000860.0000100.0000100.0000100.0000660.0000100.0000100.0000100.0000100.0000100.0000100.0002430.0003560.0005700.1160230.0008660.0000170.0000140.0000170.0233400.0002390.0000120.0000660.0004080.0000140.0000100.0000150.0000380.0000220.0002720.0000120.0005331.8098350.0288610.0001960.0000110.0000100.0000100.0000110.0000130.0028300.0002090.0000120.0000100.0008870.0000150.0000110.0000120.0000170.0000853.0911721.7760760.6117860.0035291.3182911.7986760.0101720.0002080.0000110.0000100.0000112.7983630.0153010.0004070.0000124.0974042.3955320.0127520.0000811.3448290.3731640.0029720.2369240.0018310.0000320.0000190.0000110.0000140.0000220.0000850.0007600.0000240.0000110.0000130.0000100.0000150.0000470.0000100.0003950.0011390.0000170.0000120.0000110.0000190.0000170.0000120.0000100.0000120.0000110.0000160.0000110.0000740.0000110.0001460.0000110.0000130.0000640.0000100.0000100.0002290.0000871.9419850.0083440.0001240.0000100.0000120.0000100.0000190.0000780.0000100.0000100.0000101.9710360.0080880.0000430.0000100.0000100.0000111.2043580.0048350.0000290.0000870.0000950.0000100.0000130.0000190.5994050.0023330.0001570.0078420.0000400.0000100.0000101.6060771.7105911.8589990.0069720.0000360.0000100.0000100.0000100.0000120.0050320.0000851.6165620.0089160.0000420.0000100.0000100.0000100.0000100.0000100.0000100.0000100.0000100.0000100.0000100.0000100.0009280.0000130.0009430.0001180.0000100.0000111.9298040.1044300.0003640.0000110.0000100.0000101.9489222.0244870.0066920.0000320.0054710.6489010.0021230.0000160.0002610.0000100.0000100.0000100.0000100.0000100.0000100.0000100.0000100.0003960.0000110.0000100.0004010.0000111.9595120.0060570.0000850.0000110.0000120.0000650.0003831.6728820.0053430.0000260.0022030.0000680.0008880.0000810.0000630.0000100.0001140.0000660.8012370.0023530.0000160.0000100.0000100.0000100.0000100.0000100.0000100.0000100.0000100.0000100.0000100.0000100.0000100.0000100.0000100.0000100.0000100.0000100.0000100.0000110.0000100.0000100.0000100.0000240.0000940.0000100.0000100.0000100.0000100.0000100.0000100.0000100.0000100.0000100.0000100.0000100.0000100.0000100.0000100.0000860.0000100.3699370.0011920.0000200.0000120.0001640.0004100.0000990.0017500.0000170.0000110.0000100.0000140.0005490.0000110.0000100.0000100.0000110.0000110.0000110.0000110.0000100.0000100.0000100.0000100.0000100.0000100.0041460.0000200.0001020.0000120.0739160.0001880.0000100.0001070.0000990.0000100.0002600.0005720.0000651.8106271.6156470.0038160.0001010.0000100.0000100.0000100.0000100.0000100.0000100.0001090.0000100.0000100.0000160.0000100.0000100.0000100.0000102.0575710.0046650.0000220.0031530.0081120.0004120.0000120.0001760.0000312.3736300.0053750.0001360.0000100.0000110.0001020.0000100.0000100.0000100.0000100.0000100.0000100.0000100.0000100.0002400.0001210.0000100.0004410.0010040.0009780.0000131.9633560.0041940.0003070.0002040.0000150.0000710.0000810.0014960.0000150.0000100.0000210.0001410.1807950.0009650.2139190.0004760.0000190.0000860.2607540.0011460.0000770.0009350.0025060.0000150.0000100.0001100.0000100.0000100.0000100.0000100.0001140.0001580.0000100.0000110.0000100.0000100.0000100.0001650.0000100.0000100.0001020.0000100.0002480.0209810.0000500.0000100.0009580.0115180.0032390.0000160.0000780.0015070.0000300.0000101.5058030.0028790.0000953.7710830.0071380.0026140.0000160.0000100.0001060.0000892.4132000.0045131.3155510.8310641.8819810.0034950.0000170.0000110.0001660.0000151.2401531.3395440.0026350.0000270.0000631.7861930.0032530.0000150.0001860.0000120.0000100.0003651.7848800.6210670.0011210.0000120.0001490.0000100.0004500.0000780.0000760.0000950.0000100.0000100.0000100.0000100.0001090.0000600.0000100.0001350.0000100.4145010.0007290.5107041.4054270.0024331.1119120.0021200.0000131.5420460.0026460.0088580.0001950.0000760.0000700.0001160.0000120.0002320.0000100.0003100.0001830.0000560.0000100.0000772.4617740.0042630.0002350.0005260.0009470.0005640.0004840.0002720.0005210.0001140.0002970.0000723.9013810.1068690.0003100.1350311.3029760.0021740.0000680.0000100.0000682.1065680.0034080.0000151.9695810.0032170.0000150.0000600.0000102.0146570.0032120.0000680.0000100.0000100.0000610.0000100.0001110.0000100.0000690.0000640.0000090.0369030.0458810.0119600.0026110.0002300.0004170.0006340.0000140.0016120.0000120.0001740.0001340.0000100.0001840.0000950.0000100.0000680.0002040.0003520.0003991.3956440.0022460.0284390.3059581.0911160.0016503.0422650.0045711.6066160.0024121.5913610.0024380.0000130.0000100.0000100.0001410.0003030.0003020.0003870.0001130.0000100.0000100.0000100.0000100.0000110.0000120.0000100.0004690.0000100.0000100.0000100.0000100.0000100.0000110.0000100.0000100.0001580.0000100.0001620.0000620.0000120.0000730.0000100.0000640.0000660.0000660.0000100.0011540.0001830.0000600.0000700.0003700.0000340.0191500.0000390.0000750.0000111.9956400.0027890.0000181.0742550.0739600.0001150.0000110.0000780.0000110.0000840.0002630.0011760.0042130.8317040.0015010.0004990.0003693.4338230.0047520.0000170.0000810.0000640.3240650.0005180.0000832.4528172.6553340.0037350.9337940.0013700.0000140.0003930.0010660.0000160.0000100.0685430.0149930.0024170.0000130.0022330.0000130.0000100.0000100.2850450.0003860.0000100.0001670.0000100.0069900.0000190.0000100.0000910.0000100.0002580.0002520.0002700.0002490.0002760.0002630.0000770.0003410.0000100.0000100.0001560.0000100.0000100.0000100.0000100.0001440.0000720.0006670.0001350.0000910.5958490.6586740.0008432.0649780.0027180.0000831.6525370.0021380.0004482.8821970.0075631.6699510.5667250.2775600.0003550.0006600.0008370.0000110.0001950.0005310.0000140.0000100.0008240.0000820.0000100.5988700.0007440.0066840.0001050.0000100.0000110.0268240.1689631.0341510.0012650.0004370.0000100.0107370.0000230.0008180.0005190.0000630.0001130.0001170.0002160.0003620.0003620.0000101.7116900.0022020.0000121.0262090.0012280.0000110.0000110.0000100.0000800.0013510.0000140.0000700.0001470.0000100.0000100.0000100.0004110.0004780.0001150.0000100.0000100.0000100.0000100.0000100.0000100.0000100.0313930.0000460.0000100.0000100.0000110.0000100.0000100.0000100.0000100.0000100.0000100.0000100.0000100.0000100.0000100.0000100.0000100.0008620.0024182.0252090.3724950.0004300.0012661.6148000.0020760.0002600.0000100.0000100.0000101.3917421.6849990.0018920.0006160.0000100.0002000.0002010.0121300.0004130.0002460.0000930.0001250.0000990.0000110.0004420.0003376.0481882.1091740.0023880.0007310.0000140.0001000.0001090.0001660.0001091.7087810.0019390.9471310.0010381.4493542.9040223.8659030.0043830.2709840.0004261.5069300.9494831.3725820.0016150.0000120.0001581.5335190.0023060.0001821.1178040.0013000.0232630.0000350.0000100.5668990.0006110.0000100.0000100.0000100.0000930.0000100.0000100.0000100.0000100.0000100.0002070.0001090.0000101.9975190.0020980.0000122.4481250.0026180.0000772.4090320.0025110.0000130.0013520.0000110.0020900.0000130.0000100.0000100.0021010.0000140.0000110.0001250.0047380.7636500.4641400.7190320.0179661.9311642.8956010.0042480.0264110.0000940.0000100.0000100.0000100.0000100.0000110.0000100.0000110.0000101.1984080.0012160.0000110.1146120.2848050.0002950.0020210.0000130.0000100.0000110.0000130.0052480.0000180.0000100.0000110.0002140.1620820.0001720.0000110.0002050.0010080.0195560.0007250.0001600.0000160.0000770.0000100.0000120.0000210.0000874.2100724.0128070.0042240.0000140.0000100.0000100.0041890.0002870.0003370.0002920.0002900.0010481.8614351.2920691.3222010.0013490.0003340.0003280.0003700.0000100.0002650.0174250.0145920.0000250.0001480.0000100.6844840.0164860.0000250.1574481.8970070.0018100.0000110.0000100.2334150.0002300.0436111.0703950.0684820.9508290.0009040.0000120.0178130.0001430.0000100.0047990.0000140.0000100.0050020.0001580.0000100.0040380.0000130.0280930.0225970.0000350.3768280.1559120.4645730.0718090.0003533.2756071.5259301.3623350.0014520.0009233.5472592.3537515.0516731.7653170.0018690.0001180.0002011.8272582.2744722.9727460.4379610.0014120.0022350.0000700.0006510.0167100.7986160.0007320.0008540.0004070.0004351.8697430.0018780.0000110.0000120.0000120.0000101.7572601.7222473.5146080.0032650.0000130.0000720.0000100.0000101.3876450.0012440.0000130.0000100.0000100.0001930.0000100.0000100.0002780.0000100.0001940.0001950.0000100.0000100.0000100.0000100.0000100.0000220.0000100.0000100.0000100.0000230.0006750.0013250.0003520.0029060.0913370.0013331.8536000.0018270.0005760.0000141.2682552.1893840.0439630.0001680.0000821.0057681.6807390.0015720.0000760.0000680.0000130.0000100.0000110.0000240.0000103.0365510.0026032.1899440.0019310.0000930.0000740.0000101.2952450.0011091.2246770.0010531.4421660.0012290.0001050.0000110.0000100.0000100.0000170.0000170.0000110.0000110.0003720.0000100.0000100.0000100.0000101.6217280.0013650.0002810.0000100.0000100.0000100.0007680.0005280.0005650.0005690.0000120.0000120.0000110.0000110.0001510.0001450.0001080.0000160.0000710.0000730.0004080.0003446.2811636.4354623.3237610.0028730.5078220.0005620.0002030.0002930.0002680.0000110.0003350.0005030.0000270.0000150.0000100.0000100.0000100.0000180.0000130.0005800.0000110.0000120.0346011.5450130.0017880.0000740.0000100.0000110.0000100.0000800.0000120.0000100.0000120.0001350.0000100.0000110.0000100.0000100.0000100.0000920.0000100.0000100.0001080.0000100.0000100.0000740.0000100.0000100.0000100.0000100.0001660.0000100.0000100.0001420.0000150.0002360.0000100.0000504.8725390.0044470.0009620.0010710.0007233.2942095.0586793.2285984.1934071.7147332.2116030.0019531.1118010.0012011.1076165.7365385.9690080.0048320.0002940.0002430.0002690.0004200.0003780.0005250.0005800.0007980.0000700.0027940.5088320.0007060.0005060.0004990.0001440.0002991.1198261.1265491.1278904.4204890.0175970.0016760.0000110.0000100.0000100.0000101.7254110.0013150.0000110.0002650.0003520.0000102.2528611.5611600.0194100.0042010.7016380.0010740.0008980.0005840.0000100.0010260.0011090.0001770.0000110.0001540.0016570.0000110.0350660.0000360.0000100.0004970.0000130.0000100.0000840.0004980.0000100.0000100.0000100.0000100.0000100.0050880.0157910.1053530.0073450.0020380.0000110.0000110.0000100.0009460.0185310.0000250.0003700.0000110.0000130.0000100.0000100.0131860.0000270.0000100.0000110.0000100.0000870.0000100.0000150.0000100.0000100.0002620.0002420.0000120.0000100.0000130.0005200.0000100.0000100.0000110.0000100.0001650.0001571.2034220.0023660.0076400.0187490.0008310.0018540.0079290.0001400.0000950.0001990.0003080.0000701.8324240.0020450.0011726.0224725.0840296.6086270.0049700.0002300.0002670.0005600.0000100.0017190.0000110.0017800.0000111.1732470.0018220.0000120.0026920.0002530.0001240.0002200.0001970.0001350.0002050.0002020.0002030.0001440.0002030.0002160.0000810.0001940.0000850.0003660.0010751.6910170.0713740.0000660.0001640.0011833.2112590.0023120.0000160.0001352.9923570.0023520.0002410.0961241.8089180.0012543.0541582.5434811.8937811.7006911.8062820.6682340.9157253.9554654.4600631.4963890.0017380.0002460.0002510.0002280.0001680.0000100.0000820.0001780.0000100.0000930.0000100.0000100.0000100.0001160.0000100.0000120.0001110.0000100.0004550.0001360.0000110.0000750.0000100.0000120.0000100.0000102.0727920.0015370.0002634.0621023.8716394.1196141.8660580.5781734.0823103.9919964.1845724.0980623.3548681.0628823.2062801.5486160.0015133.2891113.4409440.0023531.5506230.0216110.0001411.3315251.4792580.0013380.0001740.0002440.0002350.0002030.0005160.0001880.0001930.0002650.1146130.0009310.0001550.0002720.0000100.0005860.0001730.0000100.0000100.0000100.0000100.0000100.0000100.0000100.0000100.0000791.7036330.0011142.3036570.0015011.9601420.0012780.0000710.0031170.0014580.0006000.0004930.0001350.0003270.0016520.0015680.0024670.0008240.0000100.0000110.0004190.0004220.0002440.0000100.0000110.0002090.0000950.0001420.0001450.0001410.0003580.0001210.0001860.0001570.0000660.0001480.0003220.0001210.0004500.0011810.0002120.1042740.0506800.0163590.0003100.0000712.0817370.0014410.0000762.3460020.0016132.3790944.3673560.0028742.0976001.9420270.0012912.1662230.0014245.7000841.5623221.6538111.7879491.7372431.6792720.6178250.0004550.0001370.0000100.0003010.0003410.0002360.0000100.7728420.0007430.0003650.0000100.0000720.0000700.0000660.0000112.0115500.0012504.1722432.1936700.0013612.1001492.0545564.1733993.3266273.4588841.7056491.5963110.0012582.3518910.0015140.0002800.0001080.0000100.0001700.0000140.0000830.0000100.0000100.0000101.1512400.0007090.0000143.2882830.0020030.0000110.0000100.0000110.0000110.0001151.6180662.5405640.8100030.0017662.0051490.0012190.0001960.0000310.0000102.1721471.2367042.1754201.3343711.0365792.7492601.5745823.5063373.8261432.4153210.0014520.0000190.0004041.5527680.0009341.3848550.0008330.0000100.0002011.6679000.0010000.0000100.0000100.0000100.0000100.0000100.0001710.0001921.2254961.7016831.5807220.0010520.0013860.3603410.9498420.8667810.0006230.0001180.0032650.0000130.7325420.0004910.0001741.4765280.0009481.3278020.0093160.5052831.4910680.0008851.9817361.2778340.5933370.0005170.0000120.0000280.0000100.0002050.0000180.0001360.0001160.0001200.0001220.0001790.0002080.0001190.0002230.0000670.0001340.0000650.0000690.0000180.0000810.0000570.0000100.0001510.0001280.0000710.0000780.0001350.0000690.0000680.0001030.0000100.0001430.0000640.0143270.0000191.8477660.0011910.0001520.0000100.0001690.0000240.0000220.0000110.9043530.0005240.0000120.0002020.0001490.0000110.0002680.0000100.0000640.0000330.0000100.0000750.0000110.0000110.0001240.0001570.0000700.0000702.0954790.0011870.0000100.0000230.0000110.0000100.0000100.0000100.0000100.0001860.0000150.0002970.0000100.0000110.0000100.0000100.0001510.0001670.0000100.0001470.0000100.0000100.0000100.0006110.0007980.0003710.0029560.0005710.0002521.0992263.2267251.4637750.0013812.1472410.0029480.0003740.0002030.0003820.0005000.0001600.0002270.0007760.0002490.0003780.0003040.0003720.4258780.0005560.0000220.0003420.0003700.0001501.8098900.0011070.0009440.0002610.0002620.0002470.0003344.5227820.6139223.8204473.8909120.0037390.9902891.6296692.7075570.0018930.0043130.3535040.0021180.0000780.0259840.0457860.0001460.0001820.0006550.0002500.0001810.0003640.0002440.0010320.0001270.0008900.0001030.0000110.0000100.0000100.0001410.0012870.0007330.0001990.0000100.0000100.0000100.0000100.0002240.0000100.0000100.0000100.0000100.0000100.0000100.0000100.0000100.0000100.0000110.0000720.0000102.4214990.0012920.0000100.0000910.0000730.0001590.0001750.0000940.0001240.0000770.0001520.0001540.0000810.0002050.0000100.0000440.0005920.0007871.6918640.0038602.7209742.8116811.2316151.8013271.6271270.0027700.0011780.0001010.0000850.0000710.0000100.0026260.0000110.0000100.0000100.0077470.1739760.0001000.0001210.0000110.0000720.0007390.4028120.1251030.0000740.1093980.0036130.2343650.0012580.0077200.1197561.8720130.0110060.0081190.0015210.0063400.0000140.0665880.0001980.0002680.0010181.5535102.1832330.0016314.2264542.1334550.0023600.0327600.0021391.0513371.5220920.3469250.0002740.0004150.0006640.3977140.0007650.0001900.0009550.0005400.0003920.0016780.0032290.0001620.0003162.3619670.0014760.0014990.0000100.0007100.0000120.0000100.0000100.0000100.0000100.0000100.0000100.0019620.0640730.0000420.0000100.0000100.0000100.0011960.0004660.0066060.0068180.0000130.0000100.0000811.9843063.4611320.0019701.7920221.7442183.0402320.0018040.8583420.7370960.0003771.4880630.8501782.4891772.7012580.7324401.1191680.0006210.0001910.0000110.0001450.0000100.0000100.0001980.0002670.0002590.0046590.0001880.0000100.0000100.0000101.2347140.5370120.7031842.7891850.9519461.1771320.4801600.0021790.0013494.2421602.7624960.0013650.0000111.6895201.7910750.0008863.4099222.0482170.0010110.0000102.2421160.0011040.0002840.0000100.0000100.0000110.1949960.0001060.0000120.0000110.0005370.7340270.0003670.0000100.0012180.0002820.0000100.0002860.0000100.0002930.0000101.2707452.6099790.0015481.7805760.0318880.0002420.1952771.0600320.0073610.0006980.0004920.0002600.0002760.0000861.2266691.1937590.0005831.3529500.0007331.9175861.9789241.7502173.5230840.0019630.0002843.0690273.1675271.5049182.8995161.6993340.0038750.0004401.5424010.0007430.0005260.0000860.0000120.0000120.0003880.0000130.0000110.0000210.0038940.0003450.6917610.5837830.0030730.0000130.0004280.0403370.0628240.0000401.5692600.0019240.0210690.0042650.2030660.0001540.0008270.6397340.0319560.9246881.9878680.0009420.0434780.0271890.6481640.0028542.8581891.7399510.1343940.0003420.0000790.0002750.0000110.0365850.3611930.0003360.0001312.1657530.0014590.0058870.0005040.0004230.0015710.0659420.0011630.0000750.0003740.0001650.0000100.0003580.0006212.0996440.0009830.0000740.0000100.0001270.0000770.0002410.0000700.0004790.0001300.0000680.0001320.0001340.0002720.0004170.0000100.0000100.0044020.0002350.0001360.0001420.0001390.0000810.0000990.0001580.0000970.0000120.0000100.0000100.0008930.0000100.0000100.0048930.0000130.0000100.0000100.0000100.0000100.0000100.0000110.0045170.0000120.0000100.0340530.0000250.0000100.0000100.0014360.0000100.0000100.0002370.0001780.0002060.0000110.0000110.0000110.0000110.0004370.0000100.0003660.0000110.0004470.0000100.0000100.0000120.0000110.0000100.0000100.0000150.0000100.0004730.0000100.0010160.0000740.0000100.0000100.0000100.0003740.0011020.0000110.0000101.5677880.0007080.0010570.0001720.0016080.0002790.0004610.0002230.0003070.0002110.0002350.0004440.0003590.4459171.8089106.5576102.2943570.5427170.0007680.0000100.0017850.0008470.0004880.0006230.0006920.0002640.0002120.0000100.9292500.0008390.0001341.5255040.0006800.0035220.0000120.0000100.0001530.0000630.8679920.0003970.4085550.0191101.1247230.0005710.0000620.0000684.0895610.0021501.3016200.0006340.2444250.0002510.0000700.0000910.0001750.0000210.0019670.0003230.0000120.0001220.0000940.0003600.0000100.0001342.2200920.0009710.0000950.0000101.0524270.0004650.0001600.0000100.0000102.0243380.0010331.0645640.0007520.0000641.7272810.0007540.0000101.3971990.0006120.0002820.0000620.0003871.3389820.2815330.0013100.0001311.5407950.0007280.0000720.5563260.0002481.3961980.0006080.6170760.0002730.0004560.0000665.1087320.0034092.6882511.8085900.0007800.3098460.0834890.0020560.2213710.0346120.2301130.0001990.0186950.0072900.0526260.2899460.3563870.1472690.0015720.0000120.9564791.6673970.0017270.7909760.0015490.0013742.8489430.0125320.2835860.0016320.0001230.0003250.0007580.0002060.0000110.0001410.0001330.0000770.0001290.0001590.0000950.0002900.0001350.0001350.0000690.0002160.0001380.0002320.0000740.0001930.0003550.0000100.0000100.0003820.0002990.0001410.0000100.0002830.0000100.0002700.0001370.000010

*******************************************
EVALUATING PIPELINE 
Pipeline directory: /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_d00ea8be_2020-02-07_16-02-58gxuqrd5c/
With following parameter combination: {'batch_size_seq_length': 1, 'lr': 1e-05, 'lr_type': 'cosine'}
EVALUATION OF CHECKPOINT /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_d00ea8be_2020-02-07_16-02-58gxuqrd5c/outputs/checkpoint-3
-------------------------------------------------------------
|           |   agree   | disagree  |  discuss  | unrelated |
-------------------------------------------------------------
|   agree   |    561    |    51     |    152    |     2     |
-------------------------------------------------------------
| disagree  |    26     |    64     |    59     |     6     |
-------------------------------------------------------------
|  discuss  |    168    |    41     |   1564    |    28     |
-------------------------------------------------------------
| unrelated |     7     |     6     |    25     |   6862    |
-------------------------------------------------------------
Score: 7179.25 out of 7516.5	(95.51320428390873%)
Accuracy: 0.9406568281022657
F1 overall: 0.7503407961162147
F1 per class: [0.7342931937172775, 0.4037854889589905, 0.8686475978894751, 0.9946369038991159]
*******************************************


*******************************************
EVALUATING PIPELINE 
{'batch_size_seq_length': 2, 'lr': 1e-05, 'lr_type': 'linear'}
INFO:__main__:Creating features from dataset file at /home/ubuntu/fnd_implementation/data/processed
  0%|                                                  | 0/9622 [00:00<?, ?it/s]  0%|                                        | 1/9622 [00:02<7:23:44,  2.77s/it] 21%|███████▋                             | 2001/9622 [00:03<4:06:03,  1.94s/it] 52%|███████████████████▏                 | 5001/9622 [00:03<1:44:26,  1.36s/it] 78%|██████████████████████████████▍        | 7501/9622 [00:03<33:33,  1.05it/s]100%|█████████████████████████████████████| 9622/9622 [00:03<00:00, 2526.50it/s]
  ******************************************* 
              Running Evaluation                
  *******************************************
 
  Length dataset evaluation: 9622
  Length dataloader evaluation: 1203
  Number of epochs: 3
  Batch size: 8
  ******************************************* 
 
['/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_c8cc1a0a_2020-02-07_13-58-02figzuq9u/outputs/checkpoint-3']
INFO:__main__:Evaluate the following checkpoints: ['/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_c8cc1a0a_2020-02-07_13-58-02figzuq9u/outputs/checkpoint-3']
INFO:transformers.configuration_utils:loading configuration file /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_c8cc1a0a_2020-02-07_13-58-02figzuq9u/outputs/checkpoint-3/config.json
INFO:transformers.configuration_utils:Model config {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 28996
}

INFO:transformers.modeling_utils:loading weights file /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_c8cc1a0a_2020-02-07_13-58-02figzuq9u/outputs/checkpoint-3/pytorch_model.bin
HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=1203.0, style=ProgressStyle(description_width='initial')), HTML(value='')))
0.0002300.0002700.9851440.3284130.0821390.0164630.0027880.0004700.0001130.0000440.0000660.0000990.7934800.0613541.1268240.0751490.0047340.0003050.0001240.0000440.0002140.0000440.9729170.0430540.0024810.9341260.0359560.0013590.7735350.0267520.0010780.0038570.0002520.0000530.0079040.0003350.0000410.0000500.0000460.0000490.0001880.1301640.0031400.0002480.3738680.0083900.0002370.0044260.0044730.0001530.0001120.0000730.0000410.0000310.0556840.0012550.0000540.0000310.9093570.0154440.0003700.0000360.0000750.0000320.0000300.0000290.0004950.0018680.0000640.0000340.0003040.0000650.0001210.0000640.0002710.0042731.2935200.4007670.0051690.0028620.0004700.0003660.0007820.0000540.0000291.7122131.1482380.5782350.0328860.0004720.0000371.2092830.0132983.4104990.0363190.0275130.0895320.0012890.0000490.0000300.5829780.0058000.0000890.0002110.0000350.1968200.0018860.0000490.0000320.0000280.0000330.0000590.0000940.0000940.0000300.0001530.8332290.0071880.0000930.0000660.0000280.0052090.0000690.0000260.0002900.0000390.0001270.0000330.0005150.0001010.0007670.0000352.8936180.7683200.0057630.0000710.0037220.9190940.0070290.0000820.0000310.0000290.0000280.0000270.0004800.0010360.0003351.0102161.0010980.0067461.0682031.0181390.0766680.0350150.0003020.0000290.0000270.0000270.0000300.0002610.0003130.7081440.0044310.0004670.0002160.8106280.0052050.0002280.0000900.0000820.0113090.0000940.0000270.0000260.0000270.0000270.0000270.0000280.0000280.0000300.0000280.0000420.0000260.0001250.0000280.0000260.0000760.0000280.0000280.0000260.0000270.0000650.0005390.0000780.0001930.0821520.0004640.0000440.0008420.0000350.0000330.0000320.0000290.0000290.0000330.0001170.0001420.0022990.0005440.0001020.2847230.9017570.8085360.0038740.0000450.0000320.0000920.0000280.0002290.0000340.0000460.0000370.0008810.0002690.0000841.7010140.0076130.0000960.0000280.0000320.0000290.0000350.0001520.0004570.4598060.0020260.1297950.0097830.0001790.0021320.0000720.2828172.1138430.0094750.2975640.0179810.0011460.0000320.0002500.0000300.0006600.0001470.0000310.0000280.0001160.0000850.0002190.0001220.0000700.0001750.0000640.0000930.9230030.0035802.0602070.1160800.0005060.5861570.5663010.9790420.0036570.0004670.5823731.6253540.0061980.6485700.0025500.0000881.8980720.2094230.8091010.0037010.0001160.0000580.0000270.0000620.0000680.0000790.1028990.9185680.8157520.0029340.8070500.0273900.0001870.0001180.0001670.0005040.0000381.0026390.0037460.0005440.0006900.0012740.0003070.7551790.0164511.3067650.0043300.0000791.0787250.1167500.0004340.0000550.5366730.0017580.0000650.0001080.0000880.0000550.2751741.3303190.0046180.0004830.0026990.0005050.0001310.0000790.0001900.0005660.1085900.0007320.0614811.0048110.6912360.0245110.0001010.0000630.0013820.0003970.0000290.0000320.0000320.0008420.0000300.0004790.0000270.0000290.0000920.0001490.0000660.0000620.0001080.0002750.0001720.1595560.0558650.0002530.7747060.0021910.3095010.0008880.0000760.0001250.3521330.9003680.0050660.7259920.0021130.1906870.0007371.7912380.6351270.0017390.0006910.0000530.0054480.1483520.4035910.0011000.4187040.0011500.0006610.0000430.0000750.0002770.0002670.0002780.0001140.0000270.0001380.0000300.0001270.0006700.0005380.0287310.0242980.0002520.0257401.0957230.2721070.1052830.0005300.0006160.0003270.0000320.0004260.4056360.0635620.0002570.0846851.4426610.0037310.0072720.0005300.0003080.0001520.0007770.0034011.4579110.4914650.0011950.0000360.0001300.0000980.0001410.0000290.0003400.0000760.0000310.0000270.0000270.5139080.0012150.0000310.0000270.0000290.0000280.0000270.0000300.1395060.7088510.2038960.0547380.0004720.0000400.7909570.6526710.4893030.0014580.0006310.0003160.0001690.0178022.4606591.6504500.0038840.0005580.0006180.0004460.0026200.0020050.4054890.0011960.0949340.0142090.0001390.0332570.0007550.1459090.0003460.0382170.0001090.0000650.0000310.0000270.0001670.0000690.3895080.9800410.0021750.9472770.0025570.0005010.0000310.0005370.0000300.8639290.2081120.6638532.0505060.5322050.0011460.0000310.0000290.0000310.0615000.0001500.0316430.0005410.0000280.0000270.0003490.0000290.0004280.0000330.0004820.0016140.0000580.0000320.0000352.7217112.1831260.0042830.0014800.0004180.0005490.4224381.0825950.0025800.0011280.0003620.0129910.0001130.1759700.0238901.3106150.0025150.2226020.2743771.8185890.7868730.0159660.0001130.0020270.0035520.0000830.0370330.1137650.6883170.9380590.1454723.6606570.4372511.1476241.5712920.0067070.0034241.4481060.1023220.0150650.0258210.3129790.0008330.0003410.9773930.0017890.0000351.8096741.9923670.0036230.0000370.8077990.0014630.0001300.0000280.0002080.0002390.0000290.0000270.0019800.0000330.0002200.0021580.0006850.0006750.0003140.0004491.9569201.3337910.7893760.3237680.0006770.0000350.0000802.8310830.9198220.0016790.0000650.5527241.0146760.6085180.0011300.0000630.0000430.0000340.0004340.0000340.4998080.0011890.0000360.0015420.0021240.0012110.0000590.0001580.0001200.0001900.0001612.3875392.5982610.0046280.0003070.0005970.0003550.0003830.0000610.0000330.0000350.0007160.2890110.1773400.0003590.0002990.0001540.0000320.0000870.0000310.0000300.0001040.0001040.0000410.0000640.0000260.0001300.0000300.0001070.0001362.3072970.2896930.1325293.6090172.8634411.2032400.2738420.1737035.1656260.0083870.0004510.0005660.0011730.0003060.0003170.0003380.0001760.0004051.5570733.6763960.0061050.0000380.2951890.0004740.0002660.4053170.4737800.0080640.0011070.0002980.0008980.0001960.0503180.0041630.0000360.0002760.0000670.0002700.0000280.0000270.2092340.9789270.0043060.0000340.0006120.0002190.0001440.0000270.0017270.0000310.0000400.0000440.0000330.0006680.0000290.0002740.0000280.0000450.0298790.1133600.0295180.0083310.0112510.0002050.0002250.2602582.4504545.8343580.0088440.0006430.0005020.0011180.5966080.0010770.0007270.0001710.0001970.0335090.0003300.0003580.0001490.0001950.9381490.0013810.0004700.9416640.0106560.0834000.8440370.0692311.4436510.7435680.6617141.8710960.3055450.0012570.0002950.0001240.0001470.0000650.0000260.0000750.0000290.0000730.0010680.0000830.0002370.0000310.9788270.2720832.3387730.7710711.8252901.9901340.9476011.2211791.1908271.4973791.0494690.8879661.8414590.0027930.0003570.0004370.0003880.0371190.0003230.0001900.0000950.0000310.0000280.0000280.0000670.4009040.8665450.7777580.0011690.5447310.5443001.8055480.4122370.4436970.0010970.0007030.0000290.0003520.0002190.0006620.0010920.0002700.0003390.0004640.0017410.2799570.2527870.9669830.0013581.0815252.7932730.9882230.9005061.0618392.0846350.0032530.2678830.0012830.0000960.0040880.0002520.2475220.0006470.0000950.0000641.0736483.0281540.9785473.9118683.3498372.5808200.0469900.0002220.0000650.0002230.0000630.0000300.3977911.5418850.0018990.0000400.0001440.1107560.0118611.0771790.7515810.6389900.5156770.6036181.1084130.9892700.3424710.0125260.4171100.3273050.0007750.4713870.0005930.0000280.0001860.4300431.3820220.0022440.0006280.0056110.0003040.0002010.0001600.2716491.7245570.9935490.5831880.6270280.0009080.0002190.0008240.0001450.0001720.0002800.0003600.0001300.0000860.0002000.0001030.0001480.0001050.0001210.0001570.0000810.1557550.0002280.0001740.0000830.0172850.7814340.0009250.0003930.0001640.0000620.0001430.0005440.0000860.0004050.9636210.0011190.0001060.0000290.0000350.0001960.0002030.0000380.0001110.0001330.0001230.0000280.0012600.0014530.0006462.0004030.0065640.0045360.0013180.0005670.0002140.2001900.0151701.1655080.0015300.0029590.0006860.0003470.0007590.0006600.0218710.3781080.0163190.2715360.0037490.3300581.3276000.1738991.0578420.7259460.7982971.0819751.0821930.0012000.0001160.0029880.0000950.0000310.0061470.0000330.0000270.0000320.0001830.0000310.0000831.3759120.0015680.0002100.0004480.0002590.0002620.0003380.0000330.0014860.7147114.2142023.9752681.0360800.0013320.0001130.4041490.0004500.0544500.0603430.0002180.0023610.3124430.2266220.1777140.0045830.7797110.0148650.0027080.0447200.0004060.9063851.0993023.0620990.0090680.6193680.0080980.0004530.0046560.0037880.0309620.0016140.0610920.0541890.0011220.0006030.0000310.0000280.0000270.0024210.4387520.0004690.0011490.3572880.0021550.0000640.4644111.0488042.0500850.0042000.0011830.0040830.5575100.0034600.0001350.0001190.0000280.0002910.0011140.0001520.0000290.0019670.0232730.4467600.1992522.0619890.9712210.9923050.9239952.9654630.0029271.0594980.0013100.0000331.0729960.0010980.0004980.0000290.0890330.0003840.0015020.2429471.1251311.0502280.0456900.7423400.0015460.0004000.6519070.0609400.8465360.0026871.7202930.0020113.4419682.0457870.9921630.5193810.0005900.0000870.0001930.0000430.0001760.4405000.7064390.0008470.1722540.6483570.0030860.6368710.0942090.0014020.2094000.0014131.0534021.5967730.4546910.0006480.0001730.0969150.0002941.1234480.0143310.0005580.4337600.0007750.0001300.0007501.0467520.0010230.0001330.0001350.0001560.0001010.0001720.0001250.0001710.0003160.0002150.0001250.0001790.0000390.0000830.0000300.0403360.0000690.0000300.0000460.0043270.1082840.0001260.0014610.0000310.0002720.0036700.0000330.0002020.0004170.0001300.0000290.0000360.0000370.0000390.0004720.0016170.0000280.0000770.0021630.1265900.0002570.0003830.0004200.0002470.0002170.0003510.5377092.8114280.3643860.0031030.0014410.0020370.0002750.0826030.0002060.0017850.0763120.6601260.0029270.0004400.1051050.0070361.1361880.0155240.7428890.0008470.0005090.0002440.0002300.0001890.0003241.0299080.0009700.0025880.0003900.0000270.8753300.4737280.7025830.0006410.0004450.0007150.0284910.0875490.3854950.0004450.0092590.1046810.1292870.0006131.6676280.8670410.3748240.0068250.0083710.1844240.0078650.6455530.6601250.0109670.6956240.5091790.0042151.0401150.2641070.0009730.0003930.0000740.0001220.0003770.1623140.0003380.0003240.0018900.0002060.0010060.0001710.0002600.0001470.0001610.000126

*******************************************
EVALUATING PIPELINE 
Pipeline directory: /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_c8cc1a0a_2020-02-07_13-58-02figzuq9u/
With following parameter combination: {'batch_size_seq_length': 2, 'lr': 1e-05, 'lr_type': 'linear'}
EVALUATION OF CHECKPOINT /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_c8cc1a0a_2020-02-07_13-58-02figzuq9u/outputs/checkpoint-3
-------------------------------------------------------------
|           |   agree   | disagree  |  discuss  | unrelated |
-------------------------------------------------------------
|   agree   |    573    |    55     |    124    |     3     |
-------------------------------------------------------------
| disagree  |    24     |    51     |    33     |     2     |
-------------------------------------------------------------
|  discuss  |    159    |    55     |   1625    |    35     |
-------------------------------------------------------------
| unrelated |     6     |     1     |    18     |   6858    |
-------------------------------------------------------------
Score: 7218.5 out of 7516.5	(96.03538881128185%)
Accuracy: 0.9464768239451258
F1 overall: 0.7525790434531425
F1 per class: [0.7554383651944627, 0.375, 0.884594447468699, 0.9952833611494086]
*******************************************


*******************************************
EVALUATING PIPELINE 
{'batch_size_seq_length': 3, 'lr': 1e-05, 'lr_type': 'cosine'}
INFO:__main__:Creating features from dataset file at /home/ubuntu/fnd_implementation/data/processed
  0%|                                                  | 0/9622 [00:00<?, ?it/s]  0%|                                        | 1/9622 [00:02<6:32:24,  2.45s/it]  5%|█▉                                    | 501/9622 [00:02<4:20:25,  1.71s/it] 21%|███████▋                             | 2001/9622 [00:03<2:32:19,  1.20s/it] 52%|███████████████████▏                 | 5001/9622 [00:03<1:04:39,  1.19it/s] 78%|██████████████████████████████▍        | 7501/9622 [00:03<20:46,  1.70it/s]100%|█████████████████████████████████████| 9622/9622 [00:03<00:00, 2587.09it/s]
  ******************************************* 
              Running Evaluation                
  *******************************************
 
  Length dataset evaluation: 9622
  Length dataloader evaluation: 602
  Number of epochs: 3
  Batch size: 16
  ******************************************* 
 
['/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_d4e06774_2020-02-07_17-43-15295o0x47/outputs/checkpoint-3']
INFO:__main__:Evaluate the following checkpoints: ['/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_d4e06774_2020-02-07_17-43-15295o0x47/outputs/checkpoint-3']
INFO:transformers.configuration_utils:loading configuration file /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_d4e06774_2020-02-07_17-43-15295o0x47/outputs/checkpoint-3/config.json
INFO:transformers.configuration_utils:Model config {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 28996
}

INFO:transformers.modeling_utils:loading weights file /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_d4e06774_2020-02-07_17-43-15295o0x47/outputs/checkpoint-3/pytorch_model.bin
HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=602.0, style=ProgressStyle(description_width='initial')), HTML(value='')))
0.0008430.0062540.0032760.0012610.0005020.0004180.3486820.5133650.0643540.0074560.0034410.0016580.0723870.0058550.0006720.0006470.0002400.0002200.0002120.0002090.0005170.0002910.0004100.0008340.0121740.0009010.0001600.2708380.0098090.0011160.0003330.0002230.0002110.7876130.0233270.0084920.1897110.0054631.1480620.0296120.0011970.0006100.7264030.9492010.0224510.5327051.5130280.0492960.1353490.0029070.0004720.0001790.0005350.0001170.0001250.0002040.0003870.0016670.0316920.0007700.0075210.0002470.0008660.0005790.0004390.1921640.5097720.0077080.3538070.0261200.0004740.0001070.0252240.1827230.0156370.7627340.0855430.0013240.0001400.0010660.0060190.0003420.0118060.0015760.0004450.2813730.0033620.0001290.0000820.0000860.0000940.0001720.0000910.0000980.0001000.0002200.0102750.0011800.0001440.0013090.0001000.0000870.0006560.0004640.0005740.1152690.0448590.0005700.0002820.0001270.1099090.0078230.5071800.0048920.0001260.0000840.0021000.0547150.0526430.0008650.0892020.7580700.9295970.0094040.0007280.0006210.0001050.0005190.0088490.0995240.0021230.3344530.8295480.3515150.6845790.0055910.6392590.3387320.0277770.3944100.0035130.0003930.0002350.0003510.6282710.3050840.3532890.0035050.0018040.4447690.0183490.0040270.0667570.9424290.0065250.5854750.0040810.3128380.0022420.0023240.1877010.0029280.1700790.0014760.0029440.8338221.4149800.7414620.0046640.0024360.0001290.0011340.0001840.0001220.0009070.0005380.0005660.0302500.0024220.1735310.2957910.0020911.9725901.3050990.0383180.0244340.0349520.0045920.2249250.1242770.3518400.0095250.0008190.0013130.0005350.0005780.0005470.2473120.0127990.0866710.2705070.0026340.0006240.2710380.1025820.8817300.1997350.0034550.0012890.0548250.0009930.0004630.0004620.0008640.0002200.0000960.3932500.0019120.0001090.0000890.9753370.1529300.0013500.4614870.0454360.1086300.0013861.7716350.0100450.0015420.0746360.2576190.5749240.3215840.2420190.0155640.0002890.0001110.0001980.4194930.3629040.0032220.0009520.4054470.7081520.7686830.0033180.0001280.0593470.1989050.0009570.0003990.0013950.0023570.0002981.1368800.8073250.1081740.1984210.2666260.0024040.0200230.2501570.2778210.1124820.1692260.0058950.0073460.0015460.2762890.4479421.4482650.2446970.0029610.0028670.0032490.0033830.1236290.0005600.3568340.0014770.0046890.0102510.0081060.0001900.4575510.0104980.0575970.0016250.6870580.3380550.0013850.8688800.3926740.2583320.6638370.0026010.0001700.0014670.2319900.0500040.0150930.0706210.0310691.0923201.4309860.0067880.0021870.1478690.0026740.4626470.0018160.0002380.0001880.0003130.0002480.0001790.0004480.0010230.9303381.6507951.8595830.2397960.0062130.0018150.0013960.0012150.0773370.7758930.1222780.0006110.0016760.0162450.0055150.0102590.0030650.0003150.0003460.0001070.3314100.0095250.0009930.0001390.0001440.0675700.0009750.0004430.0001220.0777570.1837410.0017150.8567513.3403920.0111540.0053460.1391330.0041900.0013310.0015300.0008860.3771990.3560480.4842560.1693301.6751851.0639000.5566260.0023570.0006380.0003490.0002750.1628360.0006041.1865161.3558602.6699210.6759280.6032840.7384910.8103340.0035100.2478720.0018560.0003560.0001550.1681430.6235920.0074770.4571030.0976280.0029960.0015230.0019790.0007990.0019780.0254730.6364040.4104441.6253030.7661810.8816160.0084590.0007680.1349950.0013590.4680141.8288651.3682380.6227430.0017880.0003420.2086090.6462360.0119170.2026120.3969860.5964710.1687730.0144360.2960120.2813580.2726700.0011280.7013540.0350010.0591390.0010580.5139150.8653370.3957530.0014230.0007170.0009180.0005230.0004330.0008080.0007370.0044070.0005420.0004590.0083580.0115650.0004640.0005350.1300830.0004580.0001080.0011650.0003410.0007140.0016350.0063471.7478910.2330360.0034100.0067910.0097320.0027300.0015450.0020780.0022180.0036580.0107580.8222670.6883030.8436770.0020470.0005340.0003100.0001530.0002200.0002290.3244520.0039790.0010880.0003750.3538003.7821780.4380650.0021400.0019490.1587940.1280110.1317920.5092620.3979340.0853691.1696341.6059390.0650000.0031650.0052280.0130290.0062930.0011660.0001090.0775760.0015010.0849811.0705790.9965630.3828701.2450310.1716850.0015630.2615790.0009960.5485660.8342210.9748850.3269290.5757900.2977340.2809640.1599780.0043600.0010560.9318470.4643240.1840220.3764160.4870721.3206260.9837630.9433970.0515780.0010650.0032230.1461160.4049910.0398030.0035310.2148480.2505851.1028290.0037200.4179350.8588470.7580830.0144300.3883430.0012130.0007650.0007810.0006300.0011960.0006140.0003590.0052700.0001020.0080240.1364320.0015280.0010360.0007090.0010260.0001430.0000860.0016030.0002720.0527460.0008920.0017750.0014912.8395400.2859850.0025350.0489550.0654230.0116430.0249340.0157890.4965520.2942250.0017700.0006870.8539180.0026740.0002040.1010980.0014090.0324400.0962400.0771930.0188770.0849180.9127590.1218130.0846840.1853890.2393550.4209210.3938650.0804010.0013470.0007100.0033810.0012220.0008540.0012480.0011140.000677

*******************************************
EVALUATING PIPELINE 
Pipeline directory: /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_d4e06774_2020-02-07_17-43-15295o0x47/
With following parameter combination: {'batch_size_seq_length': 3, 'lr': 1e-05, 'lr_type': 'cosine'}
EVALUATION OF CHECKPOINT /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_d4e06774_2020-02-07_17-43-15295o0x47/outputs/checkpoint-3
-------------------------------------------------------------
|           |   agree   | disagree  |  discuss  | unrelated |
-------------------------------------------------------------
|   agree   |    577    |    48     |    158    |     3     |
-------------------------------------------------------------
| disagree  |    14     |    51     |    16     |     0     |
-------------------------------------------------------------
|  discuss  |    169    |    62     |   1601    |    19     |
-------------------------------------------------------------
| unrelated |     2     |     1     |    25     |   6876    |
-------------------------------------------------------------
Score: 7214.25 out of 7516.5	(95.97884653761724%)
Accuracy: 0.9462689669507379
F1 overall: 0.7596571134338485
F1 per class: [0.7454780361757106, 0.41975308641975306, 0.8770199945220487, 0.9963773366178814]
*******************************************


*******************************************
EVALUATING PIPELINE 
{'batch_size_seq_length': 2, 'lr': 1e-05, 'lr_type': 'constant'}
INFO:__main__:Creating features from dataset file at /home/ubuntu/fnd_implementation/data/processed
  0%|                                                  | 0/9622 [00:00<?, ?it/s]  0%|                                        | 1/9622 [00:02<7:31:18,  2.81s/it] 21%|███████▋                             | 2001/9622 [00:03<4:10:15,  1.97s/it] 78%|██████████████████████████████▍        | 7501/9622 [00:03<48:45,  1.38s/it]100%|█████████████████████████████████████| 9622/9622 [00:03<00:00, 2545.78it/s]
  ******************************************* 
              Running Evaluation                
  *******************************************
 
  Length dataset evaluation: 9622
  Length dataloader evaluation: 1203
  Number of epochs: 3
  Batch size: 8
  ******************************************* 
 
['/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_405507e0_2020-02-07_09-08-120r2sp91s/outputs/checkpoint-3']
INFO:__main__:Evaluate the following checkpoints: ['/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_405507e0_2020-02-07_09-08-120r2sp91s/outputs/checkpoint-3']
INFO:transformers.configuration_utils:loading configuration file /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_405507e0_2020-02-07_09-08-120r2sp91s/outputs/checkpoint-3/config.json
INFO:transformers.configuration_utils:Model config {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 28996
}

INFO:transformers.modeling_utils:loading weights file /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_405507e0_2020-02-07_09-08-120r2sp91s/outputs/checkpoint-3/pytorch_model.bin
HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=1203.0, style=ProgressStyle(description_width='initial')), HTML(value='')))
0.0003610.0003870.0002460.0001030.0000590.0000340.0000570.0000410.0001540.0000380.0001190.0001680.4444730.0345540.7811630.0520990.0033060.0002150.0003320.0000450.0012550.0000790.0049700.0004880.0007780.9691040.0372920.0014000.2930630.0104020.0005860.0000530.0001170.0000410.0001990.0000830.0000230.0000240.0000210.0000220.0007800.0000680.0000270.0001000.0000430.0000310.0000590.0023940.0022680.0000990.0000600.0005380.0000420.0000280.0732500.8232870.0147210.0028420.5984740.0101620.0003160.0000230.0001410.0000210.0000190.0000180.0010080.0103540.0001720.0000240.0001650.0001030.0002130.0000260.0000280.8550431.4271400.5095200.0065510.0001030.0003390.0003450.0002850.0000290.0000351.2158361.8400160.9382430.5006180.0058390.0000831.1337740.0125262.7521720.0293060.0037200.3066730.0055450.0000760.0000230.0003690.0000260.0000210.0000220.0000230.0001430.0000230.0000310.0000210.0000200.0000230.0001650.0003380.0001650.0000200.0007670.8210770.0132920.0001340.0001330.0000320.8077630.0066390.0000721.1557520.0092670.0004150.0000240.0640670.0015470.4785400.0036710.0079880.7313180.0054770.0000600.0015100.5260190.0041420.0000490.0000210.0000350.0000210.0000200.6541800.5865040.0040490.9073000.0286110.0002130.7101400.9261160.0067920.0121200.0002150.0000200.0000190.0000180.0000190.5859581.1257630.8393630.0053110.0001180.0005570.3639200.0025600.0003360.0001660.0001710.5112160.0030090.0000360.0000190.0000180.0000180.0000190.0000180.0000200.0000190.0000190.0001960.0000190.0006710.0000220.0000200.0000870.0000190.0000190.0000190.0000190.0001900.0257580.0001530.0016460.0004280.0000270.0000210.0003810.0000270.0000260.0000250.0000190.0000210.0000200.0077020.3482230.7535790.6680510.5760640.9889140.7878760.6626380.0036640.0000360.0000210.0004440.0000220.0000550.0000190.0002700.0000240.0350090.1150090.0008481.0585670.0049640.0002510.0000220.0000270.0000200.0003950.0001770.0015050.0005380.0000410.0012890.0010260.0002610.0000280.0000410.0054211.5569301.7036631.7040021.3477820.0061750.0000440.0003820.0000200.0007720.0005370.0000200.0000210.0005420.0003640.0006550.0008210.0005800.0009810.0002150.0005430.8412370.0033021.6819470.0079980.0001730.5033010.7167572.6047150.0096670.0004230.5068240.6389060.0024660.0009510.0003360.0005550.9544650.0039910.0005690.0009940.0005920.0001100.0000180.0000930.0002110.0004640.6659761.3392520.6839200.0045980.7791540.0189320.0002600.0002630.0003350.0057210.0000460.2798420.6238320.0058610.0052620.0083940.0005943.0976250.9867252.2300780.0074010.0001150.9173790.8078870.0026840.0001030.9309270.0030790.0000960.0007130.0001010.0000881.4261522.1444230.0074240.0012170.5653520.0339980.0003780.0001372.3938423.8545060.7911490.8558780.7337520.3387410.7344700.2249810.0006890.0006892.1043471.5610980.0046160.0000320.0000250.0007150.0000210.0003380.0000220.0000200.0001490.0002170.0003910.0001250.0008520.0009660.0002930.0011460.0006470.0002020.8240120.0023180.5765260.0016210.0001310.0005051.4780926.3720884.0169431.4682510.0044160.4918811.0313144.2004990.4506430.0012420.0026070.0000361.0378730.3837840.6355580.0017021.4001540.0037250.2336370.0006300.0001980.0006610.0008320.0008100.0006730.0000200.0006390.0000210.0003020.0005610.0005291.3467741.1534780.0032090.8058460.5494750.7719311.2716420.0035060.0002780.0004050.0000230.0006340.8558040.7291130.0021490.6972191.5169000.0040360.0049230.0004990.0005370.0003690.0010910.0002620.0850890.0009010.0000200.0000220.0004690.0003840.0006230.0000201.7839770.6816080.0016080.0000220.0000190.0828400.0002110.0000210.0000190.0000190.0000190.0000180.0000190.0005550.9948590.0147880.0028710.7964070.0018090.7185560.5938250.0013460.0003440.0070010.0229570.0004890.0014161.7452490.6328300.0015731.4149520.0043710.0624620.4865681.0353111.2059460.5307641.2647540.6290330.0015200.6066490.6470160.0022260.0000260.0259270.0000740.0006100.0000220.0000190.0002470.0002510.6713110.9256600.0022120.9314860.2403770.0007250.0000210.0002330.0000420.1867340.7347900.0146750.8830080.0030060.0002020.0000190.0000190.0000200.7890030.0016061.5328680.7770340.0015760.0000260.0019520.0000250.0006410.0000240.0006960.0276910.0000840.0000310.0000230.5700151.0657510.0020960.0006330.0017490.0004670.3730420.8796920.0024910.0013870.0065830.0139870.0002520.6093520.0016240.9668060.0018570.0181300.0005380.1673990.6204670.0021640.0002800.0005540.0012520.0003730.0004960.7831021.3633352.2377851.0111123.4766950.0085670.4078370.0054190.0549890.0005810.0002710.0004360.0013610.0009280.0082940.0015280.0021830.8345780.0015260.0000231.3955592.3664540.0043820.0000270.6019390.0010890.0002270.0000180.0002540.0005100.0000200.0000180.9259140.0016400.0003240.3532090.0194060.0706820.0003190.0004281.9851901.4765570.7915770.7779980.0014420.0000220.0000242.1651460.8913240.0021210.0002050.6964910.8578940.6135260.0013040.0000290.0000220.0000190.0005260.0000220.4979080.0011510.0000220.0051970.0514100.0029190.0000380.0002630.0005770.0001680.0008164.0272214.5647860.0099070.0007330.0003000.0002770.0002060.0000860.0000210.0000280.0002950.0016730.0034310.0001420.0015620.0002820.0000240.0001450.0000190.0000210.0001470.0002290.0000200.0001500.0000190.0002330.0000370.0002110.0002602.2216215.0909063.0392433.0931111.4625962.6887890.3938870.7269990.7742720.0396490.1765190.0018800.0032260.0765130.7445032.3598740.8124492.2556180.0148742.3445400.0051990.0000260.6525610.0010050.0016920.0577220.0402060.0023860.0021560.0006750.0006890.0004120.0145260.0008650.0000240.0003780.0001470.0003780.0000220.0000191.7326195.1274331.7515980.0025910.0002310.0001180.0002960.0000200.7459840.0011080.0003510.0000200.0000190.0002650.0000200.0001380.0000210.0000330.0008620.3186480.3335590.5909121.7756490.0636102.1398130.7406722.8552306.2493250.0092310.0006470.0002790.0002930.6349220.0012060.0016540.0007280.0006590.4837330.0013230.0008650.0005640.0006190.6008590.2769930.1002070.7358810.0012721.2789491.1163210.2452891.2857080.0033270.5638290.5494703.0507360.0051330.0006890.0002520.3647790.0104920.0000360.7887520.0010850.4060631.2931170.0019220.0004390.0000200.9615701.7428863.7122211.3762534.0990793.7466410.9105750.0119020.3896440.1572830.0065810.7813211.5172020.0025610.0051980.0372880.0094250.0150290.0008690.0011250.0004320.0000200.0000180.0000180.0001020.1519150.6379890.0117270.0005800.7688730.8250922.2649190.0272600.0009980.0006110.0008580.0000220.0004310.0006110.0009080.0003940.0002650.0007870.0005380.0008570.2887560.0266180.8421750.0013021.0089992.8778880.8311960.7904260.8634521.7131400.0036520.7684460.0022020.0001900.0005460.0002220.0270790.0002700.0002910.0001160.7415140.9849670.5904191.0924272.1271202.0717170.0673780.0005050.0001650.0002720.0001370.0000190.8532821.1341810.0014030.0000230.0003075.3543580.9121990.8913050.7313850.2814210.5022930.5610470.4963360.0181040.0044410.0004430.7221390.7071480.0032610.4797560.0005880.0000220.0003600.0006770.0327460.3735680.0038070.0362560.0006630.0008270.0003350.7902691.1252101.0874350.6475550.6690320.0010350.0000280.0003490.0003180.0008880.0007410.0006940.0002350.0001780.0001050.0000290.0005530.0003000.0005060.0004310.0001940.8800170.0010400.0003530.0001850.0000260.0000400.0000190.0005890.0007080.0002820.0002790.0001530.0002500.0034050.9234420.0010580.0000460.0000210.0000230.0002640.0002550.0000250.0001350.0001280.0001190.0000190.0007230.0008820.0005782.6600390.8036990.9875560.0026040.0008060.0003580.0005250.0005860.1128240.0004580.0006000.0003680.0003960.0007820.0007750.9926111.0847520.8836540.0887490.0033510.1945550.0014260.0015780.0445260.0006340.0066870.0006670.0005520.0000220.0002090.0011100.0002230.0000200.0418920.0000630.0000220.0000200.0000210.0000260.0001630.3062580.0004730.0003710.0004910.0002840.0004560.0003430.0005630.0013130.7133443.4630782.4632581.5464470.0042500.0006080.8031790.0008550.8209790.0034940.0002030.4771060.1631750.0021260.0054850.0125500.6781880.0089320.0085250.0503640.0006470.8705740.9892063.5136410.5168950.6621002.6899330.0031831.2295740.9685050.0032640.8123550.0172341.2624850.0019630.0004750.0000230.0000190.0000190.0008770.7468500.0007700.0004460.7589440.0010540.0001141.8824060.5587921.6309200.0033890.0012050.1489221.1143920.0038980.0005220.0004340.0000190.0012560.0010770.0007020.0000200.4427872.9244681.6013261.4451361.6033450.5564390.9791320.5631642.7921710.0027491.0394650.0014610.0000220.9790490.0009780.0007250.0000260.0006120.0003930.0003951.9476191.6492152.1635670.7780251.4470430.0024240.0012790.7469300.7245010.9797540.9684451.6315460.0023683.1509112.1362300.7431590.8262530.0011040.0002320.0006590.0000250.0002370.5860030.3187950.0006350.0014480.7972780.0350931.4596460.6099271.1165142.3321640.3480010.4134822.1957481.2877660.0015960.0002791.2756450.0015941.2982930.0055580.0006180.1161370.0005830.0001390.0008010.7582580.0008360.0005450.0006790.0064050.0006080.0010210.0008830.0008090.0009040.0005090.0002560.0004870.0000300.0005930.0000190.0007360.0000210.0000270.0000960.0004370.0017390.0000200.0005120.0000190.0007800.0007120.0000250.0005580.0209100.0595780.0000710.0000210.0000240.0001100.0052250.0318990.0000510.0003410.1182020.0018630.0005720.0075490.0753020.0026570.0056340.0050140.0036710.0171220.0152590.0018350.0013000.0015220.0009100.7278560.0014980.6435310.0009400.0001960.0016360.0016970.0015370.0003200.8865030.0021610.7899950.0010850.8599310.0009720.0003500.0003090.0002830.8852340.0009590.8811410.0011690.0000200.8176410.0011520.0005270.0000320.0003230.0003300.0006850.0007570.0003760.0001890.0001690.0003740.0005180.0007502.6700832.4156480.2543740.6279720.4281850.5023690.4612580.4858640.0393640.0021691.4635450.0360420.0022081.0500690.8432180.2491740.0026120.0004390.0006400.0003890.0005510.0004330.0004030.0007930.0001920.0028420.0000990.0002480.0001700.0001680.000134

*******************************************
EVALUATING PIPELINE 
Pipeline directory: /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_405507e0_2020-02-07_09-08-120r2sp91s/
With following parameter combination: {'batch_size_seq_length': 2, 'lr': 1e-05, 'lr_type': 'constant'}
EVALUATION OF CHECKPOINT /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_405507e0_2020-02-07_09-08-120r2sp91s/outputs/checkpoint-3
-------------------------------------------------------------
|           |   agree   | disagree  |  discuss  | unrelated |
-------------------------------------------------------------
|   agree   |    578    |    66     |    206    |     7     |
-------------------------------------------------------------
| disagree  |     5     |    34     |    20     |     4     |
-------------------------------------------------------------
|  discuss  |    167    |    60     |   1522    |    26     |
-------------------------------------------------------------
| unrelated |    12     |     2     |    52     |   6861    |
-------------------------------------------------------------
Score: 7121.75 out of 7516.5	(94.74822058138761%)
Accuracy: 0.9348368322594055
F1 overall: 0.7150653707651698
F1 per class: [0.7140210006176653, 0.3022222222222222, 0.8514685314685315, 0.9925497287522604]
*******************************************


*******************************************
EVALUATING PIPELINE 
{'batch_size_seq_length': 2, 'lr': 1e-05, 'lr_type': 'cosine'}
INFO:__main__:Creating features from dataset file at /home/ubuntu/fnd_implementation/data/processed
  0%|                                                  | 0/9622 [00:00<?, ?it/s]  0%|                                        | 1/9622 [00:02<7:14:45,  2.71s/it]  5%|█▉                                    | 501/9622 [00:03<4:48:33,  1.90s/it] 21%|███████▋                             | 2001/9622 [00:03<2:48:46,  1.33s/it] 78%|██████████████████████████████▍        | 7501/9622 [00:03<32:52,  1.08it/s]100%|█████████████████████████████████████| 9622/9622 [00:03<00:00, 2549.02it/s]
  ******************************************* 
              Running Evaluation                
  *******************************************
 
  Length dataset evaluation: 9622
  Length dataloader evaluation: 1203
  Number of epochs: 3
  Batch size: 8
  ******************************************* 
 
['/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_d2701b24_2020-02-07_16-12-30nku9tara/outputs/checkpoint-3']
INFO:__main__:Evaluate the following checkpoints: ['/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_d2701b24_2020-02-07_16-12-30nku9tara/outputs/checkpoint-3']
INFO:transformers.configuration_utils:loading configuration file /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_d2701b24_2020-02-07_16-12-30nku9tara/outputs/checkpoint-3/config.json
INFO:transformers.configuration_utils:Model config {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 28996
}

INFO:transformers.modeling_utils:loading weights file /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_d2701b24_2020-02-07_16-12-30nku9tara/outputs/checkpoint-3/pytorch_model.bin
HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=1203.0, style=ProgressStyle(description_width='initial')), HTML(value='')))
0.0003850.0004350.0002600.0001210.0000650.0000470.0000570.0000770.0000510.0000400.0000930.0001060.7589110.0600381.0000490.0667030.0042040.0002790.0001940.0000460.4649230.0221730.6170460.0271880.0016790.6146580.0236740.0009100.0000760.0001170.0001920.0007800.0001190.0000590.0002200.0000580.0000430.0000500.0000410.0000460.0000680.0294010.0007470.0001350.0001430.0000810.0000540.0171910.0018100.0001740.0001130.0001690.0001130.0000411.0614971.0619470.0190010.0003931.0116220.0171800.0004330.0000400.0001110.0000340.0000340.0000340.0005790.7977470.0117720.0002110.1110180.0016540.0002500.0000610.0000700.6347751.6260250.0569070.0007630.0000480.0005770.0002010.3893550.0047390.0000911.2074991.2569090.5767820.8724370.0099410.0001491.0633290.0119503.1617710.0338410.2169950.1711750.0022150.0000640.0000360.0283060.0003140.0000390.0000490.0000660.0001670.0000360.0000360.0000370.0000340.0000380.0000870.0001420.0001180.0000350.0007350.0418620.0004970.0000390.0000900.0000340.0022810.0000510.0000320.5127100.0041380.0004250.0000390.0242230.0004160.4862090.0037451.5672490.9475590.0071040.0000860.0026180.8243550.0063370.0000790.0000360.0000340.0000340.0000340.0018210.0013800.0001120.0591350.0008860.0000410.8330110.5004780.0122220.0116430.0001770.0000340.0000330.0000330.0000340.0002970.0005140.9039640.0056730.0004430.0004060.3497990.0024160.0002360.0001440.0001460.0773550.0004860.0000360.0000330.0000330.0000340.0000330.0000330.0000330.0000350.0000350.0000410.0000340.0002530.0000350.0000330.0000370.0000360.0000340.0000340.0000340.0001130.0037371.0282480.0057000.5982250.0200280.0001650.0003180.0000360.0000410.0000460.0000340.0000340.0000350.0015810.0003910.6551110.0039880.0007350.8228250.8832140.7781910.0037520.0000500.0000340.0001900.0000340.0000340.0000350.0000640.0000360.0015430.0005290.0002191.1080850.0050680.0001660.0000370.0000400.0000360.0000550.0003060.0138420.0004470.0029090.0767090.0019010.0001810.0479010.0002610.0365093.1631640.5125111.8617461.4066780.0061960.0000590.0002020.0000340.0002260.0003020.0000350.0000320.0002670.0001370.0002350.0002770.0002890.0010290.0001290.0002140.9117040.0035601.9287130.0108660.0001880.6044800.3673550.6497410.0024420.0002810.6176950.6675630.0034180.8900100.0035130.0000710.8795210.0041610.0002160.0002540.0001530.0000820.0000330.0000930.0000860.0001000.2330580.8294420.2459490.0015420.8369610.0059190.0001740.0001530.0002420.0008270.0000420.9263520.0033950.3034640.0026040.0014360.0004630.9664950.0047651.4330030.0047890.0001040.7688120.1264000.0004950.0000890.8599810.0028180.0000930.0001900.0001000.0000861.9879380.0352150.0008110.0013460.0329870.0109960.0002370.0001230.0003200.0010340.7933380.6020581.6578181.7373330.7820740.8715260.0026280.0001290.0007810.0005790.0000350.0001280.0000380.0004680.0000340.0000430.0000330.0002640.0001650.0002230.0001010.0000950.0001460.0005420.0002590.0005710.0004580.0003360.2136680.0006380.4981190.0014160.0001120.0002152.8643112.1436450.2668360.8594470.0024910.3314880.0161472.4614370.0279610.0001140.0014840.0000410.0039180.3141470.2565630.0007120.0522520.0001910.0016090.0000380.0001500.0004530.0004540.0004770.0005030.0000360.0002510.0000440.0001520.0014750.0003081.7644951.2005160.0032760.8763960.7511030.7463520.5744850.0021840.0007640.0003840.0000360.0005550.0122230.0017800.0001820.0068331.2637190.0039140.0350390.0010940.0006310.0002430.0005080.0035990.0019090.0003950.0000340.0000340.0068420.0001780.0004320.0000350.0511540.0020080.0000380.0000340.0000340.0110700.0000590.0000330.0000330.0000340.0000330.0000330.0000340.0030801.0144710.0695200.0135750.0005740.0000350.6875000.7817180.0018490.0004280.0006310.0004630.0003210.0008182.2705160.9572420.0026340.5395370.0014760.0009040.0005380.0973301.0930430.0042140.3355120.2105770.0006200.4347010.0049650.0013230.0000390.0005670.0000340.0001150.0000350.0000340.0002000.0001390.0008520.8629960.0020330.8132850.0024950.0008290.0000380.0007540.0000550.4112850.3955100.2478142.1505910.0069350.0001280.0000330.0000340.0000340.8473820.0017381.6710470.7896330.0016130.0000390.4018240.0008330.0004680.0000390.0004610.0013370.0000400.0000380.0000392.6768222.0475940.0040240.0010550.0004320.0004600.6247081.0930210.0025620.0007940.0005430.0101880.0001250.4467180.0061081.2691210.0024430.1491650.0143510.2184030.8746430.0135210.0001340.0018830.0020770.0001130.0032250.7441541.1417121.6282051.1232683.1698310.0125680.0040260.5510870.0016220.0002960.0006080.0016030.0012740.0006810.0013200.0008090.0013090.8950160.0016440.0000371.7817521.7093880.0031510.0000390.7585300.0013830.0002560.0000340.0003700.0006820.0000350.0000340.5180290.0009420.0000740.0028190.0021430.3674481.1713100.0031121.0241060.1917190.7764600.5405860.0010130.0000350.0000371.2879680.6274930.0012980.0001570.1409250.7436810.2347360.0005540.0000450.0000520.0000350.0008810.0000400.4624880.0014030.0000410.0012370.0027190.0006900.0000380.0001340.0003330.0000410.0002670.8707952.0433300.0171790.0003570.0004310.0003330.0005730.0000460.0000390.0000400.0005680.0844490.9682000.0016630.0000520.0001380.0000370.0001590.0000350.0000380.0001820.0001550.0000350.0001240.0000330.0001940.0000360.0001770.0002022.1145200.0095290.0009263.3795852.5938411.6789810.1891300.2016862.0279180.0047140.2700870.0018870.0010590.0040030.0076330.1473300.0012850.0087711.2397661.1405570.0023170.0000370.3036610.0004920.0003800.8410740.7412010.1034120.0016420.0003960.0010760.0011990.0006290.0001880.0000340.0001570.0000930.0001520.0000330.0000340.0139280.6557980.0038100.0000440.8680190.0014330.0001090.0000340.0001060.0000350.0000920.0000410.0000350.0025630.0000410.0003560.0000340.0001060.0010700.2094100.0113600.0011200.0422790.0045560.0003440.8435822.4765245.5183280.0083400.0006980.0006470.0013400.0068430.0004590.0013970.0003230.0003450.0003930.0003850.0004180.0002890.0001540.5785390.0008730.0004530.9727290.0015250.7267060.5544720.0687363.5605151.7903751.7224052.4224532.1388280.0035320.0004850.0001980.0608320.0007870.0000350.0009360.0000370.0040460.0036010.0003520.0000620.0000410.9494661.8872413.6183651.9307823.5378573.9871140.9621251.2042440.3862680.6639660.0773250.8767941.7378390.0027690.0005970.0010860.0011120.4466050.0009280.0002540.0001980.0000370.0000330.0000330.0000880.7752550.9684600.8352710.0016050.9140880.9308342.1492580.0045710.0009340.0004950.0005670.0000350.0006380.0002960.0023220.0005720.0002150.0005170.0004830.0008390.6763900.6701030.9928150.0014740.9716182.9599880.9441870.8578050.9155812.0872490.1763510.1590390.0136700.0001940.0003120.0002770.2190240.0006040.0001710.0000880.9812732.9464561.0196011.5871922.1069330.9679330.0018890.0002150.0001050.0001640.0000970.0000340.4520771.4129610.0017520.0000480.0002421.5066680.0113960.9383460.1288180.9369011.4213820.7131282.5480414.1580631.5697320.0028670.5924420.7119210.0025000.4665660.0005910.0000360.0007880.0026130.1484890.0005250.7921090.0017080.0003440.0002720.0002530.4338790.9599540.8840450.7350951.0054610.0015550.0000420.0002140.0002550.0002860.0003930.0004510.0001950.0001420.0001090.0001890.0002490.0001470.0001970.0001520.0001360.9526400.0054230.0002510.0001350.0000660.0001070.0000350.0003420.0002630.0000920.0000740.0001060.0001400.0002080.9057780.0010520.0000550.0000350.0000340.0003360.0004010.0000370.0002340.0002500.0002000.0000330.0009630.0018700.0009281.7583920.8958100.0112150.0007480.0009140.0005140.0013050.0006690.9744110.0014630.0009390.0002910.0189550.0007290.0006380.0134620.0255530.0009580.0012420.0036890.5572760.0012420.0007480.0005890.0003540.0013220.0005350.0003820.0000400.0001820.0014040.0001290.0000350.0005790.0000330.0000330.0000350.0000460.0000370.0001120.9171700.0011220.0003060.0005970.0002110.0003520.0012350.0000450.0008850.1557583.3717601.8786480.7750590.0012680.0002190.0033370.0000370.5607590.0075150.0001630.2289490.1056000.0065590.0022470.0015080.0264030.0023010.0048280.0030880.0005690.8369051.0222243.1152590.0095430.5732010.0014150.0004870.0005890.0005900.0008710.0008290.0010950.2705770.0021720.0010260.0000430.0000330.0000330.0486200.4931890.0005300.0008210.0282060.0008280.0001010.8194550.7691471.7692640.6352370.3206500.7581921.7713020.5568470.0007420.0001440.0000340.0003550.0007200.0001940.0000330.4961331.1622111.0178401.0466892.5313860.5258600.6520090.2329991.3850450.0013880.5998810.0008990.0000420.9899180.0012630.0007550.0000370.0005070.0002770.0610310.3524191.5975211.0320640.0715800.2998720.0015740.0009040.7843070.4539730.6573530.9525981.5956080.0022693.5959132.5043850.9253590.4710460.0006480.0001580.0002930.0000460.0002980.6770710.8279200.0011500.0796210.1552920.1639310.1476530.0012800.2498351.9746550.0064540.1200120.9455840.2252500.0006370.0002590.1418210.0004490.9085030.0388610.0011720.0560730.0004010.0001870.0008700.9602580.0009750.0002130.0002490.0039460.0002130.0004890.0004810.0003910.0003930.0003150.0002050.0003210.0000470.0001200.0000350.0251220.0000610.0000360.0000370.0346730.0477610.0000780.0004050.0000360.0005290.0006260.0000470.0016940.0028920.3261000.0003270.0000360.0000360.0000620.0023700.0022430.0000360.0002540.0021690.2421700.0007600.0117350.0010460.0006240.0007480.0008810.0113470.3535460.0988860.0012930.0008160.0008490.0004870.8639190.0013490.3825150.0005930.0001670.0006990.0004460.0005650.0001740.9752970.0014900.0009950.0003100.0004830.0002620.0004800.0002610.0002851.0203070.0010280.7367090.0008410.0000340.7423160.0009080.0003620.0000530.0002410.0002490.0004240.0006590.0006980.0001440.0001280.0003150.0305310.0006391.5364211.5647900.4807130.0267630.0112470.2227900.0084580.5177260.6724600.0093661.0240410.3789100.0032473.0587401.6323910.1862230.0006930.0001650.0002430.0003150.0004470.0002720.0002980.0003750.0002760.0005660.0009350.0003740.0002320.0002500.000161

*******************************************
EVALUATING PIPELINE 
Pipeline directory: /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_d2701b24_2020-02-07_16-12-30nku9tara/
With following parameter combination: {'batch_size_seq_length': 2, 'lr': 1e-05, 'lr_type': 'cosine'}
EVALUATION OF CHECKPOINT /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_d2701b24_2020-02-07_16-12-30nku9tara/outputs/checkpoint-3
-------------------------------------------------------------
|           |   agree   | disagree  |  discuss  | unrelated |
-------------------------------------------------------------
|   agree   |    590    |    53     |    162    |     6     |
-------------------------------------------------------------
| disagree  |    25     |    54     |    28     |     5     |
-------------------------------------------------------------
|  discuss  |    140    |    54     |   1590    |    25     |
-------------------------------------------------------------
| unrelated |     7     |     1     |    20     |   6862    |
-------------------------------------------------------------
Score: 7201.0 out of 7516.5	(95.80256768442759%)
Accuracy: 0.9453336104759925
F1 overall: 0.7552020763872345
F1 per class: [0.7501589319771138, 0.39416058394160586, 0.8811305070656692, 0.9953582825645488]
*******************************************


real	19m14.014s
user	23m7.608s
sys	6m59.488s
ubuntu@run-gpu-mg:~/fnd_implementation$ 
ubuntu@run-gpu-mg:~/fnd_implementation$ exit
exit

Script done on 2020-02-07 19:35:29+0000
