Script started on 2020-02-06 14:33:39+0000
ubuntu@run-gpu-mg:~/fnd_implementation$ exittmuxkillall --user=ubuntutime python3 model_grid_search.py --model=bert --model_type=bert-base-cased[1P[1P[1P[1P[1P[1P[1P[1P[1P[1P[1P[1P[1P[1P[1P[1P[1P[1@e[1@v[1@a[1@l[1@_[1@s[1@e[1@a[1P[1@p[1@a[1@r[1@a[1@t[1@e
/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/home/ubuntu/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/ubuntu/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/ubuntu/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/ubuntu/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/ubuntu/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/ubuntu/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
There are 2 GPU(s) available.
The following GPU is used:  Tesla V100-PCIE-16GB
INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-config.json from cache at /home/ubuntu/.cache/torch/transformers/b945b69218e98b3e2c95acf911789741307dec43c698d35fad11c1ae28bda352.3d5adf10d3445c36ce131f4c6416aa62e9b58e1af56b97664773f4858a46286e
INFO:transformers.configuration_utils:Model config {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": "multi",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 28996
}

INFO:transformers.tokenization_utils:loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-vocab.txt from cache at /home/ubuntu/.cache/torch/transformers/5e8a2b4893d13790ed4150ca1906be5f7a03d6c4ddf62296c383f6db42814db2.e13dbb970cb325137104fb2e5f36fe865f27746c6b526f6352861b1980eb80b1
INFO:transformers.configuration_utils:loading configuration file /home/ubuntu/fnd_implementation/bert/model_pretrained/config.json
INFO:transformers.configuration_utils:Model config {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 28996
}

INFO:transformers.modeling_utils:loading weights file /home/ubuntu/fnd_implementation/bert/model_pretrained/pytorch_model.bin
INFO:__main__:Loading initialized pretrained model from /home/ubuntu/fnd_implementation/bert/model_pretrained
  ******************************************* 
           Freezing Embedding Layers          
  *******************************************
 
name:  bert.embeddings.word_embeddings.weight
param.requires_grad:  False
=====
name:  bert.embeddings.position_embeddings.weight
param.requires_grad:  False
=====
name:  bert.embeddings.token_type_embeddings.weight
param.requires_grad:  False
=====
name:  bert.embeddings.LayerNorm.weight
param.requires_grad:  False
=====
name:  bert.embeddings.LayerNorm.bias
param.requires_grad:  False
=====
name:  bert.encoder.layer.0.attention.self.query.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.0.attention.self.query.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.0.attention.self.key.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.0.attention.self.key.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.0.attention.self.value.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.0.attention.self.value.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.0.attention.output.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.0.attention.output.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.0.attention.output.LayerNorm.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.0.attention.output.LayerNorm.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.0.intermediate.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.0.intermediate.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.0.output.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.0.output.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.0.output.LayerNorm.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.0.output.LayerNorm.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.1.attention.self.query.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.1.attention.self.query.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.1.attention.self.key.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.1.attention.self.key.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.1.attention.self.value.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.1.attention.self.value.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.1.attention.output.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.1.attention.output.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.1.attention.output.LayerNorm.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.1.attention.output.LayerNorm.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.1.intermediate.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.1.intermediate.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.1.output.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.1.output.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.1.output.LayerNorm.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.1.output.LayerNorm.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.2.attention.self.query.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.2.attention.self.query.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.2.attention.self.key.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.2.attention.self.key.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.2.attention.self.value.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.2.attention.self.value.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.2.attention.output.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.2.attention.output.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.2.attention.output.LayerNorm.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.2.attention.output.LayerNorm.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.2.intermediate.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.2.intermediate.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.2.output.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.2.output.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.2.output.LayerNorm.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.2.output.LayerNorm.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.3.attention.self.query.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.3.attention.self.query.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.3.attention.self.key.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.3.attention.self.key.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.3.attention.self.value.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.3.attention.self.value.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.3.attention.output.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.3.attention.output.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.3.attention.output.LayerNorm.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.3.attention.output.LayerNorm.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.3.intermediate.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.3.intermediate.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.3.output.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.3.output.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.3.output.LayerNorm.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.3.output.LayerNorm.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.4.attention.self.query.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.4.attention.self.query.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.4.attention.self.key.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.4.attention.self.key.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.4.attention.self.value.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.4.attention.self.value.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.4.attention.output.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.4.attention.output.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.4.attention.output.LayerNorm.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.4.attention.output.LayerNorm.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.4.intermediate.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.4.intermediate.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.4.output.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.4.output.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.4.output.LayerNorm.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.4.output.LayerNorm.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.5.attention.self.query.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.5.attention.self.query.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.5.attention.self.key.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.5.attention.self.key.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.5.attention.self.value.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.5.attention.self.value.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.5.attention.output.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.5.attention.output.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.5.attention.output.LayerNorm.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.5.attention.output.LayerNorm.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.5.intermediate.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.5.intermediate.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.5.output.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.5.output.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.5.output.LayerNorm.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.5.output.LayerNorm.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.6.attention.self.query.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.6.attention.self.query.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.6.attention.self.key.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.6.attention.self.key.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.6.attention.self.value.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.6.attention.self.value.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.6.attention.output.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.6.attention.output.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.6.attention.output.LayerNorm.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.6.attention.output.LayerNorm.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.6.intermediate.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.6.intermediate.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.6.output.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.6.output.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.6.output.LayerNorm.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.6.output.LayerNorm.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.7.attention.self.query.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.7.attention.self.query.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.7.attention.self.key.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.7.attention.self.key.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.7.attention.self.value.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.7.attention.self.value.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.7.attention.output.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.7.attention.output.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.7.attention.output.LayerNorm.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.7.attention.output.LayerNorm.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.7.intermediate.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.7.intermediate.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.7.output.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.7.output.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.7.output.LayerNorm.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.7.output.LayerNorm.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.8.attention.self.query.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.8.attention.self.query.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.8.attention.self.key.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.8.attention.self.key.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.8.attention.self.value.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.8.attention.self.value.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.8.attention.output.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.8.attention.output.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.8.attention.output.LayerNorm.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.8.attention.output.LayerNorm.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.8.intermediate.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.8.intermediate.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.8.output.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.8.output.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.8.output.LayerNorm.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.8.output.LayerNorm.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.9.attention.self.query.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.9.attention.self.query.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.9.attention.self.key.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.9.attention.self.key.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.9.attention.self.value.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.9.attention.self.value.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.9.attention.output.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.9.attention.output.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.9.attention.output.LayerNorm.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.9.attention.output.LayerNorm.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.9.intermediate.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.9.intermediate.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.9.output.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.9.output.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.9.output.LayerNorm.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.9.output.LayerNorm.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.10.attention.self.query.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.10.attention.self.query.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.10.attention.self.key.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.10.attention.self.key.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.10.attention.self.value.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.10.attention.self.value.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.10.attention.output.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.10.attention.output.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.10.attention.output.LayerNorm.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.10.attention.output.LayerNorm.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.10.intermediate.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.10.intermediate.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.10.output.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.10.output.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.10.output.LayerNorm.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.10.output.LayerNorm.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.11.attention.self.query.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.11.attention.self.query.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.11.attention.self.key.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.11.attention.self.key.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.11.attention.self.value.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.11.attention.self.value.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.11.attention.output.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.11.attention.output.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.11.attention.output.LayerNorm.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.11.attention.output.LayerNorm.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.11.intermediate.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.11.intermediate.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.11.output.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.11.output.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.11.output.LayerNorm.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.11.output.LayerNorm.bias
param.requires_grad:  True
=====
name:  bert.pooler.dense.weight
param.requires_grad:  True
=====
name:  bert.pooler.dense.bias
param.requires_grad:  True
=====
name:  classifier.weight
param.requires_grad:  True
=====
name:  classifier.bias
param.requires_grad:  True
=====

*******************************************
Evaluating the following pipelines 
['/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_55a0d754_2020-02-06_08-04-00unsva4rl/', '/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_4b82ec4e_2020-02-06_05-49-162j91vqkf/', '/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_5d2d45de_2020-02-06_10-08-12i5hw6cve/', '/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_7edf2f2c_2020-02-06_13-31-55200549bj/', '/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_7c38625c_2020-02-06_12-52-200c2rox5v/', '/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_797633aa_2020-02-06_12-52-16ai51o2n2/', '/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_53133bbc_2020-02-06_07-54-20bf_wbwiw/', '/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_4df90850_2020-02-06_07-14-367lv6lsx1/', '/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_5aa271fe_2020-02-06_09-32-39qdqcvxui/', '/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_48d2cd48_2020-02-06_05-49-113dv6ag8u/', '/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_5093d00e_2020-02-06_07-27-51avgl_d7i/', '/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_582282f2_2020-02-06_09-29-064i78cr62/']

*******************************************

*******************************************
EVALUATING PIPELINE 
{'batch_size_seq_length': 2, 'lr': 3e-05, 'lr_type': 'linear'}
INFO:__main__:Creating features from dataset file at /home/ubuntu/fnd_implementation/data/processed
  0%|                                                                                                                                          | 0/9622 [00:00<?, ?it/s]  0%|                                                                                                                                | 1/9622 [00:02<6:59:52,  2.62s/it] 21%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                                                                                   | 2001/9622 [00:04<3:52:50,  1.83s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9622/9622 [00:04<00:00, 2267.91it/s]
  ******************************************* 
              Running Evaluation                
  *******************************************
 
  Length dataset evaluation: 9622
  Length dataloader evaluation: 1203
  Number of epochs: 3
  Batch size: 8
  ******************************************* 
 
['/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_55a0d754_2020-02-06_08-04-00unsva4rl/outputs/checkpoint-3']
INFO:__main__:Evaluate the following checkpoints: ['/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_55a0d754_2020-02-06_08-04-00unsva4rl/outputs/checkpoint-3']
INFO:transformers.configuration_utils:loading configuration file /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_55a0d754_2020-02-06_08-04-00unsva4rl/outputs/checkpoint-3/config.json
INFO:transformers.configuration_utils:Model config {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 28996
}

INFO:transformers.modeling_utils:loading weights file /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_55a0d754_2020-02-06_08-04-00unsva4rl/outputs/checkpoint-3/pytorch_model.bin
eval_separate.py:214: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0
Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`
  for batch in tqdm_notebook(eval_dataloader, desc="Evaluating"):
HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=1203.0, style=ProgressStyle(description_width='initial')), HTML(value='')))
0.0001880.0002110.0001270.0000590.0000320.0000230.0000270.0000460.0000230.0000190.0000480.0000610.7134770.0549011.1069910.0738160.0046300.0002890.0001150.0000280.0001760.0000340.0000520.0004540.0005502.5541950.0982550.9082500.9182460.0318430.0011590.0000540.0000190.0000240.0000490.0000180.0000180.0000180.0000180.0000180.0000190.0000200.0000170.0000770.0000720.0000260.0001720.0001210.0005530.0000350.0000240.0000440.0000210.0000191.0964170.2515420.0045080.0589200.9385430.0159240.0009570.0000330.0001680.0000200.0000180.0000170.0002771.0178940.0149880.0002380.0006890.0000530.8993600.0123370.0002030.0001282.5392110.7570220.0097220.0001410.0017740.0434270.0915490.0011210.0000322.0215101.9490691.0577010.0122830.0002230.0000191.1002790.0120683.3607180.0357732.0306050.1294880.0017060.0000420.0000200.4182700.0041600.0000570.0000710.0000680.2865050.0027200.0002080.0000240.0000190.0000170.0000520.0001130.0000500.0000170.1313340.0031230.0001830.0000200.0000560.0000170.0643780.0005440.0000210.7973410.0063960.0016080.0000330.0143130.0001600.0522820.0004240.3309420.0041050.0000470.0000170.0027240.8062390.0067990.0000670.0000280.0000170.0000170.0000200.0001470.0004810.0000200.8799850.0071350.0000641.0311721.0657790.0092200.0077690.0001100.0000170.0000170.0000170.0000170.0001950.9511551.0386340.0064640.0000580.0002410.8312830.0052220.0001890.0000650.0000700.8764070.0051420.0000460.0000170.0000170.0000160.0000170.0000170.0000170.0000170.0000170.0000180.0000170.0000650.0000170.0000170.0000170.0000160.0000170.0000170.0000170.0000450.0009060.0000210.0004730.0055200.0000450.0000190.0002020.0000180.0000180.0000170.0000170.0000210.0000180.0012780.6311150.7773110.7088680.2385070.2369800.8508750.7960600.0037900.0000350.0000170.0000890.0000180.0001480.0000180.0002920.0000181.0617040.0052320.0003281.0403940.0046820.0000990.0000170.0000160.0000160.0000170.0017910.0015420.0002000.0000510.0003440.0015570.0000810.0000210.0000200.0015712.4010811.2797562.2622972.8265280.0117620.0000660.0001340.0000180.0000990.0000890.0000330.0000170.0000920.0000870.0000830.0001190.0001580.0003410.0000450.0011800.0566840.0002650.0753440.0004090.0000731.2641630.8313610.6960760.0025990.0000850.7559881.7381800.0063920.0003050.0013400.0000420.8778620.0050310.0001600.0000450.0002780.0000520.0000170.0000530.0000470.0000640.7417051.5739780.7425960.0029780.8769910.0065430.0001150.0001150.0001140.0003190.0000230.9842570.0038120.1966140.0011340.0002870.0005452.2677740.0074761.3718570.0045210.0000561.1221890.8984040.0029220.0000530.9841480.0031680.0000540.0000200.0000450.0000431.6894682.6136730.0085560.0005620.1102850.2124420.0007800.0000510.0003520.4052570.5375710.4024960.4086200.0772650.0007660.2925280.0008870.0001190.0004260.0002970.0000170.0000170.0000180.0009100.0000190.0000180.0000200.0000200.0000940.0001150.0000950.0000630.0000930.2050360.0007170.0003620.6894580.0020320.4441300.0012540.2693530.0007630.0000530.0002590.8512760.4050230.6231382.1417300.0058790.0925970.0005883.5815690.0110270.0000540.0005700.0000240.0096530.9428081.7881240.0047342.3133530.0061360.0003730.0000170.0004390.0002290.0002140.0002440.0002850.0000170.0001830.0000190.0001190.0004240.0001170.0013050.0039520.0001050.0021150.7108000.0862690.3516900.0010900.0004690.8310360.0162970.0003200.0090550.0012580.0000590.0068720.0100050.0047430.8890370.0023880.0002270.0001440.2100390.8789971.7062580.9315190.0022300.0000860.0001550.0001570.0005430.0000180.0022160.0015500.0000200.0000160.0000160.7914570.0018450.0000210.0000160.0000160.0000170.0000160.0000170.8435741.1279640.2323520.3466370.0011180.0000240.7559220.8940540.0020160.0002400.0003450.0001530.0002490.0013211.6693000.0060910.0000590.0001540.0035510.0001950.0001900.3959841.4405080.0037471.5521321.0807180.0023880.9835230.7872880.0022320.0000220.0000700.0000170.0000510.0000170.0000160.0002600.0000640.7755501.1317270.0024461.0819970.3379180.1698160.0003670.1037150.0002300.9728421.0733170.6855592.2025073.6033940.0073670.0000310.0000170.0000190.1513250.0003220.1618350.0018610.0000220.0000190.0064740.0000310.0013390.0000210.0002570.0001260.0000180.0000210.0000212.9452241.1524170.0022640.0907610.0004400.0002310.6222421.4814500.0031060.0004180.0001290.6857510.0019720.0218020.0008750.5527490.0010650.0052480.0010050.0057640.0108540.0039580.0000860.0007760.0008310.0000520.0006150.4129981.0784061.7417841.2895902.9283290.2676260.9455050.0038300.0007180.0001400.0034820.0006071.0459160.7408701.8607730.0037610.0004780.7876560.0014330.0000191.7027121.9337090.0034990.0000230.5924930.0010690.0000870.0000170.0000920.0001650.0000170.0000180.0000430.0000170.0000510.0011310.2150350.0020600.0000950.0001672.8799871.9033090.9958870.6158390.0011100.0000180.0000192.3779950.8588700.0015700.0000570.8077670.9100790.8202630.0014540.0000250.0000170.0000160.0005570.0000180.1934540.0006050.0000180.0005300.7342680.0014710.0000280.0004760.0000510.0000520.0006873.0229353.3753750.0582390.0002560.0001820.0001420.0001560.8116030.0013330.0000220.0002060.0241330.0007140.0000540.0000200.0001060.0000180.0003000.0000210.0000180.0002870.0005300.0001070.0000480.0000170.0000890.0000170.0001050.0000840.3251630.0013310.0114863.3757631.8565101.6016870.5981570.8516920.3508410.0007800.0002450.0012410.0378560.0003910.0002160.0003120.0001610.4451580.2242130.7853040.0015660.0000190.0020760.0000200.0002161.9819661.0198330.1221340.0023590.0001820.0003490.0001240.9464480.5060730.0007930.2857310.0004780.2857280.0004410.0000200.0038580.0047160.0014300.0000200.0081530.0148740.0000470.0000170.0003330.0000180.0030260.0000250.0000270.0224650.0000500.0017510.0000190.0000180.0002140.0018690.0147070.3674220.0011460.0001640.3669640.0076712.7660516.5079130.0094540.0003230.0003690.0003310.2017590.0006270.0009520.0001830.0001500.0714730.0002680.0002880.0001920.0033140.7744730.4195140.0109971.4493360.0886850.4991270.0015370.2899751.7201460.2828350.9447421.4361512.3150140.0035010.0002290.0000920.0006000.0003330.0000170.0005340.0000190.0004410.0013590.0001240.0000190.0000171.0893462.1424394.1057431.3792004.2722384.4119762.4413251.2464041.1788871.8031671.1547650.3810400.9688880.0016260.0002470.0004590.0004780.0022710.0002200.0004050.0001220.0000180.0000170.0000170.0000440.5560160.8034540.7466340.0013600.7195450.8103022.3330591.1045300.1529670.0006480.0008670.0000180.0006100.0002030.0787740.0009780.0001110.0018870.0002720.0004780.0339810.0856361.0540560.0014490.9287243.3145211.0582850.9818140.9735232.1627000.2548070.7501710.003263
0.0001810.0006200.0001890.2713470.0004780.0000760.0000501.0368002.8910201.0984371.0748960.3648690.2958230.2285020.0003860.0000550.0001210.0000560.0000160.0399970.4584880.0005720.0000170.0000527.1786741.3713281.0923120.0014580.0022662.1914161.0507622.9622765.7960002.0862010.0078440.6255720.4551370.0009560.1582920.0002040.0000170.0002410.0004980.0006040.0129200.0151180.0040640.0004910.0003470.0001240.8190510.9160351.2060080.9837401.4740100.0018450.0000270.0001250.0001400.0001210.0001750.0002510.0001120.0000840.0000540.0000510.0001470.0000810.0001240.0000850.0000870.0004560.0003520.0001370.0000690.0000500.0000740.0000170.0001760.0001850.0000520.0000230.0001410.0001180.0001280.0001290.0000170.0000200.0000170.0000170.0001090.0001420.0000180.0000750.0000780.0000710.0000160.0004580.0009230.0003760.5236241.6382702.0111010.0027260.0003610.0002070.0003160.0002910.0007670.0001920.0003740.0001920.0001260.0004890.0004051.3146871.3965981.1415250.3047270.0022540.0090830.0005010.0062340.0006510.0033000.1266100.0015510.0012680.0002370.0001350.0005290.0001580.0000440.0001050.0000180.0000270.0000730.0019630.0001690.0000680.6079900.0007090.0001380.0003360.0001670.0001760.0003400.0000380.0009941.1155474.6892583.3159790.8036300.0010970.0000670.0002150.0000170.0002260.0073320.0001030.0027750.0063530.0024010.0032810.0006790.0328790.0016920.0011380.0227590.0011040.9302681.1602714.2240191.4002592.0145890.0058370.0005150.0006470.0010320.0012140.0006710.4331780.0011400.0004350.0001710.0000170.0000170.0000170.0002690.3906650.0004120.0002990.3795490.0747630.0001160.0732260.0004710.0015830.8968980.8990481.7671373.6325011.7393700.0018310.0000990.0000170.0003500.0004170.0002290.0000170.8882112.1435551.9120393.2136592.4369260.7914650.4060400.1745311.7675650.0017460.7268420.0010580.0000201.0333510.0101170.0001900.0000210.0001900.0000860.0000940.5670680.8024520.1827260.0015220.0430380.0088290.0003920.6487880.6819510.4552201.0843051.3178300.0027652.6724521.4240470.6973770.0140370.0002530.0001390.0023510.0000211.0539580.0318350.1499670.0062900.8415800.0768371.9282421.6239330.5956101.8583913.7096370.9405480.0133341.0990150.1728420.0003080.0001130.3469240.0005090.7288560.0018050.0002960.0009650.0001880.0060000.3019380.1636260.0002090.0001290.0001600.0002970.0001740.0002270.0001860.0001890.0002650.0001570.0001020.0001220.0000180.0007110.0000200.0002780.0000190.0000180.0000180.0015540.0007290.0000190.0001450.0000180.0006150.0000670.0000180.0001140.0002770.0003260.0000170.0000190.0000180.0000180.0000930.0002390.0000170.0000400.0005520.2777980.0006680.0003920.0006790.0005670.0001620.0003022.6628736.4899050.0544980.0013110.0006870.0008410.0003210.0010700.0001020.0005360.0035540.0000860.7154360.2774210.5741530.0006301.0201290.0146920.0003770.0012920.0016380.0001170.0011860.0115000.0017281.8413960.0017530.1516400.0003840.0000170.0015760.1305320.1194720.0001220.1736340.0002301.0037060.8210780.6095830.0005870.2734770.0425520.7329640.0011651.8809781.5608140.6264350.0184830.0007100.0022340.0007120.1832460.4068670.4725130.0096200.0093460.0008181.3088770.0300670.0011300.0007010.0001490.0001900.0003260.0005830.0004250.0003020.0004440.0001150.0000820.0000750.0001650.0001260.0001840.000086

*******************************************
EVALUATING PIPELINE 
Pipeline directory: /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_55a0d754_2020-02-06_08-04-00unsva4rl/
With following parameter combination: {'batch_size_seq_length': 2, 'lr': 3e-05, 'lr_type': 'linear'}
EVALUATION OF CHECKPOINT /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_55a0d754_2020-02-06_08-04-00unsva4rl/outputs/checkpoint-3
-------------------------------------------------------------
|           |   agree   | disagree  |  discuss  | unrelated |
-------------------------------------------------------------
|   agree   |    530    |    40     |    122    |     5     |
-------------------------------------------------------------
| disagree  |    23     |    77     |    65     |     3     |
-------------------------------------------------------------
|  discuss  |    202    |    43     |   1592    |    29     |
-------------------------------------------------------------
| unrelated |     7     |     2     |    21     |   6861    |
-------------------------------------------------------------
Score: 7203.5 out of 7516.5	(95.83582784540677%)
Accuracy: 0.941592184577011
F1 overall: 0.7642135719095017
F1 per class: [0.726525017135024, 0.4666666666666667, 0.8685215493726132, 0.9951410544637029]
*******************************************


*******************************************
EVALUATING PIPELINE 
{'batch_size_seq_length': 2, 'lr': 3e-05, 'lr_type': 'constant'}
INFO:__main__:Creating features from dataset file at /home/ubuntu/fnd_implementation/data/processed
  0%|                                                                                                                                          | 0/9622 [00:00<?, ?it/s]  0%|                                                                                                                                | 1/9622 [00:02<6:55:29,  2.59s/it]  5%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                                                                                       | 501/9622 [00:02<4:35:44,  1.81s/it] 21%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                                                                                   | 2001/9622 [00:03<2:41:17,  1.27s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                                            | 5001/9622 [00:03<1:08:27,  1.13it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                            | 7501/9622 [00:03<21:59,  1.61it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9622/9622 [00:03<00:00, 2517.68it/s]
  ******************************************* 
              Running Evaluation                
  *******************************************
 
  Length dataset evaluation: 9622
  Length dataloader evaluation: 1203
  Number of epochs: 3
  Batch size: 8
  ******************************************* 
 
['/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_4b82ec4e_2020-02-06_05-49-162j91vqkf/outputs/checkpoint-3']
INFO:__main__:Evaluate the following checkpoints: ['/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_4b82ec4e_2020-02-06_05-49-162j91vqkf/outputs/checkpoint-3']
INFO:transformers.configuration_utils:loading configuration file /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_4b82ec4e_2020-02-06_05-49-162j91vqkf/outputs/checkpoint-3/config.json
INFO:transformers.configuration_utils:Model config {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 28996
}

INFO:transformers.modeling_utils:loading weights file /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_4b82ec4e_2020-02-06_05-49-162j91vqkf/outputs/checkpoint-3/pytorch_model.bin
HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=1203.0, style=ProgressStyle(description_width='initial')), HTML(value='')))
0.0009230.0013120.0012240.0006670.0004270.0002970.0004240.0003910.0002640.0003150.0006280.0011850.6629280.0511070.9238140.0616940.0039860.0004030.0003490.0011260.0008740.0008730.0006240.0008400.0005990.4907730.0189700.0007880.0005120.0013260.0005520.0004420.0001090.0006370.0648300.0025530.0004770.0001590.0002430.0005330.0003550.0009510.0005310.0007490.0002490.0002560.0002700.0009080.0291290.0009480.0011930.7581510.0150150.0005591.3279920.0265790.0006460.0012860.0006130.0002040.0018020.0002270.0003780.0001780.0004290.0002600.0018390.0006250.0002430.0001870.0007860.0002120.0009010.0001250.4329730.0060031.3891050.9052910.0118770.1125220.5804410.4840440.5229050.0065650.0005260.0009600.0009960.0004100.3884080.0046830.0006541.7965970.0201221.8986080.0203820.0689660.2871620.0515770.0013060.0003600.1402410.0017760.0003320.4745450.0053520.0035080.0005840.0003870.0005350.0001980.0003300.0003770.0006580.0009810.0001720.2924970.7337760.0097860.0001630.0002940.0001050.6564290.0054690.0001211.7748800.0149800.0026370.0006872.4837310.0195240.0051020.0003160.5100500.0043910.0001790.0003180.0008060.0021840.0004560.0001230.0001170.0001140.0002340.0006040.4389190.4074250.0029550.8612990.8390030.0057400.8246260.8493500.0060160.0058030.0004930.0001010.0000810.0001010.0000950.1190470.9064010.7661320.0051980.0001600.0009761.0892070.0070210.7392550.0047230.0034180.0762250.0005760.0000950.0000620.0000660.0000990.0000970.0000690.0000610.0000870.0000850.0001090.0000770.0004110.0000670.0000760.0000860.0000880.0001210.0000770.0001130.0001750.7055290.0037601.1396420.0061420.0003080.0012110.0007180.0003760.0005730.0009200.0000880.0041790.0001890.0028640.4140650.7762600.4666280.7074531.8944790.3438490.0058680.0004560.0000790.0001400.0035990.0001100.0002330.0000910.0005460.0001060.0144870.0016140.0012740.9279800.0059380.0018260.0003640.0001350.0001590.0001210.0005430.0007350.0007630.0018570.0006390.0006130.0010070.0004450.0007510.8030860.5788302.0289220.6579552.0380850.0096620.0001430.0005740.0000910.0004200.0007280.0001370.0001290.0014100.0003590.0174400.0027650.4656860.1001130.0019620.0202440.7760310.0039171.5718970.0064930.0017110.5567840.5646452.5115710.4365281.1219150.5792662.0332140.0079630.8144300.8248500.4342421.7116020.6561250.0047100.0003160.0009020.0003500.0001450.7464810.0038410.0017380.7872481.5087150.2669940.0030440.7723150.0082930.0005830.0011590.0007890.0011680.0006190.7289420.0039370.0075570.0015780.0007240.0021220.0024690.0532901.4944750.0058120.0003500.2160210.3167490.0013120.0003150.2372910.0009250.0003350.0495260.0004660.0008370.0043180.0054631.1162310.0044410.0050210.0008970.0004790.0006190.0019830.0032780.1093210.3271570.0981640.1010050.0281130.0958440.0005040.0016210.7207550.0056650.0005690.0001600.0008750.0005300.0001600.0001050.0003270.0002230.0002670.0004220.0007320.0008960.0011230.0062970.0008500.0077320.0260420.0012150.0027800.0001610.2332320.0008220.0003390.0007020.6983851.7440270.0804732.0139920.0056790.8221500.0029431.5223530.0150930.0006100.0015640.0015741.6583700.8376431.3946440.0037731.9686530.0053320.0007500.0001000.0003970.0011710.0012260.0013020.0005500.0000880.0005500.0001600.0003710.0013210.0004520.0069220.0059290.0006880.0072760.0023900.4558780.7330430.0079940.0499120.0144850.0013450.0048420.0084730.0052600.0005620.0031402.7156770.9188611.3763410.0045120.0011740.0017740.0031020.0004610.0013090.0002750.0001320.0005020.0004170.0010820.6946140.0017750.8140470.1357420.0004810.0001120.0000990.0029300.0003310.0000950.0000950.0001050.0000960.0001030.0001020.6494142.9019500.8423160.0081620.0021320.0001070.8729450.8604980.0022801.1512750.0036260.0012630.5602970.1178912.1015631.2513760.0030480.0019640.0282050.1279690.6733081.4528521.4870801.0030761.3490750.7959490.0023300.8184970.6379760.0990680.0003860.1895960.0004770.0003120.0001200.0000820.0003290.0008680.0013000.0031600.0004600.1920860.0008510.0003950.0001010.0003240.0001290.0779480.0227420.2965570.6264630.0033510.0009980.0000870.0001540.0000750.7969900.0016901.0672040.4829220.0011160.0001922.1659750.0045810.0008480.0002680.0008301.1343420.0027501.1407570.0037111.0053830.7938460.0018000.3273220.0014360.0006790.7930211.7178050.0045510.0015760.0035730.0022050.0008600.0062640.0003820.7622830.0015450.0049100.3789450.0041370.0037040.0015320.0018850.0004410.0007010.2102100.0009100.7926331.5528992.4344851.6211490.4363110.3384040.2091680.0020290.0012040.0007090.0008490.0011320.0044690.0026890.0070830.0048150.0097530.6132750.0013500.0002041.0997501.0822070.0025570.0001750.4537540.0009040.0002870.0000940.0004770.0005020.0000940.0000620.0003320.0000820.0001220.8199790.3153230.1072941.4915401.5745121.6491491.0079050.5107020.8762320.0018870.0001510.0001860.2744200.6667010.0023260.0004250.0344720.0451440.0158550.1968000.0010200.0004660.0002320.0008800.0001910.0220420.0004650.0003750.0028760.3957280.0030430.0002220.0003170.0006440.0004740.0007042.4105763.2702230.0065540.0007050.0007210.0007220.0006421.0467830.0022590.0006110.0009000.0108570.0037290.0002190.0000950.0102980.0001620.0003160.0001830.0001720.0005430.0005330.0002300.0002960.0000910.1999571.1332760.0024540.0004941.9125000.0100400.7659173.1823922.0019930.6937950.0044790.0025520.0048380.0055420.0096630.7920850.6765930.0036600.0041790.0039430.0030970.6428861.1775741.8228880.6008020.0009870.0005660.0001070.0007861.3242270.9193190.6045390.0024100.0010080.0010160.0004880.0043300.0018590.0004940.0021610.0339900.0017840.0001440.0005350.0063000.0735390.0041360.0025470.0012700.0003570.0004550.0001161.1189770.0018580.0007380.0001830.0002100.0008600.0000960.0005030.0000950.0002970.0009140.1823280.9197380.0036720.6376250.0024070.0018132.0860613.9516604.9880990.0075250.0006960.0005960.0007360.6284160.0021970.0014790.0008010.0014810.4462460.0015950.0022110.0009762.4198930.7267511.5082670.6931811.5716930.0055870.7541190.0115170.4687603.4613772.8195431.7333342.5641881.6127870.0391080.0029250.0010221.9238860.6288010.0010140.8322470.0012860.8436592.1823340.0044240.0000960.0001890.6076781.6577023.0635801.2352042.8131403.2031002.4458042.3873332.3906421.6622521.5350610.9708021.9215250.0033550.0007320.0007430.0008840.8590460.0016750.6561210.0012380.0001890.0001310.0001330.0002970.0005280.0907310.0010690.0015450.4121490.2354970.2818440.0104080.0168930.0006580.0007860.0000920.0012970.0010250.0030980.0010080.0003620.0039540.0008260.0012860.0175360.2128840.7961900.0014990.8321002.5751640.7770740.7637600.7603093.5267590.9778730.5990280.2485230.0006380.0010780.0003000.0118490.0003440.0007260.0003840.6445372.0104720.9462192.2080123.7786043.2189460.9460510.0016230.0003860.0097770.0003450.0001210.7613890.7603300.0011270.0003880.0010434.7009070.7761290.5945710.0230300.0006941.7533211.1165191.9293133.3706340.8393200.0023090.4026130.5282320.3568530.2840580.0021070.0015210.2925231.0334091.6160800.0838561.4392981.4320180.8423300.8370170.0015271.6022511.8284571.8543861.4152641.8307880.0026400.0003020.0020310.0005700.0130730.0047290.5801400.0011470.0005470.0007610.0002140.0009500.0003900.0009810.0011810.0004040.2108870.0006260.0007900.0003510.0003850.0002890.0002140.0008450.0010860.0004350.0009160.0008930.0005510.0008760.0006180.0001300.0016430.0000990.0001180.0003400.0005040.0001060.0002640.0003900.0002900.0001040.0008840.0023080.0032932.3761750.1381470.0087860.0012630.0011570.0005390.0016290.8210510.0020180.0009860.0010710.0664430.0005010.0012640.0017910.0015621.9966261.1660870.0025290.6482980.8528030.0016410.0050340.0021500.0028700.0023530.0019310.0021570.0002180.0006630.0168030.0009480.0005120.0019330.0001010.0006040.0002730.0001310.0006180.0008161.7078810.0021300.0006730.0018040.0007500.0010960.0008660.9963350.0018690.0024562.4261211.8825910.6014070.0016310.0006260.0005510.0000980.0009590.6324480.0012240.0017390.4775910.3046500.0031980.0031070.0074260.0053780.0040120.3906820.0019560.8211771.6302522.9961741.4808641.5374590.0026190.0006010.0015200.0006620.0015260.0010990.0010250.6494970.0015450.0007180.0002590.0002420.0002800.0005000.6159330.8860031.1504430.3104600.0018090.0004022.4779860.8166972.4963250.1032210.0700450.9052380.9119570.4064360.0023090.0331900.0001320.0070560.7374490.5820940.0006830.5894481.0562151.4164050.0115380.8182530.6066600.5623640.5249091.5090880.0016310.9816410.0016340.0003930.0003770.0006880.0010960.0001070.0030990.0007230.0007151.2122811.0302020.7868510.6003010.0773500.0014420.0021682.0334990.0029260.7129280.0140762.6126920.0094281.3129500.2220920.5492670.3313900.0173810.0016730.0015580.0001980.0016720.0986110.1963780.0023760.0399860.6253180.5549040.1066710.1112770.5991220.8081160.5350270.0786690.7054890.6972760.5176560.0009780.7867580.0015550.6896280.6021400.0012270.8175940.0012670.0002500.0010550.8737630.0011350.0014490.0010420.0013850.0011060.0019640.0265510.0011340.0013160.0009330.0006300.0006480.0001230.0007390.0000840.0005940.0001210.0001470.0001430.0010020.0004820.0004170.0005820.0001220.7659320.0062740.0003860.0008250.3888530.0015880.0001370.0002350.0004450.0004440.0004300.0014000.0002150.0010340.0019900.6373050.9574430.0061010.6707600.0036260.0032600.0039111.5725464.7301090.0556120.0009510.0008990.0009980.0032100.6146250.0030830.7678830.0014370.0004930.0019730.0009780.0009620.0003310.7604610.0035530.0011090.5891630.6887020.0010520.0063780.5839320.8961371.7327910.0018450.1935610.0008150.0001000.0004080.5607650.6584920.0009530.5606930.0008340.7254150.8216150.5994470.0008120.5918310.6467581.6105061.2193602.0211062.3952630.0366540.0037270.0039290.6593740.0056800.0025550.0040340.3878160.8523300.1820940.0024920.7581861.1696400.7979360.2333500.0014230.0011810.0017280.0017470.0010900.0010300.0009530.0003910.0003650.0003640.0005660.0004210.0005050.000542

*******************************************
EVALUATING PIPELINE 
Pipeline directory: /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_4b82ec4e_2020-02-06_05-49-162j91vqkf/
With following parameter combination: {'batch_size_seq_length': 2, 'lr': 3e-05, 'lr_type': 'constant'}
EVALUATION OF CHECKPOINT /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_4b82ec4e_2020-02-06_05-49-162j91vqkf/outputs/checkpoint-3
-------------------------------------------------------------
|           |   agree   | disagree  |  discuss  | unrelated |
-------------------------------------------------------------
|   agree   |    586    |    41     |    198    |    40     |
-------------------------------------------------------------
| disagree  |    32     |    75     |    73     |    12     |
-------------------------------------------------------------
|  discuss  |    136    |    44     |   1498    |    17     |
-------------------------------------------------------------
| unrelated |     8     |     2     |    31     |   6829    |
-------------------------------------------------------------
Score: 7118.75 out of 7516.5	(94.7083083882126%)
Accuracy: 0.9341093327790481
F1 overall: 0.7483270177348947
F1 per class: [0.7203441917639828, 0.423728813559322, 0.8572246065808298, 0.9920104590354445]
*******************************************


*******************************************
EVALUATING PIPELINE 
{'batch_size_seq_length': 1, 'lr': 3e-05, 'lr_type': 'cosine'}
INFO:__main__:Creating features from dataset file at /home/ubuntu/fnd_implementation/data/processed
  0%|                                                                                                                                          | 0/9622 [00:00<?, ?it/s]  0%|                                                                                                                                | 1/9622 [00:02<7:28:34,  2.80s/it]  5%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                                                                                       | 501/9622 [00:02<4:57:41,  1.96s/it] 21%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                                                                                   | 2001/9622 [00:03<2:54:07,  1.37s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                            | 7501/9622 [00:03<33:55,  1.04it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9622/9622 [00:03<00:00, 2563.58it/s]
  ******************************************* 
              Running Evaluation                
  *******************************************
 
  Length dataset evaluation: 9622
  Length dataloader evaluation: 2406
  Number of epochs: 3
  Batch size: 4
  ******************************************* 
 
['/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_5d2d45de_2020-02-06_10-08-12i5hw6cve/outputs/checkpoint-3']
INFO:__main__:Evaluate the following checkpoints: ['/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_5d2d45de_2020-02-06_10-08-12i5hw6cve/outputs/checkpoint-3']
INFO:transformers.configuration_utils:loading configuration file /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_5d2d45de_2020-02-06_10-08-12i5hw6cve/outputs/checkpoint-3/config.json
INFO:transformers.configuration_utils:Model config {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 28996
}

INFO:transformers.modeling_utils:loading weights file /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_5d2d45de_2020-02-06_10-08-12i5hw6cve/outputs/checkpoint-3/pytorch_model.bin
HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=2406.0, style=ProgressStyle(description_width='initial')), HTML(value='')))
0.0002150.0003360.0001820.0000800.0000490.0000230.0000180.0000170.0000160.0000160.0000150.0000150.0000170.0000160.0000660.0000180.0000160.0000150.0000150.0000150.0001160.0000200.0001240.0000200.0001770.5786870.0222720.0008381.9237450.0664580.0022290.0000850.0000160.0000140.0000140.0000140.0002240.0000190.0000130.0000130.0001001.7292720.0411870.0009710.0026840.0000720.0021050.0000570.0014510.0000410.8175051.7022320.0327480.0006310.0000340.0000130.0000150.0000140.0002580.0000170.0009570.0000280.0000140.0000140.0000130.0000130.0000160.0000130.0000150.0000130.0000130.0000130.0000130.0000130.0000130.0000130.0000130.0000130.0000130.0000130.0000130.0000140.0000130.0000130.0000130.0000130.0000130.0001310.0000160.0000170.0000140.0000170.0000270.0000190.0039420.0000540.0071190.0061340.0000750.0000140.0000140.0000130.0000120.0047890.0000580.0000140.0000130.0000132.0107920.0186320.8797210.0079390.0000840.0000150.6557290.0105320.0001050.0001800.0000150.0000140.0000130.0005470.0000170.0000130.0000130.0001070.0000130.0000130.0000130.0000130.0000130.0000130.0003060.0002900.1570081.0879320.0080160.0006290.0000290.0000191.8083210.0129540.0001100.0006880.0021130.0000570.0000131.7015820.0120020.0008551.4015350.0093150.1099253.5561631.3538530.0087480.0000690.0000140.0000150.0000150.0000140.0001110.0001110.0000150.0000140.0001440.0000150.0000140.0000130.0000130.0001211.3043640.5190770.5640260.0032540.9921761.2689800.0071820.0001310.0000130.0000140.0000352.4666850.0134920.0003140.0000153.7322102.1614610.0115100.0000750.0700770.0227750.0069340.6542830.0042360.0000350.0000140.0000120.0000130.0000130.0000130.3268350.0016310.0000210.0000130.0000130.0000130.0000140.0000130.0000140.0014180.0000200.0000130.0000130.0000140.0000130.0000130.0000130.0000130.0000130.0000130.0000130.0001160.0000150.0002150.0000170.0000160.0001400.0000140.0000130.0263200.0002210.0006970.0000161.9453980.0082910.0000490.0000130.0000400.0001080.0000130.0000130.0000130.0005730.0000160.0000130.0000130.0000130.0000131.6090010.0064580.0000390.0001200.0001110.0000140.0000130.0000530.0001320.0000140.0002640.5253900.0020250.0000200.0000191.2561262.0240771.3026780.0048920.0000310.0000130.0000130.0000130.0000141.5342200.0057121.3667800.0059820.0000350.0000130.0000120.0000130.0000120.0000120.0000130.0000120.0000130.0000120.0000120.0000131.7794760.0061491.7940260.0061570.0000340.0000142.2611712.1261600.0071830.0000370.0000140.0000122.2557992.3924060.0079080.0000390.1208800.7200730.0023590.0000210.0001250.0000140.0000130.0000130.0000130.0000130.0000130.0000130.0000130.0013070.0000160.0000120.0017710.0000182.0996230.0064930.0001280.0000140.0000130.0001090.0003520.0005970.0003210.0000140.9073440.0028290.0002570.0001090.0001070.0000140.0002080.0001101.4147070.0041510.0000270.0000160.0000150.0000150.0000150.0000150.0000150.0000150.0000150.0000140.0000150.0000150.0000150.0000140.0000150.0000150.0000150.0000150.0000150.0000150.0000150.0000160.0000150.0000170.0001150.0000150.0000140.0000160.0000150.0000150.0000160.0000150.0000140.0000160.0000150.0000150.0000150.0000150.0000150.0001090.0000150.5634420.0020080.0000210.0000130.0000480.0002030.0000140.0002510.0001830.0000150.0000120.0000130.0160080.0000530.0000130.0000120.0000140.0000130.0000130.0000990.0000130.0000120.0000120.0000130.0000120.0000120.0007330.0000140.0002560.0000140.0002170.0000140.0000130.0001800.0002280.0000140.0007570.0030740.0001251.2017651.3205280.0031200.0001590.0000130.0000130.0000120.0000130.0000130.0000130.0002430.0000130.0000130.0000130.0000130.0000130.0000120.0000130.0000190.0000130.0000130.0609291.1434190.0029980.0000200.0004100.0000142.2927980.0052050.0001440.0000140.0000130.0002670.0000130.0000130.0000120.0000130.0000120.0000120.0000120.0000140.0001740.0001530.0000120.0050580.1205040.0002750.0000140.0000130.0000130.0043880.0032550.0000210.0001200.0001320.0000140.0000130.0000130.0000140.0001131.0371550.0073203.3580761.9280461.8103521.7752011.9338843.2633470.0067550.0005420.0000930.0000130.0000130.0025370.0000180.0000130.0000130.0000130.0021790.0003950.0000140.0000130.0000140.0000130.0000130.0119370.0000360.0000130.0001320.0000130.0047860.0096610.0000310.0000120.6643950.0654390.6847920.0013290.0004810.7670800.0022870.0000170.5600010.0010780.0001113.4704200.0065730.0003910.0002700.0000130.0001760.0003202.2458120.0042030.4786600.5125922.7321990.0050740.0000230.0000500.0001430.0000330.5123652.6278230.0049370.0000220.0001260.1933560.0003640.0000131.1740800.0036240.0000200.0006001.1895651.4708520.0026440.0000170.0001430.0000130.0001140.0002410.0001300.0001140.0000140.0000130.0000130.0000130.0001130.0001070.0000130.0002080.0000131.2770730.0022261.1892121.5321210.0026541.0576900.0018940.0000161.0853350.0018680.1297450.0003760.0001090.0001090.0001200.0000140.0001540.0000140.0322110.0003690.0000170.0000130.0001091.5412360.0046990.0011960.3364191.4095870.0028570.1954950.0006110.3561490.0007040.0005140.0003044.3601760.0072550.0000442.6608352.6386020.0043900.0001190.0000140.0001151.9110790.0031180.0000172.0187390.0033440.0000180.0001090.0000132.0052340.0032010.0001130.0000130.0000120.0001110.0000140.0054120.0000210.0001160.0001170.0000193.1286643.9844271.3555530.0104630.0004210.0043040.0031140.0000171.7844350.0027620.0003880.0002190.0000130.0003070.0001080.0000130.0001240.0003200.0005270.0004420.0003820.0001440.0014870.0003000.0011900.0000150.0011460.0000150.0006730.0000140.8952220.0014560.0000160.0000130.0000140.0001481.7540870.0038460.0014300.0003730.0000140.0000120.0000130.0000130.0000120.0000150.0000130.0018330.0000150.0000120.0000590.0000210.0000130.0000130.0000130.0000150.0001000.0000130.0000930.0001090.0000130.0001760.0000130.0001210.0001180.0001080.0000130.0001540.0002430.0001090.0001080.0002220.0000150.0002740.0000140.0001090.0000151.4644620.0020530.0000171.2288500.0041280.0000200.0000140.0001230.0000320.0001080.0002751.3765750.0073750.8014770.0014990.0004000.0006113.5351160.0049250.0000250.0002800.0001501.7116720.0024940.0003821.5586172.6642780.0038092.1538610.0029090.0000580.0000162.3061930.0030890.0000210.0065560.0057590.0045000.0000180.0157690.0000330.0000150.0000120.4841750.0006490.0000130.0000240.0000130.0020000.0000160.0000140.0001540.0000140.0004210.0004290.0004130.0004850.0004200.0004240.0001090.0000190.0000130.0000130.0002110.0000130.0000130.0000130.0000140.0002490.0001100.0001140.0002100.0001100.0019410.0017280.0000160.3392590.0006440.0001130.2570850.0004730.0001311.6722860.2095971.1631082.0791650.0044610.0000390.0085130.4881950.0006171.6587690.2942972.0180220.0025010.0041580.0001820.0000130.0717850.0001000.0600880.0003940.0000130.0000360.1131581.8051311.5666780.0019140.0009890.0000140.0064400.0000200.0015760.0005850.0001200.0002170.0002150.0003580.0005460.0007490.0000140.5752720.0016540.0000150.0010940.0000140.0000120.0000660.0000170.0001230.0001250.0000140.0001100.0002050.0000140.0000130.0000140.0020150.0008170.0010720.0000140.0000120.0000120.0000120.0000120.0000120.0000120.0037930.0000160.0000120.0000120.0000120.0000120.0000120.0000120.0000120.0000120.0000120.0000120.0000120.0000120.0000120.0000120.0000120.0021930.0003604.6108921.3173610.0015010.0008270.0010300.0007830.0005910.0000130.0000130.0000131.6418451.3701160.0015430.0006470.0000892.4825742.1057580.0041350.0005260.0004260.0001470.0002140.0003070.0000150.0012410.0002015.0373563.7192330.0041010.0000190.0000130.0001841.3248780.0015680.0002220.3396830.0008770.0010680.0000141.0298951.5838741.5602010.0019561.7556320.0021401.2861510.6549101.2356760.0016060.0000140.0002691.3560120.0126840.0010670.3759130.0006670.0001240.0000140.0000120.0002220.0000130.0000130.0000130.0000130.0002350.0000130.0000130.0000130.0000130.0000130.0000160.0001410.0000131.5773590.0017020.0000151.9163570.0023700.0001092.0074480.0020970.0000150.0034890.0000160.0027210.0000150.0000120.0000130.0026630.0000160.0000120.0001161.8461302.1896433.1985801.9188102.1584703.0504355.8739310.0087020.0058910.0002900.0000130.0000120.0000120.0000120.0000120.0000120.0000120.0000121.5614450.0015830.0000141.4557181.0058310.0010201.1298610.0011420.0000160.0000130.0000210.0916060.0001310.0000130.0000130.0000960.0001760.0000220.0000800.0000950.0003691.5526860.0019960.0004140.0000140.0018610.0000180.0000130.0001700.0001144.0504243.7859830.0041380.0000160.0000260.0000130.0039260.0003400.0004680.0003350.0003250.0000130.9688751.2729071.0551920.0011270.0005110.0004380.0004520.0000160.0003150.0008950.0018630.0000150.0002070.0000130.8427070.0551880.0000650.0206451.3055130.0012510.0000140.0000120.0214890.0000330.0084750.0040530.4636630.8158470.0007800.0000130.0172210.0001640.0000130.0037040.0000160.0000120.0139290.0001500.0000130.0039800.0000160.4183370.0337420.0000440.2201040.0715870.5668390.7726800.0014522.8325431.1460171.7028210.0017870.0000261.8144220.0037441.5258090.0937790.0004120.0001170.0003261.4453320.0014230.0014910.0001240.2164650.0040620.0001650.0036720.0481290.0002420.0000130.0005320.0004940.0004621.6929950.0015380.0000140.0000130.0000130.0000121.2533040.0254951.8993820.0018340.0000140.0001580.0000130.0000120.0039910.0000160.0000120.0000120.0000110.0001510.0000120.0000120.0006200.0006390.0001500.0001510.0000120.0000120.0000120.0000120.0000120.0063330.0000180.0000120.0000120.0000140.0059510.0010090.0004480.0027110.0002410.0003060.0028970.0001430.0002360.0000132.5385441.9237152.9595110.0027690.0001091.6620350.0030080.0002070.0001070.0000130.0000130.0000120.0000130.0000130.0000131.1639670.0010070.1323270.0002600.0001800.0002420.0000130.2479010.0002230.2395180.0002200.2046610.0001860.0001470.0000130.0000120.0000130.0000120.0000120.0000130.0000120.0010780.0000140.0000130.0000130.0000131.4567120.0012280.0007350.0000130.0000120.0000130.0212270.3378960.2314990.0209920.0000320.0000130.0000130.0000130.0002520.0004360.0000150.0000140.0000130.0001530.0002890.0000663.5263773.4277451.8679300.0017380.0002800.0002080.0002970.0010220.0006360.0000130.0020720.0006720.0000140.0007410.0000130.0000120.0000120.0000130.0000130.0024810.0000140.0000120.0017560.0019020.0013600.0001090.0000130.0000140.0000130.0001160.0000140.0000130.0000140.0001130.0000130.0000130.0000130.0000130.0000140.0001240.0000130.0000140.0001220.0000130.0000140.0001090.0000130.0000140.0000130.0000120.0001750.0000130.0000120.0001180.0000150.0014960.0000140.0000144.1734170.0044590.0008550.0111810.0019392.4460915.6425151.4902983.4444662.1291993.1608730.0029401.2147340.0028381.4211260.0062260.0084960.0004460.0009070.0004920.0005080.0007060.0004960.0050471.1675940.0014730.0001170.0004480.0002980.0005910.0004400.0003850.0004020.0001771.5804410.5059921.0976191.1317401.4928870.0170070.0000260.0000130.0000130.0000130.0001070.0000130.0000130.0005520.0005850.0000142.6556501.6339770.6284020.3892680.0153980.0004950.0181300.0006520.0000130.0013740.0003220.0032710.0000150.0005130.0014040.0000140.0022450.0000150.0000130.0008400.0000140.0000130.0001170.0008400.0000130.0000130.0000120.0000130.0000130.4182051.4827920.0402500.7892010.0822430.0000730.0000140.0000120.0000880.0000170.0000130.0001030.0000120.0000130.0000120.0000120.0002000.0000180.0000130.0000120.0000120.0004190.0000130.0000130.0000150.0000120.0000880.0001370.0000130.0000130.0000130.0000870.0000120.0000120.0000130.0000120.0002140.0002190.0016140.0022560.0002040.0039100.0001300.0005620.0044230.0002120.0002860.0003260.0004120.0001213.6783643.0234747.1912044.2033994.4697335.4360530.0041080.0006990.0005980.0017260.0000130.0161110.0000240.0321140.0001560.9390780.0311710.0000340.0629710.0004730.0002160.0004290.0003170.0002110.0068550.0003340.0003460.0004060.0003510.0004280.0001090.0003130.0001310.0000300.0033190.5712200.0017710.0000860.0009270.0015741.3592980.0012910.0000150.0002250.0010640.0004790.8324460.0013480.0007800.0000200.0004110.0005700.0001080.0006140.0001120.0003910.0001160.0004564.4612730.0506880.0004450.0004410.0005250.0003860.0002910.0000130.0001650.0056220.0000170.0001140.0000130.0000130.0000120.0005040.0000130.0000130.0016880.0000140.0018610.0003100.0000140.0001060.0000130.0000130.0000120.0000132.2392050.0017280.0004504.2176424.6424664.3358352.2952950.8899164.4112234.5756054.4980324.5997351.9698560.0021410.0023410.0009870.0006810.0024290.0013610.0001130.0013640.0011710.0002171.7411153.2762090.0033180.0003010.0006040.0005520.0011380.0012140.0017940.0007990.0010491.5260130.0037930.0001100.0002910.0000130.0058970.0002150.0000130.0000130.0000130.0000130.0000120.0000130.0000130.0000140.0001181.2284570.0008121.7858680.0011681.8026850.0011790.0001220.0197560.0026541.9479851.7415050.0012451.9505255.8023768.0135548.2872166.0696360.0039060.0000160.0015471.1352240.7860070.0005150.0000130.0004560.0002590.0002090.0002120.0002000.0006380.0002010.0003040.0002050.0001110.0002080.0004430.0002010.0017870.0007950.0001961.0963670.3750430.6779770.0008030.0001101.9205100.0014220.0001092.3492480.0016842.3074954.2514220.0029531.9190161.9525790.0013311.9761720.0013463.9040030.0026620.0001260.0005243.2221380.0022470.0059520.0001420.0002290.0000130.0003520.0010640.0001790.0000130.4517140.0005490.0002250.0000130.0001070.0001080.0001130.0000162.1209820.0013214.2479402.1283140.0013232.1271652.1157113.9142254.2552204.4726762.3589672.1477800.0016150.0086950.0001441.7094350.0011520.0000140.0002040.0000140.0001060.0000130.0000130.0000131.7547330.0010780.0000151.6265790.0009980.0000130.0000130.0000120.0000130.0001218.9763495.8729002.3371890.0017671.3656790.0008350.0006030.0000150.0000131.1416590.9438270.1054800.0040780.0021030.0250770.5481670.0073910.5711250.0144130.0000210.0000130.0017711.7698100.0010661.5775340.0009510.0000130.0032071.5922810.0009570.0000130.0000120.0000130.0000120.0000130.0003190.0005160.0004410.0005360.0002670.0002080.0031450.0003170.0009590.0010600.0002060.0002230.0032010.0000150.0017350.0001110.0003131.0671570.0007702.2955540.0017371.0412170.7030980.0004371.1226550.7111020.6749690.0006690.0000150.0000140.0000130.0003370.0000140.0002000.0002010.0002980.0002500.0003210.0003620.0003030.0003060.0001070.0002000.0001060.0001080.0000140.0001170.0000150.0000130.0002160.0002060.0001120.0001170.0002390.0001120.0001150.0001100.0000130.0002160.0001120.0030130.0000150.0005510.0002230.0002210.0000130.0002150.0000140.0000200.0000130.0000150.0000150.0000140.0003320.0001150.0000130.0006020.0000140.0001090.0000140.0000140.0001240.0000140.0000140.0002120.0002260.0001330.0001101.7341410.0009880.0000130.0000150.0000130.0000120.0000130.0000140.0000130.0002080.0000130.0003740.0000130.0000130.0000120.0000130.0001280.0001380.0000130.0001330.0000130.0000130.0000130.0003760.0003640.0003690.0014880.0002090.0014161.1514424.0319140.0074470.0781750.5424971.4287170.0011170.0001810.0001950.0004240.0000870.0001920.0002190.0001870.0003230.0002100.0001960.0013450.0003130.0000140.0001780.0001770.0002201.5317800.0009520.0002140.0006220.0032070.0006480.0004943.9007020.0026901.5468563.7364501.4734192.8317440.0016381.2631270.0015010.4938890.0011700.0004990.0001150.0003050.0007040.0002040.0003040.0004960.0002760.0003060.0004820.0002010.0004010.0002000.0002160.0001100.0000130.0000120.0000130.0001940.0006490.0003510.0001980.0000130.0000130.0000130.0000130.0001580.0000130.0000130.0000130.0000130.0000130.0000130.0000130.0000130.0000130.0000160.0002350.0000132.0755220.0011110.0000130.0003890.0001970.0007350.0007780.0037530.0002770.0001060.0004110.0037240.0002280.0176990.0000220.0000130.0033740.0020921.3031110.0068903.3028904.8839731.8685594.3802131.5401200.0045020.0002170.0001090.0001100.0001620.0000120.0731620.0000510.0000130.0000120.0040340.9959630.0005300.0002040.0000150.0001250.0079040.3203290.0202460.0000230.0897030.0029690.3987060.0034800.0017170.0016470.0028350.0081580.0065020.0110010.0964620.0000620.6443280.0008330.0009520.0004921.4190641.5856790.0016223.4183481.4002322.4163231.3556502.6809341.4988380.0012510.0001210.0001220.0002530.0004060.0002410.0006020.0003870.0004300.0004880.0004260.0003330.0016680.0004440.0002350.0002320.0004460.0019390.0000140.0020580.0000130.0000130.0000120.0000120.0000120.0000130.0000120.0035191.0506310.0005410.0000130.0000130.0000130.0023310.0024450.7690340.0056280.0000150.0000120.0001201.4525383.2771610.0023061.5294601.6130223.0879250.4353740.0028760.0028710.0000230.0032710.0064480.0076681.2374400.0061640.0037400.0001090.0001390.0000130.0001110.0000120.0000130.0013080.0002510.0002320.0015660.0002060.0000130.0000120.0000132.3649890.4929721.6103623.3168763.0153180.4427460.0083500.0010920.0011983.1706360.4359950.0002270.0000132.0375102.0499980.0010173.7934692.1666430.0010720.0000142.2989800.0011350.0016940.0000140.0000130.0000130.0001350.0000130.0009840.0000130.0017670.0060870.0000160.0000120.0008730.0007900.0000260.0006650.0000340.0006900.0000131.0528190.3763050.0032620.3610650.1352050.0010230.6018850.8263660.0090230.0005590.0004390.0016120.0003280.0001261.3973411.7308110.0008433.2912170.0016885.1139065.4790050.0031443.0963030.0019280.0004312.2588401.9356451.8859460.4873331.9383260.0028000.0007301.0312070.0005030.0080220.0001710.0000130.0000130.4160400.0002100.0000130.0000420.4881100.0230162.1221890.8943370.0568040.0000390.3561250.8395611.6125030.0007731.7347440.5524990.0131300.0037371.1264760.0006970.0003920.0199790.0106161.5845192.8002080.0013270.0143820.6458290.1142520.0056101.6617490.3851990.0066640.0015070.0001320.0005440.0000130.0073820.9247510.0007770.0002770.7764370.0019410.0180500.0011900.0003020.0003820.0009400.0005590.0002200.0002800.0002880.0000130.0020680.0044481.5921400.0007560.0001180.0000130.0002170.0001230.0003280.0001140.0002330.0003040.0001140.0001180.0002200.0003540.0004020.0000140.0000130.0004650.0003050.0002010.0002040.0002050.0001120.0001170.0002080.0001130.0000120.0000130.0000130.0063520.0000150.0000120.0119030.0000180.0000120.0000130.0000130.0000140.0000120.0000130.2583020.0001300.0000120.0176150.0000200.0000130.0000130.0073010.0000170.0000120.0003500.0006620.0001960.0000410.0000130.0000140.0000130.0083300.0000170.0043360.0000150.0023330.0000130.0000130.0000130.0000120.0000130.0000130.0000130.0000120.0249270.0000240.7869160.0004650.0000130.0000120.0000120.0003110.6113620.0002860.0000130.5171740.0002430.0000480.0001360.0008600.0009570.0009470.0003090.0003430.0003820.0003040.0005360.0006080.0015243.7924345.7975904.9550181.1138260.0026960.0000130.0017170.0006130.0003670.0005000.0007030.0004140.0005450.0000131.1469760.3560470.0002751.0357390.0004680.0026940.0000140.0000130.0002280.0003100.0042730.0000150.0026450.0025460.0041460.0001320.0001230.0001232.0111120.1922000.0151830.0001340.0828280.0003940.0004440.0005030.0008650.0003990.0045080.0017770.0000150.0001780.0003380.0004830.0000142.2454991.9853340.0008740.0001280.0000131.5522040.0006850.0001130.0000130.0000140.0001440.0002170.0010810.0005270.0001180.0012360.0000130.0000130.0019560.0000150.0001900.0001120.0005450.0018510.0004770.0205460.0002370.0009760.0001260.0001310.0003440.0000130.0035520.0000150.0010110.0000130.0013830.0001154.3393190.0030462.7504981.9881660.0008595.0358900.0024870.0045710.0103730.0049060.3170620.0007890.0102040.0041800.0061490.0815350.9946390.1432840.0636960.0000391.0223921.0157150.0046841.0997700.0030920.0032206.8037706.1497255.6875881.2887340.0015290.0021460.0005580.0003550.0000130.0001490.0001320.0001650.0002260.0002070.0001090.0006590.0002430.0002200.0001200.0005420.0002160.0003280.0001080.0001210.0001970.0000120.0000130.0001220.0002120.0001130.0000120.0002040.0000130.0002140.0001100.000012

*******************************************
EVALUATING PIPELINE 
Pipeline directory: /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_5d2d45de_2020-02-06_10-08-12i5hw6cve/
With following parameter combination: {'batch_size_seq_length': 1, 'lr': 3e-05, 'lr_type': 'cosine'}
EVALUATION OF CHECKPOINT /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_5d2d45de_2020-02-06_10-08-12i5hw6cve/outputs/checkpoint-3
-------------------------------------------------------------
|           |   agree   | disagree  |  discuss  | unrelated |
-------------------------------------------------------------
|   agree   |    511    |    53     |    112    |     7     |
-------------------------------------------------------------
| disagree  |    44     |    56     |    46     |     2     |
-------------------------------------------------------------
|  discuss  |    202    |    50     |   1627    |    29     |
-------------------------------------------------------------
| unrelated |     5     |     3     |    15     |   6860    |
-------------------------------------------------------------
Score: 7210.25 out of 7516.5	(95.92563028005056%)
Accuracy: 0.9409686135938474
F1 overall: 0.735423100615544
F1 per class: [0.7072664359861591, 0.36129032258064514, 0.877562028047465, 0.9955736158479065]
*******************************************


*******************************************
EVALUATING PIPELINE 
{'batch_size_seq_length': 4, 'lr': 3e-05, 'lr_type': 'cosine'}
INFO:__main__:Creating features from dataset file at /home/ubuntu/fnd_implementation/data/processed
  0%|                                                                                                                                          | 0/9622 [00:00<?, ?it/s]  0%|                                                                                                                                | 1/9622 [00:03<8:14:15,  3.08s/it] 21%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                                                                                   | 2001/9622 [00:03<4:34:03,  2.16s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                            | 7501/9622 [00:03<53:23,  1.51s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9622/9622 [00:03<00:00, 2590.75it/s]
  ******************************************* 
              Running Evaluation                
  *******************************************
 
  Length dataset evaluation: 9622
  Length dataloader evaluation: 301
  Number of epochs: 3
  Batch size: 32
  ******************************************* 
 
['/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_7edf2f2c_2020-02-06_13-31-55200549bj/outputs/checkpoint-3']
INFO:__main__:Evaluate the following checkpoints: ['/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_7edf2f2c_2020-02-06_13-31-55200549bj/outputs/checkpoint-3']
INFO:transformers.configuration_utils:loading configuration file /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_7edf2f2c_2020-02-06_13-31-55200549bj/outputs/checkpoint-3/config.json
INFO:transformers.configuration_utils:Model config {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 28996
}

INFO:transformers.modeling_utils:loading weights file /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_7edf2f2c_2020-02-06_13-31-55200549bj/outputs/checkpoint-3/pytorch_model.bin
HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=301.0, style=ProgressStyle(description_width='initial')), HTML(value='')))
0.0008970.0011890.0008760.3603760.0904340.0196050.1732100.0287000.0038780.0006680.0027220.0015090.0037650.1184230.0086610.0009040.0017560.0004170.1070680.2937370.0154510.8909770.3058840.8178340.0827790.0036170.0003110.0001830.0006260.0023700.0012900.0015330.0013320.3842850.1788270.0052250.1177740.5820770.0517110.0017500.0892560.0347070.0205870.0005790.0001240.0002290.0001340.0001740.1596800.0068010.0002790.0595530.0861340.0210300.0006850.0017920.2505600.0045590.0023840.0051440.0360460.0523290.0014140.0005360.0130530.0452680.3870140.1933640.4349410.5510900.0085590.0004160.6243410.1848530.2230570.0086670.1903500.3752800.1677780.0026860.0236280.0035710.0288170.0034920.0017280.0013950.0002360.0005320.0008870.0788680.0143310.9006370.4099380.0466430.2359740.2158580.0034780.0005530.1311420.0852860.3335630.2639430.3598380.0507770.0591580.0371380.0017560.0002990.1387170.0013770.0553190.2536270.0037790.9109820.0092670.3435850.5571710.1765250.0016850.2629260.1785840.1864110.9970200.0082740.0306990.0006150.0028810.3429080.2578110.1725740.0047010.0783480.1868160.0170340.1362510.8585100.2481040.6379790.5379410.5999780.1483430.0309390.0060990.0113110.4359420.1959550.4593800.3962440.0030600.0218280.0128250.0019971.6246650.0122490.1651150.0496050.0006540.0004170.0003530.3833771.1261430.2687830.0039430.0018650.3787580.0052210.0230240.0036510.0007350.0258770.0069940.0002340.0410730.0025960.0905710.8806592.6606030.0901340.0439740.0018060.2104770.4209440.5966740.1345540.0013430.0015500.6136552.4113360.4537820.4062140.2029060.0028930.1642390.3511780.9929540.0117100.0012400.0262890.4049671.1173560.5192950.0065370.2129922.7849700.6639290.1417350.3028490.2562340.6337990.2541630.1929030.1300200.0044590.2187750.4619770.0030670.0009790.0010350.0007660.0005900.0015790.0006790.1062020.0009100.0004880.1729530.3820310.0035840.0018100.4084860.1717530.0043120.0023520.0007910.0002620.0021510.0094090.0011821.7703930.2063160.0119040.1446790.0600640.4032860.6149850.0050060.0039890.0013550.0127010.1577650.1575030.4432070.0200930.3584211.3039000.9887830.2271620.0216320.2952650.0725130.1381351.0634940.1085290.0014210.0771670.0877730.0318740.3399790.3777810.0266830.1745410.0014180.0009030.0005740.0027900.0606010.0065680.0023770.0001440.0021090.0084790.0012561.6333210.0326350.0221420.0096320.2792990.1903560.3506470.0018310.0013600.0066870.0031130.3934030.1823750.2390430.2638420.0021840.0016800.0014540.001387

*******************************************
EVALUATING PIPELINE 
Pipeline directory: /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_7edf2f2c_2020-02-06_13-31-55200549bj/
With following parameter combination: {'batch_size_seq_length': 4, 'lr': 3e-05, 'lr_type': 'cosine'}
EVALUATION OF CHECKPOINT /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_7edf2f2c_2020-02-06_13-31-55200549bj/outputs/checkpoint-3
-------------------------------------------------------------
|           |   agree   | disagree  |  discuss  | unrelated |
-------------------------------------------------------------
|   agree   |    568    |    49     |    118    |     4     |
-------------------------------------------------------------
| disagree  |    16     |    68     |    28     |     3     |
-------------------------------------------------------------
|  discuss  |    175    |    43     |   1633    |     7     |
-------------------------------------------------------------
| unrelated |     3     |     2     |    21     |   6884    |
-------------------------------------------------------------
Score: 7255.25 out of 7516.5	(96.52431317767578%)
Accuracy: 0.9512575348160466
F1 overall: 0.7844360637148662
F1 per class: [0.7568287808127915, 0.49097472924187724, 0.8928376161837069, 0.9971031286210892]
*******************************************


*******************************************
EVALUATING PIPELINE 
{'batch_size_seq_length': 3, 'lr': 3e-05, 'lr_type': 'cosine'}
INFO:__main__:Creating features from dataset file at /home/ubuntu/fnd_implementation/data/processed
  0%|                                                                                                                                          | 0/9622 [00:00<?, ?it/s]  0%|                                                                                                                                | 1/9622 [00:02<7:33:31,  2.83s/it] 21%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                                                                                   | 2001/9622 [00:03<4:11:28,  1.98s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                                            | 5001/9622 [00:03<1:46:44,  1.39s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                            | 7501/9622 [00:03<34:17,  1.03it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9622/9622 [00:03<00:00, 2634.58it/s]
  ******************************************* 
              Running Evaluation                
  *******************************************
 
  Length dataset evaluation: 9622
  Length dataloader evaluation: 602
  Number of epochs: 3
  Batch size: 16
  ******************************************* 
 
['/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_7c38625c_2020-02-06_12-52-200c2rox5v/outputs/checkpoint-3']
INFO:__main__:Evaluate the following checkpoints: ['/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_7c38625c_2020-02-06_12-52-200c2rox5v/outputs/checkpoint-3']
INFO:transformers.configuration_utils:loading configuration file /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_7c38625c_2020-02-06_12-52-200c2rox5v/outputs/checkpoint-3/config.json
INFO:transformers.configuration_utils:Model config {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 28996
}

INFO:transformers.modeling_utils:loading weights file /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_7c38625c_2020-02-06_12-52-200c2rox5v/outputs/checkpoint-3/pytorch_model.bin
HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=602.0, style=ProgressStyle(description_width='initial')), HTML(value='')))
0.0001420.0022520.0011820.0004630.0001620.0001350.4312780.5203860.0650960.0073540.0008410.0002080.5751500.0442890.0032400.0003430.0000810.0000680.0000870.0000550.0003140.0000960.0001270.0002180.0007150.0001220.0000820.3944910.0141340.0005790.0000970.0001030.0000490.0019850.0001170.0653000.0019360.2600590.7763330.0199660.0006180.0001600.8685851.2367030.0284740.6294631.6375850.6718000.0243240.0005570.0001040.0001110.0000980.0000510.0000510.0000700.0001040.0001710.2840670.0048800.1023280.0017240.4559810.0076720.4397090.1770131.0695180.0160120.0014830.0004420.0000670.0000510.5568510.3206940.2583370.8077650.1461420.0020150.0000650.0134550.3043050.0038190.0006010.0014310.0001530.2035090.0024140.0000770.0000460.0000510.0000460.0000820.0000480.0000460.0000500.0000700.0000750.0009440.0000670.0004710.0000610.0000490.0000610.0181400.0840860.4668380.3667000.0048310.0001620.0000540.0003030.0005120.5573350.0050640.0000970.0000450.0002870.0001860.0007370.0001120.0011520.0577030.9465270.1894640.0017370.0002110.0000480.0003190.0015550.0020980.0001610.0002660.0011090.2892020.6619270.4667730.5789870.3948240.4324560.6173810.0045630.0001550.0000700.0000980.3496780.0362600.0059800.0001730.0002900.5566840.2593510.0021500.4866660.6313230.0042010.9593450.0062430.4741760.0030660.0003310.0277490.0007560.0008520.0001370.0013710.0005610.0003300.0002640.0000730.0016160.0000620.0001760.0000760.0000490.0001470.0001010.0001220.0002210.0001810.1105130.0017610.0001162.9659221.0789310.0994380.0296680.4127440.0031640.4631440.9346331.2123310.0066250.0002740.0003770.0000720.0000870.0001390.0048520.0003420.0075260.2474320.0017620.0008990.2872400.0390640.3900550.1117110.0008790.0003070.0147380.1757570.0009590.0004630.0005080.0000950.0000430.0425520.0002370.0000420.0000401.4042320.7130070.0033990.7625730.0038100.0002940.0002752.5855370.0115360.0006591.5997391.6399791.3646030.5080850.3792380.0017290.0000800.0000520.0010100.7310530.5281330.0130510.0046080.8529473.2390572.1092000.0086440.0000860.2325520.0066510.0000720.0000470.0002700.0003000.0000510.8798860.4349570.0020890.4152200.6945590.0029850.3208770.1045990.4934580.0344250.0610790.0005940.0003980.0002280.0043810.0138111.5686280.0108750.0009100.0020751.0051680.6970180.5065080.0018672.1299380.0077650.4702130.0017540.0004000.0000570.2471300.0029880.0069120.0004100.6793560.3191190.0011751.1266160.2396520.2668780.6043470.0021300.0000580.0001770.0009990.0003770.1948960.0007370.0001411.6688902.2238230.0079290.1457240.0005870.0003510.0197400.0001620.0026700.0000940.0000920.0000900.0001370.0000950.0001762.5585663.4164491.6497490.0083330.0013830.0172750.0004980.0003020.0008870.6127810.0029340.5093470.0019710.0012640.0006520.0014160.0003670.0000900.0001090.0000460.0072350.0035130.0004420.0000470.0896540.0003310.0014680.0001680.0000490.0024600.0014160.0077531.8937925.9551160.0171500.0007130.0009370.0015290.0002830.0002940.0001810.2985830.5384752.7138342.7893480.0092510.0331470.5828720.0018610.0005420.0004560.0002100.0008290.0000471.2426682.0974283.4907281.4742921.3334501.0238750.7773410.0024440.5492650.0315910.0001980.0000460.3746980.5677900.0055880.2914040.0172940.0004340.0001630.0002740.0002210.0003580.0028120.3375060.5469681.7429770.3681580.9788110.3388440.0089700.0020840.0002680.5152332.0438246.2526183.2348470.0080770.0001300.3057170.4362850.0011491.7817050.4701021.3352810.6325590.3894110.2293180.0209660.0009410.0000850.0343400.0457750.2866410.0018480.9230880.9255240.6966020.0017650.0001930.0002550.0001370.0001670.0002750.0002420.0004400.0002260.0001640.0454170.0004950.0001130.0002180.1076170.0002910.0000500.0001550.0000730.0000990.0002770.0011911.3835730.5410280.0014540.0002930.0002820.0003010.0005820.0010280.0006530.0006880.0004540.6325231.1671910.5760210.0013220.0003030.0001280.0000460.0000780.0001040.6880010.0016600.0002200.0001240.5034434.0161470.5005530.0012370.0000970.0003910.3599070.0016830.3696450.0059380.0012020.9401481.5017230.0044050.0003360.0004170.0006960.0004580.0007920.0000480.0007840.0004070.0028921.4513081.8528960.2610111.3072900.1834300.0005090.0006980.0552440.1480550.3936421.1380700.9508501.3802040.4948470.4108020.0323640.0005410.0002160.8872120.4720090.0495870.0011530.0013911.3273290.2891880.1808570.0030700.0001840.0001900.0039760.4137290.0015610.2779950.0902000.0084061.4298240.0028960.3500050.6149500.0123810.0012500.5252380.0010880.0001670.0002130.0001560.0002280.0001740.0000890.0191980.0000860.0333770.3485380.0015290.0004420.0001620.0001500.0000500.0000570.0002760.0000770.0009760.0083930.0003960.0002825.0608920.0102700.0005320.0113430.0007410.0004460.0003920.0002910.4829600.0553080.2058520.1563080.7419450.0015940.0000700.0003290.0001760.0002530.0220970.0002350.0003840.0231951.1173510.0899790.0610310.0416270.3361620.2167470.2360790.4417390.2911890.0008360.0003310.0003770.0001430.0001930.0001680.000116

*******************************************
EVALUATING PIPELINE 
Pipeline directory: /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_7c38625c_2020-02-06_12-52-200c2rox5v/
With following parameter combination: {'batch_size_seq_length': 3, 'lr': 3e-05, 'lr_type': 'cosine'}
EVALUATION OF CHECKPOINT /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_7c38625c_2020-02-06_12-52-200c2rox5v/outputs/checkpoint-3
-------------------------------------------------------------
|           |   agree   | disagree  |  discuss  | unrelated |
-------------------------------------------------------------
|   agree   |    592    |    31     |    124    |     2     |
-------------------------------------------------------------
| disagree  |    12     |    76     |    39     |     8     |
-------------------------------------------------------------
|  discuss  |    153    |    55     |   1602    |    15     |
-------------------------------------------------------------
| unrelated |     5     |     0     |    35     |   6873    |
-------------------------------------------------------------
Score: 7232.25 out of 7516.5	(96.21831969666734%)
Accuracy: 0.9502182498441073
F1 overall: 0.7936318039383778
F1 per class: [0.7835870284579749, 0.5117845117845118, 0.8838620689655172, 0.9952936065455072]
*******************************************


*******************************************
EVALUATING PIPELINE 
{'batch_size_seq_length': 2, 'lr': 3e-05, 'lr_type': 'cosine'}
INFO:__main__:Creating features from dataset file at /home/ubuntu/fnd_implementation/data/processed
  0%|                                                                                                                                          | 0/9622 [00:00<?, ?it/s]  0%|                                                                                                                                | 1/9622 [00:02<7:33:46,  2.83s/it] 21%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                                                                                   | 2001/9622 [00:03<4:11:37,  1.98s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                            | 7501/9622 [00:03<49:01,  1.39s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9622/9622 [00:03<00:00, 2512.31it/s]
  ******************************************* 
              Running Evaluation                
  *******************************************
 
  Length dataset evaluation: 9622
  Length dataloader evaluation: 1203
  Number of epochs: 3
  Batch size: 8
  ******************************************* 
 
['/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_797633aa_2020-02-06_12-52-16ai51o2n2/outputs/checkpoint-3']
INFO:__main__:Evaluate the following checkpoints: ['/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_797633aa_2020-02-06_12-52-16ai51o2n2/outputs/checkpoint-3']
INFO:transformers.configuration_utils:loading configuration file /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_797633aa_2020-02-06_12-52-16ai51o2n2/outputs/checkpoint-3/config.json
INFO:transformers.configuration_utils:Model config {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 28996
}

INFO:transformers.modeling_utils:loading weights file /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_797633aa_2020-02-06_12-52-16ai51o2n2/outputs/checkpoint-3/pytorch_model.bin
HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=1203.0, style=ProgressStyle(description_width='initial')), HTML(value='')))
0.0001830.0002340.0001480.0000730.0000360.0000310.0000270.0000750.0000290.0000350.0000430.0000540.8650990.0665601.1291990.0752930.0047190.0002910.0001170.0000190.0015900.0000900.0012400.0001840.0002121.5400620.0592480.0022090.0001220.0000390.0001370.0000190.0000270.0000150.0000300.0000150.0000140.0000150.0000140.0000140.0000150.0000180.0000150.0000420.0000560.0000210.0000310.0002630.0004520.0000300.0000160.0000550.0000160.0000140.1800600.0033080.0000740.9642870.0448640.0007750.0000500.0000150.0000390.0000150.0000150.0000160.0003930.0001520.0000170.0000240.3090030.0043930.0001630.0000210.0000330.0000151.8235440.9588520.0123090.0001700.0003210.0001480.0004140.0000200.0000142.0830511.9726760.9230110.5593110.0063790.0000851.1217920.0133713.6333080.0386922.0913490.4401690.0049240.0000700.0000160.0044950.0000590.0000140.0000190.0001780.0003510.0000170.0000160.0000160.0000140.0000150.0000520.0000840.0000390.0000140.0001040.0000500.0000360.0000200.0001170.0000150.0000840.0000140.0000130.9019530.0072320.0001360.0000220.9346550.0072940.7021010.0053732.0625740.8977440.0067130.0000640.0008211.1499790.1041030.0007630.0000190.0000130.0000140.0000150.0118840.0182720.0001390.9696220.9372970.0063040.9699080.9905370.1064990.0042130.0000670.0000150.0000150.0000140.0000150.0002050.0009041.1941240.0074070.0000600.0002401.0979450.3532850.0022140.0000840.0000810.0343270.0002140.0000160.0000140.0000140.0000140.0000150.0000150.0000140.0000170.0000150.0000150.0000140.0000590.0000150.0000150.0000160.0000150.0000170.0000140.0000140.0000530.6909370.0035940.0000390.7929660.0040600.0000520.0200060.0001150.0000370.0000520.0000170.0000290.0000200.0041650.0001150.0008700.0033020.0003230.0006621.0932911.0253550.0050670.0000370.0000140.0000910.0000140.0001570.0000140.0001070.0000150.0017640.0004750.0001971.0887520.0048820.0000640.0000160.0000140.0000140.0000150.0001840.0002580.0001590.0000680.0001620.0001190.0000710.0000250.0002290.0010920.0012800.0007210.5978150.0045230.0001750.0000140.0001680.0000140.0001240.0000810.0000150.0000130.0000810.0000530.0002350.0002840.0004340.0006170.0000410.0015800.3950440.0015440.5381520.0020890.0000530.8422010.8853252.7044950.0100340.0001340.8878691.2503640.0046500.7029650.8283240.0030462.0835230.5451640.0023070.0000490.0000930.0000390.0000130.0000430.0000380.0000530.3607130.8784800.8239580.0031190.7546840.0070310.0000930.0000440.0000850.0001560.0000311.0983070.0038683.7181110.0127560.0003450.0001780.0880020.0030440.0243220.0001530.0000481.1564881.1749190.0038090.0000641.1616420.0037230.0000620.0000210.0000910.0000430.2330360.6877270.0023040.0001390.0009210.0001310.0000800.0042790.0011770.0005320.0000810.0000930.0000880.0001150.0000470.0001060.0000170.0000470.0001940.0001270.0000140.0000130.0000140.2691550.0007960.0000160.0000140.0000140.0001260.0001690.0000370.0000380.0000600.0049030.0001820.0002560.0002170.0001130.0267000.0000880.0053100.0000280.0000370.0000551.7449270.8395670.0027880.1304600.0003870.2561200.0007430.8226930.0030700.0000540.0002770.0000180.0049101.1197442.2742460.0060183.0038080.0079090.0006130.0000150.0001600.0002710.0002540.0002760.0002470.0000140.0015270.0000180.0000840.0001330.0001200.0001200.0002640.0000770.0005100.0066310.8964790.0034270.3705340.3800420.8226440.0020530.4939620.0018450.0005040.0000530.0005685.2898040.0129570.0090250.0003280.0002130.0000940.0002700.0002010.0004580.0005500.0000150.0000350.0140670.0001940.0002880.0000140.0002070.0000490.0000130.0000130.0000140.0002050.0000140.0000140.0000140.0000130.0000130.0000140.0000130.0001160.0990600.0026230.0008400.0001800.0000140.8696850.8551410.0021310.0002290.0008710.0001660.0000940.0001113.3463502.2137240.0048940.0000750.0000720.0004790.8176862.4413571.8711201.5715951.8623681.0475860.0023081.0341590.8181130.0238260.0000640.7384180.0015780.0000960.0000140.0000130.0280810.0001281.1720811.1822410.0025451.2083410.0090580.0004780.0000150.0005590.0000152.0923364.2183134.2472775.3098270.0117860.0000650.0000140.0000150.0000150.0000690.0000140.0001260.0001180.0000140.0000150.0004010.0000150.0005080.0000150.0002840.0022670.0000180.0000360.0000153.1690622.0902800.0040880.7542680.0016260.0001610.4971351.7041600.0035000.0005620.0004380.0041710.0000741.4605640.0085791.0514200.0020090.2899790.0008280.2046790.6672450.0018850.0000750.0004410.0002540.0000660.0035480.0375820.0375530.0026090.1412141.6377670.0034240.0003142.4093140.9349950.0018840.1401020.0016041.9317020.9748842.0318660.0038640.0003191.1810770.0021390.0000242.3583312.2351960.0040290.0000221.1868300.0021210.0000910.0000140.0001200.0001670.0000140.0000130.0000250.0000140.0000140.0025760.0011720.0007370.9200470.0018022.1293891.1703511.2071050.4134930.0007560.0000180.0000192.5446870.8562290.0017440.0000900.8914070.9381010.8634250.0015400.0000660.0000170.0000170.0001920.0000140.0005590.0000910.0000140.0005510.0007920.0002610.0000200.0000940.0001540.0000570.0000843.0280314.0607830.0067840.0001290.0003920.0001560.0001170.0000590.0000180.0000160.0002720.0001630.6207950.0010440.0000170.0000590.0000180.0001230.0000180.0000150.0000760.0001430.0000230.0000500.0000140.0004870.0000150.0001360.0062751.9543980.0054160.6684674.0118272.6483331.8521260.0053950.3880141.2724230.0021900.0002440.0010800.0007350.0001470.0001440.0001440.0001120.0002810.2196530.9922390.0020990.0000170.5961940.0009150.0003910.0002700.0002340.0013890.0006000.0002130.0007440.0001210.0059510.0003100.0000220.0015080.0000560.0015000.0000170.0000130.0012890.0020570.0288710.0000750.0017430.0003700.0000180.0000130.0002350.0000140.0000170.0000140.0000140.0028040.0000180.0053290.0000210.0000160.0000990.0006670.0006870.0005370.0002380.0001730.0002580.7630533.3245755.9984210.0086570.0002380.0001460.0001820.0006410.0002080.0037700.0001650.0001640.1102400.0003190.0002310.0001360.0000810.4689950.0008110.0010580.8856361.0726545.3092873.5043652.8479100.9283570.6419470.0201830.7999360.4456630.0008690.0002690.0001170.0002180.0000660.0000140.0001410.0000140.0001240.0023120.0000700.0000140.0000250.9860421.8519713.6738600.9954653.5726933.7740492.6770202.8562632.5475521.9261251.9360450.6696320.7723050.0011470.0001560.0001260.0001140.9241250.0021530.0701210.0003600.0000190.0000130.0000130.0000400.9563331.1729400.8445260.0013910.0054270.0008070.8415313.0283971.4676230.0022050.0004490.0000150.0002100.0001330.0001330.0001180.0000980.0002170.0003580.0005990.0041860.0022211.1956550.0015851.2229743.6408941.1571231.1570171.1667912.3717430.0428680.1324900.1669000.0002740.0001400.0001160.0013970.0000970.0000990.0000491.1405363.3542081.1116253.3901993.5622413.1314450.0039660.0002070.0000410.0000740.0000380.0000170.1982680.3540200.0004720.0000280.0001120.0453290.0023330.9844780.0016010.8741821.8998690.6514711.5870102.7563940.8907540.0065450.8909610.9221000.0012100.0006800.0000140.0000140.0001000.2524960.6780850.0010630.0030710.5220500.0016160.0136040.0001131.7295931.8785241.9041891.8187611.8896100.0023930.0000220.0000980.0001070.0001130.0001550.0001450.0000880.0000610.0000510.0000270.0001610.0000860.0001210.0000880.0000710.0386580.0000690.0001630.0000800.0000300.0037130.0000190.0002000.0001640.0000440.0000210.0001040.0000800.0001531.0144610.0011560.0772450.0001000.0000140.0000820.0001540.0000140.0000820.0000830.0000810.0000140.0002350.0005460.0005480.0030650.7993251.0215120.0022070.0003250.0001770.0005310.0002450.0005420.0001510.0003710.0001630.0001480.0002050.0001980.0003800.0005520.0003830.0005560.5197571.3940750.0016750.0001680.0001520.0001140.0001320.0001140.0000570.0000150.0000330.0000620.0000410.0000140.0001130.0000140.0000170.0000220.0000220.0000150.0000321.7966420.0019430.0000820.0001370.0000870.0001080.0003300.0001590.2754201.1322902.4429681.0574030.0575970.0001810.0000770.0002760.0000140.0001190.0002470.0000520.0003560.0002900.0002290.0020810.0005080.0009580.0010670.0008070.0005330.0002141.0386021.1700633.5372550.0041100.0254730.0005110.0003320.0002940.0004200.0009040.0005810.0495590.0006760.0002420.0005860.0000140.0000130.0000140.0063270.0000500.0000150.0245790.0049290.0315850.0000650.0003360.0041210.0011230.3212530.4512800.5934831.8486650.7719360.0009980.0003670.0000160.0003900.0012470.0012110.0000150.0240640.8140870.4736171.0776131.5606800.8731040.4153030.4422871.5579650.0015520.5548670.0007060.0000521.2219940.0012070.0048730.0000190.0002930.0006460.0006521.3672281.6130421.4999230.0537101.1629440.0017720.0003900.0109110.8007440.6891450.0046091.2508850.0013921.1238050.0025270.1724470.0131490.0002070.0000870.0003320.0000140.0006340.0011090.0007310.0008240.0010850.0005660.0069201.1110600.1641140.8111621.7174420.5894580.0701591.1190321.3249770.0013370.0013100.0070020.0001271.1440830.0017560.0003000.0006860.0001370.0000960.0004230.2044450.0002510.0001010.0000980.0220490.0001180.0001500.0000910.0001290.0001760.0001330.0001270.0001740.0000140.0009060.0000140.0004710.0000140.0000130.0000140.0002780.0162140.0000280.0003290.0000140.0001860.0000710.0000170.0011620.0005070.0001830.0000140.0000130.0000140.0000160.0001680.0002930.0000140.0002060.0002150.8029950.0013230.0001760.0002410.0001710.0001310.0002132.4127706.6076720.0066380.0003630.0002600.0003020.0002220.0635310.0001420.0002410.7930160.0007802.1025821.0042311.1499830.0010883.3453301.7230640.0049990.0001000.0004720.0000480.0001730.0000960.0001090.8326480.0008540.0022150.0001840.0000140.0003011.3120410.8636420.0007600.8908780.0008320.7381230.3662360.8656830.0007940.6899750.8295800.8137660.0009491.8903571.9212270.0033410.0148480.0012060.0011690.0013440.0007660.0012690.0069010.0022800.0013650.0009880.0018310.0013280.8335900.0012430.0000880.0000940.0001370.0002040.0001300.0001410.0001710.0001200.0076750.0000910.0002190.0001600.0001600.000105

*******************************************
EVALUATING PIPELINE 
Pipeline directory: /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_797633aa_2020-02-06_12-52-16ai51o2n2/
With following parameter combination: {'batch_size_seq_length': 2, 'lr': 3e-05, 'lr_type': 'cosine'}
EVALUATION OF CHECKPOINT /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_797633aa_2020-02-06_12-52-16ai51o2n2/outputs/checkpoint-3
-------------------------------------------------------------
|           |   agree   | disagree  |  discuss  | unrelated |
-------------------------------------------------------------
|   agree   |    562    |    20     |    112    |     5     |
-------------------------------------------------------------
| disagree  |    17     |    85     |    62     |     2     |
-------------------------------------------------------------
|  discuss  |    181    |    55     |   1602    |    16     |
-------------------------------------------------------------
| unrelated |     2     |     2     |    24     |   6875    |
-------------------------------------------------------------
Score: 7236.0 out of 7516.5	(96.2682099381361%)
Accuracy: 0.9482436083974226
F1 overall: 0.7901951650897272
F1 per class: [0.7693360711841205, 0.5182926829268293, 0.8768472906403941, 0.9963046156075647]
*******************************************


*******************************************
EVALUATING PIPELINE 
{'batch_size_seq_length': 1, 'lr': 3e-05, 'lr_type': 'linear'}
INFO:__main__:Creating features from dataset file at /home/ubuntu/fnd_implementation/data/processed
  0%|                                                                                                                                          | 0/9622 [00:00<?, ?it/s]  0%|                                                                                                                                | 1/9622 [00:02<6:40:37,  2.50s/it]  5%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                                                                                       | 501/9622 [00:02<4:25:54,  1.75s/it] 21%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                                                                                   | 2001/9622 [00:03<2:35:31,  1.22s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                                            | 5001/9622 [00:04<1:06:01,  1.17it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9622/9622 [00:04<00:00, 2332.61it/s]
  ******************************************* 
              Running Evaluation                
  *******************************************
 
  Length dataset evaluation: 9622
  Length dataloader evaluation: 2406
  Number of epochs: 3
  Batch size: 4
  ******************************************* 
 
['/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_53133bbc_2020-02-06_07-54-20bf_wbwiw/outputs/checkpoint-3']
INFO:__main__:Evaluate the following checkpoints: ['/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_53133bbc_2020-02-06_07-54-20bf_wbwiw/outputs/checkpoint-3']
INFO:transformers.configuration_utils:loading configuration file /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_53133bbc_2020-02-06_07-54-20bf_wbwiw/outputs/checkpoint-3/config.json
INFO:transformers.configuration_utils:Model config {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 28996
}

INFO:transformers.modeling_utils:loading weights file /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_53133bbc_2020-02-06_07-54-20bf_wbwiw/outputs/checkpoint-3/pytorch_model.bin
HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=2406.0, style=ProgressStyle(description_width='initial')), HTML(value='')))
0.0003520.0004730.0002460.0000910.0000320.0000150.0000120.0000100.0000100.0000100.0000100.0000100.0000100.0000100.0000100.0000090.0000090.0000090.0000090.0000090.0000920.0000130.0001360.0000140.0001341.2881440.0495640.0018452.1754390.0752520.0025170.0000900.0000110.0000090.0000090.0000090.0002220.0000150.0000100.0000100.0002270.0002280.0000140.0000090.9388220.0208720.0007430.0000250.0013210.0000372.0035582.0731860.0398780.0007620.0000230.0000090.0000100.0000140.0000910.0000110.0013350.0000310.0000100.0000100.0000100.0000100.0000110.0000100.0000440.0000100.0000100.0000100.0000100.0000100.0000100.0000100.0000140.0000100.0000100.0000100.0000100.0000100.0000100.0000100.0000100.0000100.0000100.0000730.0000110.0000100.0000100.0000100.0000100.0000100.0032740.0000440.0023160.0004870.0000140.0000100.0000130.0000100.0000100.5855230.0056400.0000630.0000100.0000101.6562410.0152910.0001480.0000100.0000090.0000090.0000090.0000120.0000090.0001560.0000100.0000090.0000090.0000860.0000100.0000100.0000090.0000830.0000100.0000090.0000140.0000100.0000090.0000100.0002520.0380030.4195010.0204480.0001610.0000200.0000100.0000090.0005040.0000840.0000100.0000851.1011380.0076030.0000610.0000100.0000120.0000100.0002820.0000111.2939371.3049331.2501710.0080740.0000610.0000090.0000090.0000090.0000810.0001370.0001750.0000100.0000090.0001320.0000100.0000090.0000090.0000100.0000923.8950621.7852171.7836110.0102621.7031941.0243060.0057960.0002230.0000110.0000100.0000102.3655070.0129360.0002300.0000104.5043132.2880220.0121790.0000803.7036330.0248110.0064160.8297820.0049360.0000340.0000090.0000090.0000090.0000090.0000091.7551310.0086980.0000520.0000090.0000090.0000090.0000090.0000090.0000090.0005060.0000160.0000090.0000090.0000090.0000090.0000090.0000090.0000090.0000090.0000090.0000090.0001110.0000090.0002320.0000100.0000090.0001040.0000100.0000100.0003250.0000890.0209120.0000990.0000850.0000100.0000100.0000090.0000940.0000960.0000100.0000100.0000100.0101270.0000500.0000100.0000090.0000090.0000090.0002060.0000100.0000090.0001180.0000950.0000100.0000090.0000450.0000920.0000090.0003170.0060110.0000320.0000090.0000092.1138682.1523361.4198150.0053270.0000290.0000090.0000090.0000090.0000100.3719580.0015321.9523560.0082940.0000390.0000090.0000090.0000090.0000090.0000090.0000090.0000090.0000090.0000090.0000090.0000091.0472220.0036201.3943610.0047840.0000260.0000101.7553321.8456870.0062240.0000300.0000100.0000091.6584791.7395390.0057510.0000280.0627400.2085490.0006880.0000110.0001670.0000090.0000090.0000090.0000090.0000090.0000090.0000090.0000091.5014750.0047160.0000243.4812300.0108211.8222280.0056330.0001040.0000100.0000090.0001000.0004920.0006560.0002860.0000101.5243830.0046380.0001630.0000750.0000740.0000090.0001410.0000740.6815040.0020020.0000150.0000090.0000090.0000090.0000090.0000090.0000090.0000090.0000090.0000090.0000090.0000090.0000090.0000090.0000090.0000090.0000090.0000090.0000090.0000090.0000090.0000090.0000090.0000100.0000930.0000090.0000090.0000090.0000090.0000090.0000090.0000090.0000090.0000090.0000090.0000090.0000090.0000090.0000090.0000940.0000090.0000100.0002560.0000100.0000090.0000220.0002210.0000100.0017630.0000130.0000090.0000100.0000100.0010840.0000120.0000100.0000100.0000170.0000090.0000090.0000100.0000090.0000100.0000100.0000120.0000090.0000100.0277600.0000770.0001410.0000090.0001680.0000090.0000090.0002210.0001620.0000090.0003720.0009050.0000841.9417631.9905590.0046920.0001050.0000100.0000100.0000090.0000100.0000090.0000090.0001380.0000100.0000090.0000090.0000090.0000090.0000090.0000090.0016660.0000130.0000090.2092943.8513810.0103910.0000330.0004850.0000102.2109090.0051860.0002100.0000090.0000090.0002080.0000100.0000100.0000100.0000100.0000100.0000100.0000090.0000100.0002100.0001710.0000100.0025230.0014770.0000140.0000100.1513610.0003300.0012200.0011580.0000140.0000800.0000940.0000100.0000100.0000100.0000090.0000810.0931841.3511210.1051150.0005220.0003170.0002590.7667490.0111220.0001040.0009440.0002600.0000100.0000090.0002410.0000090.0000090.0000090.0000090.0001180.0001960.0000090.0000090.0000090.0000090.0000090.0011820.0000110.0000090.0000980.0000090.0018990.0031740.0000150.0000100.0090280.0017060.0078980.0000250.0001660.0040180.0000170.0000091.5154900.0028900.0000932.8704090.0054350.0002220.0000100.0000110.0000890.0003910.0396110.0000842.1237840.9007384.1679840.0077270.0000240.0000090.0001400.0000100.0192311.4579531.9242690.0035200.0000870.0025670.0000150.0000090.0002950.0000110.0000102.0360530.0037640.0002610.0000100.0000090.0000990.0000090.0000850.0000810.0000890.0000790.0000090.0000090.0000090.0000090.0000900.0000800.0000090.0001900.0000100.7943360.0013850.6865301.6354890.0028291.4615740.0028330.0000141.2583780.0021600.0075600.0001190.0000790.0000840.0001110.0000090.0002010.0000090.0003010.0001730.0000150.0000090.0001182.0457100.0040561.5745971.4929354.8675190.0086780.0012180.0006540.0081040.0001580.0003570.0000904.3186940.0071500.0000213.3361142.3467500.0039240.0001420.0000090.0001841.3133010.0021240.0000121.5392850.0025800.0000130.0001080.0000091.4682670.0023430.0001180.0000090.0000090.0001190.0000090.0000090.0000090.0001020.0000940.0000090.0040230.8208100.0110790.0122990.0003040.0003270.7052680.0010992.7901890.0043080.2257730.0005070.0000100.0002480.0000780.0000090.0005280.0002655.2717030.0088060.0001470.0000940.0001800.0001440.0002290.0000090.0003260.0000090.0001310.0000090.0002260.0000900.0000090.0000090.0000090.0000850.0004610.0003110.0003280.0001050.0000110.0000100.0000110.0000100.0000100.0000110.0000170.0011780.0000110.0000100.0000100.0000150.0000100.0000100.0000110.0000250.0001930.0000100.0002270.0000800.0000100.0000840.0000090.0000800.0000880.0000980.0000090.0002780.0004950.0000790.0002160.0008660.0000110.0016240.0000120.0002160.0000100.0294750.0000500.0000090.0017270.0026520.0000120.0000090.0000790.0000100.0000790.0000800.8619400.5000051.1430630.0019250.0014362.4436596.7023970.0091970.0000220.0001500.0001471.0529931.9946520.0374815.4919123.1585960.0044121.8747170.0025560.0000120.0000861.0488590.0014080.0000110.5333611.6805622.3058530.0030634.1990150.0055560.0000170.0000096.0315150.0079350.0000190.0000100.0000090.0020100.0000120.0000090.0009220.0000110.0003820.0003870.0003810.0004410.0003610.0004030.0000880.0000770.0000090.0000090.0002320.0000090.0000090.0000090.0000090.0002280.0001120.0002020.0002550.0002100.0002780.0002810.0000100.0061280.0001650.0000830.0003470.0000830.0001004.4360370.0080500.5383760.8520050.8154490.0010241.3697281.5552720.0019360.0000481.5886830.0022170.0000121.4801670.0019160.0000121.0097290.0012470.4339550.0008120.0000112.1407910.2387903.7234185.4658620.0066430.0008540.0000100.0026260.0000130.0011010.0007350.0000810.0001540.0001570.0002910.0009651.2447360.0014960.0261061.6308960.0019511.8040520.0021510.0000110.0000100.0000090.0003130.0010940.0000100.0000800.0001850.0000090.0000090.0000090.0032750.0039970.0016380.0000110.0000100.0000090.0000090.0000090.0000090.0000100.3173610.0003760.0000100.0000090.0000100.0000090.0000090.0000090.0000100.0000090.0000090.0000090.0000100.0000090.0000090.0000100.0000100.0027550.0018300.0059240.0029440.0000120.0005140.0006240.0003130.0002350.0000100.0000100.0000101.7110181.5833080.0017790.0000130.0000100.0003120.0002840.0007690.0007390.0003650.0001700.0001520.0000850.0000100.0002430.0000946.2583854.4004530.0048450.0000180.0000110.0001140.0001440.0001360.0000910.0033700.0001101.8171200.0019821.9323313.9526593.5634010.0040373.8596010.0043561.6145720.8334371.5836820.0018640.0000110.0001631.6108420.0018070.0002311.1511810.0014051.5035050.0016090.0000111.4263220.0015220.0000110.0000090.0000090.0001220.0000090.0000090.0000090.0000090.0000090.0000090.0001010.0000101.4756980.0015510.0000101.6753750.0018710.0000812.3456210.0024450.0000110.1867310.0002030.0065940.0000160.0000090.0000090.0177960.0000300.0000090.0004092.7709323.1693383.0125751.6957254.8387643.2147635.2389110.0100080.9850520.0011010.0000110.0000090.0000090.0000090.0000100.0000090.0000090.0000090.6596540.0006720.0000090.1805170.5790780.0005900.0058070.0000150.0000100.0000100.0000160.0074810.0000170.0000090.0000100.0004160.0017280.0000110.0000100.0003840.0022090.0000120.0001010.0000100.0000090.0000100.0000100.0000100.0000100.0000783.7891211.6324670.0017530.0000110.0000090.0000090.0001760.0035210.3431470.0061880.0060470.0000151.6186381.6723491.1643950.0012300.0003410.0003420.0003620.0000100.0001880.0005051.6091540.0015480.0001090.0000100.7155650.0201290.0000290.0763692.3792400.0022670.0000110.0000090.1191820.0001220.0373750.0158090.0104070.4993890.0004790.0000110.0359300.0001280.0000100.0202490.0000280.0000100.0199910.0005030.0000100.0192460.0000270.7716710.1209780.0001220.7476470.7608860.1582020.8434850.0012547.2441191.7885410.0049420.0001673.9885071.7997750.6765100.0025700.0025960.0002420.0000940.0002361.8970170.0017560.0043800.0010180.0012420.0016360.0001230.0012800.0036140.0044010.0000140.0004030.0003650.0003742.1827570.0019960.0000110.0000090.0000090.0000092.1424112.1452344.1873480.0038220.0000130.0000850.0000090.0000092.1306720.0019030.0000110.0000090.0000100.0003420.0000100.0000100.0004430.0000180.0002990.0003000.0000100.0000100.0000100.0000100.0000100.0001250.0000100.0000100.0000100.0000100.3651600.0071970.0006830.4418120.0005410.0157042.3752350.0023000.0005170.0000180.4787051.3345990.0907670.0002730.0000860.0153200.3348320.0004490.0000820.0000100.0000100.0000090.0000090.0000100.0000095.4123650.0046271.5395510.0014050.0006120.0001040.0000101.4130870.0012081.6182610.0013801.7709780.0015070.0006270.0000100.0000130.0000090.0000700.0000090.0000090.0000090.0014080.0000110.0000100.0000100.0000100.9296170.0007860.0004990.0000100.0000100.0000090.0018360.0012870.0013490.0011920.0000110.0000090.0000100.0000090.0000860.0001070.0000090.0000090.0000100.0000790.0000910.0000425.1719784.2393821.7760950.0016410.5790670.0006620.0002580.0015060.0013940.0000110.0018130.0007870.0000110.0004910.0000100.0000100.0000090.0000100.0000100.0022970.0000120.0000092.1649640.0032750.0006810.0000860.0000090.0000090.0000090.0005400.0000140.0000090.0000090.0000930.0000090.0000090.0000090.0000090.0000090.0001350.0000090.0000090.0000880.0000090.0000090.0001090.0000090.0000090.0000090.0000100.0005450.0000100.0000100.0005550.0000110.0005120.0000100.0000102.7737430.0030961.0244381.2432130.0034532.5595763.7045742.0474752.5025580.1660570.0041410.0003140.0013330.0002900.0015445.6211905.4486990.0044940.0004880.0003240.0003241.3571650.0014590.0014190.0020270.0005470.0000810.0002160.0001820.0002030.0002090.0001860.0001120.0001130.0048830.0098911.1365834.6344800.6908490.0022800.0000110.0000090.0000090.0000091.5512860.0011820.0000100.0002820.0001020.0000090.0008470.0003390.0003440.0026390.0074260.0017130.0037000.0012520.0000100.0019100.0009130.0003420.0000100.0002290.0958460.0000811.1330750.0008520.0000180.2692750.0002090.0000090.0001040.2692750.0002090.0000100.0000100.0000100.0000100.0088650.0833630.5194380.0131131.1779420.0008750.0000120.0000100.0003400.0001540.0000090.0003040.0000100.0000100.0000100.0000090.0000110.0000100.0000100.0000100.0000100.0000100.0000090.0000100.0000110.0000100.0003260.0005370.0000100.0000100.0000090.0002740.0000100.0000100.0000100.0000090.0007140.0001600.0070330.0038650.0021400.0070140.0026330.0011801.2377450.0011150.0002090.0003270.0005260.0007121.2075650.0069860.0114983.9457413.3453634.2544970.1815690.0157640.0497330.0432450.0000400.0012860.0000100.0011230.0000100.5679730.0031740.0000120.0060340.0003220.0001670.0002460.0002390.0001741.1815680.0010680.0002540.0007300.0002460.0004020.0000960.0002410.0001250.0006930.0039450.3260850.2731241.2907740.0011540.0012121.8833600.0017200.0005990.3896841.8582871.7466750.0018531.3281211.0547670.0007342.4139562.1876851.3671180.0033340.8093201.5997221.3378852.8964804.8203310.0038170.0003120.0003130.0003050.0002980.0002400.0000090.0002250.0005840.0000090.0003190.0000090.0000090.0000090.0006700.0000090.0000090.0004550.0000090.0010220.0005370.0000090.0001290.0000090.0000090.0000090.0000091.5714400.0012180.0003042.7473023.2885493.2216231.6413741.1308693.1499423.1790793.3698622.9912481.6169860.0012121.1819160.0010000.0001230.0003600.0003830.0000830.0001421.4052970.0010802.0454953.9933660.0027750.0002140.0002140.0002750.0002190.0002130.0002110.0001520.0002091.1459020.0037540.0001110.0001230.0000090.0012310.0003590.0000090.0000090.0000120.0000090.0000090.0000090.0000090.0000090.0000921.8661660.0012182.0422010.0013301.7801360.0011600.0001070.0002650.0007041.3035961.2778600.0009431.3487034.9763657.8928577.5451295.8557190.0037650.0000220.0027000.0051540.0030280.0000110.0000090.0020820.0001010.0001520.0001450.0001460.0001860.0001540.0001570.0001480.0000800.0001470.0001860.0001540.0064320.0113450.0021710.5940380.1174300.8843270.0021390.0000782.1845170.0015220.0000782.4601750.0016962.4681334.6167900.0030532.1619992.1654750.0014352.2272150.0014737.1419972.9253631.6366373.6335031.6471322.6637561.1741950.0008420.0001940.0000090.0001870.1604240.0005480.0000100.7151260.0010100.0008220.0000100.0000970.0000880.0000820.0000092.1642120.0013424.2288622.1758970.0013472.1550912.1250965.8304905.2607436.9973335.2966004.6579310.0031290.0001890.0000910.0000180.0001040.0000090.0002030.0000090.0000870.0000090.0000090.0000091.1213890.0006900.0000102.0035310.0012240.0000100.0000090.0000100.0000090.0000899.4384548.8356272.4174380.0018491.6356050.0011250.0083470.0000150.0000381.5938471.4515002.0804121.5897801.6630112.6255501.5146603.8573712.8806012.7338300.0016430.0000120.0074201.6243170.0009771.6743860.0010050.0000100.0007081.0505860.0006330.0000100.0000100.0000100.0000100.0000100.0004870.0005060.0062800.0031280.0010130.0001620.0008840.0003682.2104520.0054150.0001500.0001570.0005230.0000090.0007900.0000760.0002201.2920830.0008352.2173691.7049851.4833221.3917140.0008233.0443801.5136080.8616880.0017090.0000100.0000090.0000090.0002290.0000090.0001580.0001440.0001590.0001660.0002280.0002280.0001650.0002530.0000830.0001500.0000760.0000850.0000090.0001050.0000100.0000090.0002050.0002020.0001050.0001080.0002060.0001020.0001250.0001190.0000090.0002040.0001010.0062520.0000130.0000940.0002220.0002060.0000090.0002070.0000090.0000200.0000090.0001000.0000100.0000090.0003470.0001050.0000090.0004600.0000090.0001040.0000090.0000090.0001510.0000100.0000090.0002150.0002120.0001520.0001241.9290520.0010930.0000100.0000210.0000100.0000100.0000100.0000100.0000100.0002910.0000100.0006410.0000100.0000100.0000100.0000100.0003200.0003620.0000100.0002740.0000100.0000100.0000100.0083661.5869971.5110054.7021470.4414730.0003800.0002540.3186010.0380730.5571362.1372911.1397010.0017290.0004760.0004650.0010120.0003830.0004760.0005120.0004810.0005500.0005780.0008281.0482590.0011990.0000100.0007580.0008000.0001700.0001550.0000800.0001560.0004470.0005310.0004330.0003540.0017890.0003310.0022780.0007212.3987320.0019630.0002110.0007410.0005360.0014470.0273250.0008330.0001300.0003070.0003790.0001450.0002120.0002910.0001680.0002190.0002340.0001620.0002600.0001780.0001090.0001020.0000090.0000100.0000100.0001700.0002850.0001090.0000980.0000090.0000090.0000100.0000100.0004050.0000100.0000090.0000090.0000090.0000090.0000100.0000090.0000090.0000090.0000100.0001210.0000091.6989090.0009080.0000090.0001160.0000980.0001960.0001980.0001590.0001530.0000770.0001680.0001920.0000790.0002300.0000090.0000610.0029400.0015900.0045510.0051131.8934855.5643161.8533674.8840051.5194060.0009350.0000970.0000940.0000850.0001030.0000090.0001770.0000090.0000090.0000090.0001320.0394600.0000300.0000820.0000090.0000780.7262930.0103010.0068240.0000130.0145020.0008040.0089950.0123510.0006530.0004250.0162480.0064970.0010420.0006130.0345150.0000270.0197510.0002180.0003670.0006061.7160911.9522930.0016203.8456001.8225321.3336220.0075070.0103930.6628050.0066030.0000870.0000980.0013010.0023160.0001780.0009270.0002411.0994870.3206990.0081420.1530380.3174840.0003300.0009530.0039530.8144240.0019090.0000110.0015430.0000110.0000100.0000100.0000100.0000100.0000100.0000100.0031670.0001760.0000100.0000100.0000100.0000100.0021690.0013560.0101870.0023410.0000110.0000100.0000810.0003220.0004770.0002930.0003460.0003270.0003450.0003010.0064440.0023170.0000110.0026540.0021380.0141890.8897910.0026450.0032780.0000990.0001030.0000090.0000870.0000090.0000090.0001730.0002610.0002480.0004120.0003160.0000090.0000100.0000101.5759370.5113141.0712862.1105923.0783421.2853840.0016070.0003580.0001094.2998502.2704240.0011230.0000212.4488642.4129560.0011924.7914902.4932990.0012830.0000252.4658320.0012120.0010940.0000100.0000090.0000131.6051490.0007900.0017550.0000100.0038250.0000990.0000090.0000100.0025590.0011830.0000100.0007330.0000100.0007510.0000093.0875741.8481370.0011971.1085970.0338270.0003560.0144181.5521400.0072150.0011800.0007930.0013830.0004060.0001001.4041020.0236110.0000201.6239170.0008941.9499270.0742210.0004552.3652000.0014310.0003354.5446492.9577990.2470362.1963721.5720020.0011250.0003341.4618580.0007050.0247950.0003130.0000100.0000102.3831420.0011400.0000100.0000102.4599691.8734534.5810600.0080590.0452560.0000310.0554060.7582082.4158530.0011491.3614100.0007950.0000900.0001660.0003400.0000760.0002690.0001620.0000930.0000990.0003070.0000090.0001130.6301490.0090580.0039370.8107980.0941810.0036550.0002330.0000820.0004640.0000100.0050170.8361380.0006220.0006851.7422100.0011800.0004060.0004320.0008130.0011850.0043100.0023390.0001110.0005280.0002860.0000440.0005990.0009401.5123010.0007080.0000880.0000090.0001600.0000820.0001760.0000820.0001690.0002040.0000810.0000970.0001580.0001830.0001900.0000090.0000090.0002690.0002850.0001950.0001730.0001610.0000760.0001210.0001740.0001560.0000090.0000100.0000090.0010570.0000100.0000100.0031180.0000110.0000100.0000090.0000100.0000100.0000100.0000100.0011460.0000100.0000100.0031320.0000110.0000100.0000100.0016400.0000100.0000100.0192030.0002360.0002850.0000100.0000100.0000100.0000120.0011990.0000100.0012060.0000100.0006660.0000100.0000100.0000100.0000100.0000100.0000100.0000100.0000090.0139150.0000160.1849410.0001790.0000090.0000090.0000090.0003052.3884710.0010750.0000100.0921250.0000500.0001560.0001240.0006760.0003240.0003880.0002340.0002220.0002470.0001220.0003160.0002770.0092310.1024233.2150021.3144830.0026560.0004020.0000100.0026420.0012960.0002360.0002400.0004160.0003130.0002410.0000090.0002610.0000820.0001020.0005580.0000091.4386760.0006410.0000090.0001440.0000771.5892910.0007070.0400830.0008910.0038580.0000800.0000850.0000824.7193670.0028830.0021140.0000770.0084920.0001570.0003042.1452660.0015470.0000110.0004310.0008020.0000100.0000971.1715130.0023340.0000110.0014961.4650150.0006440.0003040.0000100.5824030.0002610.0001770.0000100.0000101.0083160.0005871.0513520.0007820.0000860.0005600.0000090.0000090.0003160.0000090.0001650.0000790.0003120.0002120.0007710.0004670.0001530.0002620.0000870.0000880.0002000.0000090.0003970.0000090.0004480.0000092.6009430.0012255.6526252.1539613.7116652.5960270.0011151.3344550.0013720.0028080.0027150.0007300.7581020.0004980.0120690.0005660.0009010.0136980.0092680.0534920.0089380.0000140.0843761.1342450.0032430.0014290.0016750.0013367.8660307.6376997.6776301.8244880.0031480.0092600.0003460.0002480.0001080.0001800.0004970.0001000.0001500.0001500.0000790.0004300.0001510.0004170.0000770.0002460.0002180.0002370.0000780.0002140.0001820.0000100.0000100.0001690.0003430.0001710.0000100.0003400.0000110.0003480.0001680.000010

*******************************************
EVALUATING PIPELINE 
Pipeline directory: /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_53133bbc_2020-02-06_07-54-20bf_wbwiw/
With following parameter combination: {'batch_size_seq_length': 1, 'lr': 3e-05, 'lr_type': 'linear'}
EVALUATION OF CHECKPOINT /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_53133bbc_2020-02-06_07-54-20bf_wbwiw/outputs/checkpoint-3
-------------------------------------------------------------
|           |   agree   | disagree  |  discuss  | unrelated |
-------------------------------------------------------------
|   agree   |    514    |    42     |    106    |     8     |
-------------------------------------------------------------
| disagree  |     9     |    54     |    46     |     2     |
-------------------------------------------------------------
|  discuss  |    224    |    61     |   1617    |    22     |
-------------------------------------------------------------
| unrelated |    15     |     5     |    31     |   6866    |
-------------------------------------------------------------
Score: 7199.5 out of 7516.5	(95.78261158784008%)
Accuracy: 0.9406568281022657
F1 overall: 0.743973645212072
F1 per class: [0.7178770949720671, 0.3956043956043956, 0.868421052631579, 0.9939920376402461]
*******************************************


*******************************************
EVALUATING PIPELINE 
{'batch_size_seq_length': 3, 'lr': 3e-05, 'lr_type': 'constant'}
INFO:__main__:Creating features from dataset file at /home/ubuntu/fnd_implementation/data/processed
  0%|                                                                                                                                          | 0/9622 [00:00<?, ?it/s]  0%|                                                                                                                                | 1/9622 [00:02<6:57:25,  2.60s/it] 21%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                                                                                   | 2001/9622 [00:03<3:51:27,  1.82s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                            | 7501/9622 [00:03<45:05,  1.28s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9622/9622 [00:03<00:00, 2627.18it/s]
  ******************************************* 
              Running Evaluation                
  *******************************************
 
  Length dataset evaluation: 9622
  Length dataloader evaluation: 602
  Number of epochs: 3
  Batch size: 16
  ******************************************* 
 
['/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_4df90850_2020-02-06_07-14-367lv6lsx1/outputs/checkpoint-3']
INFO:__main__:Evaluate the following checkpoints: ['/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_4df90850_2020-02-06_07-14-367lv6lsx1/outputs/checkpoint-3']
INFO:transformers.configuration_utils:loading configuration file /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_4df90850_2020-02-06_07-14-367lv6lsx1/outputs/checkpoint-3/config.json
INFO:transformers.configuration_utils:Model config {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 28996
}

INFO:transformers.modeling_utils:loading weights file /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_4df90850_2020-02-06_07-14-367lv6lsx1/outputs/checkpoint-3/pytorch_model.bin
HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=602.0, style=ProgressStyle(description_width='initial')), HTML(value='')))
0.0004760.0006840.0004610.0003280.0002490.0002150.3457710.5340010.0670930.0079550.0011470.0004620.7227840.0556750.0040610.0006100.0001060.0001780.0000730.0001230.0001340.0001000.0001620.0003580.4097110.0164920.0006930.0002360.0000670.4389360.0146990.0005410.0000690.0007530.0003220.6122550.1455860.2467630.7639620.1503450.0039270.0002090.9405611.4693700.0336610.4777871.6427461.7815940.3282710.0068520.0005380.0001210.0002610.0000710.0000730.0001090.0001400.0001360.0004840.0122770.0002960.0000480.0013240.0001780.0003150.0569291.0661020.0159470.5428410.0141840.0002810.0000500.3149360.0049180.0026180.0010800.0157140.0002680.0000490.3883880.7259590.0090290.0165030.0028730.0001740.2341150.0027810.0000980.0001560.0000600.0000830.4050460.0046550.0001300.0000670.0000990.2668830.0045690.0001260.0010260.0002590.0000880.0016580.4726640.0047680.2575650.4320360.0043120.0001420.0001210.0102950.3966730.4833250.0043900.0000900.0000620.0022090.0004220.0009510.0001310.0005700.7422031.1367740.0104010.0001600.0001190.0000490.0001270.3506410.6522680.0052160.0067850.2673520.3978900.9061990.0069390.7952880.2956000.3682350.7878970.6950330.0050570.0001090.0001430.0012000.3730580.0044840.0001980.0001830.4845330.0047550.0040500.7253660.0308700.0003151.0319080.0067200.5156210.4350490.0028400.3210840.0097130.0324980.0598200.0010200.0003070.0002890.0001970.0000740.0004160.0001080.2631210.0039030.0019520.0008660.0001130.0005320.0006100.0002520.0009610.0009150.0001641.4053561.7152280.2984660.7754120.0046590.0008241.9123521.1083741.5513630.0089230.0004190.0003610.0000980.0001120.0005340.0025300.0002420.0019650.0563730.3978960.2002480.0045970.0029310.0078540.0012390.0017920.0003960.0010250.0007430.1491560.0009540.1642440.0043830.0000720.2996810.0014300.0000600.0000510.1719480.0022880.0002230.5637610.0032530.0054400.0001972.5776890.0116590.0007431.3946231.5747971.0601500.3558030.3326190.0017580.0001180.0000960.2367940.0021740.0011150.7278860.3671080.2441930.8148123.7949920.0155070.0001160.0240470.0042520.0000750.0000660.0698660.0500320.0002890.3452590.4765490.0877150.3802630.6857600.0042340.1744020.0057750.1784120.0044250.0029040.0015460.0015100.0009690.0019270.0039601.4263120.5099790.0022340.4400731.4223330.9288140.5218140.0019452.0920910.0075670.3414830.2231740.0124270.0000900.0017921.0832340.7069720.0045592.4897730.5714790.0020490.8760050.6960930.0028450.3260370.0016990.0000510.0014540.0017820.0011640.0017270.0001810.0001521.5033882.1034030.0075430.0006420.0005520.0005480.0046330.0000870.0001560.0000760.0001450.0000770.0000850.0003350.0005940.5732051.8914961.5061860.0050530.0062850.2633350.0011560.0002470.2990201.2580840.2989460.1549360.0009420.1968240.0026410.0013360.0004580.0359880.0002410.0000750.0137040.0012540.0389820.0001600.0000930.0000610.2380040.0014030.0000480.2109050.2440360.0010441.2171524.5881950.0151520.0009230.0010460.0012170.0002640.0002890.0002250.2815560.4523600.0567510.1214370.0635470.0044400.7077790.0021630.0004000.0072650.0002120.0010610.0000651.2422502.2829943.2669840.4224440.0013100.7176020.9644110.0028260.3242600.0045510.0004810.0000650.3871480.8436130.0515910.8741114.7606540.4411110.0232820.0014630.0002120.0007420.0023030.5523690.5883602.2549031.0820821.0969790.1482930.0006110.0127820.0017440.5052481.9727726.3529963.6154290.0090290.0001810.0067770.4760760.0013953.5637930.3773160.0081870.0015350.0055250.6548740.2931680.0154160.0130950.0152140.0003400.0002780.0002461.2671911.7204700.8445640.0020790.0002050.0002670.0001460.0001040.0001760.0001690.0001440.0001490.0000860.0000780.0002310.0000740.0001270.3651880.0008790.0000630.0008090.0002770.0004790.0823180.2234701.0160691.3049190.0035200.0006560.0008990.0028590.0064320.0009540.1978420.0016060.0003850.0015770.0545000.0005450.0000730.0004120.0004600.0000400.0000480.0000910.9613790.2043610.0008820.0001260.1950384.4826680.5147250.0023530.0003960.0006500.5827450.2471330.0047580.1677590.0410131.0885381.6278960.0062410.0006670.0008900.0008120.0129730.0006340.0000710.2705010.0010940.2283080.9841100.8741360.9175362.7179180.8745190.0020040.3111250.0010440.8599250.7300360.6921830.4230490.3003030.3511260.5297080.0016940.0008710.0006942.1092042.5020312.3645630.5144271.3933640.4005880.9432241.0445890.2038820.2637220.3864050.0155510.9385520.3529830.0009230.0210791.2077552.2722950.0044270.4854711.0407202.3925090.3772250.3431580.0008070.0002130.0045070.0001820.0002550.0002440.0002580.1911330.0004260.3221620.2571540.2021130.0012290.0009820.0017710.0000880.0000870.0008750.0000860.0014340.0001910.0003570.0003210.5488520.0029370.1163230.0022040.0010470.0004040.0010470.0007250.0850170.0008040.0002180.0002510.6139650.0023890.0001220.0003480.0002070.0002160.0003710.0002130.0002430.0005530.7920070.0463780.0026430.0020530.0018440.0029640.2958420.8391900.8660750.0019290.0003540.0005780.0017290.0008590.0008260.000534

*******************************************
EVALUATING PIPELINE 
Pipeline directory: /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_4df90850_2020-02-06_07-14-367lv6lsx1/
With following parameter combination: {'batch_size_seq_length': 3, 'lr': 3e-05, 'lr_type': 'constant'}
EVALUATION OF CHECKPOINT /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_4df90850_2020-02-06_07-14-367lv6lsx1/outputs/checkpoint-3
-------------------------------------------------------------
|           |   agree   | disagree  |  discuss  | unrelated |
-------------------------------------------------------------
|   agree   |    493    |    17     |    76     |     3     |
-------------------------------------------------------------
| disagree  |    25     |    93     |    40     |     5     |
-------------------------------------------------------------
|  discuss  |    239    |    49     |   1658    |    31     |
-------------------------------------------------------------
| unrelated |     5     |     3     |    26     |   6859    |
-------------------------------------------------------------
Score: 7253.25 out of 7516.5	(96.49770504889244%)
Accuracy: 0.9460611099563501
F1 overall: 0.7936974000435277
F1 per class: [0.7298297557364914, 0.5723076923076923, 0.8779454593592798, 0.9947066927706475]
*******************************************


*******************************************
EVALUATING PIPELINE 
{'batch_size_seq_length': 4, 'lr': 3e-05, 'lr_type': 'linear'}
INFO:__main__:Creating features from dataset file at /home/ubuntu/fnd_implementation/data/processed
  0%|                                                                                                                                          | 0/9622 [00:00<?, ?it/s]  0%|                                                                                                                                | 1/9622 [00:02<6:58:46,  2.61s/it]  5%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                                                                                       | 501/9622 [00:02<4:37:55,  1.83s/it] 21%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                                                                                   | 2001/9622 [00:03<2:42:33,  1.28s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                            | 7501/9622 [00:03<31:40,  1.12it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9622/9622 [00:03<00:00, 2572.34it/s]
  ******************************************* 
              Running Evaluation                
  *******************************************
 
  Length dataset evaluation: 9622
  Length dataloader evaluation: 301
  Number of epochs: 3
  Batch size: 32
  ******************************************* 
 
['/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_5aa271fe_2020-02-06_09-32-39qdqcvxui/outputs/checkpoint-3']
INFO:__main__:Evaluate the following checkpoints: ['/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_5aa271fe_2020-02-06_09-32-39qdqcvxui/outputs/checkpoint-3']
INFO:transformers.configuration_utils:loading configuration file /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_5aa271fe_2020-02-06_09-32-39qdqcvxui/outputs/checkpoint-3/config.json
INFO:transformers.configuration_utils:Model config {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 28996
}

INFO:transformers.modeling_utils:loading weights file /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_5aa271fe_2020-02-06_09-32-39qdqcvxui/outputs/checkpoint-3/pytorch_model.bin
HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=301.0, style=ProgressStyle(description_width='initial')), HTML(value='')))
0.0004360.0005680.0005080.3716920.0931660.0193080.0897830.0137480.0018990.0004100.0006100.0005090.0013100.0334130.0025460.0003890.0019660.1900490.0115410.4022380.0208400.6853480.3317390.7259620.0575970.0064110.0007240.0001730.0005860.0831440.0202960.1471720.0959760.2507200.1715050.0049970.2864530.5563220.0208410.0010430.0008390.0480180.0397640.0010160.0001060.0001580.0001020.0001520.0007050.0004190.0001140.0059830.2381070.0624730.1104930.0041970.2484540.0044500.0010390.0009570.4522030.4264970.0079560.0029650.0109080.1450270.4907600.4422740.5151020.5286500.0083440.0003810.5220890.1653590.2381440.0067590.2169570.3620620.1644740.0023750.4789520.1271410.3556330.2891840.0053580.0009480.0001120.0005550.0033630.0903380.0217871.1982820.3334480.0085660.5846160.5321940.0068080.0006830.2117750.4923800.2231370.0145980.1501680.0144130.0409720.1682710.0185280.0004250.0730610.0007380.7082920.3213490.0071290.9609200.0092981.1699440.7032170.1257930.0012860.1522140.1725440.0611130.5004250.0042230.0657840.0006390.0012530.2109990.2310540.3533600.0425820.0223160.0064710.0015190.0284850.5559840.0430120.1226610.3772560.6110520.0689500.0032010.1880080.0049660.1811570.1360310.4304330.3344740.0025780.0028900.0073480.0008611.7121390.0130790.0022340.0174410.0003900.0003530.0007150.2781992.0426930.2228030.0037870.0338530.0765080.0017040.0134690.0020260.0003490.0076830.0023330.0018080.0013930.0004900.0038160.5259042.1252770.0174310.0026140.0010910.3442050.4196131.7529580.1414750.0511210.0384290.4936651.7239281.4965600.8124520.1555340.0029490.1586330.3673030.5683960.0415960.0019140.0050660.3569351.0250550.7129040.0066680.1938722.2474580.6248190.0804980.1691370.2155361.4137871.2412250.1402160.3807310.1353200.3997370.7556930.0042940.0009750.0005200.0006990.0004390.0016020.0004050.0013390.0006920.0007290.0081180.4242210.0047450.0047500.0834860.1077930.1804840.3635740.0026800.0002070.0002120.0207020.0007141.7205200.1892800.0031880.1344670.1083630.5628490.6206920.0046520.0035610.0003760.0426990.5708610.6832550.2937310.0735960.3789110.8566460.1787490.3487980.0086570.2391240.0443790.2132930.5005380.1392440.0023280.0489990.0578880.3379180.2956950.2039030.0437130.0669560.0011110.0011200.0005660.0795670.1796180.0393760.0010260.0001560.0008750.0228240.0023901.1929780.0145730.0013860.0020280.1090650.0013220.2459160.0033990.0016090.1555650.1095290.4995640.0097010.0605180.0606770.0018440.0016920.0007890.000833

*******************************************
EVALUATING PIPELINE 
Pipeline directory: /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_5aa271fe_2020-02-06_09-32-39qdqcvxui/
With following parameter combination: {'batch_size_seq_length': 4, 'lr': 3e-05, 'lr_type': 'linear'}
EVALUATION OF CHECKPOINT /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_5aa271fe_2020-02-06_09-32-39qdqcvxui/outputs/checkpoint-3
-------------------------------------------------------------
|           |   agree   | disagree  |  discuss  | unrelated |
-------------------------------------------------------------
|   agree   |    609    |    27     |    170    |     7     |
-------------------------------------------------------------
| disagree  |    14     |    95     |    44     |     3     |
-------------------------------------------------------------
|  discuss  |    137    |    37     |   1570    |    13     |
-------------------------------------------------------------
| unrelated |     2     |     3     |    16     |   6875    |
-------------------------------------------------------------
Score: 7233.0 out of 7516.5	(96.22829774496108%)
Accuracy: 0.9508418208272709
F1 overall: 0.8125985483897753
F1 per class: [0.7733333333333333, 0.5974842767295597, 0.8827663761596851, 0.9968102073365231]
*******************************************


*******************************************
EVALUATING PIPELINE 
{'batch_size_seq_length': 1, 'lr': 3e-05, 'lr_type': 'constant'}
INFO:__main__:Creating features from dataset file at /home/ubuntu/fnd_implementation/data/processed
  0%|                                                                                                                                          | 0/9622 [00:00<?, ?it/s]  0%|                                                                                                                                | 1/9622 [00:03<8:12:26,  3.07s/it]  5%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                                                                                       | 501/9622 [00:03<5:26:48,  2.15s/it] 21%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                                                                                   | 2001/9622 [00:03<3:11:09,  1.50s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                                            | 5001/9622 [00:04<1:21:08,  1.05s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                      | 5501/9622 [00:04<50:39,  1.36it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9622/9622 [00:04<00:00, 2106.39it/s]
  ******************************************* 
              Running Evaluation                
  *******************************************
 
  Length dataset evaluation: 9622
  Length dataloader evaluation: 2406
  Number of epochs: 3
  Batch size: 4
  ******************************************* 
 
['/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_48d2cd48_2020-02-06_05-49-113dv6ag8u/outputs/checkpoint-3']
INFO:__main__:Evaluate the following checkpoints: ['/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_48d2cd48_2020-02-06_05-49-113dv6ag8u/outputs/checkpoint-3']
INFO:transformers.configuration_utils:loading configuration file /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_48d2cd48_2020-02-06_05-49-113dv6ag8u/outputs/checkpoint-3/config.json
INFO:transformers.configuration_utils:Model config {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 28996
}

INFO:transformers.modeling_utils:loading weights file /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_48d2cd48_2020-02-06_05-49-113dv6ag8u/outputs/checkpoint-3/pytorch_model.bin
HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=2406.0, style=ProgressStyle(description_width='initial')), HTML(value='')))
0.0166850.0223170.0117380.0044900.0017010.0009170.0007300.0006810.0006620.0006510.0006420.0006350.0006300.0006260.0006220.0006190.0006160.0006130.0006110.0006090.0056390.0008460.0058010.0008290.0082720.0092641.1991770.0449911.0171210.0408670.0019390.0006400.0005970.0005950.0005940.0005940.0107410.0008670.0006000.0005932.2252272.2757980.0547630.0018510.0058520.0007070.0086640.0007621.0537390.0220821.5249380.3053750.0064500.2959810.0100510.0007600.0005930.6850440.0183340.0008880.0086700.0007190.0005890.0005880.0005860.0005870.0005860.0005860.0236690.0009200.0005900.0005860.0005860.0005850.0005850.0005850.0005850.0005850.0005850.0005850.0101820.0007040.0005860.0005860.0005840.0005850.0005840.0065520.0006520.0005850.0005840.0005840.0005840.0005830.0356590.0009530.0334780.0256990.0008400.0005870.0005910.0005840.0005830.3033000.0034940.0006110.1105920.0016121.0469440.0153360.0007350.0005870.0005830.0005980.0005830.0012460.0037201.2461520.0118190.0006770.0005830.0058290.0006250.0005820.0005820.0061440.0006260.0005820.0005820.0005810.0005820.0005820.0160711.0107520.8252051.4362260.0111391.3113660.0100800.0010861.4915360.0164510.0006970.0057030.0184090.0007050.0005831.4803480.0105800.0061141.1624730.0121110.0173661.7190300.5259980.0039710.0006020.0005810.0005810.0005810.0005810.0057330.0058130.0006130.0005811.9568600.0123660.0006510.0005810.0005800.0057870.4682510.4820000.8562170.0054980.3709130.9610730.0060070.0086640.0006260.0005810.8619061.4527440.0085160.0144990.0006562.1489981.0854360.0063510.0006112.2253421.4631010.0162581.0743770.0251040.0007061.4429160.0079020.0006180.0005800.0009970.0161870.0006570.0005800.0005800.0005800.0005800.0005810.0005800.0005810.0080170.0006150.0005800.0005800.0005800.0005800.0005800.0005800.0005800.0005800.0005800.0005800.0055990.0006020.0107140.0006250.0005810.0058220.0006030.0005800.0059870.0057740.3223460.0019610.0069900.0006070.0005800.0005790.0203420.0064550.0006040.0005800.0005800.0076730.0006090.0005790.0005790.0005790.0005791.4577090.0064080.0006030.0060520.0062040.0006020.0005801.3841631.4104790.0060450.0059231.4915090.0062920.0006010.0011311.7061881.9655330.0136600.0006280.0005790.0005790.0005790.0005790.0005790.8832520.0095861.6743500.9904000.0041530.0005920.0005790.0005790.0044020.0005930.0005790.0005790.0005790.0006290.0005790.0005790.8696250.0035780.8432610.0034650.0005890.0005791.0456340.5817901.2288090.0047010.0006050.0005800.6470301.0474070.0040340.0005911.0374920.7629100.0030620.0005870.0058120.0005960.0005790.0005790.0005790.0005790.0005790.0005790.0005790.0532280.0007450.0010730.1037190.0009001.0753710.0041230.0057340.0005950.0005790.0058630.0247210.0234020.0059090.0005950.7337090.0080080.0110160.0058340.0057400.0005940.0108930.0057640.6324820.0024260.0005840.0005790.0005790.0005790.0005790.0005790.0005790.0005790.0005790.0005790.0005790.0005790.0005790.0005790.0005790.0005790.0005790.0005790.0005790.0005790.0005790.0005790.0005790.0549390.0065110.0005950.0005790.0005790.0005790.0005800.0005790.0005790.0005790.0005790.0005790.0005790.0005790.0005790.0005790.0057690.0005921.3857380.0047700.0005890.0005780.0011310.0009570.0005801.0341710.0032150.0006190.0005790.0005800.0600850.0007290.0005800.0005790.0005810.0005790.0005800.0005820.0005800.0005790.0005790.0005800.0005800.0005791.1527160.0033820.0099480.0006011.4350120.0040350.0005870.4032210.0246730.0006360.0394150.0244470.0068931.0311741.0164600.0029690.5291060.0018160.0005810.0005780.0005780.0005780.0005780.0064370.0005920.0005780.0005780.0005780.0005780.0005790.0005780.0005780.0005780.0005780.1155320.0278440.0217720.0006260.0059680.0011271.4621370.0091450.0058240.0005900.0005790.0063970.0005930.0005850.0005791.2109480.0032100.0005850.0005790.0005790.0086261.3913500.0035630.0900071.0025381.3379580.0034250.0005850.0005801.1952750.8215500.0023070.0065570.0065320.0005910.0005790.0005780.0005790.0053360.7956350.0964771.1970010.0030430.0005860.0005821.4491710.0115790.0006060.7671260.4523910.0015050.0005800.0059610.0005890.0005780.0005780.0005810.0057130.0107820.0005980.0005780.0005780.0005780.0005780.0130280.0006020.0005780.0055960.0005880.0059450.0129050.0006020.0005780.0081300.0060430.0066280.0005900.0056390.0094300.0005950.0005780.0142960.0006050.0058071.1281180.0027100.0119650.0006000.2701820.0059550.0061391.0454871.4786570.1817971.0440892.3286010.0050721.4951320.0037970.0060700.0005901.0344832.3992241.5019930.0033190.0057580.0057130.0012440.0005790.0056581.4195250.0031351.5157561.2355610.0079030.0005910.0005780.0056250.0005871.5147780.0081160.0055280.0056860.0005870.0005780.0005780.0005780.0054330.0056730.0005870.0055610.0005872.4903160.0049191.0471281.0996820.0024731.0445311.1620850.0033121.0470950.0023671.0909430.0080530.0057230.0059671.5083960.0031300.0056690.0005870.0147780.0121060.0005980.0005780.0057741.4830730.0083751.7853801.0395210.1026521.0718570.0185020.0086720.0893390.0072190.0218320.0057913.7713430.0117250.0005963.1968371.0874930.0074310.0056810.0005860.0057021.0589790.0022830.0005811.0610730.0073770.0005890.0056530.0005861.0672510.0022740.0056430.0005860.0005780.0056420.0005860.0012490.0005790.0056810.0056550.0005860.0166891.9753322.0801751.0308830.0225140.0208260.0137290.0006000.2322140.0009350.0125720.0101750.0005930.0165010.0056960.0005860.0088900.0159350.0211450.0237130.0058390.0057050.0058970.0059560.0113140.0005940.0164780.0006020.0058110.0005860.0114020.0057370.0005860.0005780.0005780.0058960.9800500.0554080.0481960.0113360.0005940.0005780.0005790.0005780.0005800.0341390.0006270.0086500.0005900.0005790.0005790.0005780.0005780.0017440.0005800.0005780.0086330.0005890.0086280.0219860.0006090.0118290.0005940.0084550.0071190.0071190.0005871.4730151.2645920.0074620.0057650.0059090.0005860.0059510.0005860.0057550.0005851.3841880.0025050.0005811.0741011.0469920.0020270.0005800.0056510.0005850.0057110.0051740.0238140.0245960.0264011.5294551.9740590.0127635.0169120.0124510.0005940.0052510.4510912.2263371.9595460.0088651.0625701.9637800.0135091.3340160.0040910.0005830.0005791.6569280.0496850.0006431.7289480.6411971.9932240.0032172.5114720.0038950.0005820.0005784.6169580.0066440.0005860.0005790.0005780.0247530.0006090.0005781.9570720.0031220.0207300.0209100.0204540.0197450.0209710.0207130.0054850.0005850.0005780.0005780.0079790.0005870.0005780.0005780.0005780.0111260.0056461.2470371.4407330.0073710.7818711.0380280.0018891.3703000.0128850.0058940.0131570.0059041.3098531.3181060.2311592.4188400.5010200.0944730.0006951.0598821.0493910.0018770.0005801.0558660.0018810.0005791.0545680.0068760.0005851.9508720.0029681.2935630.0076240.0005871.1528601.2806321.3215990.0964230.0006941.5379200.0024391.1863660.0020110.0328530.0268890.0057190.0107870.0107970.0167670.0286580.0137560.0005940.0146170.8981740.0016461.0204780.0017900.0005790.0012970.0005800.0053411.5231950.0024820.0057070.0109180.0005900.0005780.0005780.0166140.0210830.0059930.0005850.0005780.0005780.0005780.0005780.0005780.0005780.0144330.0005940.0005780.0005780.0005780.0005780.0005780.0005780.0005780.0005780.0005780.0005780.0005780.0005780.0005780.0005780.0005780.0089620.0334380.4643490.0126920.0005910.0774880.1303750.0215270.0181860.0005981.1822660.0019031.0621831.0659800.0017700.9041211.1737480.7137980.2634020.0170010.0166962.2944420.0082460.0117860.0064480.0005840.0157700.0061153.1642894.0646230.0050390.0005830.0010930.0060430.5582900.0063200.0058410.0061610.5865190.0166680.0005950.0142610.0149640.0127620.0119750.0144950.0108670.0109210.0109400.0059110.0108460.0005890.0108670.0161550.0057450.0160380.0109220.1199520.0104180.0005880.0005780.0616950.0006430.0005780.0005780.0005781.7151090.0023860.0005800.0005780.0005780.0005780.0005781.9538700.0026231.0328830.0016570.0005791.2879280.0118370.0063731.2091270.0018330.0005790.0503300.0006290.0447780.0006230.0005780.0005780.0452130.0006240.0005780.0057142.4235772.4286322.4171361.3569003.1695242.4324723.7812712.8216991.9228260.0076950.0005850.0005770.0005780.0005771.1306990.0017190.0005790.0005781.0421140.0016250.0005790.9919611.0357261.2105850.6748440.0012520.0005780.0005780.0005780.0005810.0005780.0005780.0005780.0091080.0254160.0006030.0005780.0087170.0842330.5149490.0017060.0005790.0005780.0005810.0005780.0005780.0005780.0058393.2619432.0678230.0276760.0006040.0005780.0005780.9972730.0098160.0492110.0089000.0086390.0005860.0373640.0203250.7896290.0064400.3228000.1872580.0519910.0006270.0064280.0062350.8868530.0014260.0062070.0005832.1324190.9588550.0014891.0574581.3280170.0018410.0005790.0005781.0731750.0015910.0090360.9887761.0326241.0652030.0015790.0005800.0170670.0061820.0005830.0086800.0005850.0005781.1980030.0075510.0005840.0087230.0005861.0434150.0566280.0006311.3550001.4141792.1147552.1011440.0239323.7508202.2820393.5624350.0125890.0010241.0969780.9360172.9520680.9819493.1467990.0086390.0159461.0124161.4918682.0776841.0109570.0354660.5786950.0062750.0164720.0597730.0013300.0005780.0236450.0231510.0567351.0657590.0015440.0005780.0005780.0005770.0005771.0595971.0672692.1115370.0080660.0005840.0056400.0005820.0005781.0636430.0019920.0005790.0005780.0005770.0086250.0005850.0005780.0086240.0005840.0086200.0086270.0005850.0005780.0005770.0005910.0005770.0016970.0005790.0005780.0005780.0005791.0841390.0177760.0086711.9003891.0494690.0176260.0005941.3853620.0178730.0005941.9127972.3043101.9986560.0123400.0056601.6003461.3041110.0123160.0064730.0005830.0005780.0005800.0005780.0005780.0005783.9395620.0039391.3630720.0070820.0057630.0058820.0005821.3302680.0017061.3302510.0017041.2936180.0016710.0160450.0005910.0005780.0005780.0005780.0005780.0005780.0005780.0167900.0005930.0010690.0005790.0005871.0756980.0014770.0086270.0005860.0005780.0005792.5076551.7119851.9841060.7819220.0012250.0005780.0005780.0005780.0061380.0067280.0005830.0005780.0005780.0056870.0063880.0005834.1833574.1869532.1016860.0140700.6776910.0153941.0526900.0095330.0086310.0005860.0182290.0086370.0007220.0005791.3827600.0016980.0005790.0005790.0005790.0166660.0005910.0005780.0210822.3590230.0269720.0063120.0005820.0005780.0005790.0058330.0005820.0005780.0005780.0062320.0005820.0005780.0005790.0005780.0005780.0057650.0005820.0005780.0057060.0005820.0005780.0057580.0005820.0005780.0005780.0005790.6369970.0010790.0005780.0096860.0005910.0092710.0005850.0005782.6156390.0207510.1359810.0228170.0170352.0923523.1403042.0943553.1395201.0593380.0229740.0214030.0217160.0215680.0223463.1514492.7031460.0235730.0217090.0215570.0217240.0222010.0224780.0256900.0297790.0167880.0058390.0119900.0112470.0118210.0118040.0112020.0061070.0062630.0261542.0400653.0142974.2137300.9864500.0243520.0005950.0005770.0005770.0005771.2498780.0015220.0005780.0082070.0971150.0006500.0238270.0220070.0226420.0250010.0500790.0279342.1763220.0208750.0005940.0248110.0087750.0483180.0006130.0086390.0194310.0005920.5904320.0010160.0005780.5714810.0010110.0005780.0096550.5714880.0010000.0005780.0005780.0005780.0005782.5432940.4247582.4781332.9625142.2238370.0022110.0005790.0005780.0086290.0005840.0005780.0086300.0005840.0005790.0005780.0005781.4398140.0016280.0005780.0005780.0007161.4479510.0016280.0005820.0005780.0005780.0086310.0086340.0005840.0005780.0005800.0086250.0005830.0005780.0005780.0005781.4246370.0114531.0737582.1382651.5189240.0309790.0087520.0189851.7871640.0120480.0057280.0159190.0208660.0056701.9760290.7390381.8063144.1764874.1838143.7647980.0113160.0086660.0087550.0167501.4246280.0096330.0005850.0086281.4370651.0685521.4215140.0015780.0218280.0209410.0107940.0160720.0163750.0965621.9674790.0172580.0163891.4715470.0173720.0162960.0057980.0160403.9435025.5374174.3556715.4144925.7962864.0810305.3936604.8767734.6129715.7950385.4504092.9090831.9742250.0215051.3556840.0200893.9079590.0032640.0139101.9613780.0072121.9570800.0089970.0656640.0065990.0172482.4268890.0256120.0214580.0213570.0218440.0212620.0160200.0005880.0057330.0107700.0005840.0057240.0005810.0005770.0005770.0055890.0005810.0005840.0053360.0005800.0108620.0057500.0005810.0057090.0005810.0005770.0005770.0005771.0215390.0112260.0205321.9262372.0582542.0682751.0156011.9653682.0843782.0910021.9986452.0834411.0584670.0158920.5431510.0061270.0114380.7778810.0141820.0058850.6337600.0125480.0111810.9921401.9516350.0189410.0417560.0166790.0249760.0163050.0460570.0174330.0112610.0197330.0137200.0255940.0057970.0058780.0005811.5087650.0141550.0005870.0144470.0005870.0005780.0005770.0005780.0005780.0013380.0077060.8464020.0024251.1980980.0013530.8202680.0011080.0071441.9572980.0897820.0087061.0603650.0063970.7584304.1000034.2141384.1053773.1657650.0026080.0005850.0166960.0167350.0087610.0005830.0005780.0086340.0082870.0113670.0131450.0111980.0142640.0111120.0115810.0108080.0056560.0106971.2571470.0118710.0360520.0330460.0086672.5199531.3166162.4067440.0153270.0056901.0749100.0115620.0057251.3664980.0116591.3580762.4353811.5121881.0685491.0687040.0063561.0687750.0063872.8675480.0131020.0068740.0194461.2122900.0210540.0162890.0057640.0109140.0005840.0110500.0110180.0531940.0006113.6173840.0500070.0475290.0006070.0059921.4362310.0065670.0005811.0509010.0012242.0527351.0577620.0012281.0378121.0375024.4497713.7557594.5036423.7638363.4379470.0179991.9574000.0069370.0005820.0056730.0005810.0108290.0005840.0057470.0005800.0005770.0005780.7932160.0010741.4457273.2732350.0025620.0005790.0005780.0005790.5583430.0065423.8449102.3843510.8070940.0292850.6131320.0009461.4248170.0014340.0005780.4844200.5901201.1250571.7592230.1783972.2505990.5469321.7182532.7550971.1761860.0012790.0005780.8084551.0661600.0012121.2935820.0013470.0005810.0086241.0836320.0012220.0005790.0005791.4444820.0014330.0005790.0086270.0086300.0060400.0114490.0114580.0107990.0160150.0057310.0111190.0108630.0108090.0109060.0163050.0005870.0215530.0056830.0161111.2737610.0070081.2772441.9436000.7363160.5367650.0008911.9083440.7084612.0254670.0184040.0005880.0005780.0005770.0158840.0005900.0108050.0108540.0109820.0110760.0161070.0161290.0108550.0159370.0056400.0109991.4995580.0064930.0005940.0060310.0005810.0005780.0106950.0106700.0052640.0055381.5052250.0065690.0056720.0057000.0005800.0104840.0058331.9617550.0016970.0005790.0105940.0107190.0005830.0106850.0005840.0005780.0005780.0012310.0005780.0005780.0158200.0066540.0005810.0209860.0005890.0056690.0005820.0005780.0057250.0005810.0005780.0107471.5159720.0062970.0067853.0122760.0022700.0005791.1840590.0012420.0005780.0005780.0005780.0005780.0086510.0006530.8927060.0010760.0005780.0005780.0005780.0086500.0086330.0005820.0086520.0005830.0005780.0005780.0376621.0716500.0092330.0328520.0171361.0411491.9635731.0730100.9663050.8813791.5989692.2064590.0275160.0139040.0139410.0270470.0087230.0138560.0139500.0137480.0188940.0135650.0173501.8817941.2886530.0012830.0169060.0170790.0105931.5149650.0061750.0106550.0736180.2771160.0540460.0380264.3062501.0324853.6231602.0851734.0508953.5595983.5597274.0044521.9753420.0250690.0289630.0684990.0058760.0180590.0511970.0157210.0256450.0287690.5191960.0268820.0168250.0142470.0308410.0139290.0204340.0057680.0005800.0005770.0005780.0057940.0059530.0074550.0064910.0005810.0005780.0005780.0005780.0061650.0005800.0005770.0005780.0005770.0005780.0005770.0005770.0005780.0005781.4981450.0066750.0005813.0042700.0021680.0005790.0122341.2237230.0120971.9610440.0099940.0111490.0055900.0111260.0114290.0059680.0058350.0005800.0005780.0086460.0086381.1037700.1124911.0467112.9197790.3417472.1505311.0004720.0129680.0120080.0079640.0066780.0067140.0005800.0140890.0005840.0005770.0005770.6843410.0686590.0006130.0062670.0659490.5801620.4171150.5234521.0517340.0011220.2060520.7166010.0298880.7121610.7565140.5544460.5248281.0368321.2840930.5697191.2095550.0012000.6769050.0128340.0221070.0124714.1321751.0653931.9729872.3881673.1540161.0206030.2345371.0967034.9660880.0271181.1781790.9670400.0187021.4328810.0103610.0193250.0154240.0226680.0227820.9009281.4691961.5696440.0096280.0151031.9390740.0097760.0086460.0005810.0086840.0005820.0005780.0005780.0005780.0005780.0005770.0005780.0087261.0453770.0011030.0005780.0005770.0005770.0093250.0086421.0444810.0091540.0005820.0005770.0056840.5869551.3011690.0269340.1637270.5478600.5512570.0410550.3220600.2044420.0006790.2990380.0917930.3114711.3016350.2295000.0280300.0058800.0059000.0005800.0083040.0005810.0005770.0129120.0120870.0118900.0090800.0113680.0005830.0005770.0005771.9722811.6917940.0223840.0440101.0414140.0256380.5061140.0231921.9570841.4237260.4796620.0008140.0005951.2219230.4624750.0008061.6680041.3146980.0012270.0005820.5993640.0008700.9463000.0010390.0005780.0005780.0005780.0005770.0029400.0005790.0577341.0459650.0010850.0005781.0255470.0093440.0005830.0219890.0005880.0219890.0005892.6872932.1309930.0236172.1132071.0635810.0225282.1143992.4181431.0378360.2354360.1333880.0224200.0400200.0053090.0149481.0447420.0010781.0719620.0062422.3611221.6907781.7129323.6627400.2796080.0223802.3819940.1682130.3522230.1480290.6564670.0260850.0218622.6376581.4161180.2554982.1344752.5166211.0423891.4167670.0013190.0008640.0005860.0089341.4407730.8969130.8026431.4337260.0012560.0108530.0093050.1307780.8519571.4777730.0116380.0057120.0109250.0106800.0057460.0104270.0106610.0057460.0060120.0185000.0005860.0057301.3440042.0944001.0084023.4430801.0484661.0491820.0174490.0058120.0167070.0005851.0558331.3407800.0171110.0111082.1386600.0382460.0302560.0379300.0086570.0167021.0679490.0252820.0057770.0086450.0086350.0005810.0167010.0248261.0528070.0010640.0057470.0005800.0110380.0057780.0117430.0058290.0110850.0061200.0057660.0064260.0110230.0113410.0115730.0005820.0005770.0161280.0171030.0112210.0115860.0111140.0059220.0058840.0111600.0059410.0005800.0005770.0005780.0062240.0005800.0005770.0341420.0005930.0005770.0005780.0005780.0005790.0005770.0005780.0282360.0005910.0005770.0186500.0005860.0005770.0658900.0409160.0005960.0005770.9452541.2510850.0132920.0005830.0005770.0010200.0005850.0506180.0006000.0717270.0006090.0575320.0006030.0005770.0005770.0005780.0005770.0005780.0005800.0005771.0392810.0010421.9320780.0072860.0005800.0005770.0005770.0064872.0265240.0014820.0005781.0528640.0010460.0011680.0057360.0163270.0161460.0158280.0106770.0106890.0107900.0068620.0158520.0107360.8805812.2003992.9536722.8977201.0828110.0092660.0005820.0250082.4080300.0097490.0086670.0192330.0219370.0198140.0006713.0081510.0094230.0059141.4804570.0012300.9442320.0009920.0007441.1239070.0102500.3734960.0016160.0828810.9777380.6707900.0059900.0061620.0056823.1596810.5009550.7129960.0058460.1388630.0128661.6999641.9158920.0069300.0005810.0055960.0105130.0005820.0055520.0043351.9590420.0014271.9573711.5044480.0012291.4878510.0012210.0064210.0005800.0063400.0005800.0005770.0005770.0108820.0110831.2863280.0062800.0211700.0005861.4797270.0169100.0005850.0057390.0057760.0214450.0108450.0159220.0058460.0109010.0058360.0056680.0057410.0066270.0005800.0106850.0005820.0160490.0005840.0218870.0058693.8356921.0614341.9701261.9736530.0014182.1344770.0202330.4856940.9871290.5311093.2175792.0669901.0010200.4973852.0312020.1855520.5682621.2057731.7434520.0013161.3200931.0309180.7632250.6839870.5858990.1082063.1448542.8487531.7867830.1132510.0057801.5367810.0148920.0117181.5065180.0085850.0061960.0059400.0113990.0114820.0060610.0224730.0110860.0112490.0056530.0164570.0115630.0151250.0061160.0086331.4507670.0011890.0005820.0086680.0166880.0086380.0005810.0166790.0005850.0166830.0086350.000581

*******************************************
EVALUATING PIPELINE 
Pipeline directory: /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_48d2cd48_2020-02-06_05-49-113dv6ag8u/
With following parameter combination: {'batch_size_seq_length': 1, 'lr': 3e-05, 'lr_type': 'constant'}
EVALUATION OF CHECKPOINT /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_48d2cd48_2020-02-06_05-49-113dv6ag8u/outputs/checkpoint-3
-------------------------------------------------------------
|           |   agree   | disagree  |  discuss  | unrelated |
-------------------------------------------------------------
|   agree   |    430    |    83     |    159    |    91     |
-------------------------------------------------------------
| disagree  |     0     |     0     |     0     |     2     |
-------------------------------------------------------------
|  discuss  |    314    |    72     |   1565    |    65     |
-------------------------------------------------------------
| unrelated |    18     |     7     |    76     |   6740    |
-------------------------------------------------------------
Score: 6992.0 out of 7516.5	(93.02201822656822%)
Accuracy: 0.9078154229889835
F1 overall: 0.591328397350942
F1 per class: [0.5639344262295082, 0.0, 0.820230607966457, 0.9811485552078026]
*******************************************


*******************************************
EVALUATING PIPELINE 
{'batch_size_seq_length': 4, 'lr': 3e-05, 'lr_type': 'constant'}
INFO:__main__:Creating features from dataset file at /home/ubuntu/fnd_implementation/data/processed
  0%|                                                                                                                                          | 0/9622 [00:00<?, ?it/s]  0%|                                                                                                                                | 1/9622 [00:02<7:22:10,  2.76s/it] 21%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                                                                                   | 2001/9622 [00:03<4:05:10,  1.93s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                                            | 5001/9622 [00:03<1:44:04,  1.35s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                            | 7501/9622 [00:03<33:26,  1.06it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9622/9622 [00:03<00:00, 2665.20it/s]
  ******************************************* 
              Running Evaluation                
  *******************************************
 
  Length dataset evaluation: 9622
  Length dataloader evaluation: 301
  Number of epochs: 3
  Batch size: 32
  ******************************************* 
 
['/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_5093d00e_2020-02-06_07-27-51avgl_d7i/outputs/checkpoint-3']
INFO:__main__:Evaluate the following checkpoints: ['/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_5093d00e_2020-02-06_07-27-51avgl_d7i/outputs/checkpoint-3']
INFO:transformers.configuration_utils:loading configuration file /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_5093d00e_2020-02-06_07-27-51avgl_d7i/outputs/checkpoint-3/config.json
INFO:transformers.configuration_utils:Model config {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 28996
}

INFO:transformers.modeling_utils:loading weights file /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_5093d00e_2020-02-06_07-27-51avgl_d7i/outputs/checkpoint-3/pytorch_model.bin
HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=301.0, style=ProgressStyle(description_width='initial')), HTML(value='')))
0.0001770.0003440.0002480.2908990.0728030.1791500.3492250.0558310.0077780.0009940.2316490.0217090.0034080.1813210.0130460.0009740.2532620.2113440.0453650.3997080.0208761.0998050.3435440.8991820.0406960.0018630.0001800.0000650.0147800.1482730.0947930.2688820.2555820.1688430.2046430.0061100.2155730.6484600.1829190.0049570.0008830.1013730.0134480.0003440.0000440.0000940.0000320.0000510.0005410.0746660.0016090.0228350.0928110.1797110.0034440.0070290.2280980.0040470.1126350.0027310.4811040.2104280.0036910.0002410.0614590.1132270.3388160.3538030.3656630.5593910.0083760.0002460.3313250.0092500.2671820.0134320.3539050.4178930.2219480.0039560.0413280.0657760.0021260.0007940.6028040.0079560.0001580.0058710.1259620.0024040.0058162.0762430.2294820.0050140.9547100.5688280.0062470.0409740.0777520.1262640.1581990.0557610.2941940.0464710.3825060.1131940.0014540.0001220.1063940.0010140.0554850.3765930.0288761.0743170.1396560.9282260.5527640.4677300.0045570.0092710.0025920.3607442.0855270.0174580.2719460.0022380.0110710.1401360.0886880.2242570.0026820.0647460.0354580.0042090.0081140.4866240.0046130.0124400.1792570.1987470.0771440.0007970.2419740.0039210.3020500.0155250.8232510.5754900.0040060.0025530.0015460.0009561.3695630.0102590.2434180.0035540.0017070.0002890.0516110.2655432.3245000.3764980.0041470.0805080.0241210.1362850.1042750.1893970.0016960.0065480.0755550.0005700.0001670.0001620.0027990.0857431.9485140.0147600.0449610.0006230.2391890.1847770.2643790.0421520.0036310.0027160.5712982.5822980.1971660.0533480.1212380.0109910.1392060.2838402.1266490.0116810.0005170.0034060.4664461.1007051.1296230.0165410.0785261.5979110.6688600.0524150.1046070.5840361.6865561.6219190.0405210.0005320.0010140.4963360.9900290.0048130.0002450.0004030.0002360.0002760.0002570.0002780.0002840.0004520.0003020.0021880.3732340.0028740.0016160.0038890.3503400.2561240.0082840.0003120.0000740.0024770.4698020.0113901.5177800.1667850.0031940.1449410.5557690.6687420.5247590.0035360.0018590.0004560.0044780.0233560.0116490.1800840.0094750.0731521.4759180.1210760.0390180.0012710.2635280.0708030.2824930.9164500.8504420.0075030.0694980.0636710.0449670.3461550.3707950.0387920.2002680.0783800.0007300.0895770.0045430.0237300.0028160.0009260.0001050.0006020.1224030.0010770.0947610.1327590.0020010.0091040.2590990.0014180.1866710.1232350.0015840.0625710.0872660.3155880.0060390.0544220.6498490.2383670.0014350.0949970.000671

*******************************************
EVALUATING PIPELINE 
Pipeline directory: /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_5093d00e_2020-02-06_07-27-51avgl_d7i/
With following parameter combination: {'batch_size_seq_length': 4, 'lr': 3e-05, 'lr_type': 'constant'}
EVALUATION OF CHECKPOINT /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_5093d00e_2020-02-06_07-27-51avgl_d7i/outputs/checkpoint-3
-------------------------------------------------------------
|           |   agree   | disagree  |  discuss  | unrelated |
-------------------------------------------------------------
|   agree   |    618    |    38     |    161    |    16     |
-------------------------------------------------------------
| disagree  |    13     |    81     |    28     |     6     |
-------------------------------------------------------------
|  discuss  |    128    |    41     |   1597    |    25     |
-------------------------------------------------------------
| unrelated |     3     |     2     |    14     |   6851    |
-------------------------------------------------------------
Score: 7227.5 out of 7516.5	(96.15512539080689%)
Accuracy: 0.950633963832883
F1 overall: 0.8045486079961852
F1 per class: [0.7749216300940439, 0.5586206896551724, 0.8894458368142578, 0.9952062754212667]
*******************************************


*******************************************
EVALUATING PIPELINE 
{'batch_size_seq_length': 3, 'lr': 3e-05, 'lr_type': 'linear'}
INFO:__main__:Creating features from dataset file at /home/ubuntu/fnd_implementation/data/processed
  0%|                                                                                                                                          | 0/9622 [00:00<?, ?it/s]  0%|                                                                                                                                | 1/9622 [00:02<7:03:49,  2.64s/it]  5%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                                                                                       | 501/9622 [00:02<4:41:16,  1.85s/it] 21%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                                                                                   | 2001/9622 [00:03<2:44:32,  1.30s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                            | 7501/9622 [00:03<32:03,  1.10it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9622/9622 [00:03<00:00, 2495.39it/s]
  ******************************************* 
              Running Evaluation                
  *******************************************
 
  Length dataset evaluation: 9622
  Length dataloader evaluation: 602
  Number of epochs: 3
  Batch size: 16
  ******************************************* 
 
['/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_582282f2_2020-02-06_09-29-064i78cr62/outputs/checkpoint-3']
INFO:__main__:Evaluate the following checkpoints: ['/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_582282f2_2020-02-06_09-29-064i78cr62/outputs/checkpoint-3']
INFO:transformers.configuration_utils:loading configuration file /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_582282f2_2020-02-06_09-29-064i78cr62/outputs/checkpoint-3/config.json
INFO:transformers.configuration_utils:Model config {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 28996
}

INFO:transformers.modeling_utils:loading weights file /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_582282f2_2020-02-06_09-29-064i78cr62/outputs/checkpoint-3/pytorch_model.bin
HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=602.0, style=ProgressStyle(description_width='initial')), HTML(value='')))
0.0003360.0003690.0002130.0001010.0000540.0001080.3821410.4896110.0612300.0070530.0010580.2207960.4599090.0354110.0025950.0004760.0000840.0000930.0000400.0000320.0005570.0000900.0000540.0002880.0015970.0004350.0001400.0273610.0010070.0001030.0000980.0000760.0000370.0034970.0001490.3653270.0105270.0006210.8991870.0231070.0006950.0001490.7402151.0984180.0255250.4882941.4014180.2540260.0067690.0001660.0001420.0000340.0000700.0000280.0000280.0000590.0001430.0288410.0008550.0000750.0006130.0000360.5232600.0084170.5210710.0081191.0211560.0152660.4206630.0065170.0001220.0000300.0006650.3464380.3047030.9109010.0889790.0012310.0000420.0003510.0149140.0002390.2284320.2795240.0034590.0010910.0000390.0000280.0000270.0000270.0000270.0001100.0000290.0000280.0000280.0000770.0014130.0010270.0000400.0001520.0000310.0000320.0016520.0005530.0005690.3944730.1860650.0018420.0002680.0000380.0001390.0010230.5524450.0049730.0000700.0000280.0006600.0003650.0006300.0001580.0011341.2590711.0724680.0100800.0001520.0001500.0000330.0001650.0002520.0003190.0002000.2578180.7338720.4309950.7668080.0071580.8303640.3434320.0386710.6547120.0053440.0001530.0000630.0001331.3103700.4397110.4419290.0031410.0002130.5342440.0045300.0009390.8657770.0250930.0002820.2471480.0016680.0023900.0000740.0000930.0075260.0004860.0017020.0001610.0009490.0001590.0001750.0001780.0000780.0006870.0000320.0019460.0000420.0000300.0012380.0001010.0001370.0003280.0007790.0026260.0005090.0001411.8862241.4363780.1340970.6108370.0609440.0007390.5021190.9649751.3623490.0100120.0003110.0004730.0002310.0001120.0004030.0007180.0002770.0018720.2130600.0186840.0648570.0289920.0007601.8738530.0167730.0011660.0006060.4181990.0496850.0003400.0001700.0068860.0002700.0000270.4532130.0021130.0000350.0000260.3077810.6814490.0032900.7343610.0035650.0007990.0005032.0962650.0114210.3558370.0019450.1000661.2568710.4567520.6875920.4074990.0017960.0000410.0011760.4152420.4059970.0027400.0002250.4267221.5591981.6633130.0068180.0001590.0002780.0006520.0000300.0000320.0004610.0046880.0000460.4603930.4555000.0024760.3750810.6548330.0030230.1274410.0069940.0099610.0054860.0011450.0041100.0628060.0005640.0431140.1875331.1894090.0124200.0007550.0042870.0078600.0570860.4382150.0016141.6623440.0060010.3381430.0013420.0004380.0000300.5681350.0043640.0035670.0311810.8209410.1210530.0004670.8978550.3196000.3232300.5296090.0022450.0000340.0011200.0011870.0008680.0032970.0000950.0002461.7613082.2840570.0083510.0007900.2082630.0017810.0014520.0000800.0000910.0000880.0001360.0001880.0000520.0001940.0002481.1404161.6407371.2469570.0080980.0333380.0008980.0007950.0007450.0517900.6129110.0119760.0005280.3405950.0377600.0013840.0018300.0038600.0002350.0002290.0000280.0042710.2373340.0029080.0000380.0000410.0000430.0005740.0003510.0000360.0597290.0048090.3687490.5071874.2993330.0126420.0002580.0010160.0005280.0003440.0004010.0018230.4365750.6684310.0357000.0335380.0194590.0019340.5075520.0016750.0009420.1257850.0005530.0376190.0001331.3315752.5264113.5211430.4430270.0524770.2558910.4220230.0014400.3573050.0025980.0001070.0000320.0150610.1638380.1273020.3928024.0466710.0169120.0012770.0003780.0002370.0010340.0017660.4126460.5469081.7288530.8304930.9619040.5769660.0018170.0495420.0003210.3298191.5649194.5695052.2466060.0057240.0001420.2240210.1766130.0005801.8893540.4717850.7607730.7891110.4603450.3878070.3601230.0018790.0001730.3433630.0987030.0129330.0004361.6609421.1550440.7122890.0018210.0002350.0004330.0001630.0001070.0002260.0001880.0001930.0001880.0000840.0000560.0002440.0001690.0001410.0007020.0000430.0000280.0002950.0001530.0002420.0004780.0013580.3930190.0074260.0006310.0005690.0005780.0966360.0006381.3200792.0989740.7647150.0023730.0518410.0041670.0004290.0001080.0001720.0001340.0000260.0003090.0000710.0164140.0004270.0003120.2521270.3445933.5685390.5854890.2219240.3605550.0014530.0037360.0023800.0021310.0024550.0010870.9777191.5062020.1840430.0013770.0012090.4859010.0016930.0002590.0000290.0002930.0002510.1425461.0058851.4588450.5361232.0442480.5410580.0011810.0058700.0010191.5918770.5664860.6245330.2358400.6293870.2204830.1040860.0013380.0003220.0002870.5542670.0843540.2422860.3786951.0378021.9441650.7805570.3151260.0040790.0002170.0003010.1843230.0799680.0749280.0007470.0008600.0170460.8338360.0017670.0054460.6000870.0593450.0003880.3758210.0008600.0003200.0010700.0002860.0005880.0007030.0001300.0010360.0000300.0070350.0029120.0003220.0003350.0001720.0001950.0000310.0000300.0005990.0000620.2607200.0021320.0002840.0002382.5367810.0061480.0007940.0004270.0002560.0023630.0041480.0025980.6859400.0017910.0004830.0002510.5603830.0011890.0000850.0009250.0003050.0005790.0656730.0010070.0005560.0093731.1210060.3348000.0028750.0029400.0042750.0489180.3381460.1611910.0006420.0002550.0003130.0002870.0015250.0004230.0003800.000281

*******************************************
EVALUATING PIPELINE 
Pipeline directory: /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_582282f2_2020-02-06_09-29-064i78cr62/
With following parameter combination: {'batch_size_seq_length': 3, 'lr': 3e-05, 'lr_type': 'linear'}
EVALUATION OF CHECKPOINT /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_582282f2_2020-02-06_09-29-064i78cr62/outputs/checkpoint-3
-------------------------------------------------------------
|           |   agree   | disagree  |  discuss  | unrelated |
-------------------------------------------------------------
|   agree   |    575    |    30     |    96     |     4     |
-------------------------------------------------------------
| disagree  |    15     |    84     |    41     |     2     |
-------------------------------------------------------------
|  discuss  |    165    |    46     |   1642    |    19     |
-------------------------------------------------------------
| unrelated |     7     |     2     |    21     |   6873    |
-------------------------------------------------------------
Score: 7266.5 out of 7516.5	(96.67398390208209%)
Accuracy: 0.9534400332571191
F1 overall: 0.80672365489261
F1 per class: [0.7839127471029311, 0.5526315789473685, 0.8943355119825708, 0.9960147815375697]
*******************************************


real	19m11.559s
user	23m18.959s
sys	7m15.396s
ubuntu@run-gpu-mg:~/fnd_implementation$ 
ubuntu@run-gpu-mg:~/fnd_implementation$ [Kubuntu@run-gpu-mg:~/fnd_implementation$ ei[Kxti[K[Kit
exit

Script done on 2020-02-06 17:28:05+0000
