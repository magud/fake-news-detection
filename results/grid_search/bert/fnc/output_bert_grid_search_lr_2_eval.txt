Script started on 2020-02-07 06:04:36+0000
ubuntu@run-gpu-mg:~/fnd_implementation$ exitscript output_bert_grid_search_lr_2_eval..txtM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Cexit[K
[KM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Ctime python3 eval_separate.py --model=berrt --model_type=bert-base-cased
/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/home/ubuntu/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/ubuntu/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/ubuntu/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/ubuntu/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/ubuntu/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/ubuntu/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
There are 2 GPU(s) available.
The following GPU is used:  Tesla V100-PCIE-16GB
INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-config.json from cache at /home/ubuntu/.cache/torch/transformers/b945b69218e98b3e2c95acf911789741307dec43c698d35fad11c1ae28bda352.3d5adf10d3445c36ce131f4c6416aa62e9b58e1af56b97664773f4858a46286e
INFO:transformers.configuration_utils:Model config {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": "multi",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 28996
}

INFO:transformers.tokenization_utils:loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-vocab.txt from cache at /home/ubuntu/.cache/torch/transformers/5e8a2b4893d13790ed4150ca1906be5f7a03d6c4ddf62296c383f6db42814db2.e13dbb970cb325137104fb2e5f36fe865f27746c6b526f6352861b1980eb80b1
INFO:transformers.configuration_utils:loading configuration file /home/ubuntu/fnd_implementation/bert/model_pretrained/config.json
INFO:transformers.configuration_utils:Model config {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 28996
}

INFO:transformers.modeling_utils:loading weights file /home/ubuntu/fnd_implementation/bert/model_pretrained/pytorch_model.bin
INFO:__main__:Loading initialized pretrained model from /home/ubuntu/fnd_implementation/bert/model_pretrained
  ******************************************* 
           Freezing Embedding Layers          
  *******************************************
 
name:  bert.embeddings.word_embeddings.weight
param.requires_grad:  False
=====
name:  bert.embeddings.position_embeddings.weight
param.requires_grad:  False
=====
name:  bert.embeddings.token_type_embeddings.weight
param.requires_grad:  False
=====
name:  bert.embeddings.LayerNorm.weight
param.requires_grad:  False
=====
name:  bert.embeddings.LayerNorm.bias
param.requires_grad:  False
=====
name:  bert.encoder.layer.0.attention.self.query.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.0.attention.self.query.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.0.attention.self.key.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.0.attention.self.key.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.0.attention.self.value.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.0.attention.self.value.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.0.attention.output.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.0.attention.output.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.0.attention.output.LayerNorm.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.0.attention.output.LayerNorm.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.0.intermediate.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.0.intermediate.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.0.output.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.0.output.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.0.output.LayerNorm.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.0.output.LayerNorm.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.1.attention.self.query.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.1.attention.self.query.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.1.attention.self.key.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.1.attention.self.key.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.1.attention.self.value.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.1.attention.self.value.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.1.attention.output.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.1.attention.output.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.1.attention.output.LayerNorm.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.1.attention.output.LayerNorm.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.1.intermediate.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.1.intermediate.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.1.output.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.1.output.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.1.output.LayerNorm.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.1.output.LayerNorm.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.2.attention.self.query.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.2.attention.self.query.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.2.attention.self.key.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.2.attention.self.key.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.2.attention.self.value.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.2.attention.self.value.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.2.attention.output.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.2.attention.output.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.2.attention.output.LayerNorm.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.2.attention.output.LayerNorm.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.2.intermediate.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.2.intermediate.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.2.output.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.2.output.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.2.output.LayerNorm.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.2.output.LayerNorm.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.3.attention.self.query.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.3.attention.self.query.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.3.attention.self.key.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.3.attention.self.key.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.3.attention.self.value.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.3.attention.self.value.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.3.attention.output.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.3.attention.output.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.3.attention.output.LayerNorm.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.3.attention.output.LayerNorm.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.3.intermediate.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.3.intermediate.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.3.output.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.3.output.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.3.output.LayerNorm.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.3.output.LayerNorm.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.4.attention.self.query.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.4.attention.self.query.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.4.attention.self.key.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.4.attention.self.key.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.4.attention.self.value.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.4.attention.self.value.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.4.attention.output.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.4.attention.output.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.4.attention.output.LayerNorm.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.4.attention.output.LayerNorm.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.4.intermediate.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.4.intermediate.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.4.output.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.4.output.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.4.output.LayerNorm.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.4.output.LayerNorm.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.5.attention.self.query.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.5.attention.self.query.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.5.attention.self.key.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.5.attention.self.key.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.5.attention.self.value.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.5.attention.self.value.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.5.attention.output.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.5.attention.output.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.5.attention.output.LayerNorm.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.5.attention.output.LayerNorm.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.5.intermediate.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.5.intermediate.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.5.output.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.5.output.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.5.output.LayerNorm.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.5.output.LayerNorm.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.6.attention.self.query.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.6.attention.self.query.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.6.attention.self.key.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.6.attention.self.key.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.6.attention.self.value.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.6.attention.self.value.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.6.attention.output.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.6.attention.output.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.6.attention.output.LayerNorm.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.6.attention.output.LayerNorm.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.6.intermediate.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.6.intermediate.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.6.output.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.6.output.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.6.output.LayerNorm.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.6.output.LayerNorm.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.7.attention.self.query.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.7.attention.self.query.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.7.attention.self.key.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.7.attention.self.key.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.7.attention.self.value.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.7.attention.self.value.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.7.attention.output.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.7.attention.output.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.7.attention.output.LayerNorm.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.7.attention.output.LayerNorm.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.7.intermediate.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.7.intermediate.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.7.output.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.7.output.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.7.output.LayerNorm.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.7.output.LayerNorm.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.8.attention.self.query.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.8.attention.self.query.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.8.attention.self.key.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.8.attention.self.key.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.8.attention.self.value.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.8.attention.self.value.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.8.attention.output.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.8.attention.output.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.8.attention.output.LayerNorm.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.8.attention.output.LayerNorm.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.8.intermediate.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.8.intermediate.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.8.output.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.8.output.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.8.output.LayerNorm.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.8.output.LayerNorm.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.9.attention.self.query.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.9.attention.self.query.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.9.attention.self.key.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.9.attention.self.key.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.9.attention.self.value.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.9.attention.self.value.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.9.attention.output.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.9.attention.output.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.9.attention.output.LayerNorm.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.9.attention.output.LayerNorm.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.9.intermediate.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.9.intermediate.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.9.output.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.9.output.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.9.output.LayerNorm.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.9.output.LayerNorm.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.10.attention.self.query.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.10.attention.self.query.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.10.attention.self.key.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.10.attention.self.key.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.10.attention.self.value.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.10.attention.self.value.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.10.attention.output.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.10.attention.output.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.10.attention.output.LayerNorm.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.10.attention.output.LayerNorm.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.10.intermediate.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.10.intermediate.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.10.output.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.10.output.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.10.output.LayerNorm.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.10.output.LayerNorm.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.11.attention.self.query.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.11.attention.self.query.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.11.attention.self.key.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.11.attention.self.key.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.11.attention.self.value.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.11.attention.self.value.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.11.attention.output.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.11.attention.output.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.11.attention.output.LayerNorm.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.11.attention.output.LayerNorm.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.11.intermediate.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.11.intermediate.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.11.output.dense.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.11.output.dense.bias
param.requires_grad:  True
=====
name:  bert.encoder.layer.11.output.LayerNorm.weight
param.requires_grad:  True
=====
name:  bert.encoder.layer.11.output.LayerNorm.bias
param.requires_grad:  True
=====
name:  bert.pooler.dense.weight
param.requires_grad:  True
=====
name:  bert.pooler.dense.bias
param.requires_grad:  True
=====
name:  classifier.weight
param.requires_grad:  True
=====
name:  classifier.bias
param.requires_grad:  True
=====

*******************************************
Evaluating the following pipelines 
['/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_9ef6d6f2_2020-02-06_23-51-56s3toit5i/', '/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_a1894e54_2020-02-07_00-04-51x1etl769/', '/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_a42e456a_2020-02-07_00-31-4805upq6g7/', '/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_b5ded1d0_2020-02-07_05-01-51e9ghwi9m/', '/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_9c545fdc_2020-02-06_22-26-32t3hl64rl/', '/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_99965340_2020-02-06_22-26-28lwg0mm8l/', '/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_b352ca52_2020-02-07_04-23-01vtufcmov/', '/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_ae54fad4_2020-02-07_02-44-360_fs3gz8/', '/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_b0d2ae96_2020-02-07_02-47-15hz_brz0f/', '/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_abc96354_2020-02-07_02-10-3373kz4_ya/', '/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_a9451268_2020-02-07_02-05-362jt98_g1/', '/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_a6b73fda_2020-02-07_00-40-578fsejkgg/']

*******************************************

*******************************************
EVALUATING PIPELINE 
{'batch_size_seq_length': 3, 'lr': 2e-05, 'lr_type': 'constant'}
INFO:__main__:Creating features from dataset file at /home/ubuntu/fnd_implementation/data/processed
  0%|                                                  | 0/9622 [00:00<?, ?it/s]  0%|                                        | 1/9622 [00:02<6:40:49,  2.50s/it] 21%|███████▋                             | 2001/9622 [00:03<3:42:16,  1.75s/it]100%|█████████████████████████████████████| 9622/9622 [00:03<00:00, 2441.16it/s]
  ******************************************* 
              Running Evaluation                
  *******************************************
 
  Length dataset evaluation: 9622
  Length dataloader evaluation: 602
  Number of epochs: 3
  Batch size: 16
  ******************************************* 
 
['/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_9ef6d6f2_2020-02-06_23-51-56s3toit5i/outputs/checkpoint-3']
INFO:__main__:Evaluate the following checkpoints: ['/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_9ef6d6f2_2020-02-06_23-51-56s3toit5i/outputs/checkpoint-3']
INFO:transformers.configuration_utils:loading configuration file /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_9ef6d6f2_2020-02-06_23-51-56s3toit5i/outputs/checkpoint-3/config.json
INFO:transformers.configuration_utils:Model config {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 28996
}

INFO:transformers.modeling_utils:loading weights file /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_9ef6d6f2_2020-02-06_23-51-56s3toit5i/outputs/checkpoint-3/pytorch_model.bin
eval_separate.py:214: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0
Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`
  for batch in tqdm_notebook(eval_dataloader, desc="Evaluating"):
HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=602.0, style=ProgressStyle(description_width='initial')), HTML(value='')))
0.0001800.0002010.0001340.0000780.0000410.0000820.4589760.4599080.0575140.0065040.0007720.0002110.2357630.0181650.0017340.0002930.0052830.0214010.0013580.7596050.5047400.1429280.0065940.0005570.0006380.0001860.0000380.0739540.0026630.5607360.0187480.0006590.0000430.4682690.0171040.8683000.0465550.7920500.9228920.0237580.0008230.0001370.9823801.4471880.0331950.5959581.5718840.7697360.0278860.0005990.0001340.0000890.0001580.0000260.0000230.0000550.0001200.0002390.0002410.0000560.0006580.0000350.9274820.0148660.5313860.0082520.7409800.0110790.3860090.0059100.0002690.0000220.1742290.0029730.0006440.4977940.1548500.0020570.0000470.0021250.0054470.0001270.0018420.149822
0.0019060.0372120.0004520.0000250.0000200.0000200.0000220.0001180.0000210.0000220.0000210.0002130.0001730.0003980.0000370.0001700.0000260.0000330.0000460.1707980.0017630.3903550.3587170.0034700.0002650.0000340.0000230.0012720.5467170.0049640.0000640.0000380.0005670.0002470.0046000.0001550.0004861.1701951.5249200.0171300.0012990.0002470.0000200.0001690.0139870.1266840.0296620.2776430.5187710.3483981.3758140.0103701.0794950.0861850.3759250.2313500.4576320.0033580.0000790.0001141.2736920.4903180.4904100.0034820.0002380.3669540.5729850.0045570.0027110.0020250.0001200.9133170.0059580.4460570.0028820.0002781.9513380.0126800.0012690.0003700.0004540.0014580.0011130.0006140.0000500.0003640.0000770.0002330.0000780.0000450.0002060.0001660.0001190.0003500.0002110.0077320.7108480.0040490.8665680.7573320.4712530.9912190.2811050.0020671.2306771.0756911.5055640.0081010.0003220.0004350.0000700.0001770.0001880.0005130.0006340.0004770.7897300.1768860.0072830.0044410.0033770.2529480.0023190.0005500.0004810.6134110.0422130.0003760.0001590.0002370.0000630.0000180.2710360.0012720.0000230.0000200.6499200.1616350.0034350.6919690.0332280.0006660.0014142.4095270.0108780.4249730.5725560.4111341.3068850.4335910.3883050.0166660.0001980.0000270.0001280.9206730.5227850.1517420.0035190.3527810.5525552.7807770.0113570.0000870.1153270.0026970.0000310.0000290.0003730.0002990.0000231.4951340.8689790.0039080.0627400.8239720.0151030.0418490.0295100.3135090.0575390.1916580.0011230.0002710.0006580.0267570.3910161.4616350.4994150.0024100.4991621.3474450.9256620.5363740.0019911.8261950.0065780.4288650.0017430.0008830.0000210.3897860.0077020.0024290.0001992.1600930.3953880.0014100.6463130.1363680.1886660.3608490.0013650.0000300.0003150.0007290.0003200.1153180.0014550.0011301.4525101.8592400.1273770.0007270.2171610.0009340.0130980.0001270.0000890.0001140.0001240.0001330.0000770.0001290.0002190.0013062.1558652.2421550.3307490.0294310.0444630.0008160.0008750.2387870.6214130.0027700.0000290.1281450.2609590.0025510.0004270.0049630.0002330.0003120.0000290.0195890.0037900.2358140.0007370.0000600.0000280.0002010.0001170.0000320.0104700.0092150.0003811.7760376.1671680.0180980.0074900.0022670.0383120.0011260.0003790.0002630.2587970.4069040.5024171.0968392.3833521.7245610.4907830.0016780.0002480.0002060.0001520.0021780.0000321.3638692.5466943.4965600.4263200.0015350.2929330.5190130.0017310.1723090.0019500.0001470.0000260.3603280.8635290.0035000.3773513.4434260.0100030.0002750.0003850.0003340.0110150.0706210.8740130.5468872.0953210.9670201.0983650.3131730.0010960.0107650.0002710.4546552.0233054.6634881.7623780.0044200.0001700.2479341.0500060.0026970.0111220.4614500.4886340.0110760.0089560.3443520.2565630.0012960.0001060.0023390.0002710.0003030.0002641.2483891.4293000.5902370.0015460.0002540.0003580.0001880.0000950.0001850.0001580.0001890.0001480.0000870.0000610.0002570.0000600.0001140.1154000.0002850.0000200.0002870.0001030.0001730.0004620.0022160.1001700.2013580.0009040.0006040.0005500.0021590.0003960.0314680.1785490.0016760.0007530.0013750.0004310.0003330.0001430.0004120.0000740.0000210.0000270.0001500.0236920.0003030.0002290.0001370.2346573.5377160.4066100.0011760.0002390.0003980.0728920.0011330.4493310.0087640.0028771.0539561.5874050.0045820.0020780.0008060.0016820.0011410.0036330.0000270.0021880.0003500.1762070.2434420.1016690.0032360.2885310.0098420.0001720.0024320.0077940.4535851.4934611.0375390.9898231.3723060.5257060.0020780.0029020.0004900.0004852.0555022.5053991.4728220.0127150.0144330.7177411.0371412.0176830.0520480.0002850.0001930.0038430.0005970.0004620.0004490.0006340.5949411.7393300.0034430.8768400.8714180.3581210.0029560.4443560.0009430.0002030.0001950.0001600.0003410.0003000.0465020.0006150.0000210.1558410.0013160.0004290.1678840.0005650.0002420.0000220.0000310.0008050.0002080.0032860.0004480.0009240.0005714.6152550.0090490.0005270.0008610.4751030.0544420.0140300.2513370.8448460.0040320.0003320.0003361.0518030.0019730.0001200.0096430.0002010.0002250.0075280.0004200.0003420.0124760.4089470.2556120.0013730.0008891.1023750.4490370.1558250.2435400.2812190.0018110.0003670.0013690.0001430.0002170.0002260.000137

*******************************************
EVALUATING PIPELINE 
Pipeline directory: /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_9ef6d6f2_2020-02-06_23-51-56s3toit5i/
With following parameter combination: {'batch_size_seq_length': 3, 'lr': 2e-05, 'lr_type': 'constant'}
EVALUATION OF CHECKPOINT /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_9ef6d6f2_2020-02-06_23-51-56s3toit5i/outputs/checkpoint-3
-------------------------------------------------------------
|           |   agree   | disagree  |  discuss  | unrelated |
-------------------------------------------------------------
|   agree   |    564    |    31     |    99     |     6     |
-------------------------------------------------------------
| disagree  |     8     |    76     |    34     |     6     |
-------------------------------------------------------------
|  discuss  |    188    |    52     |   1649    |    30     |
-------------------------------------------------------------
| unrelated |     2     |     3     |    18     |   6856    |
-------------------------------------------------------------
Score: 7252.0 out of 7516.5	(96.48107496840285%)
Accuracy: 0.9504261068384952
F1 overall: 0.7962734692609936
F1 per class: [0.771545827633379, 0.5314685314685315, 0.8867975262167249, 0.9952819917253394]
*******************************************


*******************************************
EVALUATING PIPELINE 
{'batch_size_seq_length': 4, 'lr': 2e-05, 'lr_type': 'constant'}
INFO:__main__:Creating features from dataset file at /home/ubuntu/fnd_implementation/data/processed
  0%|                                                  | 0/9622 [00:00<?, ?it/s]  0%|                                        | 1/9622 [00:02<6:46:45,  2.54s/it] 21%|███████▋                             | 2001/9622 [00:03<3:45:32,  1.78s/it] 52%|███████████████████▏                 | 5001/9622 [00:03<1:35:44,  1.24s/it] 78%|██████████████████████████████▍        | 7501/9622 [00:03<30:45,  1.15it/s]100%|█████████████████████████████████████| 9622/9622 [00:03<00:00, 2595.79it/s]
  ******************************************* 
              Running Evaluation                
  *******************************************
 
  Length dataset evaluation: 9622
  Length dataloader evaluation: 301
  Number of epochs: 3
  Batch size: 32
  ******************************************* 
 
['/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_a1894e54_2020-02-07_00-04-51x1etl769/outputs/checkpoint-3']
INFO:__main__:Evaluate the following checkpoints: ['/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_a1894e54_2020-02-07_00-04-51x1etl769/outputs/checkpoint-3']
INFO:transformers.configuration_utils:loading configuration file /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_a1894e54_2020-02-07_00-04-51x1etl769/outputs/checkpoint-3/config.json
INFO:transformers.configuration_utils:Model config {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 28996
}

INFO:transformers.modeling_utils:loading weights file /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_a1894e54_2020-02-07_00-04-51x1etl769/outputs/checkpoint-3/pytorch_model.bin
HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=301.0, style=ProgressStyle(description_width='initial')), HTML(value='')))
0.0005250.0006020.0004480.3094950.0775810.0160430.1246050.0211330.1529230.0173100.0136430.0018870.0014740.1477440.0107380.0008670.0010530.1333060.0486990.3815120.0197460.4422470.2685140.6355230.0278180.1223500.1219280.0046330.0005350.1826180.1577700.2465970.2409150.1015080.1853220.0053560.2166210.6131320.0564340.0018410.0008730.0028970.0005930.0000800.0000700.0001420.0001100.0001360.1956900.0042720.0001670.3726370.4918340.1889790.0036840.0039610.2860830.0050770.0023850.0008420.2455260.3201940.0057370.0004060.0028660.1194120.4809240.2969130.5037330.6031920.0095540.0003680.8222290.2370970.1997430.0228390.6142870.3953170.2134790.0036160.3324150.0062610.0596670.1464620.0136320.0008260.0001340.0004760.0005380.0531630.0852732.6621290.6823110.0087360.3942560.2726390.0038040.0003290.2566270.5112080.1839500.0066010.1536500.0635650.0050860.0006290.0345240.0033420.0073570.0001330.1447530.3324260.0080460.6445680.2060870.1597340.7646610.3376260.2304670.0504560.0069210.0840770.4484690.0037490.0303240.0003080.0009080.1405180.1334450.4540080.2604480.3549040.3516510.0036490.4048100.7982490.0527560.0306100.1427920.0765580.0030940.0008850.2058340.0098460.0118820.2154170.6675190.4901330.2725070.0033150.0110740.0771331.4695650.0177210.0581040.2719980.0021640.0002290.0002281.0601772.3533340.5634440.0103360.0673530.1607590.1401050.0446290.0186180.0010140.0059230.0014500.0000860.0103200.0002780.0163020.4924061.9429760.0141000.0046170.0008070.3051190.7536491.6580630.2508090.0032450.0033440.7225102.7166711.2840960.3165480.1769970.0016620.1253410.4950530.0281670.0018630.0011510.0064460.5610041.0523731.3900430.0107400.1715561.4753670.4367350.1497290.1693360.4803431.6684741.8437690.0733290.0404980.0142900.5946690.6873530.0038000.0006750.0010100.0005830.0003920.0006390.0003500.0074300.0004910.0004740.0018200.2785050.0033490.0816940.0047520.0098410.0541980.0180670.0006850.1715860.0009940.4273520.0023471.8142680.5367660.1408220.1534000.4112860.8667950.6454760.0058960.0122230.0003230.0396810.2617010.3097960.1872060.0782101.1071681.2932520.3712240.3807440.0029430.0073050.1280720.0119391.0112961.0057280.0050780.0237950.0027300.1520380.2070590.1391130.1409270.1761520.0230410.0239910.0013080.0003960.0006360.1326720.0009770.0000650.0016450.0501110.0028420.2110810.1396280.0067760.0051570.2926050.3511120.6366680.0576210.0035330.0700910.1385910.6429310.3179500.0569391.8655850.0655420.0025920.0008530.452215

*******************************************
EVALUATING PIPELINE 
Pipeline directory: /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_a1894e54_2020-02-07_00-04-51x1etl769/
With following parameter combination: {'batch_size_seq_length': 4, 'lr': 2e-05, 'lr_type': 'constant'}
EVALUATION OF CHECKPOINT /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_a1894e54_2020-02-07_00-04-51x1etl769/outputs/checkpoint-3
-------------------------------------------------------------
|           |   agree   | disagree  |  discuss  | unrelated |
-------------------------------------------------------------
|   agree   |    655    |    78     |    214    |     8     |
-------------------------------------------------------------
| disagree  |     9     |    58     |    30     |     3     |
-------------------------------------------------------------
|  discuss  |    95     |    23     |   1523    |    20     |
-------------------------------------------------------------
| unrelated |     3     |     3     |    33     |   6867    |
-------------------------------------------------------------
Score: 7171.0 out of 7516.5	(95.40344575267744%)
Accuracy: 0.9460611099563501
F1 overall: 0.770182051330308
F1 per class: [0.7629586488060571, 0.44274809160305345, 0.8800924588269287, 0.9949290060851927]
*******************************************


*******************************************
EVALUATING PIPELINE 
{'batch_size_seq_length': 1, 'lr': 2e-05, 'lr_type': 'linear'}
INFO:__main__:Creating features from dataset file at /home/ubuntu/fnd_implementation/data/processed
  0%|                                                  | 0/9622 [00:00<?, ?it/s]  0%|                                        | 1/9622 [00:02<7:09:52,  2.68s/it]  5%|█▉                                    | 501/9622 [00:02<4:45:17,  1.88s/it] 21%|███████▋                             | 2001/9622 [00:03<2:46:52,  1.31s/it] 78%|██████████████████████████████▍        | 7501/9622 [00:03<32:30,  1.09it/s]100%|█████████████████████████████████████| 9622/9622 [00:03<00:00, 2557.49it/s]
  ******************************************* 
              Running Evaluation                
  *******************************************
 
  Length dataset evaluation: 9622
  Length dataloader evaluation: 2406
  Number of epochs: 3
  Batch size: 4
  ******************************************* 
 
['/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_a42e456a_2020-02-07_00-31-4805upq6g7/outputs/checkpoint-3']
INFO:__main__:Evaluate the following checkpoints: ['/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_a42e456a_2020-02-07_00-31-4805upq6g7/outputs/checkpoint-3']
INFO:transformers.configuration_utils:loading configuration file /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_a42e456a_2020-02-07_00-31-4805upq6g7/outputs/checkpoint-3/config.json
INFO:transformers.configuration_utils:Model config {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 28996
}

INFO:transformers.modeling_utils:loading weights file /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_a42e456a_2020-02-07_00-31-4805upq6g7/outputs/checkpoint-3/pytorch_model.bin
HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=2406.0, style=ProgressStyle(description_width='initial')), HTML(value='')))
0.0002090.0002550.0001440.0000560.0000230.0000120.0000100.0000090.0000090.0000090.0000080.0000080.0000080.0000090.0000100.0000080.0000080.0000080.0000080.0000080.0000390.0000110.0000440.0000100.0001141.8508210.0711940.0026452.1505530.0742030.0024810.0000880.0000100.0000080.0000080.0000080.0001040.0000100.0000080.0000080.0000660.0001270.0000110.0000080.8524080.0189500.0006790.0000230.0001760.0000110.5673580.0118380.0002350.0000120.0000080.0000080.0000080.0000080.0000460.0000080.0002500.0000130.0000090.0001020.0000090.0003580.0000230.0000080.0000440.0001330.0000100.0000170.0000080.0000080.0000090.0000080.0000080.0000080.0000090.0000100.0000080.0000580.0004380.0000130.0000100.0000230.0000090.0000400.0000220.0000090.0000080.0000090.0000110.0000081.2220070.0128710.0006210.0002240.0000100.0000090.0000270.0000080.0000170.0003360.0000110.0000090.0000090.0000081.9906280.0183941.6210040.0146110.0001380.0000090.0128022.1404000.0184590.0002120.0000090.0000080.0000080.0000410.0000080.0000080.0000080.0000380.0000080.0000080.0000080.0000080.0000080.0000080.0002540.0002320.0000830.5030960.0037080.0000360.0000090.0000080.7129750.0051050.0000460.0000420.0000810.0000090.0000080.0000090.0000130.0000082.2659210.0150140.0003143.8304701.8568730.0119870.0000840.0000080.0000080.0000080.0000150.0000800.0000810.0000090.0000080.0001640.0000090.0000080.0000090.0000090.0000434.1345332.0340932.0051810.0115402.0298670.0338430.0001990.0001350.0000080.0000080.0000082.6608170.0145480.0001550.0000084.4621012.4129580.0128430.0000964.0836392.3211310.0135441.9669330.0103270.0000610.0000080.0000080.0000080.0000080.0000090.1427640.0007140.0000110.0000080.0000080.0000080.0000090.0000080.0000250.0000700.0000080.0000080.0000080.0000090.0000080.0000080.0000080.0000080.0000080.0000080.0000080.0000410.0000080.0000880.0000080.0000210.0000390.0000080.0000080.0001860.0000400.4224600.0018210.0000670.0000110.0000110.0000080.0000080.0000370.0000080.0000080.0000080.0006090.0000100.0000080.0000080.0000080.0000082.1134330.0084610.0000410.0000460.0000480.0000080.0000080.0001380.0000190.0000080.0000420.0002540.0000090.0000080.0000081.2137032.3165090.0091470.0000420.0000080.0000080.0000080.0000080.0000090.0002340.0000861.6416240.0066130.0000320.0000080.0000080.0000080.0000080.0000080.0000080.0000080.0000080.0000080.0000080.0000080.0309040.0001150.0059510.0000280.0000080.0000081.6284451.7057790.0057510.0000280.0000080.0000081.8070772.0624100.0068150.0000310.0002080.0007510.0000100.0000080.0000750.0000080.0000080.0000080.0000080.0000080.0000080.0000080.0000080.1396000.0004460.0000090.8369240.0026072.0999590.0064890.0000660.0000080.0000080.0000560.0002011.8875560.0058590.0000250.0004460.0000410.0001070.0000400.0000390.0000080.0000740.0000390.9711210.0028470.0000160.0000080.0000080.0000080.0000080.0000080.0000080.0000080.0000080.0000080.0000080.0000080.0000080.0000080.0000080.0000080.0000080.0000080.0000080.0000080.0000080.0000080.0000080.0002910.0000460.0000080.0000080.0000080.0000080.0000080.0000090.0000080.0000080.0000080.0000080.0000080.0000080.0000080.0000080.0000460.0000080.0000570.0000860.0000080.0000080.0000100.0000280.0000080.0001620.0000080.0000080.0000080.0000100.0004920.0000090.0000080.0000080.0000080.0000080.0000080.0000080.0000080.0000080.0000080.0000080.0000080.0000080.0002780.0000080.0000670.0000080.0009100.0000100.0000080.0001120.0000800.0000080.0001690.0003280.0000401.7198721.6673210.0039310.0000470.0000080.0000080.0000080.0000080.0000080.0000080.0001160.0000080.0000080.0000080.0000080.0000080.0000080.0000080.0000080.0000080.0000080.0004960.0008090.0002550.0000080.0001160.0000102.3251410.0052010.0001330.0000080.0000080.0000490.0000080.0000360.0000080.0000080.0000080.0000080.0000080.0000110.0000730.0000950.0000080.0007580.0002510.0000090.0000080.0000170.0000120.0007090.0003600.0000080.0000430.0000410.0000080.0000080.0000080.0000080.0000390.0014080.0001720.0037860.0001860.0000290.0000331.9486940.0427370.0001460.0001350.0005680.0000090.0000090.0001960.0000080.0000080.0000080.0000080.0002970.0001210.0000080.0000080.0000080.0000080.0000090.0001080.0000080.0000080.0001160.0000110.0000580.0006300.0000090.0000080.0000520.0000550.0001250.0000080.0000450.2339920.0004550.0000081.4196800.0027080.0000451.9138150.0036250.0000820.0000080.0000080.0000460.0000402.2070180.0041252.2145652.0605466.0435950.0112000.0000300.0000080.0000400.0000092.1591672.2275410.0041550.0000160.0000490.0062260.0000210.0000080.0006160.0000090.0000080.0049921.7931710.0039200.0000150.0000080.0000600.0000080.0001340.0000840.0000480.0000410.0000080.0000080.0000080.0000080.0000460.0000650.0000080.0000600.0000080.2416100.0004270.0936901.5167590.0026230.0911060.0002990.0000080.5517900.0009510.0007930.0001510.0000390.0000380.0000850.0000080.0000600.0000080.0000920.0001970.0000080.0000080.0000482.2429770.0038120.0000861.6977433.6688830.0064120.0003840.0002220.0003260.0000400.0001760.0002205.4569330.0090780.0000605.3686271.8701490.0030770.0000440.0000080.0000401.9828230.0032040.0000132.1621030.0035040.0000130.0000410.0000081.9096570.0030440.0000470.0000080.0000080.0000390.0000080.0000190.0000080.0000480.0000400.0000080.0007701.8492112.4261841.2846870.0021290.0002460.0008020.0000090.9754680.0015110.0001390.0000720.0000080.0001030.0001010.0000080.0000440.0001930.0040960.0005920.0003090.0000480.0002990.0001680.0006400.0000090.0006430.0000090.0002720.0000080.0012030.0000430.0000080.0000100.0000080.0000832.9856420.0072130.0049820.0066090.0000170.0000080.0000110.0000080.0000080.0000080.0000080.0006560.0000090.0000080.0000240.0000080.0000080.0000080.0000080.0001670.0001070.0000080.0001270.0000390.0000090.0000520.0000080.0000410.0000390.0000380.0000081.1159810.0017620.0000410.0000490.0007350.0000110.0192400.0000350.0000580.0000080.0069280.0000180.0000080.5092340.3330490.0004690.0000090.0000380.0000080.0000370.0000490.0071300.0361291.6675090.0029730.0698740.0003340.4281700.0006240.0000090.0000550.0000400.7760430.0011050.0000600.7364700.0065100.0000820.0006770.0000180.0000080.0000110.0001890.0000140.0000080.0401521.9735312.1401920.0028424.3810730.0057950.0000160.0000085.9309860.0078010.0000180.0000080.0000080.0005820.0000090.0000080.0000870.0000080.0001660.0001840.0001880.0001830.0001600.0001910.0000490.0006020.0000090.0000080.0001790.0000080.0000080.0000080.0000080.0001470.0000400.0002590.0000980.0000751.7943481.0146680.0012893.0339100.0038930.0000490.3131390.0004610.0001353.5338550.0049310.8088900.0020710.0001560.0000080.0003960.0004520.0000080.0000090.0006520.0000220.0000080.0003830.0000420.0000082.6258840.0032261.2677220.0015910.0000100.0000081.3624443.5898674.9846040.0060570.0001980.0000080.0005150.0000080.0006210.0003880.0000390.0000720.0000910.0001320.0004060.0155630.0000264.2304721.4521160.0017360.5633320.0006770.0000090.0000080.0000080.0001140.0001060.0000080.0001010.0002920.0000080.0000080.0000080.0010470.0014490.0005880.0000090.0000080.0000080.0000080.0000080.0000080.0000081.6481880.0019130.0000100.0000080.0000080.0000080.0000080.0000080.0000080.0000080.0000080.0000080.0000080.0000080.0000080.0000080.0000080.0058330.0009482.1800870.0750490.0000920.0003240.0022400.0001680.0002410.0000080.0000110.0000092.2359491.9836210.0022241.8451660.0020650.0000910.0000790.0002280.0001590.0001160.0000790.0000710.0000510.0000080.0001660.0001070.0008720.0002780.0000160.0000130.0000270.0001220.0001920.0003560.0000931.9983480.0022600.0001210.0000080.2786890.0571961.5400860.0017330.4619290.0005711.8934691.6835031.8887010.0020940.0000110.0000741.6787310.0018340.0001061.8703010.0021060.0000740.0000080.0000080.0001470.0000080.0000080.0000080.0000080.0000730.0000080.0000080.0000080.0000080.0000080.0000110.0000750.0000081.7503520.0018370.0000102.2227330.0023530.0000451.9901750.0020740.0000100.0004790.0000080.0003250.0000080.0000080.0000080.0003710.0000110.0000080.0000600.1411141.9614481.2767850.9408460.0157111.6659003.9222350.0045130.0004070.0000400.0000080.0000080.0000080.0000080.0000080.0000100.0000080.0000080.0005100.0000080.0000080.0003360.0001720.0000080.0008170.0000090.0000080.0000150.0000080.5479270.0005530.0000080.0000080.0000840.0001770.0000080.0000090.0000910.0001780.0000090.0005250.0000090.0000080.0000090.0000080.0000080.0000080.0000476.1891564.2168190.0045860.0000120.0000080.0000080.0002980.0001340.0001290.0001360.0002170.0000141.5129951.8279221.8313200.0018070.0002150.0001880.0002070.0000080.0006600.0027621.6607980.0015980.0000520.0000083.2031180.0188250.0000260.5696242.3964680.0022820.0000100.0000081.6133810.0015330.2781521.0637171.8061021.8199370.0017200.0000090.0899290.0001370.0000080.0243810.0000300.0000080.0012350.0000480.0000080.1342450.0001330.0002890.0006870.0000080.0007230.0003980.0007070.0005030.0002945.1164130.3723810.0007670.0000770.0000080.0002390.0070350.0004850.0001720.0001240.0000390.0001080.0001780.0000100.0003020.0001400.0004050.0003440.0000400.0002880.0098190.0002730.0000080.0002720.0002510.0002262.0411080.0018510.0000090.0000080.0000080.0000081.6722470.9806283.2300520.0029280.0000100.0000390.0000080.0000080.6614260.0005960.0000090.0000080.0000080.0000970.0000080.0000080.0001170.0000080.0001030.0001020.0000080.0000080.0000080.0000080.0000080.0000090.0000090.0000080.0000080.0000100.0003230.0002270.0003370.0004260.0000760.0002170.9563690.0009860.0003290.0000081.6684432.1023482.2800080.0020540.0000421.3944390.0012980.0000850.0000380.0000090.0000080.0000080.0000080.0000090.0000093.1057950.0026592.8980990.0025280.0000610.0000460.0000080.9078690.0007791.2011170.0010250.2762550.0002410.0000630.0000090.0000080.0000080.0000100.0000080.0000080.0000080.0003330.0000080.0000080.0000080.0000080.0004290.0000090.0001720.0000080.0000080.0000080.0024120.0009830.4085650.0006230.0000090.0000090.0000110.0000080.0000600.0000490.0000090.0000090.0000220.0000420.0000790.0000623.9235924.0696383.2308370.0027150.0008190.0000720.0000850.0002320.0002390.0000080.1090640.0002040.0000250.0000120.0000080.0000080.0000080.0000180.0000080.0003840.0000080.0000080.0001750.0019780.0003270.0000440.0000080.0000270.0000080.0000500.0000600.0000080.0000080.0000640.0000080.0000080.0000080.0000080.0000080.0001210.0000080.0000080.0000930.0000090.0000080.0000460.0000080.0000080.0000080.0000080.0950740.0000830.0000080.0001160.0000080.0001430.0000080.0000144.7282310.0045220.0009620.0010730.0019343.7860475.0869191.2570213.5538812.4754561.7335680.0014750.1419770.0002462.2082660.1757751.7384860.0014740.0004020.0003070.0002010.0005240.0002090.0007110.0007670.0003650.0000430.0003820.0001760.0006940.0003760.0001850.0002530.0001580.0003170.0027030.0054700.5865310.0009820.0004320.0000080.0000080.0000080.0000081.2523750.0009550.0000090.0003560.0003480.0000090.9789321.0013600.0019250.0013860.0010280.0005030.0003270.0002290.0000080.0002920.0001890.0001200.0000080.0001140.0002490.0000080.0001420.0000080.8762790.0007240.0000080.0000080.0000400.0000730.0000080.0000080.0000080.0000080.0000080.0005480.0007550.0005010.0006930.0004390.0000080.0000090.0000080.0000880.0000110.0000080.0001500.0000080.0000960.0000080.0000080.0000610.0000150.0000080.0000080.0000080.0000100.0000080.0000090.0000160.0000080.0000942.5635720.0018600.0000090.0000090.0001120.0000080.0000090.0000120.0000080.0001570.0000770.0002930.0002500.0001760.0009890.0001310.0004480.0003270.0001020.0002000.0001610.0002530.0001561.2846000.0011910.0004425.6195525.8401917.3613690.0053180.0001020.0000990.0002590.0000080.0014700.0000090.0029040.0000100.0007640.0001750.0000080.0008010.0001900.0001000.0001860.0001920.0001150.0002550.0001110.0001610.0001310.0001710.0003000.0000930.0001330.0000540.0021800.0017291.9891150.0031100.0001130.0000840.0014811.8030380.0015590.0000150.0001402.8633540.0021940.0001840.0002542.5687640.0017741.7569310.6168491.4497310.2942210.0399951.3231011.0170703.3253281.5971600.2928170.0004020.0001550.0001730.0001320.0001020.0000080.0000390.0001510.0000080.0000740.0000080.0000080.0000080.0000720.0000080.0000080.0000980.0000080.0002570.0001020.0000080.0000560.0000080.0000140.0000080.0000102.0007960.0014130.0001553.9782744.1628093.9470861.9391391.3267094.1114384.3629374.2718073.9921993.7528191.4999363.7311931.4671620.0010193.8367413.6323040.0024461.7368221.5890220.0011250.1284120.8916110.0008590.0003850.0003700.0001270.0002450.0004470.0001900.0004490.0002510.0039170.0015820.0000450.0000670.0000080.1215250.0002240.0000080.0000080.0000100.0000080.0000080.0000080.0000080.0000080.0000391.5875440.0010362.4449600.0015901.8135550.0011800.0000400.0004460.0011072.2802592.0779780.0013932.0288914.6200971.5431060.0066640.0062770.0000120.0000180.0002320.0002110.0000930.0000080.0000080.0001200.0004990.0000710.0000780.0000710.0006950.0000690.0002540.0000710.0000440.0000720.0003700.0000820.0001540.0002700.0000700.0007300.0006950.0233000.0001190.0000381.9007440.0012670.0000392.3701810.0015622.4376454.3935410.0028721.7911561.9046990.0012301.9942750.0012873.9815420.0030370.0180150.0008102.3058930.0018830.0018330.0000500.0000710.0000080.0000930.0000840.0000870.0000080.0065990.0000770.0000740.0000080.0000520.0000450.0000420.0000082.1018300.0013034.3050142.3090230.0014292.1890352.1277226.1561366.1770837.4110165.3735325.3178070.0033770.0005100.0000490.0000160.0000500.0000080.0000880.0000080.0000430.0000080.0000080.0000090.9958270.0006130.0000312.3076860.0014510.0000090.0000080.0000090.0000120.0000441.5945580.0262020.6196340.0005742.0742720.0012560.0001230.0000080.0000080.0264961.0187702.6580430.1343880.5111842.0456421.6068221.5799822.3725791.8531740.0011140.0000090.0004501.7435760.0010460.6573600.0003990.0000080.0005280.0008160.0000090.0000080.0000080.0000080.0000080.0000080.0003590.0003930.0006510.0022350.0007730.0000710.0001990.0003670.0746871.9512540.0012170.0000710.0346730.0000280.0019140.0000400.0001001.3941960.0008562.7481290.0019241.8008811.0985330.0006541.4933521.9737071.4894090.0009830.0000120.0000080.0000080.0001360.0000080.0000770.0000750.0001000.0000850.0001330.0001260.0000950.0001680.0000440.0000730.0000410.0000410.0000080.0000460.0000300.0000080.0000910.0001100.0000600.0000420.0001150.0000620.0000640.0000900.0000080.0000910.0000571.6347110.0009410.0000620.0000750.0002980.0000080.0000780.0000090.0000080.0000080.0000500.0000080.0000080.0001530.0000650.0000080.0002400.0000080.0000570.0000080.0000080.0001740.0000080.0000080.0001080.0000890.0001300.0000670.4024040.0002340.0000080.0000090.0000090.0000080.0000080.0000110.0000080.0000990.0000080.0001400.0000080.0000080.0000080.0000080.0000750.0000740.0000080.0000770.0000080.0000080.0000080.0001790.0008980.0002840.0007310.0005660.0000482.2275143.9390712.0685780.0013910.0003770.0010060.0002950.0001480.0001430.0003360.0001280.0001730.0001110.0001600.0002520.0001230.0002030.0004080.0002130.0000110.0002200.0003400.0000850.0000970.0000420.0001100.0002230.0002530.0001710.0002020.0018210.0007690.0062190.0012581.8834400.0014530.0002050.0007070.0004930.0009770.0084240.0009330.0000440.0001710.0002990.0000770.0001100.0002090.0001370.0001120.0001770.0000900.0002640.0000790.0001970.0000440.0000080.0000080.0000080.0000510.0002520.0000540.0000510.0000080.0000080.0000080.0000080.0000480.0000080.0000080.0000080.0000080.0000080.0000080.0000080.0000080.0000080.0000080.0000430.0000082.2516590.0012000.0000080.0000800.0000380.0000800.0002400.0002940.0000720.0000370.0001110.0000800.0000390.0003160.0000080.0000180.0005880.0004591.8744880.0014023.3578974.0450061.1688182.6323150.0029510.0003020.0001430.0000810.0000670.0000420.0000080.0002910.0000080.0000080.0000080.0004540.0004100.0000080.0000390.0000080.0000402.1350860.5997830.0005840.0000080.7383520.5155840.0006731.3041562.1168942.1187772.5861793.6826553.5312951.7743451.9266420.0009992.0377520.0012100.0001530.0017261.1513402.2583870.6448122.3354661.6727050.0012090.0006440.0004550.8457342.0867940.0011140.0000390.0001440.0002040.0000890.0001790.0001120.0002560.0002180.0001650.0002150.0002770.0000800.0001250.0020280.0002070.0001770.0000080.0002950.0000080.0000080.0000080.0000080.0000080.0000080.0000080.0007800.0003620.0000080.0000080.0000110.0000080.0002100.0002270.0009471.0692140.0005440.0000080.0000480.0002370.0002890.0001540.0002210.0002360.0003070.0001620.0019040.0011110.0000120.0009010.0009720.0032731.2767140.0016400.0008110.0000390.0000590.0000080.0000580.0000080.0000080.0001360.0000920.0000850.0002150.0002460.0000080.0000080.0000081.3461191.2755391.9096793.3424732.0950721.1573101.5897730.0416261.3470143.8704860.1919710.0001020.0000081.7709701.7131450.0008461.8881202.0228950.0009970.0000082.2899090.0011250.0001290.0000090.0000080.0000111.1756660.0005810.0000230.0000080.0002010.0000510.0000080.0000090.0000850.0001130.0000130.0000890.0000100.0000960.0000083.6775373.8408960.0019782.8590631.0525400.0006311.9763332.4622810.9841160.0008760.0002330.0001910.0001080.0000491.8112600.0017090.0000081.0434290.0005521.6994660.0011780.0003014.8741140.0028070.0010614.4321203.6031651.9791103.0913302.0123930.0067560.0001620.0005540.0000080.0002010.0000430.0000090.0000080.0002180.0000080.0000080.0000090.0002830.0001830.0005920.0017090.0002160.0000080.0003750.0002400.0007880.0000081.3280020.0226911.9620091.5986191.5710100.0007781.6354241.8413361.3693621.6292504.7539770.0022481.5970661.2366360.0173820.0035223.0349751.6597221.1719750.0006440.0000380.0000980.0000080.1273940.9903960.0005620.0000692.6992400.0015290.0003790.0003820.0000860.0001740.0003860.0002710.0000410.0001020.0000790.0000080.0001640.0002342.0074170.0009370.0000550.0000080.0001020.0000400.0001550.0000450.0001550.0001660.0000440.0002110.0000761.8420510.0011380.0000080.0000080.0002140.0003700.0001810.0001850.0000940.0000490.0001210.0001250.0000910.0000080.0000080.0000080.0001700.0000080.0000080.0001930.0000090.0000080.0000080.0000080.0000080.0000080.0000080.0003270.0000080.0000080.5521800.0002590.0000080.0000080.0000980.0000080.0000080.0003010.0001530.0000450.0000080.0000080.0000080.0000080.0003080.0000080.0005290.0000080.0001270.0000080.0000080.0000080.0000080.0000080.0000080.0000080.0000080.0001620.0000080.0023910.0000410.0000080.0000080.0000080.0003630.0085120.0000120.0000081.2938250.0005840.0003750.0000590.0002540.0001760.0002310.0001060.0001260.0001160.0001000.0001790.0001622.0600954.2796678.7281416.3591730.0035260.0002180.0000080.0004470.0001810.0001110.0001060.0001910.0002170.0001380.0000090.3383240.0002040.0000540.0003860.0000080.0002310.0000080.0000080.0000700.0000390.0003970.0000080.0001940.0003580.0002250.0000380.0000390.0000422.1775980.0010830.0002930.0000380.0002660.0001440.0000450.0000500.0020280.0000240.0003760.3898500.0001780.0000470.0000520.0022860.0000091.8062721.6809420.0007360.0001240.0000080.0029950.0000090.0001950.0000080.0000080.7899590.0004150.0013200.0000410.0000380.0002760.0000080.0000080.0003610.0000080.0001330.0000370.0001340.0002210.0006970.0001620.0000680.0002420.0000380.0000390.0001890.0000080.0006130.0000090.0009030.0000080.0002500.0000493.2811040.0022321.8457651.3719710.0005920.0003511.8998390.0009460.0003490.0001550.0005300.0000430.0003270.0001650.0001980.0004830.0004030.0006190.0006540.0000300.0011320.3697020.0004990.0006860.0004820.0004396.2892885.9451938.0700442.0960490.0010310.0001920.0001040.0001200.0000080.0000420.0000530.0000420.0000690.0000980.0000640.0003380.0001080.0001160.0000380.0002250.0001300.0001350.0000400.0000690.0001810.0000080.0000080.0000770.0001330.0000680.0000080.0001330.0000080.0001320.0000700.000008

*******************************************
EVALUATING PIPELINE 
Pipeline directory: /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_a42e456a_2020-02-07_00-31-4805upq6g7/
With following parameter combination: {'batch_size_seq_length': 1, 'lr': 2e-05, 'lr_type': 'linear'}
EVALUATION OF CHECKPOINT /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_a42e456a_2020-02-07_00-31-4805upq6g7/outputs/checkpoint-3
-------------------------------------------------------------
|           |   agree   | disagree  |  discuss  | unrelated |
-------------------------------------------------------------
|   agree   |    578    |    36     |    122    |     6     |
-------------------------------------------------------------
| disagree  |     8     |    59     |    44     |     5     |
-------------------------------------------------------------
|  discuss  |    168    |    66     |   1619    |    21     |
-------------------------------------------------------------
| unrelated |     8     |     1     |    15     |   6866    |
-------------------------------------------------------------
Score: 7227.5 out of 7516.5	(96.15512539080689%)
Accuracy: 0.9480357514030348
F1 overall: 0.7675860506902474
F1 per class: [0.7686170212765957, 0.4244604316546763, 0.8813282525857377, 0.9959384972439803]
*******************************************


*******************************************
EVALUATING PIPELINE 
{'batch_size_seq_length': 4, 'lr': 2e-05, 'lr_type': 'cosine'}
INFO:__main__:Creating features from dataset file at /home/ubuntu/fnd_implementation/data/processed
  0%|                                                  | 0/9622 [00:00<?, ?it/s]  0%|                                        | 1/9622 [00:03<8:30:58,  3.19s/it] 21%|███████▋                             | 2001/9622 [00:03<4:43:19,  2.23s/it] 78%|██████████████████████████████▍        | 7501/9622 [00:03<55:11,  1.56s/it]100%|█████████████████████████████████████| 9622/9622 [00:03<00:00, 2590.14it/s]
  ******************************************* 
              Running Evaluation                
  *******************************************
 
  Length dataset evaluation: 9622
  Length dataloader evaluation: 301
  Number of epochs: 3
  Batch size: 32
  ******************************************* 
 
['/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_b5ded1d0_2020-02-07_05-01-51e9ghwi9m/outputs/checkpoint-3']
INFO:__main__:Evaluate the following checkpoints: ['/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_b5ded1d0_2020-02-07_05-01-51e9ghwi9m/outputs/checkpoint-3']
INFO:transformers.configuration_utils:loading configuration file /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_b5ded1d0_2020-02-07_05-01-51e9ghwi9m/outputs/checkpoint-3/config.json
INFO:transformers.configuration_utils:Model config {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 28996
}

INFO:transformers.modeling_utils:loading weights file /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_b5ded1d0_2020-02-07_05-01-51e9ghwi9m/outputs/checkpoint-3/pytorch_model.bin
HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=301.0, style=ProgressStyle(description_width='initial')), HTML(value='')))
0.0006950.0009030.0008190.3621660.0909280.0212770.0453200.0071510.0013540.0005290.0395990.0046590.0066500.1126270.0082830.0010010.1132990.0946970.0104010.4958990.0253860.5441890.2529400.7517720.0511150.0106780.0028680.0003170.0007870.0663030.0803620.0064590.1009750.4024310.2337460.0067920.2954940.3845440.0731960.0025140.0020250.1734970.0285130.0007990.0001340.0002880.0001400.0002260.0093410.0011610.0001640.1261190.1082800.0137230.0014720.2092730.2353650.0042390.0019400.0152660.0624730.0697310.0024850.0015820.0334460.1162470.3262810.2369260.5012060.3249300.0053900.0005730.5551040.1653060.1919630.0460760.1888340.2380340.0603630.0016020.1356150.0787680.3931680.8026690.0484190.0016170.0011490.0010710.0061370.2421930.2741570.8108610.1890440.0541550.1796310.1245460.0037700.0005820.1227720.2273160.1876450.1346780.1588820.0301300.0056550.0148690.0070710.0009960.1470860.0014570.2497930.2543080.0059680.8110360.1276710.2985470.2335340.0690940.0008130.1753420.0853610.0928490.5834780.0050110.5076390.0042380.0023380.3684390.2213580.1620060.0084980.0776440.0730730.0576590.1941090.9185160.0098390.1974620.4619180.6556580.0889680.0025230.1736360.1336640.2807720.0654100.4087640.2470240.0021450.0884200.0169290.0026081.0820730.0089950.0081610.1721540.0016640.0005270.0003620.3397451.2849540.1054770.0045260.0131690.3377000.1404900.0495380.0071130.0011640.0729430.0126180.0002450.0102490.0004870.1719110.1044111.9150570.0318180.0069200.0019870.2602090.2507031.0907830.2135240.0384290.0393080.6651482.4952760.8147320.5002850.1194490.0016530.1782530.3575120.0869690.0028380.0032020.0162490.4129071.0721580.6256720.0153400.1752621.4194250.2616060.1297570.3391020.3378710.5047880.2310740.2720870.1915450.0032330.2079510.3287540.0025360.0014120.0009250.0011560.0008170.0031810.0014040.0042610.0008300.0006180.0073250.2711230.0049950.0074130.0078700.0047820.1914270.3960480.0028000.0003740.0003600.2038850.0035501.7881480.2019510.0807620.3423760.6690670.5433390.6254160.0073170.0164060.0012420.0275520.4436130.4607360.4893500.0079390.1263720.7322770.5968140.2892880.0039060.3970730.2306060.2083011.1871150.5784140.0038950.0450280.0388970.3425560.3171590.3158010.0937890.0947320.0017540.0015960.0009040.0019200.0483900.0147800.0024410.0001380.0020340.0070900.0077730.9096100.0335310.1068900.1441450.1930570.0020600.2557050.0042680.0261730.0044720.0079060.2257730.1053200.1996400.2702200.0026210.0021030.0020000.001828

*******************************************
EVALUATING PIPELINE 
Pipeline directory: /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_b5ded1d0_2020-02-07_05-01-51e9ghwi9m/
With following parameter combination: {'batch_size_seq_length': 4, 'lr': 2e-05, 'lr_type': 'cosine'}
EVALUATION OF CHECKPOINT /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_b5ded1d0_2020-02-07_05-01-51e9ghwi9m/outputs/checkpoint-3
-------------------------------------------------------------
|           |   agree   | disagree  |  discuss  | unrelated |
-------------------------------------------------------------
|   agree   |    578    |    44     |    130    |     1     |
-------------------------------------------------------------
| disagree  |    31     |    68     |    38     |     0     |
-------------------------------------------------------------
|  discuss  |    152    |    50     |   1614    |    22     |
-------------------------------------------------------------
| unrelated |     1     |     0     |    18     |   6875    |
-------------------------------------------------------------
Score: 7238.5 out of 7516.5	(96.30147009911528%)
Accuracy: 0.9493868218665558
F1 overall: 0.7755353182542568
F1 per class: [0.763036303630363, 0.45484949832775917, 0.8873007146783948, 0.9969547563805105]
*******************************************


*******************************************
EVALUATING PIPELINE 
{'batch_size_seq_length': 2, 'lr': 2e-05, 'lr_type': 'constant'}
INFO:__main__:Creating features from dataset file at /home/ubuntu/fnd_implementation/data/processed
  0%|                                                  | 0/9622 [00:00<?, ?it/s]  0%|                                        | 1/9622 [00:02<7:13:06,  2.70s/it]  5%|█▉                                    | 501/9622 [00:03<4:47:29,  1.89s/it] 21%|███████▋                             | 2001/9622 [00:03<2:48:08,  1.32s/it] 78%|██████████████████████████████▍        | 7501/9622 [00:03<32:45,  1.08it/s]100%|█████████████████████████████████████| 9622/9622 [00:03<00:00, 2433.98it/s]
  ******************************************* 
              Running Evaluation                
  *******************************************
 
  Length dataset evaluation: 9622
  Length dataloader evaluation: 1203
  Number of epochs: 3
  Batch size: 8
  ******************************************* 
 
['/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_9c545fdc_2020-02-06_22-26-32t3hl64rl/outputs/checkpoint-3']
INFO:__main__:Evaluate the following checkpoints: ['/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_9c545fdc_2020-02-06_22-26-32t3hl64rl/outputs/checkpoint-3']
INFO:transformers.configuration_utils:loading configuration file /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_9c545fdc_2020-02-06_22-26-32t3hl64rl/outputs/checkpoint-3/config.json
INFO:transformers.configuration_utils:Model config {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 28996
}

INFO:transformers.modeling_utils:loading weights file /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_9c545fdc_2020-02-06_22-26-32t3hl64rl/outputs/checkpoint-3/pytorch_model.bin
HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=1203.0, style=ProgressStyle(description_width='initial')), HTML(value='')))
0.0006250.0006500.0009680.0003430.0000990.0000330.0000430.0000580.0000380.0001300.0002700.0007300.8519070.0655800.7080080.0472110.0029620.0001850.0007300.0000550.0003380.0000290.0011330.0003020.0004230.7443740.0286410.0010720.0000510.0003620.0002330.0000240.0000190.0000350.0001110.0000310.0000170.0000220.0000130.0000160.0000440.7278030.0173510.0006850.0000430.0000220.0000350.0007310.0022750.0000710.0000820.0005870.0000260.0000320.8951790.0170990.0003170.0002100.0004530.0000230.0008360.0000260.0005190.0000200.0000150.0000160.0120700.3817200.0056400.0001150.7392820.0107240.1680030.0023220.0007070.3821711.5716650.8474590.0108840.0001600.0007220.0016180.0010590.0000360.0000141.0070630.6276380.5060960.5890610.0067770.0000891.1635040.0140172.2043630.0235260.6659310.3610660.0049100.0000950.0000490.8986570.0089220.0001050.0042880.0000740.8899540.0084100.0001010.0000240.0000130.0000160.0003070.0007110.0002450.0000160.0011510.8294570.0074030.0000750.0002920.0000140.4957780.0040740.0000441.0952580.0087880.0011130.0000220.0053720.0002960.5579000.0042920.7815360.9726900.0072700.0000650.0034400.3937060.0030860.0000340.0000140.0000120.0000180.0000130.0008120.0002660.0000260.8132390.6713330.0045180.8364930.9362180.0064280.0018780.0005660.0000150.0000110.0000110.0000110.1476020.0953010.0122410.0003520.0000140.0006740.8850030.0129290.0011100.0004410.0004600.0388650.0002380.0000120.0000110.0000110.0000110.0000110.0000110.0000110.0000120.0000120.0000120.0000110.0007000.0000160.0000110.0000130.0000110.0000130.0000110.0002150.0003590.0003100.0000140.0000590.0178790.0001050.0000140.0002150.0000130.0000150.0000650.0000130.0000270.0000140.0020390.0009640.0251580.0013490.0012350.0045510.5432640.7995250.0039620.0000290.0000120.0009390.0000150.0000110.0000120.6494850.0029510.0040650.0023130.0010900.9219290.0052640.0011330.0000160.0000120.0000110.0000110.0012550.2133180.0218680.0001230.1079220.1767570.0012260.0000970.0002230.0333510.5290210.0032330.4072410.2447120.0021450.0000200.0035440.0000250.0013220.0022580.0000260.0000110.0016390.0018780.0057820.4830530.0378940.1057330.0006570.1538320.6916010.0028661.7162100.0070720.0002900.8942580.7966562.3140620.0089540.0014600.8036400.8414710.0035260.6007540.4558090.0016820.4918580.0038910.0006550.0005700.0011740.0002970.0000120.0002250.0005830.0008130.9711711.8615040.7796760.0028111.0045990.0061350.0004380.0006030.0006410.0020320.0000260.8740950.0054720.0019080.0009830.0005280.0022550.0068040.0003200.0030970.0004590.0002391.4522450.6860470.0024510.0002830.6828290.0024230.0002210.0002610.0382610.0003570.5778610.7741240.0053220.0024830.0499740.0020200.0007510.0002930.0020850.5769860.0032420.0019180.0014110.0017270.0007080.0016290.0000170.0006120.0032670.0026370.0000190.0000120.0001310.0002430.0000130.0000230.0000120.0000140.0001510.0005850.0010460.0008010.0011440.0014510.0004120.0009030.0009510.0004090.7684450.0021750.3945320.0011850.0052890.0005880.4393370.0185431.1507220.8866980.0028110.0015370.0006682.8476360.0084550.0001320.0006270.0000190.0057080.0154281.0101020.0026761.0587560.0033750.0004480.0000120.0006030.0025420.0029160.0025210.0009030.0000140.0016720.0000190.0010790.0015060.0017900.4055050.1373290.0009620.0109360.0171570.7375240.1762270.2011810.0153480.5951610.0018220.0185110.0008170.0079050.0004490.0155500.0093760.3197881.0794180.0033300.0017410.0021580.1801770.0013110.9532770.0030230.0000190.0000210.0013300.0007850.0014170.0000152.5713580.8079440.0018940.0000150.0000110.0003840.0000120.0000120.0000110.0000110.0000110.0000110.0000110.0003522.1253960.4593330.8846780.0055090.0002220.7742350.8285710.0660870.0005040.0007390.0009280.0018750.0041262.0189411.2276960.0027470.0013020.0024120.0011550.9236222.7767121.9528281.1504361.8131370.8934970.0023451.0201580.9537650.0034060.0000190.0005090.0000120.0016440.0000150.0000110.0008750.0009720.0098010.7537980.0019990.6223620.5671710.2193080.0004660.2341240.0004940.0852760.2151060.0058950.8836510.0305170.0003270.0000120.0000130.0000130.6519450.0013230.5998780.4037030.0008190.0000130.0000550.0000120.7060640.0014110.0005040.0022000.0000160.0000130.0000121.5051880.7681380.0015100.0008880.0003900.0003610.8748561.5056450.0057180.0047850.0026650.0027470.0002680.0006860.0002260.8441560.0016270.0006040.0002870.0007190.0005950.0005340.0002370.0002520.0017430.0002210.0002510.9441600.8001421.5371501.9703631.9394590.0054050.0123020.0016780.0015220.0010880.0005790.0008030.0017900.0006170.5545870.0046610.0079271.3695570.0024820.0000171.3667401.3415580.0026590.0000160.5741990.0010310.0002090.0000130.0002300.0004830.0000120.0000110.0007570.0000130.0000230.6040590.3070750.0020930.0022720.0004521.9595821.1653860.5464510.9812020.0024630.5053880.8676602.1013480.4846520.0029630.6044320.6790520.8092190.7063960.0022480.0000830.7353840.4318300.0010660.0000130.0009800.0001720.0000110.0008450.0019510.0011900.0000210.0014520.0005550.0000210.0008603.9108204.9697540.0099550.0012080.0113690.0005130.0007010.0005650.0000170.0001130.0003940.3528520.7538930.0015050.0000240.0005990.0000150.0039560.0000180.0000130.0011490.0012910.0000250.0005210.0000120.0001830.0000130.0001830.0002222.1077150.0075380.0037814.9259753.3124003.7434900.6961921.7669362.5695150.0066050.0025770.0066140.0104820.0022060.0023170.0028910.0017960.0273720.9306291.6464020.0368480.0000670.7324320.0011190.0023600.6907530.3386430.0057300.0093050.0007110.0006860.0001530.8383790.6459890.0009730.4271510.0008450.4271430.0006890.0000120.0014650.0024360.0007060.0000150.0003340.0001660.0000430.0000110.0002600.0000150.0002810.0000610.0000190.0004510.0000170.0001720.0000110.0000220.0019320.0039790.0009680.5552990.7822370.0036640.0023152.4740335.3995156.8661040.0101230.0006240.0002070.0002130.0007240.0002030.0022480.0019790.0021410.7066020.0030490.6301420.0025390.0002581.4159420.0028260.0005880.9812780.0017871.2436700.5093651.1836320.0195400.0146040.0060580.0172561.2799730.0044840.0024280.0006620.0012480.0004980.0000120.0006710.0000140.0005100.0016850.0004410.0000160.0000230.8625391.6931883.3041370.4940833.3539833.3874790.7626440.0046090.0026530.0033820.0023750.6094890.4712660.0023900.0020990.0021950.0015880.7544780.0028780.5404430.0016950.0000150.0000110.0000110.0002390.4251450.5889270.5246140.0139180.6509800.4168222.0459354.7515351.8437650.0030730.0009630.0000210.0013870.0014410.0027540.0019220.0007450.0018850.4585741.0998631.9327390.4576130.5133070.0016290.5070032.3979810.4898900.4862080.5259651.1897040.0042410.6959170.0025400.0005210.0013730.0001900.0008090.0001850.0009420.0002410.5548211.9944140.5871773.4337375.2853094.5715220.0070830.0015020.0002520.0005740.0002350.0000120.0005000.5861230.0007320.0000170.0002450.6082810.8720630.9498920.0016350.9341352.1325261.1177071.3796802.4624441.0472420.5484120.9259510.9242730.0012610.0010840.0000140.0000110.0001730.6231800.6754680.0022060.2841770.0037890.0039680.0043880.0009720.8417031.6228231.6234021.6063431.6161120.0023200.0000310.0010950.0009600.0015290.0021480.0020050.0007730.0004850.0002800.0000820.0011960.0005940.0009900.0007260.0005650.7508570.0021950.0011070.0005050.0000260.0000500.0000130.0019850.0015260.0003720.0000400.0108800.0007350.0017130.8694840.0009880.0008520.0000120.0000130.0001640.0003120.0000130.0001530.0001700.0001500.0000110.0006190.0010940.0009480.2640810.7437721.2804980.0025870.0012600.0005410.0009680.1811180.0987110.0009480.0007720.0014260.0010310.0038950.0036972.2411311.5846051.9898991.4206370.0069900.0034260.0020190.0042300.0031970.0023470.0024830.0023960.0021840.0000180.0003110.0134890.0003060.0000120.5046300.0005490.0000170.0000160.0000140.0000140.0003001.7680740.0024890.0018440.0025220.0008620.0024070.0035220.0001070.0004350.6951531.9013091.5915950.5269550.0019410.0009220.0016110.0000120.0016070.1046790.0004100.0066570.0016110.0012950.2209000.2569750.9715880.9847640.5087950.4991140.0030500.6365431.2281512.5390230.0065211.4888690.2018510.0233900.8404790.3526621.6110841.1482951.4519930.5298250.3314380.0005710.0000280.0000120.0000120.6114140.0073640.0000190.0002330.1414530.5056700.0007620.0294080.0174620.0605950.6617490.6552841.3327832.7191121.2686350.0033550.0027370.0000130.0046720.3166210.2110800.0002192.2839722.2161891.6791640.0073761.5462850.0127620.8681720.9115882.6013700.0025550.9418490.0013910.0000130.0046080.0002020.4163290.0004160.0004980.0002420.0002400.6369390.0050740.0021230.8957150.0035540.0015750.0039950.0147590.5535180.6297880.8733601.9470280.0070282.9243692.1156880.6865440.0044030.0006310.0002060.0019320.0000190.0009410.0024490.0026150.0005920.0057770.3166430.0451120.7211470.5567800.4468952.5384240.2090140.0015901.0861810.0057920.5592810.0015540.6946220.0017920.9228830.0180191.5687671.1816880.3939680.0005200.0007610.0051430.0002360.0009000.0012480.0012530.0009630.0016540.0015020.0013800.0027640.0016820.0009790.0013210.0000150.0003550.0000110.0005760.0000120.0000200.0000270.0003320.0007900.0000120.0004880.0000110.0032390.0003300.0000160.0003240.0002460.0001970.0000170.0000120.0000110.0000240.0002280.0009670.0000130.0005350.0005000.0010820.0001690.0021790.0032550.0019070.0014480.0028761.9537744.7166420.0049970.0006300.0015460.0010350.0028050.0102480.0006640.1631720.0003950.0003900.0010210.0007670.0005520.0004900.7311370.0014100.0006320.0013150.0022180.0010850.0051440.0020160.0041230.7878770.0012990.0524410.0008310.0000110.0004790.6208530.9158590.0008010.7315490.0015820.9034780.6388550.9973740.0012720.1613180.7712530.6987030.0014981.6312311.8793890.0023040.0278110.0006010.0007750.0005810.0006960.0412500.0006250.0836230.0015490.0016132.1599933.1121671.0041880.0066530.0012610.0006430.0028210.0041760.0027460.0030110.0034130.0007660.0015740.0001670.0003910.0002730.0002670.000196

*******************************************
EVALUATING PIPELINE 
Pipeline directory: /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_9c545fdc_2020-02-06_22-26-32t3hl64rl/
With following parameter combination: {'batch_size_seq_length': 2, 'lr': 2e-05, 'lr_type': 'constant'}
EVALUATION OF CHECKPOINT /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_9c545fdc_2020-02-06_22-26-32t3hl64rl/outputs/checkpoint-3
-------------------------------------------------------------
|           |   agree   | disagree  |  discuss  | unrelated |
-------------------------------------------------------------
|   agree   |    502    |    33     |    130    |     3     |
-------------------------------------------------------------
| disagree  |    17     |    83     |    56     |     2     |
-------------------------------------------------------------
|  discuss  |    236    |    45     |   1585    |    21     |
-------------------------------------------------------------
| unrelated |     7     |     1     |    29     |   6872    |
-------------------------------------------------------------
Score: 7202.25 out of 7516.5	(95.81919776491718%)
Accuracy: 0.9397214716275203
F1 overall: 0.7690156490462122
F1 per class: [0.7020979020979021, 0.51875, 0.8597775969622999, 0.9954370971246469]
*******************************************


*******************************************
EVALUATING PIPELINE 
{'batch_size_seq_length': 1, 'lr': 2e-05, 'lr_type': 'constant'}
INFO:__main__:Creating features from dataset file at /home/ubuntu/fnd_implementation/data/processed
  0%|                                                  | 0/9622 [00:00<?, ?it/s]  0%|                                        | 1/9622 [00:02<6:58:46,  2.61s/it]  5%|█▉                                    | 501/9622 [00:02<4:37:55,  1.83s/it] 21%|███████▋                             | 2001/9622 [00:03<2:42:34,  1.28s/it]100%|█████████████████████████████████████| 9622/9622 [00:03<00:00, 2496.26it/s]
  ******************************************* 
              Running Evaluation                
  *******************************************
 
  Length dataset evaluation: 9622
  Length dataloader evaluation: 2406
  Number of epochs: 3
  Batch size: 4
  ******************************************* 
 
['/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_99965340_2020-02-06_22-26-28lwg0mm8l/outputs/checkpoint-3']
INFO:__main__:Evaluate the following checkpoints: ['/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_99965340_2020-02-06_22-26-28lwg0mm8l/outputs/checkpoint-3']
INFO:transformers.configuration_utils:loading configuration file /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_99965340_2020-02-06_22-26-28lwg0mm8l/outputs/checkpoint-3/config.json
INFO:transformers.configuration_utils:Model config {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 28996
}

INFO:transformers.modeling_utils:loading weights file /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_99965340_2020-02-06_22-26-28lwg0mm8l/outputs/checkpoint-3/pytorch_model.bin
HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=2406.0, style=ProgressStyle(description_width='initial')), HTML(value='')))
0.0010780.0016940.0008640.0003060.0000950.0000370.0000240.0000220.0000210.0000200.0000190.0000190.0000200.0000200.0000200.0000200.0000190.0000190.0000190.0000190.0006370.0000490.0006890.0000480.0010560.0017510.0000820.0000171.5435960.0538080.0018110.0000760.0000200.0000180.0000180.0000180.0009350.0000430.0000170.0000150.0005760.0002580.0000230.0000160.0009770.0000360.0010850.0000370.0054920.0001262.8685140.0605940.0011820.0000400.0000170.0000170.0000170.0000180.0009720.0000310.0027950.0000600.0000150.0000150.0000140.0000150.0000150.0000150.0000160.0000150.0000150.0000150.0000150.0000150.0000150.0000150.0000140.0000140.0000140.0000140.0000140.0000150.0000150.0000150.0000140.0000140.0000150.0008310.0000260.0000160.0000160.0000240.0000160.0000170.0028670.0000440.0044860.0067490.0000830.0000160.0000140.0000150.0000140.0019870.0000340.0000140.0000150.0000141.2744980.0125140.0001330.0000190.0000180.0000180.0000180.0000190.0000180.0006940.0000250.0000190.0000220.0004950.0000260.0000220.0000220.0005360.0000260.0000220.0000240.0000230.0000260.0000240.0017950.0016290.0009200.0000220.0000150.0000140.0000140.0000150.0000140.0022830.0000300.0030760.0009110.0000210.0000140.0000160.0000140.0000151.8472930.0122480.0010620.0041531.3306220.0085990.0000700.0000150.0000150.0000150.0000150.0029991.5579940.0095730.0000731.0781650.0065100.0000540.0000160.0000160.0018252.4885011.2894271.1863870.0068351.2658361.3783340.0078020.0007660.0000190.0000150.0000152.0306350.0111110.0017790.0000283.2478371.5364020.0081910.0003560.0120391.2621270.0163730.1132590.0031640.0000320.0000160.0000150.0000150.0000150.0000251.4360750.0071250.0000500.0000160.0000160.0000160.0000160.0000160.0000160.0010490.0000210.0000150.0000150.0000160.0000150.0000160.0000150.0000150.0000160.0000170.0000160.0005540.0000240.0010850.0000270.0000170.0022950.0000250.0000151.4786170.0071590.0004580.0000180.0007040.0000200.0000170.0000170.0000170.0009010.0000200.0000170.0000170.0009000.0000200.0000170.0000170.0000160.0000160.7793480.0031330.0000280.0007020.0004080.0000170.0000150.0000160.0051880.0000360.0022182.7214800.0104430.0000550.0000161.0841940.0061671.4533560.0054580.0000350.0000140.0000150.0000150.0000160.0046290.0005351.5048540.0067710.0000390.0000150.0000140.0000140.0000150.0000140.0000140.0000140.0000140.0000140.0000140.0000140.0071910.0000400.0018010.0000210.0000150.0000151.8113211.6542660.0055850.0000330.0000150.0000151.8662411.7444740.0057720.0000330.0133140.8477550.0027770.0000250.0009080.0000180.0000160.0000150.0000150.0000160.0000150.0000150.0000160.0058070.0000330.0000150.0045500.0000291.6277200.0050400.0010510.0000190.0000150.0009300.0006611.6378720.0054770.0000330.0027920.0009770.0014550.0009120.0009890.0000210.0019880.0011570.1331300.0004060.0000170.0000160.0000160.0000160.0000160.0000160.0000160.0000160.0000160.0000160.0000160.0000160.0000160.0000160.0000160.0000160.0000160.0000160.0000160.0000180.0000160.0000170.0000160.0000170.0006190.0000180.0000160.0000160.0000160.0000160.0000170.0000170.0000160.0000160.0000160.0000160.0000160.0000160.0000160.0007520.0000181.6697410.0058570.0000300.0000150.0000150.0000150.0000150.0008580.0000170.0000150.0000140.0000160.0006970.0000160.0000150.0000140.0000150.0000140.0000150.0000150.0000150.0000140.0000140.0000150.0000150.0000150.0023330.0000200.0011460.0000190.0006540.0000180.0000160.0035390.0013620.0000190.0038420.0035440.0003861.6301041.4910380.0035240.0015510.0000190.0000160.0000160.0000160.0000160.0000160.0004800.0000170.0000160.0000160.0000160.0000160.0000160.0000160.0000170.0000160.0000160.0014652.2984681.3030980.0029310.0010490.0000182.0285200.0050860.0006140.0000170.0000160.0010990.0000170.0000150.0000140.0000150.0000140.0000150.0000140.0000150.0002670.0004190.0000150.0031570.0014130.0000180.0000161.9506300.4659611.2133030.0046830.0006420.0016800.0018700.0000190.0000170.0000150.0000160.0017432.1245140.0076730.0016150.0000770.0000150.0000150.2442270.0030180.0000210.0044190.0011800.0000170.0000150.0008400.0000180.0000160.0000160.0000160.0007900.0019090.0000200.0000160.0000160.0000160.0000160.0023880.0000210.0000170.0008370.0000190.9336151.0564970.0020660.0000190.0061780.0014990.0041210.0000220.0014250.0098850.0000360.0000170.0010280.0000200.0010220.0024690.0000210.0017590.0000190.0000150.0020430.0013331.2118710.0022770.6643300.2205121.2653660.0023580.0000190.0000160.0027560.0000210.9812010.4415400.0008240.0000180.0011800.0017710.0000200.0000160.0010040.0000180.0000160.0016520.0021590.0007530.0000170.0000160.0006130.0000190.0006830.0004460.0007360.0007310.0000220.0000190.0000200.0000200.0006750.0005710.0000210.0006010.0000151.4629250.0025491.4622281.5074510.0026131.4495330.0044640.0000221.4566680.0025040.0056530.0005170.0008480.0008100.0004230.0000200.0004370.0000190.0627530.0014090.0000210.0000180.0005151.9784680.0036900.5081660.0077860.0145190.0038650.0041100.0019890.0056310.0020060.0018230.0005436.9554630.0120750.0000355.2159353.9353800.0075160.0012660.0000180.0010511.5053701.6592990.0026841.5831910.0036910.0000220.0011240.0000181.6283840.0026050.0010970.0000170.0000160.0011460.0000180.0000160.0000160.0617090.0012640.0000180.0043422.7858372.4054551.2550310.0045740.0019140.0018470.0000170.0064920.0000270.0010760.0011530.0000190.0020230.0006420.0000180.0004740.0017600.0018242.6688020.1682400.0015880.0006300.0019630.9725730.0014770.0205650.0000450.9948520.0015020.3930670.0012850.0000210.0000190.0000190.0005040.0183090.0034720.0029990.0004930.0000180.0000160.0000170.0000160.0000160.0000160.0000180.0013140.0000190.0000170.0000180.0000170.0000170.0000170.0000170.0000170.0001850.0000150.0001930.0005040.0000190.0004150.0000180.0004110.0004820.0005890.0000180.0049590.0005810.0013400.0004840.1241920.0001910.0020210.0000190.0004810.0000182.1655610.0030320.0000200.0223310.7290550.0010260.0000180.0012880.0000180.0012090.0009270.0227080.0249010.0973315.1663832.0488461.2218376.4636400.0098450.0000300.0007780.0010251.1937500.0034770.0006580.7763822.8239740.0049691.6647280.0022470.0000170.0000160.0020430.0000180.0000140.0032920.0042561.8602770.0024793.6830960.0048800.0000220.0000153.6869900.0048590.0000210.0005240.0000160.0051940.0000250.0000180.0004210.0000190.0047770.0049270.0051700.0041800.0050610.0047060.0005550.0000230.0000170.0000170.0004200.0000170.0000160.0000170.0000190.0015420.0010760.0046050.0017540.0009500.0013760.0008320.0000180.0035400.0018690.0009220.0017460.0005380.0007370.0037570.0062782.1697610.9558860.0020080.0000180.0030250.0065750.0000230.0001090.0038040.0000220.0000150.0023220.0014980.0000172.7399750.0033741.6904790.0029140.0000200.0000172.9176560.9445210.0540880.0000800.6464450.0007980.0307330.0000520.0032020.0025630.0004420.0010050.0008320.0030910.0040950.0030260.0000180.0027981.3280140.0015960.0023880.0000180.0000150.0000150.0001050.0005310.0004270.0000180.0005700.0025510.0000190.0000160.0000160.0059080.0057750.0018880.0000170.0000140.0000150.0000140.0000140.0000140.0000140.0030950.0000180.0000140.0000140.0000140.0000140.0000140.0000150.0000140.0000140.0000140.0000150.0000140.0000140.0000140.0000150.0000140.0024680.0031965.4301291.3715210.0015660.0043391.9989860.0052580.0016780.0000160.0000150.0000151.6907631.6766830.0018880.0000800.0000140.0002760.0002440.0083680.0005060.0015130.0012120.0024410.0015760.0000180.0045370.0025864.4805423.0208510.0033330.0000200.0000170.0007400.0009840.0010070.0007020.0007200.0008841.5440880.0016931.4642403.0716342.9915020.0089332.8985550.0079600.4841160.0031550.0460840.0037990.0000190.0031720.9203550.0026480.0046221.2721260.0017341.2448600.0013390.0000161.3256580.0014220.0000180.0000160.0000170.0005960.0000170.0000160.0000160.0000160.0000160.0013290.0003770.0000171.7341130.0018290.0000192.2178300.0027100.0007782.2933630.0023970.0000180.0022920.0000180.0010440.0000160.0000150.0000150.0010840.0000160.0000150.0022920.6506042.0996661.8477211.1556351.0166283.3102924.0585190.0090090.9864580.0021480.0000170.0000150.0000150.0000150.0000160.0000160.0000150.0000150.0023360.0000180.0000150.0020590.0020270.0000180.0017660.0000170.0000150.0000150.0000150.0000160.0000140.0000150.0000150.0037280.0043070.0000190.0000150.0024280.0053110.0000200.0000770.0000140.0000140.0000150.0000150.0000150.0000150.0009083.3289962.0593000.0036010.0000190.0000160.0000150.0010480.0006770.0006140.0006810.0005790.0000171.2354980.0141721.0361940.0020030.0031430.0023350.0025850.0000190.0045710.0004941.1583510.0011220.0028610.0000161.6932050.0141120.0000270.8344582.0658650.0019730.0000150.0000140.8182060.0007870.0271660.9470500.6973202.0887590.0019790.0000161.1727970.0034980.0000170.0091410.0000220.0000140.0146920.0021980.0000160.0097180.0000242.2239330.1628600.0001674.4465102.2368534.1712884.4329030.0081108.3328300.0701920.0089210.0050630.0000200.0082220.0013730.0067880.0051900.0073210.0027170.0092990.0035730.0000210.9256260.0017431.2340171.3167050.0022981.3380162.7628740.0062120.0000210.0064160.0053280.0042191.5147540.0013840.0000170.0000170.0000160.0000161.6070741.6277373.2200290.0036980.0000200.0008120.0000170.0000171.6092300.0014460.0000160.0000140.0000140.0010790.0000150.0000150.0013860.0000160.0010420.0010430.0000150.0000150.0000150.0000140.0000140.3887580.0003550.0000150.0000140.0000161.1222781.2238410.9401011.4884080.7968031.2317840.0010840.0005630.0013080.0000163.2976781.4991383.2924330.0043270.0007351.6713470.9408580.0023900.0010680.0000170.0000160.0000160.0000160.0000160.0000166.1477260.0052612.2493240.0029250.0010000.0012670.0000171.8281730.0015671.9298430.0016501.7703730.0015120.0006750.0000170.0000160.0000160.0000160.0000160.0000170.0000160.0016990.0000160.0000140.0000140.0000150.3534450.0003090.0007520.0000150.0000140.0000141.9635130.0671380.9907280.8529140.0007230.1863570.0004290.0000161.5539750.0038790.0000190.0000201.6659100.0020661.0281620.0008655.4392374.4802782.9816700.0036720.0042260.0012460.0020130.0006240.0009920.0000160.0029430.0007810.0000170.0000160.0000150.0000150.0000150.0000140.0000150.0019110.0000170.0000150.4030900.0057980.0040820.0006520.0000170.0000170.0000160.0005250.0000180.0000160.0000160.0004200.0000170.0000170.0000160.0000160.0000160.0003610.0000160.0000160.0004560.0000170.0000160.0005900.0000170.0000160.0000160.0000151.1593890.0009280.0000160.0009990.0000160.0009880.0000160.0000153.9029410.0042960.0015940.0021830.0013312.7437504.9070323.1802993.3512201.5584830.0034330.0036650.0033900.0035380.0023830.0499040.0467510.0040210.0045490.0032610.0032510.0022540.0021180.0035300.0040160.0042960.0020991.2225491.2206441.2277832.3881621.2008980.0075861.2167921.1208502.4597371.3389196.2115951.4897700.0031280.0000190.0000160.0000170.0000171.3038290.0010040.0000190.0004160.0004000.0000180.0048650.0077211.1847050.0052450.0046120.0110110.0069750.0080550.0000210.0007590.0003850.0005680.0000150.0004900.0008060.0000170.9311320.0007090.0000170.0010410.0000180.0000160.0010290.0010410.0000170.0000170.0000160.0000160.0000174.0186273.2738205.1781285.9934543.0670300.0022680.0000160.0000150.0002010.0000150.0000140.0002460.0000150.0000150.0000150.0000140.0000150.0000150.0000150.0000150.0000140.0000150.0000140.0000160.0000150.0000140.0002033.2996950.0023990.0000170.0000150.0001920.0000150.0000150.0000170.0000140.0021410.0020332.1491900.4872620.0037880.5216820.0170670.2849382.5796980.0031000.0003660.0015152.4935800.0023710.0197831.4557123.7121994.1636354.3701964.0600750.0035640.0008170.0006670.0014680.0000150.0080940.0000200.0077660.0000200.0797940.0073790.0000190.0211640.0035940.0016760.0027550.0028490.0019220.0029640.0031920.0027910.0015270.0025740.0022070.0007790.0032230.0023710.0000170.0035122.1795670.0015280.0000162.7184652.1415874.4394440.0030830.0000230.0035060.8677560.0070880.0067050.0223711.1187220.0007841.3679120.3365851.5087490.0087120.6458890.6503731.3737431.5253893.1582390.0071670.0032230.0032440.0026440.0036530.0028720.0000170.0010910.0752960.0000660.0128860.0000240.0000150.0000150.0162600.0000260.0000150.0012090.0000160.9301330.9354380.0006450.0112050.0000230.0000160.0000150.0000161.3511620.0031500.0043352.3004452.7523001.4089430.5048031.4963901.5349142.5502012.8190422.6714770.0057860.0012090.0040150.0023040.0008020.0077830.0053920.0011500.0017840.0006810.0022851.1848752.7277570.0027020.0020840.0018900.0028930.0016720.0016010.0017090.0012600.0017801.2905510.0093080.0010860.0025910.0000180.0122680.0009310.0000170.0000170.0000180.0000170.0000170.0000170.0000170.0000180.0012791.5221330.0010042.2111640.0014481.5070700.0009920.0012310.0004880.0014290.0027850.0138380.0008890.0034201.2591442.8533152.9582911.8363980.0011930.0042440.5366640.9471990.3688370.0002510.0000150.4365300.0007130.0010190.0011330.0013280.0008470.0013600.0013070.3311430.0009150.0009670.0055710.0012600.0012870.0025130.0006390.1489010.4709950.1501640.0013450.0006311.6979070.0022790.0006152.2783500.0025732.2916563.9204980.0035761.7246041.6078450.0016901.6912470.0016835.7058032.4080451.2446383.4268400.0021531.2787461.0447100.0010610.0011510.0000170.0009500.0011680.0033990.0000170.5684330.0030350.0031020.0000160.0011410.0010930.0011570.0000181.5171830.0009522.9766081.3414410.0008431.4728991.5065886.0765795.8480026.0709985.4049763.4726220.0038850.0004540.0006590.0000210.0007170.0000190.0012140.0000200.0006150.0000190.0000180.0000140.8630220.0005380.0000150.9123380.0005670.0000150.0000150.0000140.0000150.0016456.3596702.3019543.0471170.0059341.4979550.0009170.0016110.0000160.0000150.0056501.4587962.8434931.4959011.5774373.1112511.5556054.6416994.6472803.1010020.0018660.0000160.0022841.3968130.0008461.4743850.0008910.0000150.0009160.5795160.0003580.0000150.0000150.0000150.0000150.0000150.0007060.0006910.0005620.0015700.0015490.0035520.0438730.9012172.8800422.3790010.0042910.0036161.1518220.0006911.9339910.0027040.0047831.9523510.0021354.2948740.0040371.3711871.3888800.0008463.2148031.4067121.3744360.0037240.0000180.0000160.0000160.0022440.0000180.0016420.0018450.0012030.0020640.0018310.0023080.0011790.0025970.0007450.0014300.0009250.0007630.0000170.0012970.0000210.0000180.0025720.0020840.0011520.0013720.0025490.0011730.0012240.0010020.0000190.0028060.0011900.0023880.0000200.0000210.0025060.0026680.0000210.0029750.0000210.0000180.0000190.0000210.0000200.0000180.0033520.0013540.0000200.0040190.0000210.0010990.0000210.0000200.0007870.0000190.0000180.0023410.0027570.0009170.0010941.9396600.0011060.0000160.0000160.0000150.0000150.0000140.0000150.0000140.0005020.0000150.0013880.0000150.0000150.0000140.0000150.0006590.0005180.0000150.0006580.0000150.0000140.0000140.0009180.0033160.0008600.0034190.0035360.0025350.0135651.2355661.1415852.2556163.0707193.1375450.0035640.0020610.0021920.0039110.0008050.0023140.0018010.0021961.3064530.0025910.0014690.0025350.0035130.0000180.0015710.0015920.0026840.0023350.0013220.0024460.0046880.0055610.0033850.0044733.2561100.0020961.2422281.1927440.0013330.0028520.2487850.0032070.0030710.0179790.0134840.0033700.0008090.4588530.0109810.0013010.0022260.0042300.0020740.0026190.0018940.0015060.0029240.0017630.0007860.0006080.0000180.0000170.0000180.0007910.0004490.0004180.0008360.0000180.0000170.0000180.0000170.0032510.0000190.0000180.0000170.0000170.0000180.0000170.0000180.0000170.0000180.0000180.0008010.0000172.7549180.0014750.0000180.0003430.0006530.0011150.0011440.0005470.0011760.0007110.0009610.0007550.0003740.0007910.0000170.0000170.0019670.0035241.2867520.1462560.1855963.0512921.2941951.5604090.9303700.0009230.0004710.0004460.0005640.0006210.0000170.0004670.0000170.0000180.0000160.0010960.0032650.0000160.0044490.0000170.0057631.8148630.0069700.0043840.0000170.0049700.9243070.0029062.0196810.9060680.0013941.9754273.0727593.6007011.9123222.5480610.0013260.0685780.0012010.0020790.0051303.7158341.6546360.0024123.3378622.1046280.8215420.9558061.9432461.2535423.4082850.0050510.0040090.0012970.0051580.0070930.0076420.0123560.0051150.0056080.0076810.0048290.0056340.0061860.9578930.0045230.0007061.1582050.0006010.3628190.0001980.0000150.0000150.0000150.0000160.0000150.0000151.2097430.0049090.0000170.0000150.0000150.0000150.0041321.0547640.0104440.0085920.0000190.0000150.0009330.0049800.0031671.0633910.0049940.0036190.0031400.0026860.0221371.1687880.0005980.0303231.0266450.7311591.7487340.0330000.4339370.0018750.0005880.0000170.0004840.0000170.0000160.0010170.0009360.0011040.0011780.0010580.0000170.0000170.0000160.0029010.0030030.0026000.0025610.0065710.0036531.8565180.0060862.5729655.4011153.1696590.0015700.0000171.4145701.4474530.0007253.3993891.8268770.0009090.0000161.6091290.0008010.0049760.0000170.0000150.0000151.8606110.0009210.0000160.0000150.0021220.0009240.0000150.0000150.0009970.0009560.0000160.0010480.0000160.0010480.0000164.5278193.3519150.0044903.4454711.5846950.0038203.3708714.0088141.7208380.0019940.0022990.0018140.0021480.0006441.1686541.3241960.0006502.8281290.0019340.0025200.0034642.4762193.9039500.0047140.0023041.9916431.7075463.2288402.2897000.7499401.8825802.6179140.2184990.0001170.0002960.0059630.0000170.0000150.0002790.0000140.0000140.0000140.0002560.0002363.2925571.8222560.0011340.0000150.0003190.0012811.0336510.0005020.0029670.0015910.0005470.0028371.4972540.0014510.0301350.0019530.0029271.1820210.1005040.0000630.0035281.8970792.7520551.5784274.5937831.6427271.7043680.0035420.0010050.0023990.0000171.5497212.2095910.0035360.0021472.7625300.0037210.0041740.0022330.0017340.0032891.2809070.0054290.0036370.0016580.0010250.0000150.0020900.0032521.3810670.0006570.0008050.0000180.0013430.0007950.0012380.0006930.0011670.0004310.0007090.0004230.0015931.9737510.0019060.0000190.0000190.0018230.0015700.0011810.0011060.0013850.0006130.0004630.0014160.0004660.0000150.0000150.0000150.0013190.0000160.0000150.0051110.0000170.0000150.0000150.0000150.0000150.0000150.0000151.1633780.0005430.0000161.2577400.0005850.0000160.0000150.0016720.0000160.0000152.5707840.0020150.0043530.0000160.0000140.0000140.0000150.0030420.0000163.0157730.0013710.0014330.0000150.0000140.0000150.0000140.0000150.0000140.0000150.0000140.0023030.0000150.0066170.0033420.0000160.0000140.0000140.0027410.0034140.0000160.0000142.3717510.0010710.0040340.0006210.0027980.0020490.0022400.0016990.0013780.0014360.0009610.0018570.0014611.3372372.4170895.2526463.9036101.7464510.0013860.0000150.0024460.0021150.0006250.0007240.0015730.0019510.0015360.0000170.0023820.0004440.0004030.0006690.0000181.2205840.0005520.0000160.0037190.0016851.9860810.0008880.5546650.5383630.8377740.0020410.0013080.0022024.4842050.6288841.1559990.0024840.5559000.0033360.0009850.0009920.0007710.0000180.0008960.0017810.0000180.0008500.0009010.0017950.0000192.6702641.9430320.0008600.0004090.0000181.8804550.0008310.0004700.0000180.0000180.0000200.0036140.3136900.0025110.0021540.7594920.0003420.0000150.8024990.0003620.0021300.0021520.0075390.0044580.9759090.1020220.0048240.0529230.0022110.0018990.0030260.0000170.6697210.0003021.3696760.0006003.3324100.0021526.2020590.0077134.5215722.7266970.0011774.9000590.0039811.9592730.0029260.0009131.3823430.0062770.0020322.0089751.0299970.0119030.0054323.2025480.0062860.0000173.1119991.5730960.0043231.8106880.0120530.0041162.2905030.0069310.0946910.0962750.0028272.5681110.0046390.0033040.0000180.0015960.0016500.0019680.0015820.0013100.0007920.0024240.0016830.0013760.0009210.0028470.0010540.0024770.0009960.0003810.0006140.0000150.0000153.2590250.0024590.0005360.0000150.0008930.0000150.0009450.0005710.000015

*******************************************
EVALUATING PIPELINE 
Pipeline directory: /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_99965340_2020-02-06_22-26-28lwg0mm8l/
With following parameter combination: {'batch_size_seq_length': 1, 'lr': 2e-05, 'lr_type': 'constant'}
EVALUATION OF CHECKPOINT /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_99965340_2020-02-06_22-26-28lwg0mm8l/outputs/checkpoint-3
-------------------------------------------------------------
|           |   agree   | disagree  |  discuss  | unrelated |
-------------------------------------------------------------
|   agree   |    491    |    62     |    132    |     3     |
-------------------------------------------------------------
| disagree  |     7     |    18     |    25     |     2     |
-------------------------------------------------------------
|  discuss  |    248    |    67     |   1606    |    22     |
-------------------------------------------------------------
| unrelated |    16     |    15     |    37     |   6871    |
-------------------------------------------------------------
Score: 7158.0 out of 7516.5	(95.23049291558571%)
Accuracy: 0.9339014757846602
F1 overall: 0.6741838034967612
F1 per class: [0.6772413793103448, 0.16822429906542055, 0.8581351856799359, 0.9931343499313435]
*******************************************


*******************************************
EVALUATING PIPELINE 
{'batch_size_seq_length': 3, 'lr': 2e-05, 'lr_type': 'cosine'}
INFO:__main__:Creating features from dataset file at /home/ubuntu/fnd_implementation/data/processed
  0%|                                                  | 0/9622 [00:00<?, ?it/s]  0%|                                        | 1/9622 [00:02<6:43:53,  2.52s/it]  5%|█▉                                    | 501/9622 [00:02<4:28:02,  1.76s/it] 21%|███████▋                             | 2001/9622 [00:03<2:36:47,  1.23s/it] 78%|██████████████████████████████▍        | 7501/9622 [00:03<30:32,  1.16it/s]100%|█████████████████████████████████████| 9622/9622 [00:03<00:00, 2627.04it/s]
  ******************************************* 
              Running Evaluation                
  *******************************************
 
  Length dataset evaluation: 9622
  Length dataloader evaluation: 602
  Number of epochs: 3
  Batch size: 16
  ******************************************* 
 
['/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_b352ca52_2020-02-07_04-23-01vtufcmov/outputs/checkpoint-3']
INFO:__main__:Evaluate the following checkpoints: ['/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_b352ca52_2020-02-07_04-23-01vtufcmov/outputs/checkpoint-3']
INFO:transformers.configuration_utils:loading configuration file /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_b352ca52_2020-02-07_04-23-01vtufcmov/outputs/checkpoint-3/config.json
INFO:transformers.configuration_utils:Model config {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 28996
}

INFO:transformers.modeling_utils:loading weights file /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_b352ca52_2020-02-07_04-23-01vtufcmov/outputs/checkpoint-3/pytorch_model.bin
HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=602.0, style=ProgressStyle(description_width='initial')), HTML(value='')))
0.0002620.0003140.0002160.0001550.0000810.0001430.3242220.4671570.0584380.0066310.0723920.0068070.1108610.0085910.0007150.0001780.0074980.1532260.0085890.0005090.3328520.0159410.0008060.0003390.0009270.0002130.0000880.1605400.0057860.0002870.0001130.0000870.0000490.1588010.0047250.0003750.0002620.0035510.1041610.0027130.0002540.0002010.8539481.0123080.0232440.5653901.5205110.4368180.0111720.0002880.1222220.0024990.0012220.0000610.0000420.0000750.0001590.0003610.0053660.0001850.0002720.0000430.2832990.0046360.0009760.0060671.3095950.0195830.1502180.0023320.0000960.0000380.0043250.0614810.0521310.8753980.0134880.0002900.0000420.0004240.0012440.0001060.2447980.0107930.0003150.0053320.0001020.0000420.0000390.0000400.0000400.0001000.0000420.0000400.0000410.0000790.1542040.0045500.0002440.0001130.0000380.0000390.0000460.0002270.0005010.0377830.0024220.0000730.0002350.0000460.0006120.0473490.5229170.0052960.0000810.0000370.0006430.0001450.0004740.0001280.0046121.2043870.5877200.0073820.0003000.0010940.0000470.0006410.0113100.0367400.0005310.1713640.4644600.3083720.7029840.0073950.5770230.3980300.3846380.6518680.0059610.0002070.0000790.0001290.2593850.3306930.0933710.0008650.0004060.4788600.0044140.0009470.6494150.0401130.0004330.1299130.0012220.0816710.0006060.0001391.1129290.0091590.0741870.0006600.0005580.0104070.0081920.0519600.0003810.0006450.0000490.0014340.0000540.0000440.0002200.0001220.0001920.0004850.0002370.4105570.0717470.0091703.0291071.7273800.0144820.8910810.0056920.0006580.4500200.8019501.0983300.0062530.0004190.0006270.0000960.0004360.0002210.0004120.0012630.0410550.3868700.4099810.1079100.1976230.0018840.3729430.0098800.0009320.0006320.0006310.0001620.0003770.0002020.0055040.0001530.0000380.3442270.0016340.0000470.0000361.5516050.1795950.0011290.7936840.0038670.0007850.0015841.7666430.0081030.0005840.9265511.0261101.1721600.4189320.5488230.2816480.0013060.0000540.0026550.4270890.3412500.1525510.0148600.4929091.7893401.8397220.0075550.0003930.1687940.3281100.0013630.0000550.0003440.0003660.0000750.7452540.5291460.0029910.2944450.5788850.0090110.0209030.0086910.4366120.0044370.0026710.0004650.0002770.0002590.0758690.3400711.2024510.2626710.0014740.0006680.3632650.5281170.4332410.0016041.7141600.0062130.4006040.0015320.0002660.0000400.5394390.0063520.0019470.0003931.1118030.3712620.0013820.8131600.2936620.2383220.5491110.0083480.0000810.0004820.0026210.0004360.0016660.0001490.0001261.4870381.8384980.0065560.0005020.0000950.0003850.3126190.0010960.0000900.0000960.0000980.0000870.0000860.0001260.0002030.5368301.9480172.0388900.0106010.0023860.0634440.0018690.0006440.0504880.3424520.0049100.4448290.0026470.2075840.0015860.0005120.0002770.0000900.0001300.0000410.0120470.0222840.0008230.0000450.0004420.2364560.0009190.0001110.0000400.0021110.0009620.0004651.8581835.8326710.0169510.0009170.0008340.0270140.0006360.0006420.0002390.1690590.4133800.2650860.0572621.8870731.8839800.2269100.0010460.0004120.0007430.0001430.0006720.0000401.3664672.5794733.5973700.6260140.3163480.1186230.3010410.0013460.3117090.0013540.0001710.0000460.4238620.9150960.0042300.0090770.0037780.0005990.0002450.0007150.0003450.0007410.0025100.5043540.5300551.9443090.9056870.9201340.0047130.0003900.0012970.0002460.4787641.9032334.5465372.2194380.0057070.0002020.2884190.5685000.0015160.0162760.4295091.0609040.6980890.3975410.3313450.2268760.0039270.0001460.4053680.4060840.2681800.2111271.3485891.0407670.6799420.0017960.0003300.0004810.0002410.0001400.0003260.0002990.0003100.0002000.0001430.0018460.0006840.0001140.0002700.0010530.0000480.0000370.0003250.0001330.0002360.0005190.0013710.2316920.0056260.0007120.0007280.0012740.0005710.0007940.0556070.1028440.0260190.0005720.4170120.2283190.2770760.0007010.0002550.0001010.0000370.0000890.0000960.7138290.0021530.0004480.0003240.0017333.8939470.4855540.0014950.0002420.0004350.1736410.0072920.0410220.0029510.0020750.9755091.4420410.0048710.0005950.0009540.0041480.0012750.0014970.0000420.0023970.0005220.0036251.0953311.3758940.3010171.3167760.3193850.0007700.0183150.0006281.2668890.3919050.6900960.7180891.1357900.4664030.3493480.0375180.0005120.0003280.7365320.5878560.1894080.0295760.0175920.8632010.6468560.1914900.0024940.0002230.0003550.0471080.0888730.0026160.0016800.0736720.0088941.1083810.0024410.0715470.4998800.0887610.0051610.0502160.0002950.0003540.0003100.0002630.0004770.0002890.0001520.0005490.0000420.0004770.3672040.0008450.0005960.0002650.0002350.0000430.0000630.0008620.0000890.0447020.0055290.0160610.0064193.2987640.0075200.0007130.2531170.0008140.3715660.0191190.4008600.5334340.0021220.0004090.0002940.8660790.0557070.0001880.1227060.1785820.0381180.5665000.2244440.0247010.2651380.5972450.2418830.0038270.0029260.2083860.0039190.0291280.0933790.0105010.0003820.0005120.0005780.0002340.0002810.0003000.000205

*******************************************
EVALUATING PIPELINE 
Pipeline directory: /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_b352ca52_2020-02-07_04-23-01vtufcmov/
With following parameter combination: {'batch_size_seq_length': 3, 'lr': 2e-05, 'lr_type': 'cosine'}
EVALUATION OF CHECKPOINT /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_b352ca52_2020-02-07_04-23-01vtufcmov/outputs/checkpoint-3
-------------------------------------------------------------
|           |   agree   | disagree  |  discuss  | unrelated |
-------------------------------------------------------------
|   agree   |    593    |    23     |    122    |     3     |
-------------------------------------------------------------
| disagree  |    11     |    88     |    42     |     0     |
-------------------------------------------------------------
|  discuss  |    154    |    50     |   1615    |    21     |
-------------------------------------------------------------
| unrelated |     4     |     1     |    21     |   6874    |
-------------------------------------------------------------
Score: 7255.5 out of 7516.5	(96.5276391937737%)
Accuracy: 0.9530243192683434
F1 overall: 0.813421374819208
F1 per class: [0.7890884896872921, 0.5808580858085809, 0.8873626373626373, 0.9963762864183215]
*******************************************


*******************************************
EVALUATING PIPELINE 
{'batch_size_seq_length': 1, 'lr': 2e-05, 'lr_type': 'cosine'}
INFO:__main__:Creating features from dataset file at /home/ubuntu/fnd_implementation/data/processed
  0%|                                                  | 0/9622 [00:00<?, ?it/s]  0%|                                        | 1/9622 [00:02<7:29:15,  2.80s/it] 21%|███████▋                             | 2001/9622 [00:03<4:09:06,  1.96s/it] 52%|███████████████████▏                 | 5001/9622 [00:03<1:45:44,  1.37s/it] 78%|██████████████████████████████▍        | 7501/9622 [00:03<33:58,  1.04it/s]100%|█████████████████████████████████████| 9622/9622 [00:03<00:00, 2523.83it/s]
  ******************************************* 
              Running Evaluation                
  *******************************************
 
  Length dataset evaluation: 9622
  Length dataloader evaluation: 2406
  Number of epochs: 3
  Batch size: 4
  ******************************************* 
 
['/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_ae54fad4_2020-02-07_02-44-360_fs3gz8/outputs/checkpoint-3']
INFO:__main__:Evaluate the following checkpoints: ['/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_ae54fad4_2020-02-07_02-44-360_fs3gz8/outputs/checkpoint-3']
INFO:transformers.configuration_utils:loading configuration file /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_ae54fad4_2020-02-07_02-44-360_fs3gz8/outputs/checkpoint-3/config.json
INFO:transformers.configuration_utils:Model config {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 28996
}

INFO:transformers.modeling_utils:loading weights file /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_ae54fad4_2020-02-07_02-44-360_fs3gz8/outputs/checkpoint-3/pytorch_model.bin
HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=2406.0, style=ProgressStyle(description_width='initial')), HTML(value='')))
0.0002820.0003380.0001830.0000740.0000360.0000210.0000170.0000160.0000150.0000150.0000150.0000140.0000150.0000150.0000180.0000150.0000140.0000150.0000140.0000140.0000500.0000160.0000570.0000160.0000721.8305780.0704190.0026212.3523590.0814570.0027290.0001010.0000170.0000140.0000140.0000140.0001000.0000160.0000140.0000130.0001011.5692720.0373770.0008830.2557800.0056970.0016490.0000480.0013510.0000400.5868791.5762040.0303250.0005860.0000240.0000140.0000150.0000430.0000570.0000140.0006280.0000240.0000190.0000250.0000130.0000180.0000200.0000130.0003060.0000250.0000130.0000390.0000130.0000130.0000130.0000130.0000130.0000140.0000130.0000330.0000160.0000130.0046330.0000680.0000140.0000130.0000190.0000500.0000270.0000150.0000150.0000490.0002320.0005140.0004280.0000170.0011280.0015400.0000280.0000170.0000150.0000400.0000130.0000850.0000140.0000130.0000180.0000131.9916910.0183672.3439220.0211450.0002040.0000770.0002612.2849380.0197152.4180820.0205060.0002080.0000150.0001270.0000140.0000130.0000130.0000560.0000140.0000130.0000130.0000130.0000130.0000130.0001500.0006790.0002020.0000160.0000160.0000130.0000130.0000153.2643660.0232050.0001890.0000540.0001670.0000140.0000130.0000140.0000130.0000310.0005410.0000170.0002993.5637972.0927790.0135150.0001000.0000140.0000130.0000140.0008650.0002730.0003040.0000170.0000140.0003790.0000160.0000140.0000130.0000140.0000512.1623141.0868110.4168820.0024111.1883181.9933710.0112740.0001640.0000140.0000130.0000132.4352500.0133200.0001700.0000154.7461802.4743030.0131750.0000842.7980190.0166110.0016990.0051160.0013550.0000220.0000150.0000130.0000140.0000140.0000140.0003520.0000160.0000130.0000130.0000140.0000150.0000150.0000130.0000150.0000510.0000170.0000140.0000140.0000140.0000130.0000140.0000130.0000140.0000140.0000130.0000140.0000640.0000170.0001170.0000180.0000330.0000730.0000190.0000162.1218640.0092450.0009060.0000170.0000560.0000140.0000180.0000140.0000400.0000570.0000140.0000140.0000130.0001510.0000140.0000130.0000130.0000130.0000130.0009680.0000200.0000130.0001000.0000710.0000140.0000140.0003360.0001430.0000130.0000540.1259130.0004950.0000140.0000122.1259602.1781370.0121040.0000580.0000130.0000130.0000130.0000130.0000130.0008320.0001131.9684990.0076560.0000400.0000130.0000130.0000130.0000130.0000130.0000130.0000130.0000120.0000140.0000120.0000130.7860430.0027250.4228720.0014610.0000180.0000140.0142370.0258930.0001020.0000140.0000190.0000141.7481172.0381050.0067410.0000360.0088630.1122300.0003790.0000140.0000620.0000140.0000130.0000130.0000130.0000130.0000130.0000130.0000130.0008500.0000160.0000130.0599210.0001991.9526970.0060400.0000730.0000140.0000140.0000540.0003600.0004850.0002980.0000140.0002410.0000520.0001610.0000530.0000500.0000140.0000880.0000521.9465300.0057070.0000310.0000140.0000130.0000140.0000140.0000140.0000160.0000150.0000130.0000190.0000140.0000140.0000130.0000150.0000150.0000180.0000150.0000170.0000140.0000160.0000150.0000130.0000160.7880740.0022020.0000220.0000140.0000140.0000140.0000140.0000150.0000140.0000150.0000190.0000140.0000140.0000140.0000140.0000140.0000550.0000140.0009690.0000200.0000170.0000130.0000510.0000130.0000210.0002270.0000180.0000130.0000130.0000130.0002890.0000130.0000130.0000130.0000130.0000130.0000130.0000130.0000130.0000130.0000120.0000180.0000130.0000130.0000570.0000130.0001920.0000140.0001910.0000140.0000130.0020630.0000930.0000140.0002010.0002440.0000581.2781861.4106250.0033320.0000620.0000130.0000130.0000130.0000130.0000130.0000130.0000990.0000130.0000130.0000460.0000130.0000130.0000130.0000130.7419070.0016910.0000170.0752861.8514110.0043870.0000230.0000890.0000142.4287200.0054510.0000900.0000140.0000130.0000710.0000130.0000130.0000130.0000130.0000130.0000130.0000130.0000130.0001220.0001130.0000130.0010370.0003220.0000160.0000150.0000360.0000150.0003590.0004040.0000210.0000570.0000580.0000150.0000140.0000130.0000160.0000530.0007300.0035801.7779400.6687380.0023050.0020430.0146150.0017230.0007370.0006480.0000650.0000130.0000130.0002580.0000140.0000130.0000130.0000130.0001040.0000870.0000130.0000140.0000130.0000130.0000130.0003510.0000130.0000120.0000510.0000130.0014881.2184190.0023780.0000170.3979390.0133270.7127980.0013830.0000540.1067460.0002380.0000131.8757920.0035800.0000593.7503540.0071020.0001050.0000130.0000130.0000700.0000531.5618100.0029261.5794281.3142902.4444270.0045390.0000210.0000130.0000990.0000201.4944121.5740281.5337200.0028340.0000561.3485400.0024670.0000170.0002391.0378290.0018931.9470080.6564560.0526640.0001160.0000130.0006960.0000140.0005080.0000750.0000540.0000500.0000140.0000130.0000140.0000140.0000570.0000610.0000130.0001100.0000131.5032660.0026181.4334401.8253520.0031601.2983600.0022430.0000161.5143010.0026011.1787280.0020810.0000530.0000510.0000910.0000140.0004220.0000140.0001110.0001300.0000150.0000130.0000762.2374070.0040520.0000811.5664633.9507180.0072620.0004500.0002540.0028530.0000850.0002080.0000805.2446272.5060120.0044290.0115361.8011710.0029760.0000590.0000130.0000560.0805110.0001430.0000130.0068540.0000630.0000120.0000520.0000130.0029900.0000170.0000510.0000120.0000120.0000530.0000120.0000290.0000120.0000520.0000550.0000130.0009431.4696360.8414420.0018560.0001620.0002720.0007760.0000140.3892580.0006130.0001590.0000920.0000130.0001420.0000550.0000130.0005250.0001400.0002480.0001890.0001240.0000490.0003010.0001660.0003190.0000130.0007100.0000130.0003690.0000130.0004390.0000530.0000140.0000150.0000130.0000600.0014550.0001830.0002060.0001640.0000130.0000120.0000120.0000120.0000130.0000150.0000120.0005610.0000130.0000130.0000120.0000120.0000130.0000140.0000120.0000120.0001150.0000130.0001230.0000510.0000150.0000550.0000140.0000600.0000510.0000570.0000140.0000580.0001940.0000520.0000590.0001500.0003260.0021330.0000170.0000610.0000161.2137720.0017040.0000161.2403990.2889820.0004140.0000140.0000570.0000140.0000490.0000671.4929233.0692901.7438140.0026080.0005290.0015601.9621180.0027190.0000170.0001540.0191041.1181520.0015640.0002512.5754412.8497540.0039192.2796080.0030700.0000170.0000190.0041500.0000180.0000130.0006730.0004350.0035520.0000181.2394980.0016500.0000160.0000140.0241850.0000480.0000130.0002660.0000131.0269910.0013540.0000150.0000630.0000140.0001800.0001820.0001770.0001770.0001750.0001860.0000540.0037450.0000170.0000130.0000880.0000130.0000130.0000130.0000130.0001200.0000530.0000990.0000940.0001110.0092531.4202960.0018060.4689920.0006790.0000541.7203110.0022190.0000593.4835350.2344511.5342531.6360630.0021470.0000150.0003200.0003520.0000130.4276610.0008740.0004740.0000140.0003120.0000620.0000130.0238830.0000420.0281590.0000850.0000130.0000140.0430544.3367765.9787690.0072680.0003500.0000130.0195780.0000360.0003870.0002570.0000500.0000850.0000920.0001580.0002380.0002200.0000130.0001930.4722060.0005750.0002470.0000140.0000130.0000130.0000190.0000620.0001070.0000140.0002100.0005340.0000140.0000130.0000140.0005000.0002150.0000870.0000120.0000120.0000120.0000120.0000120.0000120.0000120.7730830.0009060.0000130.0000120.0000120.0000120.0000120.0000120.0000120.0000120.0000120.0000120.0000120.0000120.0000130.0000120.0000120.0026030.0012985.2875001.2863750.0014680.0007321.7903170.0022030.0001570.0000130.0000130.0000141.4001681.6380440.0018430.0053260.0000190.0001480.0001410.9788440.0013880.0001620.0001770.0000920.0002620.0000140.0003830.0004247.0040764.6699060.0051640.0000320.0000160.0000620.0000850.0000850.0000530.0622020.0001211.4319050.0015721.8006173.5606103.3783370.0037433.4567760.0038501.7264331.5691631.7522950.0020350.0000200.0001261.7589300.0020040.0002211.2522900.0014080.2433300.0002740.0000140.8168070.0008790.0000140.0000130.0000130.0000560.0000130.0000130.0000130.0000130.0000130.0003260.0000590.0000132.2616660.0023770.0000162.1748530.0023240.0000562.2750230.0023760.0000160.3434010.0003690.0428070.0000580.0000140.0000140.0612910.0000800.0000140.0000512.5637153.4203661.9965782.0664283.1964692.6391095.4505150.0060330.0002760.0000510.0000130.0000130.0000130.0000130.0000130.0000130.0000130.0000130.0061500.0000190.0000130.0019560.0037960.0000160.0022140.0000150.0000130.0000130.0000130.0040310.0000180.0000120.0000130.0001600.0004660.0000210.0000130.0002200.0005880.0000260.0000710.0000130.0000130.0000290.0000140.0000130.0000130.0000655.9665284.4576350.0044620.0000180.0000130.0000130.0005380.0001990.0002390.0002510.0001650.0000141.5875881.7051511.5131140.0015080.0001830.0001790.0002050.0000140.0000830.0001770.6023580.0005900.0000550.0000121.4300650.0103540.0000221.0069662.4090890.0022990.0000150.0000120.3635520.0003560.0534560.0013190.6231751.0708190.0010200.0000150.0073880.0000610.0000120.0019590.0000140.0000120.0035990.0000680.0000120.0021550.0000150.3559770.0052000.0000180.9567050.8735480.0052071.2318080.0018101.7099960.2257080.0038080.0000952.2512622.3340480.0171440.0006600.0002600.0001370.0000560.0001351.4439510.0013350.0008340.0001491.2795571.0792570.0010331.0599691.9283730.0018400.0000140.0002480.0003270.0003222.3036780.0022890.0000150.0000130.0000140.0000132.0897042.1155374.1850140.0037910.0000170.0000530.0000130.0000141.8728960.0016770.0000150.0000120.0000120.0001600.0000130.0000120.0001710.0000130.0001480.0001480.0000130.0000120.0000120.0000120.0000120.0000150.0000120.0000120.0000120.0000130.0096390.0056720.0006500.0030010.0001150.0020342.0785660.0020270.0005730.0000142.8847662.2956292.6137500.0023430.0000560.1433160.4094590.0006400.0000510.0000130.0000130.0000140.0000140.0000150.0000132.3770240.0020422.0964070.0018370.0000680.0000600.0000150.5162840.0004540.3878360.0003470.9535630.0008210.0000800.0000140.0000840.0000130.0000280.0000140.0000150.0000130.0038280.0000160.0000130.0000120.0000140.8549380.0007260.0011350.0000140.0000120.0000130.1701500.7657601.3420680.0017240.0000150.0000140.0000130.0000140.0045930.0002720.0000140.0000160.0000160.0000510.0000781.2525744.2548784.1302222.4443570.0020920.0001030.0000910.0001180.0007500.0005880.0000130.0008310.0005380.0000170.0000150.0000120.0000130.0000120.0000130.0000130.0014980.0000140.0000130.2616270.0015810.0013260.0000540.0000130.0000140.0000130.0000650.0000140.0000130.0000140.0000650.0000130.0000140.0000140.0000130.0000140.0001070.0000130.0000130.0002190.0000140.0000140.0000530.0000130.0000140.0000130.0000140.0002910.0000180.0000130.0001890.0000140.0002510.0000130.0000202.2851900.0023930.0013970.0023210.0007872.5748114.1127562.2361202.7955051.8885901.1661010.0010721.0468650.0009890.5275710.0011520.0015980.0001650.0002180.0002170.0001970.6434220.0007190.0004120.0012270.0004330.0000540.0006390.0002250.0005320.0005400.0004690.0003320.0004100.1970831.7765030.9297615.5368990.1591790.0003070.0000140.0000130.0000130.0000141.4580760.0011160.0000140.0000700.0000720.0000132.4211670.0120640.0003871.3699950.0753160.0004640.0006560.0003820.0000130.0007700.0003140.0001070.0000150.0001140.0303820.0000350.2997820.0002360.0000130.0009360.0000170.0000130.0000510.0009360.0000130.0000130.0000130.0000120.0000130.0025640.0036580.0019610.0154600.0016560.0000140.0000210.0000130.0001460.0033530.0000150.0001290.0000660.0000200.0000120.0000120.0000550.0000140.0000120.0000140.0000130.0000140.0000120.0000500.0000140.0000130.0001290.0002140.0000130.0000120.0000130.0001380.0000120.0000130.0000140.0000120.0001310.0001270.0024670.0009800.0022010.0015270.0009530.0007090.0001890.0000950.0000550.0001660.0001760.0000550.0633950.4830560.1082844.2040624.7816825.9404140.0044500.0002220.0002240.0004100.0000130.0001900.0000140.0003450.0000130.0051860.0002400.0000150.0005570.0001800.0000940.0001450.0001620.0001030.0001850.0001360.0001490.0001060.0001460.0002010.0000730.0001370.0000650.0000640.0019982.1123710.0020090.0000360.0000900.0001441.5303840.0010960.0000840.0001030.4004940.0007420.0001821.3334273.3314750.0023063.1362143.2042831.9564711.5664351.7260842.0052091.8160404.0105682.2149920.0027030.0003140.0002120.0002460.0001630.0001270.0000130.0000560.0106320.0000200.0009180.0000130.0000130.0000130.4122260.0002910.0000150.0001130.0000131.1339910.9684850.0006660.0000600.0000130.0000130.0000130.0000152.2043470.0015700.0001814.2414334.2522214.1396192.0172281.8753504.2016584.2252194.2581544.3467782.1614050.0015030.0007260.0001230.0000510.0004880.0010640.0000530.0001310.0014270.0000961.3594223.6225340.0025470.0001260.0001920.0001590.0001600.0001690.0001900.0001480.0001480.0001960.0002120.0000580.0000730.0000130.0001610.0001080.0000130.0000140.0000160.0000130.0000130.0000130.0000130.0000140.0000510.0039330.0000161.3840200.0009080.0012590.0000140.0000530.0003980.0036501.3511021.5031640.0010200.0733653.1185290.2661110.0017360.0008470.0000130.0000160.0002800.0002220.0001230.0000150.0000140.0001190.0022760.0000910.0003090.0000950.0026900.0000920.0010570.0000930.0000530.0000900.0002170.0000880.0002330.0004750.0001340.5758860.0146400.0032430.0001700.0000512.3262210.0015520.0000522.4320430.0016152.4520304.7819280.0030882.3229002.3249900.0015062.3556650.0015244.8024780.0032801.7275060.0012992.3596951.6245600.5070000.0004210.0001060.0000140.0001250.0001100.0022910.0000150.0614680.0006950.0016470.0000140.0000600.0000500.0000510.0000131.8655280.0011623.8956942.3170480.0014381.9431892.1621787.8787606.1649457.7110495.8648714.4642090.0028652.4316280.0015370.0021320.0000510.0000140.0000910.0000210.0000490.0000130.0000140.0000161.0062710.0006250.0001281.5188150.0009360.0000160.0000170.0000150.0000300.0000516.9153852.5987681.2873400.0020791.9115680.0011630.0015470.0000150.0000130.0005301.4609242.7098610.1133430.6350911.0342360.5772861.7526721.4559471.6605760.0010040.0000130.0005951.5442910.0009331.5133320.0009130.0000140.0008561.0425800.0006310.0000130.0000130.0000180.0000130.0000130.0002930.0002450.0003370.0003200.0001450.0000870.0005200.0001800.0008320.0042120.0000870.0000840.0016250.0000140.0002560.0000480.0001233.5963812.0721582.4422230.6138193.5309001.3847700.0046842.8329571.5292621.1245360.2665240.0001690.0000150.0000140.0001470.0000470.0000860.0000850.0001340.0001380.0001920.0001520.0001430.0001590.0000500.0000870.0000500.0000510.0000140.0000560.0000150.0000140.0000920.0000930.0000540.0000560.0000970.0000580.0000640.0000560.0000140.0000920.0000590.0001350.0000140.0000180.0000930.0000930.0000140.0000930.0000150.0000140.0000140.0246210.0000290.0000130.0001420.0000610.0000140.0002120.0000140.0000540.0000150.0000140.0001010.0000140.0000140.0001090.0000960.0000600.0000561.8799390.0010700.0000150.0000210.0000170.0000130.0000130.0000180.0000130.0001880.0000140.0003320.0000130.0000160.0000120.0000130.0001220.0001350.0000140.0001230.0000130.0000130.0000130.0004870.0006450.0003830.0021380.0006230.0001121.8693972.1854120.4301800.0016971.7584270.0026040.0002140.0001660.0001580.0002820.0001170.0001620.0001910.0001760.0002080.0001710.0002440.0003590.0001960.0000140.0002040.0002170.0001100.0770170.0001010.0001050.0003340.0003230.0002400.0001980.0006040.0001860.0003280.0005570.0048910.0002870.0002650.0003370.0003280.9498380.0029190.0012120.0000520.0001470.0001980.0000960.0001680.0002230.0001460.0001520.0002280.0001620.0010500.0000900.0009720.0000590.0000130.0000130.0000130.0000540.0003170.0000670.0000550.0000120.0000130.0000130.0000130.0001520.0000130.0000130.0000130.0000130.0000130.0000130.0000150.0000130.0000130.0000200.0000490.0000134.5321810.0024130.0000150.0000820.0000730.0001120.0001840.0002730.0001060.0000600.0001130.0001820.0000620.0007380.0000140.0000970.0006320.0004410.0353830.0014691.7297605.2642351.7623134.7836811.5598180.0084480.0062020.0000700.0000550.0000580.0000130.0058990.0000160.0000130.0000130.0007320.0090840.0000220.0000740.0000150.0000520.0039710.1178621.2638780.0006670.0526910.0024570.0017820.0023920.0023350.0026110.0031890.0047400.0064020.0025360.0056430.0000160.0062320.0001160.0002060.0012943.2183172.3454300.9936294.7269372.3940470.0040300.0047640.1502840.0026650.0015220.0000520.0000540.0002720.0002700.0000930.0002350.0001340.0002950.0002610.0003060.0002740.0003400.0001060.0002190.0003210.0001820.0003700.0000130.0003750.0000130.0000120.0000120.0000130.0000120.0000120.0000130.0006240.0058410.0000150.0000130.0000120.0000120.0008160.0004790.0755070.0018860.0000130.0000120.0000530.0004450.0005990.0001750.0003570.0014840.0016360.0002401.0009381.4818910.0007511.4237361.0959211.7554772.3741721.5051071.6782590.0008930.0000560.0000130.0000570.0000130.0000140.0000980.0000920.0000910.0000600.0002890.0000130.0000130.0000140.9746110.0213500.4803660.1835400.0147740.9831940.5573860.6910630.6424224.5354141.9176440.0009540.0000152.4278092.2340710.0011074.5446142.3882610.0011840.0000132.3672990.0011690.0005280.0000140.0000130.0000190.0000370.0000130.0000440.0000130.0011030.0000670.0000130.0000140.0861810.0010930.0000140.0007230.0000131.6431420.0008080.0051802.2852970.0013030.8170020.0019450.0001980.0033200.0035520.0019800.0005780.0004690.0044000.0001740.0000521.8570691.2892210.0006323.2943820.0016322.0622532.8146390.0016403.5419140.0018660.0001710.0750951.4069061.0116941.1853731.3719810.0009880.0001971.3668210.0006640.0847260.0001160.0000130.0000150.0040520.0000150.0000130.0000161.7558430.0023242.7235051.3440390.0147570.0000220.9566550.0081400.1311050.0000741.1578650.0304700.0030190.5033110.4249570.0002510.0030620.4829710.0189330.1207390.9211660.0004450.0052250.0019620.0034020.0018652.5889850.0903342.0024540.0011290.0000560.0001800.0000130.0015590.0015700.0001550.0001460.0316420.0001850.0001800.0001710.0002640.1428711.2265340.0012250.0000540.0003240.0001410.0000120.0004770.0010681.1133640.0005370.0000660.0000140.0001020.0000560.0001220.0000510.0001190.0000970.0000520.0001290.0000961.6348470.0009300.0000140.0000270.0001620.0001260.0000940.0000860.0000880.0000530.0000620.0000880.0000600.0000130.0000120.0000130.0000760.0000120.0000120.0047300.0000150.0000120.0000120.0000120.0000130.0000120.0000160.0015110.0000130.0000121.9072210.0008770.0000130.0000130.0004450.0000130.0000120.0001850.0001720.0002630.0000130.0000130.0000130.0000140.0005770.0000130.0016020.0000140.0150810.0000200.0000140.0000130.0000130.0000130.0000130.0000180.0000120.0008730.0000130.0013620.0000790.0000120.0000120.0000120.0001210.0015530.0000160.0000121.2263180.0005590.0004660.0000640.0002160.0001880.0001710.0000990.0001020.0001060.0000720.0002780.0001381.7370333.6218357.2723505.5964010.0180150.0006250.0000130.0016370.0003820.0007100.0006920.0006150.0002170.0967400.0000552.1142950.0206880.0001341.8772670.0008390.0004670.0000150.0000130.0000920.0000500.0031730.0000160.0006402.0015120.0015840.0000520.0000520.0000510.3655110.0006640.0016410.0000530.0005960.0000950.0000550.0027870.0000560.0000230.0000590.0001340.0000140.0001590.0000550.0001820.0000130.0001082.3224550.0010200.0000790.0000140.0004910.0000140.0000660.0000130.0000140.0107540.0000920.9863990.0005390.0000500.0273520.0000240.0000130.2771260.0001320.0001560.0000480.0001620.2458071.5944410.6926530.0003820.6149320.0003130.0000500.4424850.0002020.7905410.0003611.2316840.0005393.0281830.0013543.5582420.0025422.4722230.0020330.0000142.1617790.0011410.0016730.0042140.0022430.0053370.0000570.0047480.0022800.0018560.0019891.2567870.3409430.0134350.0000180.5516720.8058340.0020470.0299890.0020410.0023293.1180490.0623940.0207791.1389200.0007930.0002710.0001360.0001150.0000130.0000560.0000560.0000500.0000910.0000950.0000560.0002000.0000990.0000910.0000520.0001590.0001200.0001360.0000510.0001330.0001260.0000120.0000150.0001230.0002390.0001280.0000150.0002370.0000130.0002770.0001350.000013

*******************************************
EVALUATING PIPELINE 
Pipeline directory: /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_ae54fad4_2020-02-07_02-44-360_fs3gz8/
With following parameter combination: {'batch_size_seq_length': 1, 'lr': 2e-05, 'lr_type': 'cosine'}
EVALUATION OF CHECKPOINT /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_ae54fad4_2020-02-07_02-44-360_fs3gz8/outputs/checkpoint-3
-------------------------------------------------------------
|           |   agree   | disagree  |  discuss  | unrelated |
-------------------------------------------------------------
|   agree   |    558    |    48     |    114    |     9     |
-------------------------------------------------------------
| disagree  |    19     |    68     |    52     |     1     |
-------------------------------------------------------------
|  discuss  |    174    |    44     |   1612    |    26     |
-------------------------------------------------------------
| unrelated |    11     |     2     |    22     |   6862    |
-------------------------------------------------------------
Score: 7218.25 out of 7516.5	(96.03206279518393%)
Accuracy: 0.9457493244647682
F1 overall: 0.7688783383960129
F1 per class: [0.7484909456740443, 0.4503311258278146, 0.8818380743982495, 0.9948532076839435]
*******************************************


*******************************************
EVALUATING PIPELINE 
{'batch_size_seq_length': 2, 'lr': 2e-05, 'lr_type': 'cosine'}
INFO:__main__:Creating features from dataset file at /home/ubuntu/fnd_implementation/data/processed
  0%|                                                  | 0/9622 [00:00<?, ?it/s]  0%|                                        | 1/9622 [00:02<6:54:19,  2.58s/it]  5%|█▉                                    | 501/9622 [00:02<4:34:58,  1.81s/it] 21%|███████▋                             | 2001/9622 [00:03<2:40:50,  1.27s/it] 78%|██████████████████████████████▍        | 7501/9622 [00:03<31:20,  1.13it/s]100%|█████████████████████████████████████| 9622/9622 [00:03<00:00, 2531.57it/s]
  ******************************************* 
              Running Evaluation                
  *******************************************
 
  Length dataset evaluation: 9622
  Length dataloader evaluation: 1203
  Number of epochs: 3
  Batch size: 8
  ******************************************* 
 
['/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_b0d2ae96_2020-02-07_02-47-15hz_brz0f/outputs/checkpoint-3']
INFO:__main__:Evaluate the following checkpoints: ['/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_b0d2ae96_2020-02-07_02-47-15hz_brz0f/outputs/checkpoint-3']
INFO:transformers.configuration_utils:loading configuration file /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_b0d2ae96_2020-02-07_02-47-15hz_brz0f/outputs/checkpoint-3/config.json
INFO:transformers.configuration_utils:Model config {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 28996
}

INFO:transformers.modeling_utils:loading weights file /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_b0d2ae96_2020-02-07_02-47-15hz_brz0f/outputs/checkpoint-3/pytorch_model.bin
HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=1203.0, style=ProgressStyle(description_width='initial')), HTML(value='')))
0.0004980.0005200.0002820.0001130.0000470.0000280.0000260.0000230.0000260.0000220.0000630.0000830.6992490.0538081.0714380.0714480.0044850.0002840.0001380.0000340.0004270.0000390.6560930.0293420.0017411.1232350.0432210.0016200.0000790.0000730.0002280.0000310.0000220.0000250.0000490.0000220.0000190.0000220.0000200.0000210.0000320.0000800.0000230.0000670.0000590.0000230.0002190.4570140.0108490.0002470.0001260.0000840.0000220.0000210.7631860.3995430.0071560.0074360.0015840.0000470.0000860.0000210.0000790.0000210.0000200.0000190.0006410.0007240.0000380.0000390.0721140.0018750.0004170.0031860.0000760.8859781.7710640.9505020.0122050.0001750.0000780.0000730.0001500.0000230.0000191.1850011.3300020.3309270.7383600.0085260.0001141.2185810.0133653.2853860.0349712.1330530.0899170.0014350.0000370.0000290.7218430.0071660.0000900.0001920.0001290.4266710.0040500.0000610.0000210.0000190.0000190.0000630.0001200.0000650.0000190.0002030.2083840.0018420.0000370.0000620.0000200.0746110.0006300.0000240.7382130.0059250.0001820.0000200.5438250.0042910.5397690.0041501.1764310.8706600.0065160.0000670.0212030.3918720.0033210.0000430.0000190.0000190.0000190.0000200.0041200.0015050.0000300.0143520.0002170.0000240.7667080.7408040.0249570.0789490.0005960.0000230.0000190.0000190.0000190.0056840.3250920.1405220.0009310.0000250.0004701.0935310.1102580.0008200.0001040.0001010.9580740.0056220.0000520.0000190.0000190.0000190.0000190.0000190.0000190.0000190.0000190.0000190.0000190.0004130.0000210.0000190.0000190.0000190.0000190.0000190.0000190.0000660.3087360.0016940.0001180.0005760.0000250.0000220.0002880.0000210.0000200.0000200.0000190.0000250.0000200.0005810.0001080.0068590.0002100.0001000.0005870.7845250.7039210.0033760.0000350.0000200.0000750.0000200.0000490.0000190.0001790.0000210.0011520.0003540.0001381.2260680.0055120.0001020.0000230.0000200.0000190.0000200.0003130.0013700.0002650.0000480.0016020.0004100.0001130.0000250.0000220.0053522.5633231.4613112.0270200.8682930.0064390.0000460.0000730.0000190.0000710.0001050.0000200.0000190.0001090.0000610.0001950.0003020.0012230.0014720.0000760.0001950.7255560.0028221.7324960.0076690.0001050.4729600.4624311.2194060.0045370.0007200.5076701.2667790.0047860.3331140.0036480.0952790.6602600.5151160.0019330.0008820.0001380.0000630.0000190.0000680.0000610.0000830.0457840.7913690.5786680.0023070.4315520.0715580.0003550.0000920.0001760.0002880.0000200.9515400.0046960.0012170.0020250.0016280.0004111.4117920.0047183.4291270.0112320.0000941.1048111.0745310.4338660.0014451.1012360.0035660.0000690.0006620.0000670.0000580.4856481.3275650.0045790.3428701.7543680.0057690.0001590.0000620.0003780.0007070.3931880.8349441.0488561.2753270.5053830.5388770.0016230.0000940.0005120.0003440.0000210.0000200.0000200.0003490.0000210.0000200.0000190.0000220.0001410.0001920.0000780.0000730.0001170.2622630.0277190.0002070.0000850.6366210.8802150.0024951.0663410.0029770.0000730.0001080.0070490.0506951.2805682.2570620.0062941.1120951.3000184.0203180.4940730.0013460.0008580.0000240.0014240.9367491.0921350.0029011.4946570.0040720.0028750.0000260.0000810.0003810.0003900.0003890.0005280.0000200.0006360.0000200.0001340.0004430.0001690.8635350.6294390.0017350.0063980.0921300.4706400.6399850.0935690.3923530.7976470.0026760.0206140.0133760.0041050.0000930.0065034.2061240.0110030.0562150.0009760.0005720.0002050.0004320.0005720.1364210.0015590.0000220.0000210.0001810.0000700.0001230.0000192.0486350.4008840.0009540.0000210.0000190.0015300.0000220.0000190.0000200.0000190.0000190.0000190.0000190.7512341.4349220.1682380.0019530.0004160.0000200.5592480.5510580.0012510.0003360.0007000.0002560.0012340.0004772.7096912.0044990.0044280.0006440.0001790.0002520.0591700.5068740.3565450.0442511.1592650.7288630.0017220.7316030.6514130.0016330.0000220.0001130.0000190.0000650.0000190.0000190.0011230.0000830.8951691.0331800.0022611.0839390.0028490.0004520.0000190.0003730.0000200.0107570.1125610.1116960.3333330.0013640.0000720.0000190.0000190.0000210.6189190.0012651.0919860.0400270.0000990.0000200.0213340.0000610.0011030.0000290.0018870.0007220.0000260.0000300.0000261.9618761.8669030.0036580.3529190.0011510.0005180.5243420.5361390.0012990.0004330.0013680.0437830.0001910.1034310.0030700.6196080.0011940.0196770.0055800.1284070.0127400.0063830.0000910.0013970.0016660.0000640.0022010.5109210.3346270.8059330.7106571.8605611.5624881.2279713.3601200.8745400.0018150.9407142.0162171.5708950.7712661.6376010.0045390.0006860.9111540.0016570.0000221.3946141.3650650.0025040.0000240.5735220.0010380.0001510.0000200.0002120.0003150.0000200.0000190.0000230.0000190.0000210.0013390.0091240.7564240.6940820.0021152.4030411.1166610.5176410.4525100.0008380.0000200.0003831.5980620.7744420.0014460.0000650.4480460.4488590.6209590.0011550.0000210.0000200.0000190.0012100.0000200.5144750.0013270.0000210.0011600.0018210.0006530.0000220.0002970.0001270.0000260.0005963.2681713.9895130.0081350.0002820.0004140.0003000.0002770.0106090.0000380.0000260.0004710.0007130.0016600.0000720.0000200.0001850.0000210.0000750.0000200.0000190.0000960.0000690.0000230.0000640.0000240.0002390.0000330.0001700.0002361.9835800.0036870.0004954.2137193.5805992.8411870.5176860.8075031.1533610.0025250.0330820.0006630.0004550.0164240.0094990.0269820.0052630.0703180.0213901.5819770.0050960.0000260.0393240.0000780.0001761.5973981.6591550.5597740.0020790.0004420.0012030.0003310.0003460.0004350.0000210.0001480.0000580.0001460.0000210.0000210.1260640.1644490.0352110.0000730.0002320.0001680.0000200.0000190.0000690.0000190.0000190.0000370.0000200.0005070.0000200.0002130.0000190.0000190.0007450.5104960.0076760.0013170.0406230.0002780.0002992.4364494.8605915.8947930.0089580.0010950.0011260.0013130.3549110.0013960.0017370.0002640.0002650.0206680.0002840.0335090.0002620.0001090.8901750.0014220.0001351.0819630.0300371.5882590.4778051.0499190.0074900.0020870.0156980.2518152.2965740.0035200.0003580.0001480.0001910.0000760.0000190.0000810.0000200.0000770.0002000.0000750.0000190.0000200.9010831.7951773.5446321.4909584.0311463.7098340.8950710.0037830.0004460.0005890.0018120.9365001.8050760.0027260.0003810.0004050.0003340.4012800.0007350.0010480.0001180.0000200.0000180.0000180.0000660.9544681.1300931.0334020.0076760.1661520.0089521.2068567.9087583.0018910.0044280.0005180.0000230.0003010.0002210.0003570.0002150.0001520.0004220.0003910.0007700.2516250.0045730.9977270.0014151.0980043.1319401.0213550.9377201.0015042.0487110.0302321.1020390.0023270.0002070.0004640.0007090.1878430.0017620.0001200.0000620.9284853.0998400.9887453.6470415.8029783.2926560.5513160.0008470.0000830.0001800.0000840.0000190.6369540.7609490.0009430.0000190.0000644.4085570.8362190.9028910.0144350.8046441.1674941.3805631.2606771.0248890.6341300.0018960.7231370.7208690.0017730.5295410.0006470.0000200.0007580.0009720.0002120.0002650.0003430.0003280.0002250.0001890.0001800.3297920.9080500.6630000.8444580.6155430.5986400.0007750.0001630.0001840.0001880.0002680.0002750.0001490.8623400.0011330.0068840.0002580.0001330.0002010.0001350.0001100.5215750.0011180.0002050.0001210.0096770.0008250.0000200.0004130.0003860.0000680.0000270.0002430.0001170.0001750.8085520.0009280.0000590.0000230.0000210.0001580.0003200.0000210.0001260.0001360.0001310.0000200.0005630.0010100.0003821.5486280.3401850.0166670.0024620.0005480.0003350.0004890.0004600.1146360.0003650.0005690.0889010.0004610.0004660.0004552.6138373.3320792.8497471.5666670.0039400.9115660.0013620.0005340.0003660.0002800.0002940.0003470.0002350.0000190.0001130.0014200.0000720.0000190.0002140.0000190.0000190.0000190.0000200.0000200.0000640.9319340.0011560.0002060.0005490.0002040.0003290.0004860.1167790.0006700.2831733.2223962.2866660.1392250.0008950.0001530.1582710.0001840.0044400.0503230.0001300.0059360.4059260.0786750.0358780.0049560.0292320.0471850.0076440.0362990.0005290.9358911.1007533.3106810.2491010.7847140.0014260.0004110.0303110.0006080.0066260.0008190.0013950.9138600.0014200.0002300.0000240.0000190.0000190.0004810.0001510.0000200.0003140.0011440.3657160.0004281.1521720.0644921.1571980.0230860.0134910.6913031.7874241.3878700.0014980.0000930.0000190.0002470.0005270.0001420.0000181.2883751.2763381.0790350.0020751.8111370.4504261.0001480.9564232.8099680.0027661.0895480.0013990.0000270.6045000.4526530.0012820.0000240.0009990.0002430.0002591.8844361.7773822.4647121.3102001.8054830.0027290.0007000.5843530.1307201.0384744.0812241.6403760.0019621.1335950.7911430.0046050.8613010.0009920.0000720.0002400.0000310.0002020.8382580.8514010.0010540.0011110.0234380.0004440.0193750.0006090.0006020.5999140.0006521.9209392.5318411.6995710.0017970.0001601.5145910.0016711.4272830.0037630.0007580.0056950.0003650.0001810.0015450.8225060.0008250.0001570.0001610.0001820.0001160.0002290.0001510.0001820.0002590.0002210.0001280.0001970.0000210.0000960.0000200.0012640.0000210.0000220.0000200.0007410.5227500.0004940.0009420.0000200.0003300.0001030.0000200.0009690.0005810.0019460.0000220.0000200.0000190.0000210.0004510.0010910.0000190.0000920.0013120.0017360.0001730.0004230.0004360.0002980.0002540.0004412.9159647.0699280.0119680.0009430.0006270.0007410.0004010.0051000.0001410.0482040.8244750.0008291.0532220.5173991.0488840.0010282.6006191.3250950.0040080.0001990.0002630.0001180.0001590.0002170.0001581.0541360.0010240.4278270.0004530.0000200.0003610.7296340.5678550.0005160.5445380.0005740.3828570.4240671.4709740.0014020.0921470.7275050.4042830.3194071.3047211.4187731.0883860.0027620.0064460.2927950.0075220.1027750.6710140.0055221.0297980.0080630.0029117.7153084.4832080.0101810.0006430.0001640.0001680.0002490.0003810.0004510.0002730.0003220.0002220.0002110.0001940.0004250.0002720.0002690.000174

*******************************************
EVALUATING PIPELINE 
Pipeline directory: /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_b0d2ae96_2020-02-07_02-47-15hz_brz0f/
With following parameter combination: {'batch_size_seq_length': 2, 'lr': 2e-05, 'lr_type': 'cosine'}
EVALUATION OF CHECKPOINT /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_b0d2ae96_2020-02-07_02-47-15hz_brz0f/outputs/checkpoint-3
-------------------------------------------------------------
|           |   agree   | disagree  |  discuss  | unrelated |
-------------------------------------------------------------
|   agree   |    486    |    55     |    111    |     9     |
-------------------------------------------------------------
| disagree  |    20     |    60     |    55     |     9     |
-------------------------------------------------------------
|  discuss  |    247    |    45     |   1607    |    27     |
-------------------------------------------------------------
| unrelated |     9     |     2     |    27     |   6853    |
-------------------------------------------------------------
Score: 7183.0 out of 7516.5	(95.56309452537751%)
Accuracy: 0.9359800457285388
F1 overall: 0.7329471865787097
F1 per class: [0.6830639494026705, 0.39215686274509803, 0.8625872249060654, 0.9939807092610051]
*******************************************


*******************************************
EVALUATING PIPELINE 
{'batch_size_seq_length': 4, 'lr': 2e-05, 'lr_type': 'linear'}
INFO:__main__:Creating features from dataset file at /home/ubuntu/fnd_implementation/data/processed
  0%|                                                  | 0/9622 [00:00<?, ?it/s]  0%|                                        | 1/9622 [00:03<8:16:37,  3.10s/it] 21%|███████▋                             | 2001/9622 [00:03<4:35:22,  2.17s/it] 31%|███████████▌                         | 3001/9622 [00:03<2:47:28,  1.52s/it] 52%|███████████████████▏                 | 5001/9622 [00:04<1:21:49,  1.06s/it] 78%|██████████████████████████████▍        | 7501/9622 [00:04<26:17,  1.34it/s]100%|█████████████████████████████████████| 9622/9622 [00:04<00:00, 2033.99it/s]
  ******************************************* 
              Running Evaluation                
  *******************************************
 
  Length dataset evaluation: 9622
  Length dataloader evaluation: 301
  Number of epochs: 3
  Batch size: 32
  ******************************************* 
 
['/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_abc96354_2020-02-07_02-10-3373kz4_ya/outputs/checkpoint-3']
INFO:__main__:Evaluate the following checkpoints: ['/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_abc96354_2020-02-07_02-10-3373kz4_ya/outputs/checkpoint-3']
INFO:transformers.configuration_utils:loading configuration file /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_abc96354_2020-02-07_02-10-3373kz4_ya/outputs/checkpoint-3/config.json
INFO:transformers.configuration_utils:Model config {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 28996
}

INFO:transformers.modeling_utils:loading weights file /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_abc96354_2020-02-07_02-10-3373kz4_ya/outputs/checkpoint-3/pytorch_model.bin
HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=301.0, style=ProgressStyle(description_width='initial')), HTML(value='')))
0.0005740.0006870.0005540.3634580.0910980.0197050.0372290.0059850.0013920.0003900.0008050.0008690.0020380.0403360.0031570.0004600.0103190.0402420.0114950.1913800.0102130.2872890.2667100.7562730.0394630.0696020.0032360.0002810.0005680.0484410.1505530.0624140.1315760.4030520.0632080.0019050.1376640.3503740.0130650.0009560.0058540.0036680.0842550.0020580.0001390.0001620.0001050.0001470.0013740.0004960.0001130.0013340.0169660.0568880.0014220.0030910.2344290.0042050.0300540.0032410.0929200.1026660.0033670.0012850.0026410.0285410.3164280.3042710.3810300.0485340.0011740.0002680.1603550.0755410.2263470.0739400.0710100.3109780.2000820.0028250.5139160.1277070.0275590.0353710.0020600.0005100.0001370.0006530.0009750.0939900.1193181.2051280.3110030.0463040.4195520.4223270.0055310.0002950.1205090.1483070.2310450.1710330.0364760.0472090.0045530.0029850.0016060.0002150.1747200.0017050.2164630.3170860.0051210.7664610.0081610.4607160.4998660.0600580.0006880.2572200.1968790.1779101.2215300.0100840.0054270.0001710.0019930.2237750.2674140.3277930.0045750.2083530.0180130.0014830.0281270.5794770.0127950.3349330.5277760.6217500.0130210.0045260.0391370.0192300.9075650.1681030.5549980.4055890.0035300.0045920.0100970.0033401.3979880.0112320.0030940.0460190.0005380.0010920.0004130.4651701.7370190.1694620.0041560.0028050.2845810.0027750.0939420.0027020.0003840.0467280.0178090.0002230.0015320.0003890.0961820.5014592.1642110.0179920.0031790.0011120.2842060.1775341.3431480.1941570.0332810.0612300.5414652.4161450.8269730.5100870.1330430.0018260.2137460.4305431.0704050.0174730.0025030.0074290.4208961.1083570.4436420.0100590.1804063.0271691.3412480.0261640.1564850.4603110.4062660.2099280.0636770.1300350.0015240.2779890.5925340.0034020.0007990.0007230.0009160.0006130.0648730.0008590.1343180.0014270.0010240.0224900.0956310.0034350.0057220.0021330.0571070.1280890.0422050.0007090.0002310.0002240.1866400.0014431.6564220.2110170.0300670.0650940.5232060.4758280.7055090.0063890.0038030.0008540.0891860.3466140.5604401.0649110.1166870.1641960.6710520.4421130.2035090.0041540.3107900.3149500.1863571.0362890.4939350.0041150.1337170.0025390.1797990.2157200.3520030.1077000.2113720.0015630.0010670.0008020.0042700.0805320.0021710.0009040.0000960.0014330.0686330.0065591.9305720.0100150.0084320.0518320.1744780.0058820.3776970.0031710.0049860.0010000.0013060.4679020.0126540.0731920.0832380.0018150.0017600.0051390.001971

*******************************************
EVALUATING PIPELINE 
Pipeline directory: /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_abc96354_2020-02-07_02-10-3373kz4_ya/
With following parameter combination: {'batch_size_seq_length': 4, 'lr': 2e-05, 'lr_type': 'linear'}
EVALUATION OF CHECKPOINT /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_abc96354_2020-02-07_02-10-3373kz4_ya/outputs/checkpoint-3
-------------------------------------------------------------
|           |   agree   | disagree  |  discuss  | unrelated |
-------------------------------------------------------------
|   agree   |    570    |    26     |    112    |     4     |
-------------------------------------------------------------
| disagree  |     4     |    74     |    36     |     1     |
-------------------------------------------------------------
|  discuss  |    187    |    61     |   1628    |    13     |
-------------------------------------------------------------
| unrelated |     1     |     1     |    24     |   6880    |
-------------------------------------------------------------
Score: 7253.5 out of 7516.5	(96.50103106499036%)
Accuracy: 0.9511536063188526
F1 overall: 0.7967845657798168
F1 per class: [0.7734056987788331, 0.5342960288808665, 0.8826240173488751, 0.9968125181106926]
*******************************************


*******************************************
EVALUATING PIPELINE 
{'batch_size_seq_length': 3, 'lr': 2e-05, 'lr_type': 'linear'}
INFO:__main__:Creating features from dataset file at /home/ubuntu/fnd_implementation/data/processed
  0%|                                                  | 0/9622 [00:00<?, ?it/s]  0%|                                        | 1/9622 [00:03<9:08:58,  3.42s/it] 21%|███████▋                             | 2001/9622 [00:03<5:04:24,  2.40s/it] 78%|██████████████████████████████▍        | 7501/9622 [00:03<59:18,  1.68s/it]100%|█████████████████████████████████████| 9622/9622 [00:03<00:00, 2464.11it/s]
  ******************************************* 
              Running Evaluation                
  *******************************************
 
  Length dataset evaluation: 9622
  Length dataloader evaluation: 602
  Number of epochs: 3
  Batch size: 16
  ******************************************* 
 
['/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_a9451268_2020-02-07_02-05-362jt98_g1/outputs/checkpoint-3']
INFO:__main__:Evaluate the following checkpoints: ['/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_a9451268_2020-02-07_02-05-362jt98_g1/outputs/checkpoint-3']
INFO:transformers.configuration_utils:loading configuration file /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_a9451268_2020-02-07_02-05-362jt98_g1/outputs/checkpoint-3/config.json
INFO:transformers.configuration_utils:Model config {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 28996
}

INFO:transformers.modeling_utils:loading weights file /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_a9451268_2020-02-07_02-05-362jt98_g1/outputs/checkpoint-3/pytorch_model.bin
HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=602.0, style=ProgressStyle(description_width='initial')), HTML(value='')))
0.0003080.0003530.0002210.0001270.0000820.0001390.3928480.5536630.0692560.0078550.0010620.0009400.0892400.0069190.0006300.0008350.0001360.0001470.0000910.0000610.0002400.0001450.0001150.0004880.0034210.0003220.0000610.3900040.0139690.0005680.0001280.0001010.0000780.4885720.0144580.3028670.0087140.0287370.6605170.0279670.0010010.0001610.9845541.4534990.0345760.5958891.4027380.0927970.0045310.0001390.2183610.0047610.1844940.0035210.0001050.0000740.0001390.0002620.0013170.0001070.0004000.0000430.6096140.1054850.4094240.0065981.0619790.0158850.3374500.0126340.0002440.0000390.1563580.4933100.5108860.7791000.0315860.0005000.0000430.0004240.0006840.0001970.0007280.0055190.0002510.1696250.0020060.0000580.0000340.0000340.0000340.0002130.0000370.0000360.0000370.0000770.0003830.0002960.0000490.0006040.0000450.0000390.0000970.0165790.0024720.2893500.3411590.0035970.0001320.0005200.0001350.0282520.6733850.0062670.0000890.0000490.0005750.0003750.0005820.0001590.0019380.3509610.0118150.0005230.0003700.0010190.0000460.0012220.0053030.0022570.0003680.0002590.0054260.2511150.4552240.0035930.5181570.1543610.0013970.1680540.0013890.0001760.0001040.0001351.3481060.4000380.5107240.0037000.0005480.5016370.0047740.0013020.1219330.1838710.0013400.9400410.0061790.4698230.0030630.0010811.2490030.0083790.0013620.0002030.0006290.0012650.0006620.0003540.0000770.0007430.0000410.0512470.0009910.0000470.0002820.0001460.0002080.0003750.0004040.0135870.0182220.0002831.8431940.8228030.2033010.0676760.0228120.0007140.0801050.1596520.7482920.0049280.0003680.0006100.0001100.0002730.0002500.0055380.0287190.0050920.3865990.0028020.0002660.2231440.0383140.3927760.0065030.0009990.1138250.0346380.0134770.0002840.0003150.0003750.0000880.0000350.2465900.0011720.0000400.0000340.5917490.2469680.0015990.6458000.0635900.0008720.0004021.7141250.0086150.0017050.3085530.5447370.6916670.2919630.1977300.0016410.0001060.0000560.0000920.5372760.4342940.0050540.0008760.0098120.2902150.3134300.0013510.0000480.1421270.1712150.0007200.0000460.0007250.0008240.0000651.2597540.6703490.0094600.3365870.3980190.0079610.0014790.4266380.3594650.1457760.5248740.0121060.0462910.1215260.7549221.2327020.9547110.0047370.0006680.0008790.0008940.0016830.3731840.0014301.3367960.0048700.1847820.0010280.0010460.0000400.3564540.0070790.0026860.0003110.7397910.0069910.0001161.0842480.3703000.3772190.7579790.5045070.0017580.0008150.0129010.0021680.0022090.0001860.0003250.2647180.7253880.0029010.0003840.0000390.0004020.0086560.0001420.0001060.0001100.0001290.0001180.0000890.0001290.0002191.5708453.1907221.9294250.1619091.6031690.0058260.0009310.0042460.0068660.3704630.2497040.0033810.0010080.0338140.0012640.0008140.0006600.0006430.0001270.0000380.0126240.0021780.0003460.0000650.0006190.0000620.0002030.0001390.0000400.2105190.0053100.0039130.2834134.4625920.0133830.0005160.0027610.0010630.0005480.0005750.0003380.5222240.4498170.0555980.0945260.4485201.2262710.3576510.0014280.0063560.2746280.0211740.1909550.0005551.2828521.8260913.4853320.7416170.2554820.3973630.7230890.0026750.3529410.0015790.0001130.0000370.3787380.4470380.0021820.0134730.3697360.0016670.0002920.0004980.0004490.0007790.0055300.3289870.2689351.3523730.7115061.7175250.4567460.0014660.0171270.0017850.3816821.9278424.4036651.8792590.0047400.0001930.3205600.3550410.0038120.0156190.5302311.3891741.8633383.1380730.3531640.3510870.0088510.0002270.0011160.0018290.0057920.0007550.5309050.6042430.2363800.0007570.0003920.0005020.0085680.0001460.0002680.0002350.0002260.0002000.0001190.0002760.0004010.0001020.0001850.4448470.0010450.0000380.0003240.0001460.0002060.0003340.0009230.4440120.3270280.0016320.0013600.0038770.0018620.0005710.0031550.1092290.0535070.2645690.2315270.4086240.5719570.0013740.0002910.0001130.0000400.0001790.0001210.1118930.1468710.0007700.0001830.4640392.6411790.4676580.0020120.0003260.0335630.1159850.0734620.2975880.0409300.0109520.9401151.3687980.0065660.0013410.0011560.0068860.0956140.0048670.0000480.3611570.0084100.1795620.2867730.8135000.0051800.2150190.0015760.0001690.1257590.0004100.7093970.7029360.8807430.6950800.9570400.4808670.4727720.0024450.0005400.0010320.2756400.3338320.0357020.2782330.0812151.3066620.2465810.5524370.0791520.0030710.0335470.0440980.0063840.0007620.0017430.0115810.0152480.7859630.0018820.0071340.0356250.2710780.0008930.2727270.0007300.0004900.0416690.0004250.0004920.0003130.0001720.0081890.0000530.0088540.1001970.0065020.0009020.0001900.0002170.0000450.0000350.0012830.0009920.0993100.0005800.0009730.0007084.6834720.0103560.0008580.0007000.0006420.0010960.0036490.0031310.3685580.0014010.1034090.0005950.5901380.2368940.0004890.0310600.0006920.0009920.0122740.0147060.0033910.0079381.0788430.0472230.0247910.0237940.3363660.0375980.7389580.0300370.0021480.0003930.0005020.0004390.0004470.0002840.0002750.000200

*******************************************
EVALUATING PIPELINE 
Pipeline directory: /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_a9451268_2020-02-07_02-05-362jt98_g1/
With following parameter combination: {'batch_size_seq_length': 3, 'lr': 2e-05, 'lr_type': 'linear'}
EVALUATION OF CHECKPOINT /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_a9451268_2020-02-07_02-05-362jt98_g1/outputs/checkpoint-3
-------------------------------------------------------------
|           |   agree   | disagree  |  discuss  | unrelated |
-------------------------------------------------------------
|   agree   |    601    |    33     |    112    |     4     |
-------------------------------------------------------------
| disagree  |    14     |    88     |    45     |     6     |
-------------------------------------------------------------
|  discuss  |    145    |    40     |   1623    |    12     |
-------------------------------------------------------------
| unrelated |     2     |     1     |    20     |   6876    |
-------------------------------------------------------------
Score: 7265.75 out of 7516.5	(96.66400585378834%)
Accuracy: 0.9548950322178341
F1 overall: 0.8117818019931469
F1 per class: [0.794973544973545, 0.5587301587301587, 0.8966850828729281, 0.9967384213959556]
*******************************************


*******************************************
EVALUATING PIPELINE 
{'batch_size_seq_length': 2, 'lr': 2e-05, 'lr_type': 'linear'}
INFO:__main__:Creating features from dataset file at /home/ubuntu/fnd_implementation/data/processed
  0%|                                                  | 0/9622 [00:00<?, ?it/s]  0%|                                        | 1/9622 [00:02<6:54:25,  2.58s/it]  5%|█▉                                    | 501/9622 [00:02<4:35:01,  1.81s/it] 21%|███████▋                             | 2001/9622 [00:03<2:40:53,  1.27s/it] 78%|██████████████████████████████▍        | 7501/9622 [00:03<31:20,  1.13it/s]100%|█████████████████████████████████████| 9622/9622 [00:03<00:00, 2522.43it/s]
  ******************************************* 
              Running Evaluation                
  *******************************************
 
  Length dataset evaluation: 9622
  Length dataloader evaluation: 1203
  Number of epochs: 3
  Batch size: 8
  ******************************************* 
 
['/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_a6b73fda_2020-02-07_00-40-578fsejkgg/outputs/checkpoint-3']
INFO:__main__:Evaluate the following checkpoints: ['/home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_a6b73fda_2020-02-07_00-40-578fsejkgg/outputs/checkpoint-3']
INFO:transformers.configuration_utils:loading configuration file /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_a6b73fda_2020-02-07_00-40-578fsejkgg/outputs/checkpoint-3/config.json
INFO:transformers.configuration_utils:Model config {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 28996
}

INFO:transformers.modeling_utils:loading weights file /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_a6b73fda_2020-02-07_00-40-578fsejkgg/outputs/checkpoint-3/pytorch_model.bin
HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=1203.0, style=ProgressStyle(description_width='initial')), HTML(value='')))
0.0001320.0001640.0003660.0001460.0000580.0000330.0000300.0000850.0000350.0000260.0000470.0000650.9159010.0704761.0358130.0690740.0043390.0002750.0000880.0000290.0001370.0000260.0001580.0000790.0001451.0203900.0392670.0014740.0000750.0000840.0000820.0000250.0004010.0000470.8030880.0230040.0006610.0000480.0000230.0000280.0000370.0000510.0000300.0000590.0000270.0000280.0000280.0006770.0005300.0000350.0000320.0000710.0000310.0000230.0022980.0001680.0000240.0000320.0000730.0000230.0000490.0000210.0000430.0000200.0000210.0000200.0002270.0010420.0000370.0000230.0621330.0009140.0000850.0000230.0000220.0000452.0856250.9142110.0117410.0001720.0046580.0001370.0002940.0000240.0000260.3209880.8601220.6797560.4445400.0050600.0000781.1563900.0126703.4156190.0363580.0022050.0006290.0001620.0000250.0000230.2757760.0027530.0000500.0000270.0000240.0305400.0003110.0000270.0000240.0000220.0000230.0000430.0000760.0000880.0000220.2765080.6211730.0053510.0000700.0000420.0000210.1711330.0014230.0000321.1304030.0090660.0001670.0000241.2573710.0098000.4650520.0035701.7548750.9735610.0072870.0000760.2874611.0321270.0076220.0000770.0000250.0000210.0000210.0000210.0185960.0015990.0000311.0915241.0594600.0071311.1044591.0704940.0071950.0007400.0000670.0000210.0000210.0000210.0000210.0001470.0001561.1292770.0070280.0000670.0001780.0002650.0002230.0001090.0000670.0000660.0009650.0000250.0000200.0000200.0000200.0000200.0000200.0000200.0000200.0000200.0000200.0000240.0000200.0000990.0000200.0000200.0000210.0000200.0000210.0000200.0000200.0000540.0001730.0000220.0010240.0000660.0000220.0000230.0001490.0000220.0000230.0000300.0000210.0000220.0000220.0001880.0000790.3006220.0015510.0000850.0004860.6844230.7429130.0035610.0000360.0000210.0000730.0000200.0000270.0000200.0009980.0000250.0004840.0002300.0000921.1942220.0053670.0000940.0000210.0000210.0000210.0000210.0000920.0001600.0001280.0005120.0001580.0001820.0000710.0000690.0000560.0006110.0003410.0000580.1672190.0009500.0003690.0000220.0176820.0000910.0928580.0011830.0000260.0000200.0005300.0005330.0001380.0002460.0000820.0002950.0000790.0001290.0001640.0000421.0264180.0039480.0000790.9976070.9777122.1016710.0078060.0005150.9800001.0061130.0058041.0934561.1405190.0041441.0314840.9906310.0036280.0001740.0000730.0000390.0000200.0000450.0000410.0000680.3899611.4257200.8335550.0031710.6308520.0028910.0000740.0000600.0000560.0002490.0000350.9267420.0048710.0176080.0006870.0004660.0002120.3522610.0013490.2758060.0009540.0000451.0554900.8942570.0029090.0000490.9901070.0031830.0000480.0001000.2573930.0008471.4271482.6546730.0084220.0001180.0002340.0016190.0000920.0000450.0002150.0003310.0004760.0005340.0006690.0008140.0218840.0005210.0000240.0000440.0004190.0003610.0000210.0000200.0000230.0002010.0000210.0000210.0000200.0000210.0000630.0000820.0000440.0000400.0000620.0002900.0001200.0000980.0004390.0000550.5863850.0016550.0896260.0002700.0000570.0000951.7285210.2507291.0337551.2604700.0034970.1330250.0004513.5875550.0104890.0000550.0001570.0000240.0110790.6145611.4113640.0037461.8160620.0048580.0003260.0000210.0000630.0001810.0001840.0001790.0001130.0000200.0001730.0000220.0000760.0002500.0001540.0002140.0002120.0000880.0001771.0230231.0083200.9390120.0024260.0002790.0012320.0000370.0002650.0021610.0003410.0000810.0006361.5785070.0039250.0006350.0002080.0001700.0000970.0004230.0056921.0104180.1382300.0003480.0000230.0016800.0000700.0001440.0000200.0071200.0001170.0000210.0000200.0000200.0005870.0000220.0000210.0000200.0000200.0000200.0000200.0000200.0001071.9482610.4106950.0053420.0001830.0000220.8679980.9974270.0022500.0001930.0004630.0002330.0002950.0011682.9096341.8601210.0041330.0117630.0003010.0003520.8246582.6281881.7442171.5254631.8198210.8846280.0019610.7255870.8625040.3479070.0007730.5810790.0012510.0000520.0000200.0000200.0014680.0000620.9130630.8906890.0019301.1557450.0090500.0014590.0000230.0003780.0000230.6180730.6646390.4675981.7319030.0038980.0000730.0000210.0000210.0000210.5194310.0010660.0229990.0003630.0000210.0000210.0002190.0000210.0019890.0000260.0002330.0001460.0000310.0000240.0000251.7131751.1780120.0023170.0002680.0003790.0002120.8405771.2106500.0027370.0006000.0003410.1027810.0003840.0010730.0001200.8776120.0016870.0003060.0002210.0016220.0001660.0002930.0001320.0001110.0002020.0001320.0001390.0007290.0003370.0005150.0006463.3602170.5082800.0380000.9056890.0779860.0002390.1839860.3057880.6137340.3658721.6679380.0031690.0002511.0671770.0019430.0000262.0334031.9804330.0036140.0000280.9383350.0016870.0000840.0000200.0001100.0001160.0000200.0000200.0000250.0000210.0000240.0003460.0002990.0002530.0000770.0001132.0728651.3423430.9711170.0018140.0000570.0000210.0000222.4852240.9044060.0016260.0000530.8510240.9630671.0567850.0018520.0000240.0000210.0000210.0003320.0000200.0008950.0001660.0000230.0004490.4127180.0008910.0000560.0001350.0018570.0110580.0003034.0594895.1492580.0085910.0001800.0001120.0001170.0000660.0000420.0000210.0000220.0001150.0002830.0050040.0000520.0000210.0000480.0000220.0000670.0000210.0000230.0000550.0000800.0000360.0000460.0000200.0000990.0000210.0000910.0000811.4014410.0030430.0021365.3350483.7856423.7900390.4366201.0710604.2173980.0068300.0002400.0008380.0021150.0001730.0001390.0001420.0001040.0001870.0039461.1641570.0019790.0000230.9153400.0014050.0001501.3759021.0356250.0323250.0004320.0002180.0005210.0000640.1042040.0232820.0000570.0004190.0000560.0003450.0000210.0000200.0010430.0149790.0003330.0000220.0000600.0000680.0000280.0000200.0130100.0000400.0000280.0000250.0000230.0001130.0000220.0000690.0000210.0000220.0002260.0010910.0007660.0003930.0016660.0001520.0001770.0056093.3062707.5496670.0108370.0002240.0001200.0002410.0004490.0002550.0110140.0001390.0001290.0001820.0001210.0001690.0001140.0000651.0024500.0014400.0001300.9940340.0014580.0156400.0008100.0045783.8617602.0635802.0117483.1337121.3138650.0020180.0002090.0000890.0001200.0000550.0000210.0025670.0000240.0000570.0001930.0000830.0000260.0000220.8276431.7822603.1347810.3619673.1412063.6252081.2824361.5657111.0308441.1271301.3562290.7274381.8412630.0037060.0002130.0002110.0049960.6288530.0010280.0003600.0000940.0000240.0000210.0000200.0000420.6432751.0585330.9440330.0013510.4135790.7121422.5455150.0112100.0014180.0002650.0050470.0000290.0001470.0001590.0002390.0001140.0000960.0002310.0001730.0002760.0010060.0086661.0172990.0013600.9952223.0639620.8701590.9930551.0353442.2989380.4238201.3518520.0053170.0000780.0001190.0000800.0013850.0001000.0000840.0000441.0600663.0664420.9983173.8642961.8505962.8551310.2271650.0003580.0000570.0000920.0000560.0000200.4637380.7786530.0009670.0000240.0000730.2220360.0410941.0778930.0014750.0022712.6506691.8275303.0107865.9633981.4212780.0020420.0003610.0002670.0001600.0006500.0000210.0000230.0000800.0066881.3804710.0018270.0002280.0001730.0001800.0001530.0001080.8617071.5640991.3366630.8748781.6462160.0020030.0000240.0000980.0001030.0001260.0001720.0001430.0000840.0000630.0000550.0000270.0001080.0000620.0000850.0000710.0000620.0001160.0000280.0001000.0000580.0000280.0000260.0000210.0002440.0001050.0000450.0001200.0000540.0000630.0000900.0011020.0000220.0000290.0000220.0000210.0000580.0000970.0000240.0000590.0000590.0000590.0000200.0001920.0002760.0002841.2615730.1713920.9929750.0012740.0002720.0001290.0001590.0001960.0003930.0001270.0002170.0001450.0005680.0004130.0003690.0001720.0003880.2124220.0004370.2517970.0031040.0763060.0036640.0002610.0003050.0001890.0002950.0002380.0000220.0000470.0001110.0000540.0000210.0000850.0000210.0000220.0000210.0000210.0000300.0000690.6116800.0007170.0002170.0004330.0001180.0002160.0002760.0006740.0003990.5037363.9299112.4019880.9571980.0014200.0000840.0293990.0000510.0004530.0001780.0000480.0003460.0044390.0001890.0008340.0007740.0282370.0041520.0119630.0024850.0002130.9376791.0900652.7541100.0999420.0074210.0001630.0001000.0001570.0001750.0002360.0002210.6924530.0008580.0003630.0002080.0000210.0000200.0000200.0011940.0967230.0001180.0001230.0009970.0002810.0000410.0109720.0002560.0003810.0068510.0008700.0018250.3125250.0018000.0001040.0000600.0000200.0001950.0002160.0001310.0000210.4881911.0913581.6366412.7109722.0563240.7928801.0937641.0454643.1224630.0030741.1964520.0012670.0000220.0005070.0000280.0002730.0000210.0003060.0000610.0005300.3191590.0021510.0071570.0170130.0007960.0003800.0002330.3628920.5688210.3595600.0034001.2298790.0014334.0576032.4639611.0137520.0417700.0001100.0000650.0000870.0000250.0000810.0578010.0013940.0001250.0002710.0003610.5916751.4585910.9070110.7144192.6173890.0060850.0004270.9573920.0040320.0001190.0000990.5964250.0006760.3582740.0010540.0088290.2622590.0110430.0000770.0002560.1832510.0002090.0000850.0000940.0001080.0000690.0001330.0000810.0001000.0002320.0001610.0000870.0001310.0000910.0000860.0000210.0014320.0000220.0000260.0000260.0009570.0014850.0000230.0001680.0000210.0002340.0001980.0000230.0002450.0000950.0000720.0000210.0000220.0000200.0000240.0001420.0002910.0000230.0000730.0006450.0666930.0005440.0004110.0005970.0004420.0002280.0004180.0020800.0286140.0003760.0002290.0001880.0001630.0001930.0018960.0000770.0000620.0037550.0000710.0002520.0002340.0004030.0000700.9713900.0011720.5010130.0005600.0009110.0001320.0001010.0001200.0001781.0889470.0010090.0149140.0127940.0000310.1897120.0101480.0363370.0000540.0005760.0003950.0373240.0156340.0091220.0000890.0202200.0012290.0003070.0002182.2078750.8406010.6534120.0013410.0005330.0007240.0005820.0006280.0286140.0068650.1424200.0006390.0004805.6110343.6133140.0046100.0003220.0000730.0001500.0001260.0001520.0001240.0001440.0002870.0000830.0001800.0000590.0001250.0000900.0000920.000067

*******************************************
EVALUATING PIPELINE 
Pipeline directory: /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_a6b73fda_2020-02-07_00-40-578fsejkgg/
With following parameter combination: {'batch_size_seq_length': 2, 'lr': 2e-05, 'lr_type': 'linear'}
EVALUATION OF CHECKPOINT /home/ubuntu/fnd_implementation/bert/grid_search/results/pipeline_a6b73fda_2020-02-07_00-40-578fsejkgg/outputs/checkpoint-3
-------------------------------------------------------------
|           |   agree   | disagree  |  discuss  | unrelated |
-------------------------------------------------------------
|   agree   |    600    |    20     |    123    |     4     |
-------------------------------------------------------------
| disagree  |    22     |    98     |    61     |     1     |
-------------------------------------------------------------
|  discuss  |    137    |    42     |   1600    |    12     |
-------------------------------------------------------------
| unrelated |     3     |     2     |    16     |   6881    |
-------------------------------------------------------------
Score: 7260.0 out of 7516.5	(96.58750748353621%)
Accuracy: 0.9539596757430887
F1 overall: 0.8133397818732602
F1 per class: [0.7952286282306164, 0.5697674418604651, 0.8911166805903648, 0.9972463768115942]
*******************************************


real	19m8.798s
user	22m49.430s
sys	7m0.877s
ubuntu@run-gpu-mg:~/fnd_implementation$ 
ubuntu@run-gpu-mg:~/fnd_implementation$ exit
exit

Script done on 2020-02-07 06:47:27+0000
