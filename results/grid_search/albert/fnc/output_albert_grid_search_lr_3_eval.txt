Script started on 2020-02-04 08:11:32+0000
ubuntu@run-gpu-mg:~/fnd_implementation$ exitscript output_albert_grid_search_lr_3_evaal.txtM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Ctime python3 eval_separate.py --model=albert --model_type=albert-base-v1
/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/home/ubuntu/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/ubuntu/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/ubuntu/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/ubuntu/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/ubuntu/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/ubuntu/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
There are 2 GPU(s) available.
The following GPU is used:  Tesla V100-PCIE-16GB
INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/albert-base-config.json from cache at /home/ubuntu/.cache/torch/transformers/8eff152e0e6c9b5bca31d5ed10ab2b543d201465c907d1e7d6a8cedb28ec3a7f.422e3ad6212153abef6df151efafdff1939214d0acdbc8c8011e538a0c2a8e99
INFO:transformers.configuration_utils:Model config {
  "architectures": [
    "AlbertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "down_scale_factor": 1,
  "embedding_size": 128,
  "finetuning_task": "multi",
  "gap_size": 0,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "inner_group_num": 1,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "net_structure_type": 0,
  "num_attention_heads": 12,
  "num_hidden_groups": 1,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "num_memory_blocks": 0,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 30000
}

INFO:transformers.tokenization_utils:loading file https://s3.amazonaws.com/models.huggingface.co/bert/albert-base-spiece.model from cache at /home/ubuntu/.cache/torch/transformers/e941f532bbbf6d6b7c96efbde9c15d38fc236e7fb120158bfc766814e6170529.c81d4deb77aec08ce575b7a39a989a79dd54f321bfb82c2b54dd35f52f8182cf
INFO:transformers.configuration_utils:loading configuration file /home/ubuntu/fnd_implementation/albert/model_pretrained/config.json
INFO:transformers.configuration_utils:Model config {
  "architectures": [
    "AlbertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "down_scale_factor": 1,
  "embedding_size": 128,
  "finetuning_task": null,
  "gap_size": 0,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "inner_group_num": 1,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "net_structure_type": 0,
  "num_attention_heads": 12,
  "num_hidden_groups": 1,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "num_memory_blocks": 0,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 30000
}

INFO:transformers.modeling_utils:loading weights file /home/ubuntu/fnd_implementation/albert/model_pretrained/pytorch_model.bin
INFO:__main__:Loading initialized pretrained model from /home/ubuntu/fnd_implementation/albert/model_pretrained
  ******************************************* 
           Freezing Embedding Layers          
  *******************************************
 
name:  albert.embeddings.word_embeddings.weight
param.requires_grad:  False
=====
name:  albert.embeddings.position_embeddings.weight
param.requires_grad:  False
=====
name:  albert.embeddings.token_type_embeddings.weight
param.requires_grad:  False
=====
name:  albert.embeddings.LayerNorm.weight
param.requires_grad:  False
=====
name:  albert.embeddings.LayerNorm.bias
param.requires_grad:  False
=====
name:  albert.encoder.embedding_hidden_mapping_in.weight
param.requires_grad:  True
=====
name:  albert.encoder.embedding_hidden_mapping_in.bias
param.requires_grad:  True
=====
name:  albert.encoder.albert_layer_groups.0.albert_layers.0.full_layer_layer_norm.weight
param.requires_grad:  True
=====
name:  albert.encoder.albert_layer_groups.0.albert_layers.0.full_layer_layer_norm.bias
param.requires_grad:  True
=====
name:  albert.encoder.albert_layer_groups.0.albert_layers.0.attention.query.weight
param.requires_grad:  True
=====
name:  albert.encoder.albert_layer_groups.0.albert_layers.0.attention.query.bias
param.requires_grad:  True
=====
name:  albert.encoder.albert_layer_groups.0.albert_layers.0.attention.key.weight
param.requires_grad:  True
=====
name:  albert.encoder.albert_layer_groups.0.albert_layers.0.attention.key.bias
param.requires_grad:  True
=====
name:  albert.encoder.albert_layer_groups.0.albert_layers.0.attention.value.weight
param.requires_grad:  True
=====
name:  albert.encoder.albert_layer_groups.0.albert_layers.0.attention.value.bias
param.requires_grad:  True
=====
name:  albert.encoder.albert_layer_groups.0.albert_layers.0.attention.dense.weight
param.requires_grad:  True
=====
name:  albert.encoder.albert_layer_groups.0.albert_layers.0.attention.dense.bias
param.requires_grad:  True
=====
name:  albert.encoder.albert_layer_groups.0.albert_layers.0.attention.LayerNorm.weight
param.requires_grad:  True
=====
name:  albert.encoder.albert_layer_groups.0.albert_layers.0.attention.LayerNorm.bias
param.requires_grad:  True
=====
name:  albert.encoder.albert_layer_groups.0.albert_layers.0.ffn.weight
param.requires_grad:  True
=====
name:  albert.encoder.albert_layer_groups.0.albert_layers.0.ffn.bias
param.requires_grad:  True
=====
name:  albert.encoder.albert_layer_groups.0.albert_layers.0.ffn_output.weight
param.requires_grad:  True
=====
name:  albert.encoder.albert_layer_groups.0.albert_layers.0.ffn_output.bias
param.requires_grad:  True
=====
name:  albert.pooler.weight
param.requires_grad:  True
=====
name:  albert.pooler.bias
param.requires_grad:  True
=====
name:  classifier.weight
param.requires_grad:  True
=====
name:  classifier.bias
param.requires_grad:  True
=====

*******************************************
Evaluating the following pipelines 
['/home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_e414339b_2020-02-04_00-39-57bqxgns1a/', '/home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_e414339c_2020-02-04_01-12-04_li9xclj/', '/home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_e226a48d_2020-02-03_21-19-449ib9mz7e/', '/home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_e55e89d0_2020-02-04_02-33-27n9o2fq27/', '/home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_e414339d_2020-02-04_01-14-41iyih8w6c/', '/home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_e2d857c2_2020-02-03_22-38-31tt6w1cdx/', '/home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_e226a48c_2020-02-03_21-19-44qituzjrx/', '/home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_e55e89d1_2020-02-04_02-36-598m93g___/', '/home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_e2d857c3_2020-02-03_22-44-43ujdinn7p/', '/home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_e414339a_2020-02-04_00-36-37pk2qy95d/', '/home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_e2d857c5_2020-02-03_23-18-49ygk4jv45/', '/home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_e2d857c4_2020-02-03_23-14-31z6_1xrv8/']

*******************************************

*******************************************
EVALUATING PIPELINE 
{'batch_size_seq_length': 4, 'lr': 3e-05, 'lr_type': 'linear'}
INFO:__main__:Creating features from dataset file at /home/ubuntu/fnd_implementation/data/processed
  0%|                                                  | 0/9622 [00:00<?, ?it/s]  0%|                                        | 1/9622 [00:01<2:45:24,  1.03s/it] 21%|███████▋                             | 2001/9622 [00:01<1:31:43,  1.38it/s]100%|█████████████████████████████████████| 9622/9622 [00:01<00:00, 5953.79it/s]
  ******************************************* 
              Running Evaluation                
  *******************************************
 
  Length dataset evaluation: 9622
  Length dataloader evaluation: 301
  Number of epochs: 3
  Batch size: 32
  ******************************************* 
 
['/home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_e414339b_2020-02-04_00-39-57bqxgns1a/outputs/checkpoint-3']
INFO:__main__:Evaluate the following checkpoints: ['/home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_e414339b_2020-02-04_00-39-57bqxgns1a/outputs/checkpoint-3']
INFO:transformers.configuration_utils:loading configuration file /home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_e414339b_2020-02-04_00-39-57bqxgns1a/outputs/checkpoint-3/config.json
INFO:transformers.configuration_utils:Model config {
  "architectures": [
    "AlbertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "down_scale_factor": 1,
  "embedding_size": 128,
  "finetuning_task": null,
  "gap_size": 0,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "inner_group_num": 1,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "net_structure_type": 0,
  "num_attention_heads": 12,
  "num_hidden_groups": 1,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "num_memory_blocks": 0,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 30000
}

INFO:transformers.modeling_utils:loading weights file /home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_e414339b_2020-02-04_00-39-57bqxgns1a/outputs/checkpoint-3/pytorch_model.bin
eval_separate.py:214: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0
Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`
  for batch in tqdm_notebook(eval_dataloader, desc="Evaluating"):
HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=301.0, style=ProgressStyle(description_width='initial')), HTML(value='')))
0.0006910.0009150.0270020.4116130.3067530.0915370.1329700.0423300.0064950.0010470.1418840.0196540.0102640.2082470.2146380.0145720.1624580.0172380.0574240.2508580.2340561.1922650.3101441.1950750.0890160.0151840.0377740.0017830.0043030.0100540.0038380.2594120.0809690.5430890.4481550.0129700.3852790.2784510.0506320.0018530.0143280.1803150.1659660.0040940.0003010.0006510.0005530.0002400.0507130.0038790.0003620.0116690.2208170.1165570.0024280.3417210.2608690.0054960.1070980.0418560.6397240.2375210.0042100.0005550.0112730.0028230.1046750.1830650.4433080.3986120.0297540.0008390.6604910.2021960.2822320.0402960.6554980.3190550.1714090.0118580.1659130.1418400.0035260.0314250.0085240.0267300.0183590.0261950.0052490.1582030.1074971.6511710.4572810.4266810.5956250.2667600.0035750.0010460.0401090.0432010.3764150.1907831.1996290.0181480.0523260.1588630.0030870.0014010.0514590.0006880.2532090.1969970.1746530.6613610.0190620.7548100.3607750.0068300.0008810.1528210.1637780.2052560.8084370.0067820.0680680.0010770.0031960.1953460.3112760.0966020.0380050.2439550.1481780.0162940.2657220.9904520.1623680.2267190.3446680.6013990.1685930.0036190.0009210.2177880.5208760.1227020.4443510.3862540.0093700.0839680.0459910.0738651.5398610.0134810.0020070.0448760.0008300.0250360.0008461.1224892.4146390.2805430.0441240.0329000.8602430.1369320.0850050.2229300.6363880.6960720.1560990.0466710.0605390.0053880.2235350.1797081.8227430.0757900.0711680.0968460.9226302.5114180.5432200.2244540.1784150.0872120.5009992.2296091.8874770.5347740.0650220.0837260.1619080.3841800.0727090.3464660.3209040.2532010.3876510.8823900.7587390.2558150.1621971.2177820.2874840.1156830.1154111.8269751.1332751.0926120.2206510.0103220.0017020.5282590.6501580.0191760.0008810.0027820.0113840.0005860.0035370.0278390.1264990.0015880.0007850.6781770.1191990.0269100.2914890.2172910.5394720.0916820.0051660.0007830.0010330.0004580.3822070.0027500.8741040.1218160.0547310.5675540.3139610.4980371.0421860.0668880.0556180.0041110.0136030.0404070.0169950.2970190.1950750.3853660.9396991.0477880.6644250.0356890.5074790.3753460.2580872.1451270.6375920.1143820.8686050.4741240.3230000.3069390.5830760.0613350.1213580.1573800.0021610.0283690.0132830.0053590.0775290.2098540.0013200.0465950.1998300.5091141.4879100.4414300.3479140.4415791.1749250.2629890.2456390.0234660.0019330.0039070.0038010.7721350.3017710.4800721.6033140.0539310.0229530.0038840.149947

*******************************************
EVALUATING PIPELINE 
Pipeline directory: /home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_e414339b_2020-02-04_00-39-57bqxgns1a/
With following parameter combination: {'batch_size_seq_length': 4, 'lr': 3e-05, 'lr_type': 'linear'}
EVALUATION OF CHECKPOINT /home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_e414339b_2020-02-04_00-39-57bqxgns1a/outputs/checkpoint-3
-------------------------------------------------------------
|           |   agree   | disagree  |  discuss  | unrelated |
-------------------------------------------------------------
|   agree   |    507    |    61     |    160    |    26     |
-------------------------------------------------------------
| disagree  |    16     |    35     |    29     |     2     |
-------------------------------------------------------------
|  discuss  |    212    |    56     |   1561    |    61     |
-------------------------------------------------------------
| unrelated |    27     |    10     |    50     |   6809    |
-------------------------------------------------------------
Score: 7089.75 out of 7516.5	(94.32249052085412%)
Accuracy: 0.9262107669923093
F1 overall: 0.6972654928271349
F1 per class: [0.6688654353562006, 0.28688524590163933, 0.846070460704607, 0.9872408293460925]
*******************************************


*******************************************
EVALUATING PIPELINE 
{'batch_size_seq_length': 1, 'lr': 3e-05, 'lr_type': 'cosine'}
INFO:__main__:Creating features from dataset file at /home/ubuntu/fnd_implementation/data/processed
  0%|                                                  | 0/9622 [00:00<?, ?it/s]  0%|                                        | 1/9622 [00:01<3:08:54,  1.18s/it] 21%|███████▋                             | 2001/9622 [00:01<1:44:45,  1.21it/s] 78%|██████████████████████████████▍        | 7501/9622 [00:01<20:24,  1.73it/s]100%|█████████████████████████████████████| 9622/9622 [00:01<00:00, 5255.68it/s]
  ******************************************* 
              Running Evaluation                
  *******************************************
 
  Length dataset evaluation: 9622
  Length dataloader evaluation: 2406
  Number of epochs: 3
  Batch size: 4
  ******************************************* 
 
['/home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_e414339c_2020-02-04_01-12-04_li9xclj/outputs/checkpoint-3']
INFO:__main__:Evaluate the following checkpoints: ['/home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_e414339c_2020-02-04_01-12-04_li9xclj/outputs/checkpoint-3']
INFO:transformers.configuration_utils:loading configuration file /home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_e414339c_2020-02-04_01-12-04_li9xclj/outputs/checkpoint-3/config.json
INFO:transformers.configuration_utils:Model config {
  "architectures": [
    "AlbertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "down_scale_factor": 1,
  "embedding_size": 128,
  "finetuning_task": null,
  "gap_size": 0,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "inner_group_num": 1,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "net_structure_type": 0,
  "num_attention_heads": 12,
  "num_hidden_groups": 1,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "num_memory_blocks": 0,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 30000
}

INFO:transformers.modeling_utils:loading weights file /home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_e414339c_2020-02-04_01-12-04_li9xclj/outputs/checkpoint-3/pytorch_model.bin
HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=2406.0, style=ProgressStyle(description_width='initial')), HTML(value='')))
0.0010640.0011870.0006180.0002990.0001050.0000570.0000340.0000270.0000540.0000770.0000280.0001040.0000290.0001030.0000450.0000270.0000290.0000250.0000250.0002470.0001750.0000500.4488790.0195390.0012041.6352470.0629140.0023501.9065730.0658910.0022190.0000920.0002400.0000630.0000320.0000220.0003090.0000290.0000430.0002330.0007671.7531900.0417610.0009900.0062090.0001570.0006500.0000370.0146550.0003202.1824170.0445260.0008770.0000410.0000220.0000210.0000310.0063640.0005680.0000530.0027020.0000880.0000740.0000380.0000290.0002271.7016640.0254500.0019860.0002920.0011550.0014290.0001070.0001210.0000490.0000400.0000290.0000490.0004090.0001100.1592610.0093300.0009830.0000410.0000710.0002700.0002060.0002860.0000560.0001200.0001170.0000290.0001440.0000490.0007080.0000260.0019190.0012140.0000590.0002600.0000740.0000740.0001090.0007240.0001480.0000500.0001370.0000231.4675440.0137110.0001480.0000330.0000240.0000210.0000240.0005750.0000260.0706050.0006190.0000310.0000190.0002670.0000210.0000190.0000180.0002910.0000230.0000190.0000190.0000190.0000190.0000180.0003870.0014462.2400470.0228710.0001902.1759680.0158500.0001861.5266600.0109850.0002520.0093440.0006060.0000920.0000220.0000270.0043320.0001280.0400570.0002861.8814501.8854711.3124650.0085310.0002700.0005030.0001970.0000340.0001220.0004080.0004830.0001860.0006830.0007930.0000870.0000400.0000210.0002670.0004571.6773611.1629320.5778590.0035321.2108480.0071920.0002690.0006950.0000310.0000820.0001382.3615850.0129320.0006710.0000424.3183742.2292710.0118970.0001390.9435240.0190310.0029870.1647541.1890020.0067600.0011550.0000480.0010630.0038580.0020200.0021620.0092470.0737920.0005990.0002240.0003231.4550370.0073761.8410280.0090010.0647630.0004390.0004021.7960100.0085960.0009880.0003230.0004130.0000280.0011200.0001110.0001350.0000220.0002610.0000240.0000620.0003730.0000280.0000390.0002790.0001381.6952220.0072952.1650910.0092330.0001660.0000200.0000200.0001640.0000240.0000210.0000220.0002430.0000210.0000190.0000210.0000210.0000211.7151480.0068830.0000550.0034160.0034150.0000540.0000330.1722271.9060050.0074130.0003460.0002140.0000370.0000180.0000281.2675590.8378861.4623350.0054950.0000410.0000180.0000190.0000180.0000180.0135510.0006961.8566560.0075630.0000780.0012480.0000240.0000220.0000210.0000270.0017510.0000340.0000290.0000540.0000200.0000221.8691630.0065301.7605710.0060830.0000420.0000211.6208041.3550390.0045830.0000360.0000200.0000191.5231561.5645140.0051830.0000370.5299320.0250530.0001320.0000250.0001780.0000240.0000260.0000350.0000270.0000340.0000230.0000210.0000300.0010330.0000660.3602680.0038960.0000392.0796720.0064390.0001810.0000200.0000210.0001300.0012632.0088020.0061940.0000411.5074060.0048440.0003560.0001860.0002080.0000300.0003100.0001891.8430460.0054080.0026290.0000270.0000190.0000260.0000200.0000210.0000400.0000190.0000350.0000220.0001690.0000190.0000200.0000220.0000200.0000220.0000790.0000250.0000190.0000190.0000190.0000190.0000190.0001850.0001270.0000230.0000210.0000190.0000210.0000230.0000470.0000190.0000190.0000230.0000190.0000200.0000200.0000270.0000230.0001290.0000200.0000750.0023530.0001050.0021720.0010950.0022240.0002490.0480400.0001520.0018940.0047480.0003710.0054910.0000760.0000320.0000400.0000840.0000260.0001180.0000580.0000520.0000200.0000890.0000550.0009200.0113360.0002840.0000210.0025380.0000420.2367090.0006570.0000231.3248591.5053410.0036121.5034380.3648730.0009931.5437741.6613230.0039280.0007590.0000210.0000190.0000190.0000310.0000200.0000180.0002600.0000310.0000210.0020060.0000240.0000230.0000180.0000200.0011670.0000260.0000221.4456174.0735800.0098000.0002530.0002000.0001512.0355220.0046900.0002010.0000460.0154240.0001890.0000250.0000240.0000340.0000400.0000380.0000730.0000710.0003020.0004690.0005540.0000390.0092200.0006340.0000330.0011781.0429560.0022820.0823860.0015060.0000830.0932080.0006880.0001160.0000270.0000221.9073370.0042301.3339390.0066231.4965570.0149661.5559960.0367890.0068020.0698010.0040340.0007180.0051620.0000350.0000200.0001270.0000220.0000220.0000210.0000210.0001360.0002400.0000220.0000200.0000210.0000200.0000210.0002520.0000210.0000210.0001310.0002670.0003220.0063520.0000320.0000200.0007540.0003370.0006680.0000390.0012810.0008170.0000250.0000271.3583340.0026030.0004730.3039020.0005930.0006130.0000480.0009560.0002550.0015931.9032610.0046800.8498250.2788751.3093620.0024850.6370380.0023900.0007670.0000590.9372550.9431351.8718421.9182660.0036570.0002260.0000800.0000200.0001790.0001990.0004131.8310950.0036090.0003780.0000300.0000210.0001700.0000200.0002040.0001390.0001440.0001340.0000210.0000210.0000200.0000300.0001840.0001270.0000210.0001380.0000541.0619890.0018641.0762941.2970360.0022591.4174440.0025070.0000261.0972450.0019040.4991780.0010640.0025060.0008690.0004250.0000370.0005880.0001410.0004960.0012800.0001280.0004850.0006562.0376980.0062960.0022061.2590120.0050720.0061520.0018890.0010690.2836170.0015180.0007170.0001892.6320810.0068880.0005190.0753361.3737340.0023540.0003130.0000250.0001741.7164690.0029710.0000241.5037260.0026870.0000230.0001240.0000191.0640680.0017110.0002290.0000200.0000190.0001970.0000180.0005060.0000190.0006230.0003620.0000190.0015621.4871250.0128550.0014720.0005110.0005150.0008330.0000261.5961060.0026550.0004590.0004270.0000260.0004801.9046360.0029540.0004600.0004460.0005140.0005420.0003240.0002670.0003200.0010900.0007610.0000250.0059750.0000350.0011230.0000260.0005750.0001260.0000210.0000210.0000260.0001480.8249890.0023870.0022290.0006030.0000280.0000210.0000340.0000210.0000220.0000690.0000230.0009300.0000270.0000220.0000990.0000220.0000240.0000240.0000340.0000320.0014110.0000260.1307050.0007730.0000450.0001600.0000240.0001510.0002080.0001330.0000740.0003440.0005900.0002280.0003030.0005480.0003971.4572460.0020680.0057830.0000301.8730050.0026450.0000431.7319761.1669330.0016370.0000330.0001670.0000200.0002190.0002303.6284312.5680492.5267090.0044560.0008500.0008243.8421400.0054370.0000530.0013200.0003480.6469682.2050500.0033210.2930992.7354360.0039540.5205860.0007260.0000240.0000340.0058320.0000290.0000252.2161020.1874240.8576800.0011971.7848280.0024690.0005400.0000262.5076850.0033270.0000490.0000460.0001190.0033520.0000280.0000230.0001810.0000240.0005270.0005450.0005800.0005480.0005320.0005590.0006240.0001610.0000190.0000180.0013540.0000210.0000240.0000180.0000240.0002500.0001340.0009200.0002640.0006300.0005290.0006940.0000260.0011370.0003340.0004330.0006350.0001690.0003761.3526240.0043782.6770981.9653350.0027090.0000271.3824551.3387080.0017300.0000881.5097830.0019900.0002461.3702290.0025480.0000590.8058670.0011500.0202290.0349730.0000710.0002460.0998601.3653401.6803330.0020601.6967450.0021510.0016160.0000240.0020060.0013640.0001430.0002960.0002630.5332390.0019100.0006460.0000230.1103881.4277570.0017230.0005910.0000790.0000260.0000210.0005350.0017710.0001300.0000210.0001450.0003930.0000230.0000210.0000212.3641490.0036790.0013200.0000230.0000210.0000200.0000210.0000210.0000210.0000310.1062930.0001430.0000250.0000340.0000230.0000200.0000210.0000210.0000190.0000200.0000200.0000200.0000220.0000200.0000200.0004880.0000250.0054100.0485730.1836400.0053550.0000250.8697160.9135340.0014980.0005040.0003830.0000480.0000581.6653551.5705920.0018630.0003790.0000572.2766130.0034910.0019420.0013810.0014300.0003020.0003840.0046480.0000280.0014020.0653772.1614203.2287790.0059420.0000380.0000331.1345160.0028100.4064980.0012211.2054410.0021360.0028760.0006850.0030040.0049991.3464400.0022740.0022631.1214120.2639800.0026110.1098630.0006060.0000200.0004620.0022050.0043360.0007120.2041490.0005920.0152890.0000380.0000580.9975590.0010780.0000250.0000180.0000180.0005300.0000200.0000180.0000190.0000190.0000180.0000250.0001850.0000251.9085690.0020160.0000212.0488530.0024840.0002891.6782760.0017700.0000211.6198460.0017530.4029020.0004480.0000200.0000190.6230820.0006610.0000230.0004632.4194232.8462052.7993161.1641864.0226053.2037124.6563940.0256771.7875930.0020760.0000210.0000230.0000230.0000260.0000330.0000500.0000200.0000350.0017090.0000220.0000550.0015120.0007350.0000200.0011960.0013030.0000220.0004770.0000191.6689130.0020620.0006340.0000290.0007010.0010210.0001130.0000510.0008990.0014350.0007230.0008730.3762470.0003911.7566150.0017480.0018280.2639820.0005863.6213752.1055340.0024550.0000250.0000780.0000200.0002280.0005150.0005090.0005420.0014560.0001600.0651720.0740551.7044330.0019100.0006050.0006810.0006120.0000210.0004250.0004101.7983100.0017610.0019190.0000241.2728630.3541450.0003560.1356170.0426780.0000630.0000200.0000200.0327020.0000520.0248380.0010681.1782600.7677650.0007440.0000370.0028990.0006540.0000240.0015080.0000210.0000250.0016890.0008900.0000240.0009960.0000201.7074340.3025470.0003252.8213081.8048582.0828372.5332890.9491963.0743381.6095261.6489520.0019740.0000220.0020741.2875050.9186841.5605820.0045250.0002230.0004630.0006600.0147481.3878870.0018211.0553571.4161610.0032660.0161662.1092490.0020300.0000250.0006430.0009100.0008631.6981830.0029590.0000250.0000210.0000240.0000311.6439821.5709753.4545740.0033280.0000440.0003180.0000230.0000551.4891650.0013470.0000290.0000230.0000200.0009260.0000240.0000220.0235050.0000410.0006030.0006140.0000210.0001040.0000210.0000220.0000200.0233590.0000430.0000220.0000210.0003320.0015020.0040240.0044490.6915980.0011850.6812763.3997020.0036620.0011130.9458073.4959071.7907583.2640580.0033530.0003591.7081711.4871650.0015230.0001980.0000460.0740740.0001000.0000350.0000560.0000203.4912020.0030072.2532220.0023340.0003980.0010790.0000241.4103020.0021280.8738940.0012291.1873560.0010290.0006910.0001820.0004130.0000250.0003430.0000190.0000200.0000410.0028590.0000220.0000200.0000230.0000231.5358520.0013010.0006820.0000240.0000310.0000300.0058980.0028760.3918500.7155170.0006180.0000230.0000220.0000200.0004590.0007670.0000340.0000250.0000610.0015490.0011150.0000192.4043093.2480091.4575180.0015520.0004100.0003361.0878560.0025470.0014210.0001250.0036090.0009480.0000720.0003760.0000300.0000480.0000240.0000500.0001940.0018700.0000380.0000400.0016330.0097700.0019390.0003710.0000210.0007270.0000380.0005890.0002190.0000370.0000300.0002220.0012260.0001260.0002200.0000490.0000560.0005100.0014680.0000350.0026490.0001100.0003140.0003240.0000590.0001250.0000230.0000440.0008950.0000280.0000500.0005450.0000210.0007670.0000260.0015933.9031841.9742832.5559531.3517931.4189012.1039592.4921030.9039721.1491640.5553162.4815920.0030610.0089270.0014522.8495220.0049480.0019760.0006660.0009540.0008410.0010250.0008370.0004250.0250790.7872700.0029470.0001460.0008400.0003090.0015540.0011990.0004750.0014870.0014660.0158222.3436931.2520766.0165531.5344160.0045240.0000220.0000180.0000190.0000180.0001340.0000190.0000210.0002490.0004040.0000201.3350670.9649740.0020780.0089090.0051780.0023250.0044580.0013280.0000210.0027650.0011920.0012470.0000420.0010430.0187210.0000570.2767400.0005230.0076170.0049020.0001330.0000200.0021500.0045770.0000460.0000440.0001240.0002540.0000205.1945624.4321485.2408916.8609183.7055160.0027690.0001060.0000310.0950200.0025960.0000850.0010770.0001610.0001050.0000470.0000440.0000840.0001050.0000510.3161310.0013192.1667940.0016060.0016340.0001220.0000600.0005280.0006760.0000350.0001630.0000770.0007430.0000820.0000581.0541350.0008040.0020750.0003310.3579080.0021650.0045880.0030700.0014730.0010731.7120120.0014920.0001440.0004690.0005030.0001351.6395440.0043150.0026102.6895492.4447802.9554370.0027270.0015080.0005730.0011760.0000240.0010580.0000280.0013570.0001170.6088710.0042220.0000250.0073610.0004580.0005730.0003490.0003260.0002321.6484040.0014810.0003830.0011580.0003320.0003370.0001290.0003270.0018320.0007360.1421560.6489000.0006600.0004420.7288132.2633491.8265960.0017180.0002790.0009660.1293170.0006570.0006990.0020681.3134590.0009341.2659751.0181880.0047040.0090290.7185060.0044080.0013740.0017075.0261030.0041330.0010290.0005360.0006520.0005170.0003830.0001280.0001981.1180090.0809750.0022410.0000680.0001300.0004610.0015380.0002200.0000620.0004040.0000310.0007532.0397350.0025940.0017040.0000250.0003710.0000580.0001031.1997310.0013990.0005902.8460403.3539883.0614311.4055501.3543531.6726322.7747592.4343692.9043151.5169290.1040470.7126350.0022410.0006400.0135240.0565470.0006010.0032020.1782130.0008211.9326094.1111090.0030570.0004740.0009910.0005460.0004230.0007940.0004800.0002850.0004410.0008230.0012790.0002090.0003400.0000190.0033460.0002520.0000220.0000330.0000310.0000240.0000220.0000210.0000210.0000360.0002901.8212410.0012042.2164140.0014571.8517430.0012210.0001640.0240590.2500370.0062270.6653800.0007941.2835752.4168874.8248012.0192910.0577870.0005230.0000380.0166130.0039230.0214840.0007530.0002050.0014510.5518080.0007801.6939190.0013822.4048560.0018640.4229700.0005920.0002660.0004961.7994820.0014930.0070100.0072280.0007710.8978792.0828811.5222670.0033470.0001542.0847760.0015760.0001572.2466700.0016662.3107373.9739590.0032162.0462072.0043510.0013841.9675370.0013865.4724510.0039580.0002600.3004050.0009610.0008560.0006420.0001820.0003170.0000210.0003480.0003860.0008780.0000211.2423220.0014960.0007790.0000240.0001860.0001740.0001690.0000251.9766560.0012423.7177792.0635790.0041001.9883581.8148367.5286916.1647918.0168696.4570376.1374970.0040920.0003050.0001480.0018860.0002640.0000240.0002340.0000490.0001370.0000270.0000230.0000311.8114770.0011270.0005141.8000380.0011290.0000220.0000280.0000430.0000190.0034010.6606480.3154620.0218771.2761211.5951350.0009891.5863050.0009780.0000253.6780331.0583944.0910892.9367791.5659333.2694511.5548914.5628494.3994102.9705220.0017950.0000310.5630411.5277960.0009311.4483610.0009290.0000260.0016041.3385830.0008270.0000260.0000250.0000350.0000620.0000540.0008080.0009000.0004930.0004000.0003500.0006530.0004730.0001400.0007040.0009540.0002380.0002430.0004760.0000290.0006840.0001400.0003980.8570753.8464542.6656501.2701691.5547220.9841130.6025082.3818980.1086411.6498250.0024990.0000440.0000250.0000200.0003900.3278900.0004480.0002440.0003300.0003050.0006780.0004310.0002750.0003950.0001220.0002610.0001320.0001470.0000220.0001450.0000860.0000270.0002480.0002520.0001590.0002540.0002430.0001340.0001460.0001540.0000190.0002400.0001371.4527240.0008530.0000630.0002380.0002550.0000230.0002460.0000630.0000220.0000210.0000390.0000250.0000640.0005000.0002000.0000220.0005010.0000220.0001350.0003230.0000240.0001510.0000340.0000200.0002460.3585170.0006430.0001390.7672420.0004590.0000200.0005940.0000290.0000530.0000190.0000280.0000200.0008730.0000200.0023550.0000200.0000200.0000250.0000200.0005690.0005980.0000220.0005080.0000220.0000270.0000200.0011791.0213570.0017960.0063880.0023040.0010920.0009730.0023540.1863390.0074601.3078661.5869990.0018310.0013530.0006110.0015310.0005280.0007450.0018310.0006430.0012940.0006100.0011971.8554400.0021770.0000430.0009330.0010190.0009091.0467270.0015290.0004110.0008070.0008700.0010930.0008840.7001711.7186500.0367531.8688431.0191610.8887210.1482100.2599270.0044600.1616411.9534450.8101880.0006920.0045221.3884460.0013900.0010090.0022870.0117550.0009290.0013540.0003490.3894530.0007970.3890760.0005130.0000210.0000190.0000180.0002680.0002520.0004790.0002670.0000200.0000180.0000180.0000970.0004280.0000220.0000180.0000200.0000210.0000440.0000190.0000230.0000180.0000200.0000190.0002550.0000223.9963350.0021370.0000280.0001760.0002390.0003900.0004000.0003290.0003210.0001380.0004570.0003710.0001690.0002520.0000220.0000220.0006730.0006340.0046850.0017052.8020323.1526441.3317453.9344620.4468170.0021780.0003560.0001260.0001390.8136540.0004430.0007840.0000210.0000200.0000180.8992860.0512080.0000511.8219860.0010970.5621392.7672611.1295880.2816960.0001712.6538780.0045492.1706580.0039360.0079860.0019130.0051850.0066660.0067370.0036100.1409500.0000940.6246570.0007890.0005360.0003511.9567252.0118610.0017193.8864253.5262220.0212500.0210750.0102112.3353580.0027790.0010880.0002560.0013310.0014870.0004630.0011090.0006870.0012870.0034100.0159360.0057320.0072970.0004740.2391970.0009370.0005110.0007810.0000240.0022670.0000210.0000210.0000200.0000220.0000190.0000190.0000190.0013681.3708250.0007100.0000190.0000250.0000190.0010380.0008260.1962090.0051630.0000830.0000250.0004380.0230750.0032630.0015460.0377201.3486601.3505680.0015230.0079680.0546930.0001650.0040990.0993670.1519281.0232830.0039040.0010810.0004750.0003560.0000190.0003130.0000190.0000180.0005750.0008310.0008380.0005540.0004840.0000190.0000190.0000190.0009950.0030700.0016541.2598170.1469880.7317053.9890081.5896852.6935184.5012313.0054470.0014990.0000230.0530941.8382680.0009234.0769210.7688690.0004010.0000200.0459340.0000470.0021980.0000210.0000210.0000213.2280000.0015900.0001000.0000200.0022140.0010220.0000190.0000210.0682350.0016880.0000230.0010010.0000710.0010170.0000223.0183152.7916470.0033602.3935311.4472170.0020912.9283750.8534340.0046840.0043700.0120730.0060150.4249510.0023052.9560430.0023950.0000890.0102850.0003180.1930231.2211923.1203834.7830271.4059902.6530884.1170582.9870591.9093102.6960631.7427210.0021110.0012101.7120910.0008380.0109610.3629780.0002350.0001152.3543360.0011390.0000680.0000431.7726960.0022263.4991450.0299481.4344520.0007400.0028251.7758852.4647720.0011843.2488590.0023890.0009200.0006090.0005400.0003200.0008161.3694610.0014200.0012760.0016860.0005070.0034340.8699830.7197200.0017592.8233990.0024641.5480550.0090830.0004750.0033500.0000210.5582941.6121240.0015120.0005513.3509990.5084602.3107740.9593020.0020690.0019660.9348231.4223590.0280210.0005970.0010510.0000310.0023550.0019401.6021410.0007600.0001530.0000220.0003640.0001290.0005350.0001300.0003400.0001620.0001591.7309450.0010710.0004270.0005170.0000200.0000250.0005800.0010730.0004740.0005600.0004480.0002650.0008870.0003790.0741540.0000560.0000240.0000391.4422400.0006780.0000210.0025860.0000230.0000340.0000250.0000190.0000500.0000300.0011500.0007980.0000230.0000850.0009020.0000200.0000200.1207600.0026910.0000470.0000210.0006250.0010901.0832900.0005210.0004100.0002510.0001181.0450890.0006862.0251490.0115120.0015390.0000230.0000270.0000880.0000620.0000420.0000740.0000570.0000210.0258990.0000392.8191110.0015750.0000280.0000280.0000210.0003910.9338750.0005500.0000211.6016990.0008220.7683930.0005760.0008070.0006100.0006500.0003910.0006100.0007280.0004450.0006320.0004131.5567072.4149734.2882482.8096051.3826090.0013320.0000620.0020480.0021780.0008970.0007830.0011500.0011930.9261090.0004822.4487091.2720920.0016990.0009530.0006050.5651380.0005190.0000230.0006810.0004640.0568100.0000460.0110491.0666500.0018320.0027630.0002330.0003744.5886742.8080301.4500360.0010303.1287861.8266672.7182761.1722331.3045250.0005940.0016250.0164190.0002290.0010700.0026710.0012960.0000340.1411191.8501690.0008250.0001560.0000261.4921540.0006751.2879580.0005790.0000252.0158450.0011640.0026830.0002570.0003480.0025130.0000320.0000200.0008110.0000210.0002260.0002740.0006450.0003850.0007090.0005490.0015940.0008630.0002910.0002730.0002480.0000200.0013200.0000320.0233110.0000340.1956780.0004411.4160000.0042870.1288300.0047180.0000223.4874430.9290870.0043410.0112310.0307591.1560701.0125470.0117240.0043920.0075232.4298810.3810821.2288112.1494220.0009911.1165051.2380440.0046841.4212990.0049130.0030728.0218776.0550437.2170071.8064340.0015690.0008030.0011200.0007750.0000450.0003220.0002230.0002800.0005370.0319140.0003510.4240750.0006540.0022690.0002230.0009340.0009330.0008540.0005180.0007500.0011410.0000800.0135740.0005340.0015390.0004850.0000310.0009650.0000240.0136930.0005410.000066

*******************************************
EVALUATING PIPELINE 
Pipeline directory: /home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_e414339c_2020-02-04_01-12-04_li9xclj/
With following parameter combination: {'batch_size_seq_length': 1, 'lr': 3e-05, 'lr_type': 'cosine'}
EVALUATION OF CHECKPOINT /home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_e414339c_2020-02-04_01-12-04_li9xclj/outputs/checkpoint-3
-------------------------------------------------------------
|           |   agree   | disagree  |  discuss  | unrelated |
-------------------------------------------------------------
|   agree   |    496    |    58     |    148    |    20     |
-------------------------------------------------------------
| disagree  |    17     |    47     |    13     |     3     |
-------------------------------------------------------------
|  discuss  |    218    |    47     |   1586    |    49     |
-------------------------------------------------------------
| unrelated |    31     |    10     |    53     |   6826    |
-------------------------------------------------------------
Score: 7125.75 out of 7516.5	(94.8014368389543%)
Accuracy: 0.9306796923716483
F1 overall: 0.7255443363146419
F1 per class: [0.6684636118598383, 0.3884297520661157, 0.8572972972972973, 0.9879866840353163]
*******************************************


*******************************************
EVALUATING PIPELINE 
{'batch_size_seq_length': 2, 'lr': 3e-05, 'lr_type': 'constant'}
INFO:__main__:Creating features from dataset file at /home/ubuntu/fnd_implementation/data/processed
  0%|                                                  | 0/9622 [00:00<?, ?it/s]  0%|                                        | 1/9622 [00:01<3:07:22,  1.17s/it]  5%|█▉                                    | 501/9622 [00:01<2:04:21,  1.22it/s] 21%|███████▋                             | 2001/9622 [00:01<1:12:44,  1.75it/s]100%|█████████████████████████████████████| 9622/9622 [00:01<00:00, 6056.76it/s]
  ******************************************* 
              Running Evaluation                
  *******************************************
 
  Length dataset evaluation: 9622
  Length dataloader evaluation: 1203
  Number of epochs: 3
  Batch size: 8
  ******************************************* 
 
['/home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_e226a48d_2020-02-03_21-19-449ib9mz7e/outputs/checkpoint-3']
INFO:__main__:Evaluate the following checkpoints: ['/home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_e226a48d_2020-02-03_21-19-449ib9mz7e/outputs/checkpoint-3']
INFO:transformers.configuration_utils:loading configuration file /home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_e226a48d_2020-02-03_21-19-449ib9mz7e/outputs/checkpoint-3/config.json
INFO:transformers.configuration_utils:Model config {
  "architectures": [
    "AlbertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "down_scale_factor": 1,
  "embedding_size": 128,
  "finetuning_task": null,
  "gap_size": 0,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "inner_group_num": 1,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "net_structure_type": 0,
  "num_attention_heads": 12,
  "num_hidden_groups": 1,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "num_memory_blocks": 0,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 30000
}

INFO:transformers.modeling_utils:loading weights file /home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_e226a48d_2020-02-03_21-19-449ib9mz7e/outputs/checkpoint-3/pytorch_model.bin
HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=1203.0, style=ProgressStyle(description_width='initial')), HTML(value='')))
0.0323310.0324140.0162530.0055090.0014250.0003420.0001320.0000720.0000600.0000570.0001870.0004110.0011670.0001460.9718600.0648360.0051440.0004260.0011480.0002701.1293330.0538210.0049340.0213780.2472260.8077530.0311270.0012160.0013760.0005050.0172050.0006220.0000890.0984370.0041660.0019100.0001450.0000950.0000730.0002470.7046390.0175330.0008140.0004990.0011890.0006800.0002640.0134160.0858510.0018330.0001440.0006550.0001080.0000640.3360980.0061620.0001560.0006700.5751090.0097950.0004690.0000550.0073210.0001670.0000490.0000470.0355150.6359630.0097650.0003570.6549440.0105300.0104940.0001970.0005550.0020061.0698630.4077980.0055460.0001340.0005080.0004710.0005260.0000680.0001400.4791160.5131110.5863380.0097840.0098360.0002550.8443200.0706642.9951010.0320390.9347670.2568700.2566930.0027200.0000890.4813550.0048520.0004180.0004150.0002660.0007380.0000800.0002460.0000720.0001270.0000890.0002030.0003250.4969320.0044170.5148790.0095720.0070640.0004370.0040840.0000820.0016310.0000560.0000480.4827480.0039080.0018580.0000840.0010850.0003410.0007020.0000600.3588570.3772000.0028610.0000670.0848440.8664010.0214700.0002040.0000550.0002050.0000500.0000470.8211900.2127710.0015040.4404980.4400620.0029980.4373090.4121150.0402580.2874200.0021970.0001090.0000820.0000820.0000880.4794570.8254740.8263330.0053310.0000830.0241640.7988190.0313680.0006190.0002450.0002600.8576440.0069990.0001040.0000490.0000510.0000820.0001670.0000470.0000540.0001020.0000620.0000450.0000480.0006090.0000610.0000500.0003790.0000480.0000590.0000460.0000570.0002060.0012390.0046500.0019070.0039140.0002850.0006990.0110370.0001250.0000890.0000930.0000710.0001350.0010240.0017240.1854600.3143370.1444330.4181601.1844860.6361530.7084970.0125920.0001040.0000510.0002940.0000650.0004010.0000580.0030330.0000653.9682250.0185380.0003540.9135380.0042610.0002850.0000550.0000590.0000860.0002220.0094050.6173010.0145980.0004560.0365290.0141400.6775790.0030230.3372091.0215002.7266291.6827721.5250761.7721390.0489630.0002520.0001960.0000480.0002210.0003340.0000510.0000520.0003480.0002010.0005870.0063890.2508770.0040030.0002910.0004130.2469870.0011510.5643300.2574750.0022500.0642100.0534600.2636420.0010580.0013680.6482110.1819530.0028030.0522000.3670180.0015590.2111420.4978200.0020820.0007790.0003980.0003760.0000470.0001980.0002320.0003070.3749210.7487970.3646780.0016620.3546760.3276380.0025240.0003770.0005400.2633450.0012150.8248921.6716471.2244450.4693730.0397550.1800262.3152580.0094701.0209780.0035720.0002400.9204120.8981390.0030280.0001520.9090560.0030420.0001600.0002170.0006850.0001990.4517600.2218580.0020730.0094390.9854730.0042270.0011750.0011670.0009070.0015940.0003900.0004810.0007850.0008200.0010940.0011520.0000480.0002910.6142620.0030210.0000750.0000590.0000520.0237940.0002630.0032420.0000770.0000780.0065100.0124570.0002930.0002130.0003950.0007590.0074220.0004510.0019480.0001810.9697480.0027551.5971560.0045010.0002640.0006901.1525980.1718400.0036381.6609490.0046790.6903540.5416941.9876740.6955610.0019100.0460320.0001710.9594390.9609580.5808300.0018091.1675840.0033180.0284030.0001210.0002670.0010540.0011010.0009980.0025460.0000520.0014500.0000620.0065630.0210340.8376560.0028580.0006660.0008130.0008780.9481590.4426781.3451770.8058190.7554960.8092660.0024030.7235510.6585690.2714080.0010711.1482763.4632970.0157340.0212410.0708630.0329890.0008811.8043000.0177500.1886600.0264560.0001100.7440340.0027340.0008070.0013590.0000840.1901170.0194030.0000990.0000480.0000500.0226750.0001200.0000480.0000470.0000460.0000530.0000460.0000880.0326161.2698070.4304080.7420730.0028860.0001130.3015720.3356320.0096540.0094440.0200010.0043830.0005280.6317561.5307000.9763920.0022000.2025380.6222080.0037420.0102850.1737890.0907922.1511680.6483810.3972760.0236070.5206730.2382920.0661510.0001870.1563450.0003760.0023180.0000480.0000460.0000530.0004820.8973641.1256260.0035151.1492690.0132710.0058330.0000590.0058010.0000711.7478063.8049133.6305174.9226000.9486000.0021770.0000530.0000500.0000500.3501540.0007590.7044910.3352080.0011600.0002350.0016680.0000670.0163700.0001480.0143460.0015790.0002440.0002130.0002472.8426771.7524900.0036500.0002760.0155410.8037420.2601170.7013820.0025300.0013360.0006690.1680990.0025830.4167010.0354900.4050110.0008210.2315940.0320700.2474980.1989660.0652280.0009970.0305620.0301570.0802090.0309120.9395400.4863391.0156221.0040282.0731061.8121740.1398883.2741150.9660270.0022331.2041332.2402931.5617860.8114661.3855650.7090800.2705041.0093770.0018590.0000601.6869051.6650410.0031790.0000840.8921970.0016370.0070190.0000610.0117370.0209890.0001690.0000630.0032500.0000730.0020861.4910170.3767150.9279810.0339400.0210712.5155591.7060630.8421410.5481570.0012220.0000560.0000522.1201950.4927470.0017400.0009850.3625090.3448540.3514060.0011510.0000670.0000490.0000510.0515780.0001320.4410230.0233200.0000930.0628060.0831530.3053460.0005690.0006370.0006330.0004780.0005331.7949622.6195410.0052780.0069550.0275000.0174410.0127600.0024190.0000830.0001220.0292340.6392300.4870860.0009820.0026030.0030580.0000910.0005470.0007730.0002470.0015710.0019280.0006290.0004760.0001020.0746510.0001760.0227180.0299171.7626771.4347140.7654862.3372442.0087330.4739790.0030180.0060640.8783240.0023820.0011200.7740841.4274090.6771370.6170050.6998790.1277660.4770271.0560112.7170900.0055450.0000580.2317640.0003960.0007560.3063690.0039540.0961640.0935400.0198440.0551690.0110800.2338920.1656160.0007780.0187290.0073710.0185990.0001230.0004631.8969112.3092210.5811540.0009950.0086700.0068650.0032380.0000620.0003670.0019900.0030630.0016150.0002990.0139240.0002440.0105400.0001120.3240360.0011781.7881840.0267950.7471460.6803980.0016180.0007261.8172572.9225611.8936460.0150530.6282390.0186680.0186100.2429910.0212110.0356880.0006250.0005830.7873830.5171490.6159800.0013670.0285510.2452460.0013721.6535211.7596490.0050342.3740531.6067642.3998270.0079130.5184800.0015460.0032802.3055970.0056620.0015160.0003651.3792390.4423580.0006460.4543820.0006810.4079361.3078980.4123030.0013360.0000700.0013380.0013130.0020991.1780750.6129790.0045720.7287791.1003471.0257940.7620670.5366650.0554950.4193280.0015990.0009800.0010020.0007540.0205010.0005290.0006390.0004480.0000530.0000460.0000480.0002190.8731351.1604300.9625050.5121000.0274120.0883042.1164393.2140570.8412700.0119720.0244650.0017000.0061670.7816840.6221670.0016170.0007880.7493040.0159500.0342880.4008580.0998060.9852390.0018801.0522063.1221290.9939040.9854070.9543463.9967271.7959200.3600230.0032120.0005810.0031490.0114050.3500470.0107130.0030510.0002490.7135142.4138030.7501113.2646844.7750314.6336890.6876680.0025530.0015890.0008280.0002300.0000860.2473190.3393190.0004700.0000570.0159872.5909501.0176040.3898500.3550520.3957101.4786080.8867851.3398732.8883170.8641180.0185300.3237590.3272640.0272760.2761230.0003780.0000690.0113570.0156120.0010670.0043830.0010390.3302760.0463690.3138640.0008631.1807720.6981500.7005110.6846851.0713950.3259980.0004240.0005930.0004730.0014130.0012810.0013190.0003430.0002370.0001930.0000750.0005260.0003190.0004040.0004250.0002900.7339950.0010050.0005330.0002800.0000440.0000710.0001700.0018620.0006510.0001790.0011250.0004340.0003220.1708590.0389490.0001150.0001740.0002490.0000610.0132260.0132070.0000750.0063230.0083790.0065830.0001280.0498650.0579430.2654371.6971840.2849980.2953850.0168170.0408570.0194440.0190370.0163130.4762670.0099990.1099340.0013790.0006020.0020280.0018351.9805060.9700190.2931650.8308350.0032810.0010890.5506011.1831880.0046030.0012890.0014590.6768080.0011900.0000460.0002300.0004540.0002630.0000440.6466550.0007380.0000640.0006300.0000450.0000450.0001941.3356100.0020160.0005930.0048390.0005080.0008610.0006120.0000490.0412960.4746180.5611591.3543290.0206110.0003210.0004060.0002950.0000470.0004500.0915690.0235700.1267570.3642450.2576870.2981110.1401750.3458450.2090860.4169930.1476120.0018510.8852600.9802693.4356290.7069402.0526751.0391430.0232040.0627650.0414920.0498050.0334920.7799740.0225550.0339640.0259610.0000910.0000780.0000530.0238570.3998270.0004600.0190900.3848960.0174270.0006970.0041390.0025850.0022510.5698680.0181730.0357090.4291160.0394400.0004110.0003910.0000500.0016220.0010720.0004900.0000480.0351560.0419990.5956741.6486082.1819401.4255531.3473280.2481922.7107820.0027021.1237160.0345750.0002871.4521370.0015120.2550710.0002960.0268650.0139680.0140660.7838821.2607201.3771360.9062621.0228630.0675410.2402650.8436400.6322381.3852680.3254572.9749282.3962872.8066241.0108470.7171841.4271370.6953750.6941421.1430250.0011561.1917602.5794312.0793380.7510893.1575170.8394580.6482570.0060140.0017081.0814000.1132950.0265650.8363131.0538130.8334480.0533150.0024091.2000670.0018020.8281550.1605160.0208371.3296690.1372990.0045420.1135520.3146890.0004950.0006040.0005540.0007790.6761450.0183000.0010500.2285680.0011070.0010470.0005270.8589650.0008350.0004610.0000530.0353730.0000810.0000790.0001190.0320520.0153600.0000610.0180390.0000660.0022010.1422750.0005120.0138530.7125130.0156140.0000630.0006080.0000710.0000490.0168150.2071310.0002350.0016490.0342370.4599320.0018420.0075660.0018970.0012270.0053440.0019300.6491190.7535630.6201270.0587030.0915710.0491231.8821680.0933000.0906190.0009540.2438110.0006410.1020440.0643860.1274710.0014361.2546930.7728341.4419220.8344720.6071250.0014440.6052100.0009410.0005300.7377120.0009680.0325790.0003550.0000450.0017940.0024880.0009520.0000760.0133010.0014760.0010270.0013500.0348270.0004510.0003620.0165500.0062550.0630322.2749401.3887510.0450401.3143430.5415350.6807791.1908231.0892840.3480851.0490990.8611830.7991180.1192242.9302381.0661490.0207090.0146480.0006770.0007551.4801980.8353300.0031060.0021500.7258410.0044880.0050480.0056970.0139240.0084130.0121350.065444

*******************************************
EVALUATING PIPELINE 
Pipeline directory: /home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_e226a48d_2020-02-03_21-19-449ib9mz7e/
With following parameter combination: {'batch_size_seq_length': 2, 'lr': 3e-05, 'lr_type': 'constant'}
EVALUATION OF CHECKPOINT /home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_e226a48d_2020-02-03_21-19-449ib9mz7e/outputs/checkpoint-3
-------------------------------------------------------------
|           |   agree   | disagree  |  discuss  | unrelated |
-------------------------------------------------------------
|   agree   |    488    |    72     |    189    |    11     |
-------------------------------------------------------------
| disagree  |     1     |    12     |     2     |     0     |
-------------------------------------------------------------
|  discuss  |    217    |    63     |   1496    |    29     |
-------------------------------------------------------------
| unrelated |    56     |    15     |    113    |   6858    |
-------------------------------------------------------------
Score: 7031.5 out of 7516.5	(93.54752877003925%)
Accuracy: 0.9201829141550614
F1 overall: 0.6476860607300784
F1 per class: [0.6412614980289093, 0.13559322033898305, 0.8299583911234397, 0.9839311334289813]
*******************************************


*******************************************
EVALUATING PIPELINE 
{'batch_size_seq_length': 3, 'lr': 3e-05, 'lr_type': 'cosine'}
INFO:__main__:Creating features from dataset file at /home/ubuntu/fnd_implementation/data/processed
  0%|                                                  | 0/9622 [00:00<?, ?it/s]  0%|                                        | 1/9622 [00:01<3:25:32,  1.28s/it] 21%|███████▋                             | 2001/9622 [00:01<1:53:58,  1.11it/s] 78%|██████████████████████████████▍        | 7501/9622 [00:01<22:12,  1.59it/s]100%|█████████████████████████████████████| 9622/9622 [00:01<00:00, 6174.95it/s]
  ******************************************* 
              Running Evaluation                
  *******************************************
 
  Length dataset evaluation: 9622
  Length dataloader evaluation: 602
  Number of epochs: 3
  Batch size: 16
  ******************************************* 
 
['/home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_e55e89d0_2020-02-04_02-33-27n9o2fq27/outputs/checkpoint-3']
INFO:__main__:Evaluate the following checkpoints: ['/home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_e55e89d0_2020-02-04_02-33-27n9o2fq27/outputs/checkpoint-3']
INFO:transformers.configuration_utils:loading configuration file /home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_e55e89d0_2020-02-04_02-33-27n9o2fq27/outputs/checkpoint-3/config.json
INFO:transformers.configuration_utils:Model config {
  "architectures": [
    "AlbertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "down_scale_factor": 1,
  "embedding_size": 128,
  "finetuning_task": null,
  "gap_size": 0,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "inner_group_num": 1,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "net_structure_type": 0,
  "num_attention_heads": 12,
  "num_hidden_groups": 1,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "num_memory_blocks": 0,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 30000
}

INFO:transformers.modeling_utils:loading weights file /home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_e55e89d0_2020-02-04_02-33-27n9o2fq27/outputs/checkpoint-3/pytorch_model.bin
HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=602.0, style=ProgressStyle(description_width='initial')), HTML(value='')))
0.0003910.0004840.0003450.0003340.0002230.5049040.3390330.4598720.0578230.6055020.6319450.0583910.1951560.0152250.0038540.0010310.0006980.0014350.0002490.0018340.4908540.0237730.0022360.0004530.0386500.0024740.0004030.4408660.3483320.0139440.0005780.0001550.0000900.2659890.3041410.1145030.0709070.4995180.4840620.2538000.3882030.0099190.5387150.6329640.0166100.4786091.5929791.3691870.1562010.0033600.1603690.0033470.0004320.0001790.0001830.0001680.0002700.2199220.0114500.0006630.0004090.0000910.5197590.0087051.1536060.0202911.5028420.0225960.4508610.0454580.0007380.0001050.3941520.0083060.0006460.4831840.0162910.0003970.0001740.0020260.1426910.0018860.5330240.3042990.0038110.4099720.0049140.0002100.0003450.0001480.0000890.0009550.0000990.0014190.0001190.0002200.1434530.3060590.1677470.0164520.0007100.0005490.0033680.3445920.0042710.7022740.2827550.0028770.0002840.0021550.0010600.6324780.4071310.0039700.0003070.0006980.0071710.0331590.0147250.0033970.2682371.0982870.7958370.0334400.0005920.0003270.0001050.0004310.0008560.0019020.0207520.0024280.0009140.4173950.8344190.1618870.8514800.0274240.2287400.3054340.0250440.0003330.0001320.0001850.1039030.0071180.1256330.0011820.0013660.5678870.8972980.0422540.4998010.4148480.0029380.7481980.0049440.3432030.0024050.0722790.0227070.0006460.6726150.1967790.0015630.0003760.0011980.0011570.0001600.0059250.0036500.0078630.0021450.9414030.0174700.0008150.0007870.0006060.0034440.2159110.3064620.0020853.5462841.0229490.0452080.6935650.4485360.5700091.7463700.6869980.6738740.0057800.0004150.0005490.0006500.0003890.0015100.3863520.1637390.5193450.7825350.0292690.0154440.0733670.1883192.3315680.0134630.0051790.1588860.1898800.0022220.5689220.0116520.0055070.0007610.0000940.3028710.0014810.0001110.0015180.3161920.2798240.0016710.6456510.4505750.0028890.1405051.9144930.0141310.0007681.0140650.9920760.9427800.5167690.3274130.0016440.0001400.0000910.0003190.8305610.3999410.1437400.0211380.8867903.4637902.3606240.0097280.0001480.4304811.0963540.0050600.0034570.0007170.0018090.3821250.6895040.5468160.0039890.1734210.3698070.0077130.0028310.2000220.1466150.0134490.0825420.0031840.0036430.0018431.0559461.3146251.2524270.0117090.0182110.2396930.5959660.1369680.2948710.0013641.1742430.0043310.1194820.0014710.0055330.0002870.3758460.1124600.0378890.0011352.1836670.1611690.0007100.8112840.3385180.2984070.6753340.2089660.0008130.0006090.0806910.0068060.0579150.0167420.2076201.2576831.1995330.0056830.0007440.0008060.0005050.0404080.0005040.0003450.0003850.2095340.0040250.0023760.0004860.0018243.1543082.9701261.1204330.0045540.0061020.0010240.0039720.0009370.4060850.9772710.4219200.1469100.0907480.5098900.0170640.1314780.4403281.1869540.5398260.4009001.0687390.1881750.3528660.0021390.0084920.0820570.0018500.0005210.0020460.2420880.1508790.3187670.6277983.0341260.0295860.0037860.1705600.0057830.2320970.0014190.0025490.2402370.6810562.1693214.7371790.0172810.0027091.2340750.0040840.5328080.2220220.2266800.9604300.0035151.1454932.1364953.4242032.4496921.5699881.1266080.6736340.0025450.1064790.0014660.0002610.0000970.4108530.9912890.0059300.3487163.9718060.0125270.0009060.5939160.0018110.5246800.2537120.9634790.4044631.4988440.8015631.4932800.3470890.0795290.0958380.0009550.4388411.8342501.7667960.9909580.0030150.0002310.3242880.2610480.0008164.4916580.3824801.0345072.1578953.1180640.6552600.3325250.1026510.0006310.0039040.0004750.0003410.0002801.7046510.9279500.6003680.0016880.0003310.0003400.0002400.0003360.0002570.0002430.2090540.0006670.0001530.0002060.0003500.0005830.0001670.0758290.1004630.0003790.0005200.0001890.0003160.9325551.9811340.0593700.0870510.0012240.0023460.4260810.3425260.0023811.1077351.9115300.8537770.0023660.3742790.0012450.0002920.0002350.0006110.1006350.0003880.0001520.0001761.0497830.0173730.0004260.0001860.5153303.5075550.3770600.0155820.0003280.0079010.1234330.2128920.0076920.0063930.0049160.6171101.1656020.2816910.0026180.0020020.0045190.0025330.0003150.0000930.0820150.0011190.2395780.0008480.0009920.0009900.3292550.0016130.0005290.0041810.0008110.2842921.1661431.3899900.8546871.4293490.6976100.7151060.0069730.0007970.0007380.8874570.4816770.3457270.7809290.3209940.9650141.4468500.2396090.1940840.0056130.0042770.9008350.2911100.1428350.0233160.7847040.1881230.8685310.0081850.0409980.5349950.3042270.0014930.5277260.0012130.0003410.5795610.0014230.0005070.0007540.0112850.1092790.0003490.1639740.0039510.0079820.0695870.0009030.0576060.0003700.0001240.2467650.0010810.3356290.0019930.0017090.3849623.7411820.3537990.0049810.8574270.1113720.9121960.8323991.6425182.7156341.9195090.2221290.2637620.4487410.3085700.0066720.0237530.0003380.0004150.0004440.0004380.0002890.0040160.6022120.7571270.0222970.2297510.4504430.4373930.5569090.0227170.1766750.0013220.0313470.0614290.0017650.0006970.3469510.001228

*******************************************
EVALUATING PIPELINE 
Pipeline directory: /home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_e55e89d0_2020-02-04_02-33-27n9o2fq27/
With following parameter combination: {'batch_size_seq_length': 3, 'lr': 3e-05, 'lr_type': 'cosine'}
EVALUATION OF CHECKPOINT /home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_e55e89d0_2020-02-04_02-33-27n9o2fq27/outputs/checkpoint-3
-------------------------------------------------------------
|           |   agree   | disagree  |  discuss  | unrelated |
-------------------------------------------------------------
|   agree   |    521    |    58     |    146    |    16     |
-------------------------------------------------------------
| disagree  |    10     |    47     |    19     |     3     |
-------------------------------------------------------------
|  discuss  |    209    |    48     |   1574    |    76     |
-------------------------------------------------------------
| unrelated |    22     |     9     |    61     |   6803    |
-------------------------------------------------------------
Score: 7106.25 out of 7516.5	(94.5420075833167%)
Accuracy: 0.929640407399709
F1 overall: 0.7297420517005834
F1 per class: [0.6932801064537591, 0.3900414937759336, 0.8492042082546534, 0.9864423983179874]
*******************************************


*******************************************
EVALUATING PIPELINE 
{'batch_size_seq_length': 2, 'lr': 3e-05, 'lr_type': 'cosine'}
INFO:__main__:Creating features from dataset file at /home/ubuntu/fnd_implementation/data/processed
  0%|                                                  | 0/9622 [00:00<?, ?it/s]  0%|                                        | 1/9622 [00:01<3:11:59,  1.20s/it] 21%|███████▋                             | 2001/9622 [00:02<1:46:28,  1.19it/s]100%|█████████████████████████████████████| 9622/9622 [00:02<00:00, 4496.03it/s]
  ******************************************* 
              Running Evaluation                
  *******************************************
 
  Length dataset evaluation: 9622
  Length dataloader evaluation: 1203
  Number of epochs: 3
  Batch size: 8
  ******************************************* 
 
['/home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_e414339d_2020-02-04_01-14-41iyih8w6c/outputs/checkpoint-3']
INFO:__main__:Evaluate the following checkpoints: ['/home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_e414339d_2020-02-04_01-14-41iyih8w6c/outputs/checkpoint-3']
INFO:transformers.configuration_utils:loading configuration file /home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_e414339d_2020-02-04_01-14-41iyih8w6c/outputs/checkpoint-3/config.json
INFO:transformers.configuration_utils:Model config {
  "architectures": [
    "AlbertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "down_scale_factor": 1,
  "embedding_size": 128,
  "finetuning_task": null,
  "gap_size": 0,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "inner_group_num": 1,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "net_structure_type": 0,
  "num_attention_heads": 12,
  "num_hidden_groups": 1,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "num_memory_blocks": 0,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 30000
}

INFO:transformers.modeling_utils:loading weights file /home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_e414339d_2020-02-04_01-14-41iyih8w6c/outputs/checkpoint-3/pytorch_model.bin
HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=1203.0, style=ProgressStyle(description_width='initial')), HTML(value='')))
0.0004330.0005400.0003090.0001470.0000980.0000750.0000750.0000570.0000470.0000470.0000900.2239780.0555660.0043101.0393230.0693290.0046890.0014100.0002090.0011390.0095180.0004860.0004840.0002720.0004091.7963010.0691350.0026280.0953520.0034060.0009930.0000870.0000840.0008990.0004320.0012650.0000860.0000840.0000440.0000590.9510720.0233700.0006360.0001200.0009080.0015030.0001790.0002280.0011380.0000640.0000800.0015970.0000890.0000520.1171020.0021700.0000750.0003640.0001270.0000380.0001070.0000340.0001010.0000340.0000320.0000320.0005611.5146620.0441060.0006880.0148500.0003000.0002360.0000390.0016370.0691830.1441680.7739100.9729170.0124250.0009370.0002310.0001870.0000550.0012971.6484051.6801700.7742840.7268860.0083450.0004121.0477200.0116663.2496760.0346121.2610550.0194540.5317430.0054750.0001640.3496330.0035490.0001390.0003370.0002410.0003160.0000450.0000700.0000440.0000460.0000720.0000850.0001460.0002640.0000450.0005140.4536250.0420090.0004020.0001320.0000360.1489610.0012540.0000430.8027790.0064620.0018300.0003400.9595570.0075410.0001960.0000400.9753700.7698090.0057840.0000810.0518330.9484010.8567070.0062090.0000800.0000870.0000400.0000410.8854070.9374950.0064630.6351890.0048990.0000680.0213550.7055130.0092460.0424770.0004440.0000390.0000370.0014930.0000450.0009530.7356830.7391120.0046460.0000660.0004261.0646230.0262230.0003560.0001240.0001300.7853410.0049370.0000760.0000790.0000450.0000540.0000710.0000370.0000500.0002620.0000430.0000390.0000370.0001910.0000400.0000390.0002190.0000390.0000420.0000360.0000720.0000940.0019970.0004970.0001720.0102450.0001110.0005160.0001840.0000370.0000570.0000500.0000390.0000440.0436080.0003520.5056520.1146790.4631360.7436531.6624040.3961770.4418960.0022800.0000450.0000440.0002170.0000740.0002420.0001750.0002430.0000571.2225410.0060880.0001660.9280450.0042780.0001150.0000420.0000470.0000440.0002480.0002450.0202450.0004670.0013740.0019280.0009580.0003460.0000870.0008840.7083480.9996650.4730710.0038420.0018100.0004810.0000500.0001660.0000350.0001400.0002120.0000360.0000340.0010010.2057550.0009680.0023260.0002070.0002670.0001180.0002570.0196130.0001860.6793000.0028050.0001401.2109070.6137751.0065970.0037830.0005220.2906900.6280411.0105610.2979350.0038760.0001780.6922370.6778880.0028890.0004950.0001640.0000970.0000410.0000840.0000880.0001080.6479101.0974900.3656470.0018070.0926240.0335910.0006180.0001730.0002120.0004780.0001281.1211350.0040560.0037700.0026540.0602660.0030371.1701890.2666100.6682710.0022990.0001131.9509220.9462920.0031060.0000860.8498440.0027680.0000970.0001930.7181000.0023430.4854320.5946870.0022080.0002080.9080780.0060870.0002390.0001810.0004210.0005610.3208160.4776591.0667571.4051060.3687240.3871500.0011870.0001050.0006290.0004160.0000370.0000450.0000420.0004230.0000410.0002760.0000460.0000490.0002470.0005600.0002330.0001210.0001550.0003110.0002320.0002800.0126990.0001850.6367300.0018200.9947450.0027980.0001080.0003972.0108940.5526170.0081942.3136700.0064570.7323230.0022681.9361210.9218260.0025140.0037720.0000460.0018370.8950131.7662950.6645461.7046260.0050900.3439620.0009360.0000960.0004250.0004650.0003760.0004660.0000350.0005570.0000370.0001730.0005830.8008730.0047130.0019520.0003250.0005010.0274551.0670881.2729430.0043640.0351040.0065960.0003360.0021120.0050950.0015240.4071930.0081583.3020460.1376960.0010950.0008800.0008660.0002950.7337840.4117001.1076170.5201900.0012690.0002610.0001220.0001420.0002300.0000541.6737670.4466940.0011070.0000370.0000370.0011420.0001630.0000350.0000340.0000350.0000350.0000340.0001160.0407370.0626500.0051471.3395600.0037590.0002750.7249550.5240490.6926770.4548900.0017120.0004130.0003770.0006511.7660340.9951050.0022490.0002130.0005640.0002200.1065630.2258251.3220680.5038471.2584930.7411270.0018120.7494100.0199620.0108800.0000750.0142280.0000670.0001260.0000350.0000450.0001090.0001191.0318731.1537350.0025411.1719760.6248650.6957970.0014820.7157180.0015140.0806422.0088170.0546010.5394690.0320840.0001480.0000360.0000380.0000350.7943280.0016371.3894710.7322830.0015450.0002590.8918890.0023300.0036610.0002710.0036580.0025700.0002210.9615700.0096430.9222981.1095390.0022000.0003180.0007640.0017780.4408950.8752550.0019500.0003720.0008060.0004350.0000990.3366330.0137120.0038280.0000440.0042610.1062340.0249620.0046230.5324280.0010860.0066970.0061220.0001280.0054590.7304750.7997112.3581941.0011662.9308631.6892240.8587063.4602941.0209400.0020840.9410982.5800490.7715190.0400011.0507650.0022290.0004710.9158780.0016800.0000381.7483301.6314790.0030180.0000660.8386630.0015250.0001620.0000380.0002910.0003020.0000410.0000360.5251230.0009570.0001961.0843710.0036070.8303280.0021820.0002532.3101021.4978660.8233000.6639060.0012650.0000450.0000441.5213180.7381960.0014690.0007530.5886330.4740500.2865710.0009860.0000430.0000350.0000450.0003200.0000370.0040790.0001890.0000400.0023350.0100900.0014090.0000410.0002500.0001980.0000640.0003732.9553373.2906930.0057300.0007030.0006280.0491560.0006610.0018070.0000590.0000730.0009070.0021520.0611730.0002550.0001900.0432150.0003350.0005530.0001140.0000420.0044860.0036990.0000650.0002570.0001400.0006350.0000420.0001930.7207951.3766460.2433590.2651003.5213822.5076940.8269010.0190240.3929820.0020660.0005350.0006020.6767920.0046150.5308320.0085800.2438230.1361190.6003940.7893552.7759100.0044810.0000480.0332050.0000880.0005050.4277220.0040210.0052460.0012250.5148290.3965150.0007770.6063400.5212810.0009060.1792500.0007100.1792620.0003400.0001570.3829200.2293190.0068890.0000620.0060160.4393770.0008730.0000440.0026310.0000690.0002300.0002280.0000770.0015120.0000460.0001910.0000620.0005590.0004260.9255360.1387870.9821560.0021830.0003790.0002600.8323551.9970414.2034720.0072800.0031370.0001930.0002080.0305080.0007020.0008810.0002750.0003280.7572370.0014270.0006360.0002660.0003170.5061750.0007530.2350991.8597070.0027080.6430480.0013040.0005512.7403931.1308331.0303062.0871251.8680150.0045690.0007170.0002190.7399640.0013030.0000540.0864660.0001750.0002590.0023170.0007100.0003560.0000690.0898001.3755082.7453160.9069263.0686331.8068780.9077011.3614950.7152120.8853780.1613730.9645431.3593600.0021080.0004490.0004990.0003700.2729560.0005870.0006170.0001360.0000410.0000340.0000360.0001160.9331881.1113380.9359120.0018210.0011520.0029780.8435587.3949282.6706460.4349010.3328040.0007700.2135070.9187640.8815540.0014310.0001820.9372170.0021020.0008510.8319120.1889081.0150120.0014761.0034083.2191791.0024150.9661480.9976002.8368830.3916700.5602050.0138140.0003250.0015500.0030120.0167960.0024840.0008350.0001690.6787282.2948810.2950272.8753585.7606585.5100960.0070750.0001630.0004990.0001650.0000850.0000560.9225580.6135890.0007910.0000610.0022353.6497171.0974750.8768230.0012642.0124381.6775101.1761332.5619474.9991311.7941180.0222640.9122720.7526690.0014550.0022550.0000390.0000420.0002830.0044620.0007180.0003900.0003350.0013130.0003770.0003290.0002171.8173300.8705030.8632420.4391420.7683020.0014720.0000430.0002060.0002080.0003070.0004890.0009100.0001640.0001280.0000920.0000450.0002790.0001640.0002090.0001840.0001380.0455910.0009140.0002350.0001350.0000400.0000440.0000510.0004080.0002420.0000920.0009840.0001560.0001370.1058190.0291120.0000710.0003500.0000400.0000350.0002710.0003720.0000370.0001630.0001540.0001480.0000390.7145750.2519780.0012980.0117350.0219910.9837380.0016810.0006890.0003150.0006890.0008080.7470880.0029750.0006710.3540030.0014410.0006370.0006481.1589340.6018630.5366290.6526440.0014900.0003350.0010120.0024680.0151720.0004300.0004180.0004200.0002610.0000390.0001150.0003300.0001020.0000380.0004950.0000400.0000400.0001180.0000380.0000370.0001411.8750850.0021310.0002450.0003030.0002010.0003950.0002000.0000350.0005520.8072110.8849370.7197980.3711140.0005560.0005900.0001200.0000350.0001130.0373590.0006690.8694970.5419201.1005450.7508700.0029030.0029420.0039680.0025430.0149620.0006310.8673331.0292323.0166780.2790111.3420560.0119170.0005110.0024150.0004120.0011920.0008280.0217270.0428690.0006280.0003780.0000380.0000360.0000340.0005940.1239430.0001610.0005100.6051340.0247410.0001140.0007130.0021390.0007370.2749190.0042340.7544231.4620090.8986090.0010430.0001560.0000350.0003390.0002890.0002150.0000350.4023361.2292090.1033280.0245582.0701560.1579690.0293900.5167321.4741030.0014790.9153290.0026760.0000381.9065290.0019030.0007950.0000360.0004930.0002860.0003132.0744981.8754622.5535771.6460182.6710310.0038390.0009660.1204570.2262711.2384920.7057401.7536191.1882141.1062130.6535530.7812390.7729760.1548000.0004460.1188790.0001490.0036161.3661951.5156280.0045631.8045040.7747530.8164350.4681890.3605670.9794051.9743120.2749852.1769052.9963271.5889830.0024260.0003161.5995370.0017851.5115480.4102110.0013370.7596120.0134380.0001660.0006970.6442210.0006710.0001640.0001810.0001930.0001740.4183410.0005320.0001880.0007430.0005180.0006600.0004490.0000390.0411120.0000720.0031520.0000410.0000420.0000420.1279020.0013630.0000360.0244970.0000580.0006980.0008500.0002280.0008500.6457660.0044980.0000450.0001560.0000450.0000490.0007530.2814270.0003000.0012800.0397910.8685360.0009030.0033000.0030710.0006450.0016760.0022522.2213914.3378770.0237610.0011520.0008200.0010360.1371040.8539880.7826870.1283531.4189490.0014990.0009240.0003970.6351950.0028250.9873081.8430561.7065221.1759431.4668660.0431700.2389370.0497530.0010451.5796410.0015940.4676910.0005960.0000350.2043550.0004730.0004850.0000460.0004060.0002280.0005050.0004210.0007080.0001790.0002840.0002700.0005970.8603522.1433471.6446330.2873600.0487560.0026330.0040230.0040230.1180450.0689401.0439460.0585330.0076320.0017831.9902570.0105950.0003420.0003580.0013800.0002640.0007760.0402530.0003330.0003030.6433860.0007780.0007280.0002000.0066440.0002511.1645470.001143

*******************************************
EVALUATING PIPELINE 
Pipeline directory: /home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_e414339d_2020-02-04_01-14-41iyih8w6c/
With following parameter combination: {'batch_size_seq_length': 2, 'lr': 3e-05, 'lr_type': 'cosine'}
EVALUATION OF CHECKPOINT /home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_e414339d_2020-02-04_01-14-41iyih8w6c/outputs/checkpoint-3
-------------------------------------------------------------
|           |   agree   | disagree  |  discuss  | unrelated |
-------------------------------------------------------------
|   agree   |    499    |    43     |    150    |    21     |
-------------------------------------------------------------
| disagree  |    20     |    65     |    40     |     1     |
-------------------------------------------------------------
|  discuss  |    222    |    43     |   1572    |    36     |
-------------------------------------------------------------
| unrelated |    21     |    11     |    38     |   6840    |
-------------------------------------------------------------
Score: 7146.0 out of 7516.5	(95.07084414288565%)
Accuracy: 0.9328621908127208
F1 overall: 0.7436762778377414
F1 per class: [0.6766101694915254, 0.4513888888888889, 0.8559760413830656, 0.9907300115874855]
*******************************************


*******************************************
EVALUATING PIPELINE 
{'batch_size_seq_length': 3, 'lr': 3e-05, 'lr_type': 'constant'}
INFO:__main__:Creating features from dataset file at /home/ubuntu/fnd_implementation/data/processed
  0%|                                                  | 0/9622 [00:00<?, ?it/s]  0%|                                        | 1/9622 [00:01<3:12:34,  1.20s/it] 21%|███████▋                             | 2001/9622 [00:01<1:46:47,  1.19it/s]100%|█████████████████████████████████████| 9622/9622 [00:02<00:00, 4744.64it/s]
  ******************************************* 
              Running Evaluation                
  *******************************************
 
  Length dataset evaluation: 9622
  Length dataloader evaluation: 602
  Number of epochs: 3
  Batch size: 16
  ******************************************* 
 
['/home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_e2d857c2_2020-02-03_22-38-31tt6w1cdx/outputs/checkpoint-3']
INFO:__main__:Evaluate the following checkpoints: ['/home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_e2d857c2_2020-02-03_22-38-31tt6w1cdx/outputs/checkpoint-3']
INFO:transformers.configuration_utils:loading configuration file /home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_e2d857c2_2020-02-03_22-38-31tt6w1cdx/outputs/checkpoint-3/config.json
INFO:transformers.configuration_utils:Model config {
  "architectures": [
    "AlbertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "down_scale_factor": 1,
  "embedding_size": 128,
  "finetuning_task": null,
  "gap_size": 0,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "inner_group_num": 1,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "net_structure_type": 0,
  "num_attention_heads": 12,
  "num_hidden_groups": 1,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "num_memory_blocks": 0,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 30000
}

INFO:transformers.modeling_utils:loading weights file /home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_e2d857c2_2020-02-03_22-38-31tt6w1cdx/outputs/checkpoint-3/pytorch_model.bin
HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=602.0, style=ProgressStyle(description_width='initial')), HTML(value='')))
0.0011490.0013990.0008550.0005640.0042000.0117440.0785480.1958860.0260920.1226870.0575290.0080140.7050220.0608900.2063360.0212260.4279160.0301740.0018480.1305180.7386350.0417050.0021640.0044490.0131370.0021900.0006610.1246480.1591060.3036630.0102950.0005150.0001530.4419690.0155670.2644940.0102490.0153190.6618060.0177900.0016090.0011620.8836231.9838800.3518600.5181041.3389510.4559710.0515810.3065790.0186430.4095060.1255370.0029430.0003310.0002370.0657360.0017910.0018400.0002890.0776790.0013820.3973710.0066910.3623810.0061300.5788540.0088160.5490000.2372480.0035190.0001690.0418870.3266920.0320080.7318940.1690720.0093560.0015760.1471540.0550240.0008930.4766600.0066500.0004070.3216260.0039660.0001800.0001820.0106580.0010350.0187010.0003200.0169970.0007040.0001840.0038370.4109350.0069440.0012100.0002880.0017600.0033370.2851970.4989710.3849130.4397430.0063050.0003080.0003400.0011671.3684740.5331620.0051240.0020480.0003770.0429280.0367060.3533240.0293420.6541751.9953661.4104090.1823380.0016460.0003740.0001410.0003100.0016700.0034860.0055730.0037780.0011170.3561221.5504750.0220121.1508730.4504180.7718150.6057820.0112230.0003500.0002280.0004080.2467330.2668100.1530610.0050220.0631620.4995910.0121810.0086860.4184870.3169780.0024231.0656240.0070320.2175040.0203880.3556951.8256090.0123741.2468471.4026300.0194520.0008130.0009030.0011760.0001820.0011750.0833180.1792380.0084860.1364310.0047750.0003750.0026920.0234490.5739440.5504850.9918460.0173182.9508151.1394780.3481710.9145280.5545720.7394690.9318740.6313521.2376900.0688620.0010530.0008650.0335460.1091650.0258940.1266530.2740220.1524950.8320500.0090960.0025680.7595590.3203281.8012220.4327150.0046860.0667340.0024930.0007200.4811090.0041030.0006310.0002470.0001280.1922570.0009820.0001120.0025480.0671700.0776180.0304930.4912870.6909900.1846850.0018120.3614060.3346690.0087071.4070781.6688590.2070430.1221490.0135110.0005520.0002170.0001100.0002420.8307310.5269300.6678240.3335190.0565600.3960490.2933030.0016240.0003490.3201130.7604660.0223520.0696450.0042880.0027000.1533750.9691140.7708430.0091910.4365990.2949850.0020940.3915930.3608310.2432320.1426120.4815580.0655750.1227530.0209830.6671280.8782670.3778360.0150020.0020030.1247200.7347920.4598450.1326410.0006221.0193810.0038640.2674800.0012370.0050520.0001790.0890820.2944030.2247960.0050550.7876520.1758030.3319851.1467510.4065340.7583140.7008350.0038560.0006140.0008570.0086480.0087140.0662890.0006020.1442141.3375021.5637360.3207150.0025970.0056210.0014450.1388640.0095480.0008880.2175040.3461870.4529500.0017930.0013540.0304462.3127072.8609261.3273370.0653890.0758380.0017310.3712350.5859731.0077823.1492640.0736060.0392900.2994080.0853270.2815890.6220400.3475011.4077960.9279410.3734213.0316690.1762880.0144490.0027900.0457470.0051950.0014850.0005020.0059400.0797400.2745200.0591850.2724852.7265250.2463760.0314790.3874340.1607810.1938020.0015530.0240800.2871001.2012094.1440315.2290312.0548521.6153391.2737090.0043171.0352180.3960310.1843681.4468310.0086330.7767611.2023262.3619091.7913891.5652120.6801020.4391600.0018790.0008490.0004300.0005820.0002170.4369120.7950270.0223460.1651573.3527480.0101140.2207380.8250660.1147350.4131270.0325610.4718930.4744201.9965560.9499040.9804610.4702260.1558810.1168810.0045710.4484191.8258272.2282761.2002540.0043780.0004340.4119530.8175390.0022673.5312710.3147561.0880301.7796602.9178580.2761650.2691720.0066080.0006070.0011950.0151250.0018380.0007111.1157210.8472580.1957190.0010670.0007810.0010040.0006290.0465810.0006340.0004350.0661710.0006200.0002860.0003430.0005250.0023720.0004040.1395210.0039210.0014180.0030520.0007880.0008290.1965740.0105000.0710170.5088260.0034620.0086080.1738690.3966920.0025770.2170591.2951520.4477340.0017830.0010350.0021760.0008680.0003360.0005370.0014180.0001350.0003130.0002350.9098950.0046190.0031620.0008930.4775670.9972500.0106490.4373450.0017600.0100790.2008760.2875490.1593840.0108440.0093050.5644690.5352360.1981620.0032160.0045800.0283070.0057760.0011240.0001450.3843880.0043740.3496430.0017460.0017400.0050300.2568980.0053200.0003960.0676260.0007040.1433350.6329191.7030920.9445971.5484260.7127550.8329450.0074060.0036020.0035140.6008521.1158821.0027040.7471990.4798390.9981251.2843970.1227500.4748740.3069110.1638491.5989681.2728150.1780200.0026430.0129720.1727570.4230090.0379020.0946030.3563330.3210230.0048630.3514670.0015890.0008320.5029250.0615810.0031340.0009480.0027990.6066360.0012790.2112590.1199840.0226370.0012330.1086610.3528690.0007900.0002060.0203910.0024640.2110840.4747880.8767830.7942680.5417800.2293050.0078620.2910910.6273570.7859130.3548421.5145821.4050251.4014700.4774690.0179930.4107730.3143970.1539960.3506190.0043570.0126090.0014580.0012580.0009670.0026121.3432910.0099390.2602550.6033730.7543340.5579910.2992670.3862541.1088350.0081400.3269430.0962370.0009260.0513170.4401790.001305

*******************************************
EVALUATING PIPELINE 
Pipeline directory: /home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_e2d857c2_2020-02-03_22-38-31tt6w1cdx/
With following parameter combination: {'batch_size_seq_length': 3, 'lr': 3e-05, 'lr_type': 'constant'}
EVALUATION OF CHECKPOINT /home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_e2d857c2_2020-02-03_22-38-31tt6w1cdx/outputs/checkpoint-3
-------------------------------------------------------------
|           |   agree   | disagree  |  discuss  | unrelated |
-------------------------------------------------------------
|   agree   |    527    |    46     |    175    |    20     |
-------------------------------------------------------------
| disagree  |    31     |    46     |    35     |     7     |
-------------------------------------------------------------
|  discuss  |    182    |    59     |   1539    |    114    |
-------------------------------------------------------------
| unrelated |    22     |    11     |    51     |   6757    |
-------------------------------------------------------------
Score: 7048.25 out of 7516.5	(93.77037184859975%)
Accuracy: 0.9217418416129702
F1 overall: 0.7082893458200702
F1 per class: [0.6888888888888889, 0.3274021352313167, 0.8332430969139144, 0.9836232622461606]
*******************************************


*******************************************
EVALUATING PIPELINE 
{'batch_size_seq_length': 1, 'lr': 3e-05, 'lr_type': 'constant'}
INFO:__main__:Creating features from dataset file at /home/ubuntu/fnd_implementation/data/processed
  0%|                                                  | 0/9622 [00:00<?, ?it/s]  0%|                                        | 1/9622 [00:01<3:38:46,  1.36s/it]  5%|█▉                                    | 501/9622 [00:01<2:25:11,  1.05it/s] 21%|███████▋                             | 2001/9622 [00:01<1:24:55,  1.50it/s]100%|█████████████████████████████████████| 9622/9622 [00:01<00:00, 5183.19it/s]
  ******************************************* 
              Running Evaluation                
  *******************************************
 
  Length dataset evaluation: 9622
  Length dataloader evaluation: 2406
  Number of epochs: 3
  Batch size: 4
  ******************************************* 
 
['/home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_e226a48c_2020-02-03_21-19-44qituzjrx/outputs/checkpoint-3']
INFO:__main__:Evaluate the following checkpoints: ['/home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_e226a48c_2020-02-03_21-19-44qituzjrx/outputs/checkpoint-3']
INFO:transformers.configuration_utils:loading configuration file /home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_e226a48c_2020-02-03_21-19-44qituzjrx/outputs/checkpoint-3/config.json
INFO:transformers.configuration_utils:Model config {
  "architectures": [
    "AlbertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "down_scale_factor": 1,
  "embedding_size": 128,
  "finetuning_task": null,
  "gap_size": 0,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "inner_group_num": 1,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "net_structure_type": 0,
  "num_attention_heads": 12,
  "num_hidden_groups": 1,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "num_memory_blocks": 0,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 30000
}

INFO:transformers.modeling_utils:loading weights file /home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_e226a48c_2020-02-03_21-19-44qituzjrx/outputs/checkpoint-3/pytorch_model.bin
HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=2406.0, style=ProgressStyle(description_width='initial')), HTML(value='')))
0.0201290.0321160.0432720.0187510.0096480.0064360.0022540.7140300.0957980.0350080.0059020.0053220.0070380.0025840.0030140.0069510.0064430.0020250.0075720.0026470.0087940.0032350.0062000.0026380.0055670.0088460.0186210.0012141.4356230.0802690.0341550.0223990.0803050.0202261.3640380.0502070.0218960.0152630.0172620.0012720.3736362.0529740.0620600.0106220.0354120.0023320.0076800.0011020.7146610.0152623.3552470.1580210.0036820.0016610.0009300.0006640.0008870.9895200.0192060.0009030.0099400.0005540.0040270.0010020.0004710.0027550.4444490.0076820.0046970.0040170.0014120.0063920.0004120.0006470.0010960.0012910.0015090.0026640.0034320.0026861.4495330.0224450.0021880.0012900.0012680.0034450.0021510.0019790.0142921.2163300.0159120.0019790.0075580.0023560.9140910.0099721.9576990.0510910.0019740.0027300.0044200.0012000.0046420.0041890.0065850.0038140.0137060.0007161.5512260.0416270.0236520.0333240.0623710.0196050.0499010.0219630.0294671.1742460.1062950.0277980.0011750.0020600.0004790.0120210.0022880.0026680.0087030.0059200.0014200.3821670.0036400.0010790.0045710.0158020.2282960.0089690.0006200.0009190.0012770.0068960.0012100.0017680.0010320.0018841.1120000.0096870.0007630.0005430.0007950.0142800.0010610.0005491.0094761.4076040.0182420.0370860.0091710.0060411.1712910.0163890.0057520.0111750.0072270.0159750.0053450.0035361.1759980.0198410.0098060.0118380.0032482.6406351.4000941.3426720.0215911.3664720.5710840.0054670.0077670.0003760.0003440.0020141.4997570.0086880.0053350.0052873.5946961.4316230.0125400.0068782.0374720.9561970.0196681.2524560.5177520.0364480.0074380.0432510.0138740.0343380.0406820.0191020.0195530.0118190.0121510.7465350.0249260.0161820.0161341.2260330.0246840.0070650.0178270.0387931.3655640.0162730.0417770.0136880.0064390.0158760.0026600.0383680.0511230.0324860.0253990.0548830.0281781.0414230.0217200.0152140.0046000.0025830.0183830.0097140.0023740.0170150.0183300.0172880.0463470.0170160.0091880.0018000.0600250.0290520.0394720.0029770.0006890.0007960.0007271.0795440.0049060.0008070.0025090.0040530.0071070.0220551.2298970.0067710.0022400.0099320.0083990.0029680.0004520.0011191.1797852.0661991.0317970.0042330.0005410.0003520.0005130.0010790.0040381.0050370.0118221.3712490.2714350.0017130.0008840.0003380.0078830.9050870.0096520.1598130.0054620.0117870.0106870.0045620.0039781.4120030.0124821.3973620.1827690.0021810.0090022.0884030.8684120.0629050.0092360.0101540.0007371.0153111.0693040.0577800.0236010.0081981.1449560.0123170.0151510.9901720.0183660.0036500.0263290.0023050.4389990.2334030.0116750.0097530.2614670.0020840.0022212.4064170.0103491.4753010.0254360.0279050.0519600.0491150.0344770.0482321.6357220.0120960.0116800.9546280.0101190.0058420.0072840.1088550.0190760.0064450.0271710.2586650.0046220.0133800.0212650.0095250.0082830.0096020.0048500.0082510.0048170.0042080.0099580.0033190.0100740.0103540.0144570.0063670.0028130.0067570.0120580.0027830.0040750.0083620.0035050.0036850.0097200.0115670.0248120.0021650.0074520.0108080.0074530.0060500.0104270.0039370.0123360.0048620.0432030.0113020.0042570.0058530.0070090.0061110.0050910.0046010.0007301.4633490.0074660.0043010.0016231.9761770.0064290.0029050.0010740.0020020.2010770.0009710.0008330.0008360.0004670.0004550.0004520.0005440.0004530.0953620.0009360.0004320.0011080.1267370.0010100.0005720.9521800.0032170.9103580.0032830.0006061.0439331.0423170.0030181.0434240.0088900.0051991.4207941.4466130.0055180.0027160.0313670.0031850.0062790.0017810.0026870.0016050.0029190.0151450.0150750.0359780.0088460.0309910.0060650.0115860.0028180.0102770.0120820.1785490.2427110.0063470.0304830.0061140.0169141.6599980.0100540.0238850.0160850.0062240.0019190.0006190.0012510.0006520.0013390.0006930.0010230.0009850.0025720.0075660.0125190.0003943.2623840.9973200.0030930.0059710.0053280.0030281.2416200.4543820.0029200.5527511.6443080.0101770.0013430.0006660.0126491.1264181.7851021.0397931.2463990.2774440.1387600.8592821.0431161.1010300.0797360.0074600.0039500.0012560.0017190.0081150.1008780.0244860.0050260.0023700.0170270.0044170.0057260.1159310.4063590.0028370.0092750.0041460.0030490.0103830.0070880.0241460.0096641.0637950.0026330.0018220.0106880.0080890.0095020.0004660.0294010.0098750.0014420.0017440.0105560.0008480.0101480.1692270.4997490.0129290.0008620.1597760.4031620.7309740.1669320.1003710.4953990.0080351.0886570.0029410.0032470.0043460.1080890.0028870.2395650.2806711.5630701.6512320.0093620.0596140.0886130.0223000.0193361.4123651.5119501.5527770.0274300.0157510.0150770.0249990.8272580.0134540.0115960.0035940.0045060.0084640.0032320.0025960.0154780.0052660.0080530.0141070.0059320.0044300.0012160.0064130.0004500.0056210.0090900.0004280.0119690.0020680.0005170.6403750.0036911.3095000.0074310.0762230.8395510.0106350.0047580.0115150.0024090.0084861.9732020.0049420.0040300.0247461.4072870.0119590.0152760.9651032.7249561.0868660.0171060.0074820.0150310.0155600.0060880.2383613.1743800.0482240.0956861.9886250.7393290.0124240.0165170.0294720.0306941.4472570.0363190.0227271.4112400.0205480.0189140.0149260.0175391.4284520.0148100.0373760.0104660.0409200.0145450.0326801.2460220.0494890.0308410.0147640.0352060.1888162.4462501.3585940.6243470.0068990.0061870.0112000.0003320.6490670.0019350.0055940.0057860.0032990.0048500.0021210.0011970.0031310.0051850.0058500.0075810.0053450.0026290.0041980.9742560.0057580.0017360.0077250.0010670.0247460.0010300.0045620.0044510.0027460.0024910.0046960.0029290.4666980.0071440.3014560.0116140.0009090.0007970.0032570.0005170.0005310.0007080.4381980.3646160.0834900.0005360.0044040.0611400.0368470.0217330.2681560.0643550.0110510.0002420.4592750.0205760.0033190.0037680.0006110.0019271.3071650.0037020.0039470.0049330.0190950.0047111.2067060.0059841.2567560.0370380.0033070.0188460.0017781.7636460.0030030.0009891.3339430.9091780.0045130.0057350.0021480.0017790.0023140.0022611.1641420.0210771.3595733.1560910.5415110.0045673.3539740.0072380.0003881.0495710.0052571.4183300.0939790.0025571.0907391.2659070.0059291.6593630.0067560.0023100.0101590.1969740.0218620.0006330.0320070.0320631.1431950.0023582.2552670.0039101.3887970.0039172.9985100.0046700.0003900.0003760.0010740.1927330.0065410.0063410.0163040.0123420.0059720.0065150.0060230.0060970.0060110.0061240.0058681.0963540.0019380.0022190.0026960.0129230.0012070.0009620.0033620.0087840.0046210.0102300.0059231.0170490.0034021.0097150.4633030.0107240.0038960.0077610.0062120.0033260.0102860.1929221.6928883.4079073.1480910.0124410.0190221.2895081.0975600.0034280.0017151.3275960.0025110.0266201.2743800.0059400.0006951.3163450.0024641.7496660.0101930.0005550.0265911.2590783.1856752.8607530.0038581.5380750.1456520.0224100.0004910.2708130.9883880.0116201.1706660.0088851.2097660.0102950.0160110.0029550.0137290.1287990.0009670.0114480.0013670.0006870.0006981.2630350.0031870.0674440.0115450.0077580.0229700.8165860.0150310.0083670.0369180.0226640.0106450.0075030.0026230.0006740.0007170.0004680.0003990.0008250.2158330.0005990.0755070.0052580.0004580.0004100.0004940.0002900.0218680.0325660.0006180.0007870.0005830.0003070.0112360.0032250.0004170.2808754.0256790.0128200.0047920.0086940.0428340.0245280.0220120.0282430.0031270.0012730.6437101.1316001.3224770.0068150.7925920.0024182.5650432.1245180.0980420.1957551.3189850.0079560.0088460.0080280.0091951.0456460.0052400.1078121.0050300.0046440.0009330.0007620.0057110.0022160.0043870.0026610.0024920.0029070.3025960.0435590.0125220.0197650.0195160.0057560.5621270.7890230.0196570.0174550.0104300.0187790.0004440.0101650.0217330.0108050.0209590.0184070.0017130.0030760.0019640.0024400.0107040.0452590.0220890.0274460.0420830.0109710.0060230.0246590.0023110.0036650.0028930.0077710.0030240.0136611.2859800.0016140.0003561.6087840.0913540.0029281.7683410.0025570.0040300.0087480.0018570.0095910.0007350.0019160.0143930.0075660.0004640.0048510.0019223.2118253.1843283.1895491.8247514.2023273.1969084.9761131.2006981.1823800.0111610.0004810.0004930.0008140.0083310.0008890.0006190.0018990.0003991.0765280.0019330.0010161.0777341.0391500.0020182.0645220.0071600.3299080.0071880.0040760.0078401.4535490.5297450.0647640.0140781.1926970.9888010.6180660.0233740.0541660.0662070.0058730.0038690.0045682.1389220.0040960.0114471.4772810.0068234.0134122.3807280.0134260.0010610.0011710.0090050.0039080.2312530.0094320.4254281.3288000.0543120.7176740.0611902.4277680.0066150.0059250.0058840.0058830.0041540.0203270.0110790.9166390.0021940.0094900.0007832.1980640.0315890.0005491.1058001.2050530.0017360.0929360.0008061.1294890.1004250.8885221.3898781.4776270.7960490.2007760.2133570.8962930.0102910.0054660.0076280.0504430.0007450.0092130.0096570.3667740.0086460.0005761.1291910.1900120.0361452.2502081.1306042.4297012.2843720.9224443.4434031.7815881.9731120.0056290.0069970.0388991.7437221.3643661.1075670.0064620.0016760.0068741.7486380.0025811.3933570.0099080.0091631.7983280.0513210.0075650.0174440.0033650.0003410.0059930.0059510.0059382.7432740.0050640.0058700.0018280.0039830.0020181.3886661.3770982.7613250.0062040.0027870.0025740.0031610.1247361.3979970.0018300.0269630.0003120.0081400.2706900.0037040.0096980.1925930.0017490.2442820.2445480.0021470.0077460.3594890.0020640.0127100.0248200.0378250.0004440.2406580.0132250.0167461.8885980.0835151.3660190.6633480.0899500.1496460.3964571.2740260.0016462.7133801.3520852.6965530.0065050.0055751.3545411.0617010.0194190.0038580.0265130.5426310.0102140.3868130.0025830.0014634.6746050.0352261.7566900.0066110.0033500.0235740.0057871.7288790.0214691.6778860.0052451.4744290.0024070.0075840.0072950.0023180.0017360.0009270.0018450.9502570.0020460.0154060.0005680.0004380.0004610.0003621.2701940.0014770.0071310.0004520.0009110.0006754.1248822.4100851.1751102.4412860.0063140.0004600.0004980.0004520.0050980.0099050.0007550.0004950.0008870.0018100.0093190.0022853.2963872.7513841.6261200.0070150.0086460.0269532.0720110.0089690.0072800.0005860.4630760.0077950.0005350.0143090.0004370.0006350.0005500.0008510.0008860.0140410.0005600.0004830.0094661.0994200.0265970.0162810.0517160.0104140.2481911.4450500.0330680.0128770.0263140.2777290.0695290.0137780.0078240.0112710.0181061.0990400.0078790.0110780.0065990.2138470.0064130.0737570.0081420.0069450.0250150.0006820.0899570.0005430.0015710.0072980.0004421.0802670.0012631.1366660.9850540.9027630.0162730.0238820.0160051.6652542.1284381.6302893.0151760.8315240.0069460.0060100.0062810.0063800.0061331.7665870.9730150.0066190.0059520.0057560.0058320.0078090.0060320.0079440.0238670.0169210.0020580.0150550.0046020.0102010.0064130.0051510.0034980.0096160.0165291.8872541.4377743.2233021.1659920.0065540.0007190.0005980.0205040.0012380.0025200.0007680.0028760.0023320.0222950.0024520.9707490.0075131.0550520.0133740.0292551.9272950.0316740.8897840.0069342.6410910.5918821.2302890.5930860.1525660.0178760.0027470.0030810.0050610.0032720.0735640.0476300.0168520.0037370.0027490.0085130.0038180.0048181.0282760.0078554.8933244.0721846.1364866.5161953.5115030.0029590.0103950.0191470.1598470.0024500.0003150.2845810.0018310.0101590.0004830.0386710.0068550.0073930.0025060.0826580.0008000.3425680.1778380.0056620.0039780.0004380.0079820.1240920.0004980.0007110.0374280.0104220.0004040.0102050.1844470.0049501.4542260.0056250.7285290.8571930.9196511.1457381.1377540.4863761.0551020.0135470.0210570.0155301.8775450.0159722.8091462.7477305.5488012.6881103.0501572.8514400.0096251.0570551.0527120.2356590.0004230.2635910.0005570.0077160.0009921.1295550.0140840.0004940.0688130.0062140.0071620.0068010.0073180.0096341.0198750.0079520.0077040.0087290.0113070.0076660.0131220.0073540.8545450.0013870.0092291.0803080.0037750.0024920.1690570.3858203.6858550.0035370.1271270.0036721.5587190.0078310.0094370.0112870.0063610.0012660.0036880.0067070.0031330.0067760.0044910.0045970.0047120.0074763.8328910.3620680.0060160.0058510.0057410.0058240.0081970.0029410.7045401.1167770.1296160.0040950.0254550.0124320.0024200.0054870.0024970.0172780.2752280.0087721.0239821.8709820.0060700.0507140.0199600.0066810.0029360.0010840.9808100.4596360.0400671.9275711.7824571.3919652.2253141.1660621.6684971.8207531.8278441.8244191.8257550.9236671.0225240.0095870.6796331.2144791.0516230.8896390.8571190.8799501.0137811.4058362.4531770.0089580.0063500.0062000.0063520.0079790.0077240.0065940.0057280.0071200.0127590.0070910.0116670.0193620.0243820.0168610.0037820.0024340.0077310.0186690.0021800.0072700.0012600.0024120.0062030.0027911.3999820.0021021.7790640.0027311.3606410.0019810.0032840.0026230.0071451.4247021.8334140.0038051.4366763.5175015.1559045.5770274.1592660.0063230.0133220.6160261.3952481.1104840.0042160.0018750.0770010.0492470.0072891.2906110.0204721.3459450.0186910.0049270.0106120.0066700.0117641.3510590.0068610.2713650.0300090.0091211.4689202.5845862.1850550.0109420.0020301.3379160.0052300.0027231.7758110.0085041.7733273.1519270.0061521.3868611.3918070.0031011.3632620.0027644.2773320.0089860.0100970.0948711.7251850.0145810.0052240.0019150.0123560.0034300.0035690.0080111.0712720.0027052.8372821.1717250.6285900.0037020.0208520.0152540.0218740.0120141.4044260.0264772.7828171.3995730.0143061.4062491.3952405.8660924.8726435.8895734.9486544.5152990.0090120.0336000.0152780.0105431.2097130.0187360.0147190.0064600.0110900.0094510.0103340.0006040.8771460.0022340.0020491.9210640.0024610.0017240.0008500.0107380.0023470.0067022.8460243.3178351.2769390.3501311.0251870.0017461.0571060.0014950.0007152.5719270.0061742.8128842.1510381.9851921.9668870.5101523.0966723.1130072.0016240.0019520.0207940.0076851.1389280.0025501.0379240.0014370.0004841.6724952.7652980.0028060.0006520.0007890.0006750.0009900.0008530.0073960.0074120.2261060.0073510.0229330.0281630.0075050.0207450.0092870.0085370.0067590.0131130.0087120.0154720.0058930.0066680.0049820.8295382.0039160.9586722.3731861.5695010.7330350.3464162.7432422.0568732.4290981.2546680.0114300.0163450.0273970.0052371.3620810.0125230.0231760.0308110.0067230.0046240.0045550.0088580.0062670.0100900.0671580.0144331.3556980.0099760.0045670.0171390.0277260.0034050.0408930.0066320.0067300.0031740.0159600.0058450.0048990.0098130.0040730.0025431.0272450.0043080.0615240.0041670.0091940.1003090.0226170.0050700.0189360.0012960.0058700.3391240.0019230.0051430.0175740.0126150.0059760.0139530.0121130.0085380.0516590.0032190.1433350.0009700.0082070.0105810.0184080.0022931.3536740.0023420.0072990.0190590.0034280.0016950.0036890.0010360.0006410.0116340.0009750.0178500.0168490.0014850.0008730.0024870.0083060.0080060.0008220.0540970.0007960.0006860.0008260.0276420.9747970.0079210.0282150.0143601.0690261.3147121.9777901.9119130.0790941.9255880.9855720.5584810.0251900.0133480.0315750.0091820.0103900.0161720.0219820.2434250.0175120.0179621.9309000.0142950.0012830.0196170.0182170.0125040.0043240.0028660.0059910.0057700.0061900.0058300.0066704.0410631.7591454.1910433.5546842.8137912.7161962.1634162.3812450.0076550.0059870.0056810.0061840.0204670.0054991.2823200.0144530.0103530.0060440.0170540.0094400.0061380.0110780.0339630.0349010.0163090.0021710.0009930.0009360.0008870.0032190.0035830.0032230.0055910.0017690.0008600.0007460.0015130.7220200.0011090.0016160.0093340.0007201.6115800.0033630.0011500.0006170.0008410.0006500.0021010.0019832.0604640.0170611.6012500.0128400.0066260.1238370.0051500.0072300.0087670.0507510.0085910.0062020.0064010.0175540.3901780.0134850.0476760.0081080.0290070.8065592.0155343.0353231.2978163.8512680.5748510.0087710.0029740.1324390.0352540.0651880.0058010.0094740.0726330.0998640.0011710.0154750.9984320.0010542.0123620.0023510.0028573.4178980.9072730.6280740.0009322.0659880.9233381.5946201.2333791.4438471.2468351.1133532.4506752.3686710.9974492.7121970.0115552.2506250.9243450.0061390.0044321.4183631.4160000.0080562.8998302.3459320.0182960.9264732.0223571.0072540.2509810.0366460.0024680.0141990.0587850.0056250.0120090.0049750.0226130.0167990.2214070.0173860.0217270.0045120.3694470.0158740.0095110.9121411.0839740.0329640.0041040.0009680.0026930.0037630.0007910.0017550.3720010.9089500.0599160.0681130.0478030.1772090.0042010.2893200.4393110.0399861.4117930.4761790.0014190.0032580.0061070.0065520.0074790.0060650.1416890.1418710.0063471.3062871.3527560.0045421.3369891.3625022.6371613.0645721.3651101.3633910.0061420.0036380.0190150.0036970.0165810.0113750.0033960.0047200.0076130.0309260.0354370.0052940.0046690.0108401.2012852.4653610.5836360.0160910.3110520.0064400.0872820.0062130.0022143.8058620.2140100.0019810.0017170.2515460.8027640.0019712.3400900.6777410.0010540.0008970.2648270.0055050.0109030.0049490.0006060.0155132.5605850.0084790.0045180.0059850.0315870.2171790.0014320.0033050.0103870.3304040.0153680.0078300.0055220.0115290.0019732.9517502.4423950.0271372.0799901.3960040.0213412.3195592.0360550.8997120.0455210.0195530.0213500.0185520.0129631.3920500.9587471.6535832.6341630.0205870.7791060.8287932.6727623.0132580.0169130.2620182.0366760.2900250.0099910.0149891.2312040.0068000.0060481.2898020.0010180.0077370.0147240.0022380.0011590.0092320.0007980.0009660.5380340.0103090.0073840.7696941.1255270.2141610.0009140.1209701.0289081.0917840.0012632.3013040.0706810.3977710.0131260.2415171.4296751.4587200.4018310.5478560.0152630.9488440.0881120.8739621.1620441.7775680.8987273.6307540.4087890.8905050.0158260.0031040.0250400.0002400.8832491.0954700.0099720.0143402.2818700.0074440.0067670.0069821.3226222.6402852.7578653.9436310.0047671.3316460.0084140.0003890.6473540.3053581.6075310.0119440.3440710.0025180.0043230.0058360.0101960.0209840.0166990.0030970.0041380.0026140.0075591.5610710.0057870.0078510.0737740.0053950.0070700.0056360.0066000.0073340.1419600.0057220.0046010.0054850.0007020.0016040.0005020.0046320.0007090.0007490.8503080.0014150.0003240.0091790.0004390.0010420.0040400.0013030.0074490.0321100.0022010.9522910.0014940.0004440.0006890.0075950.0167400.0003340.0064010.0040990.0926650.0006790.0011220.0040090.0051470.2637370.0071191.2972870.0206740.9601120.0013060.0012810.0009470.0084490.0006870.0020240.0009810.0026890.9141530.0030622.1763400.0089610.0012460.0010360.0013060.0078541.8779870.0026700.3747990.9251680.0009560.0092730.2706070.0059950.0504530.0051900.0043900.0043970.2952470.0320570.0111231.3451021.4026362.7824455.5356554.1831091.1400600.0097210.0003520.0229800.5828090.0073540.0071350.0099890.0058811.3213890.0020720.1404420.7675140.0103880.0188260.0007423.0073060.0303730.0337471.2988860.0539013.9262400.0048021.4040262.8210741.2282931.4401950.1049700.0208034.4787222.9149122.8442810.0047623.7149431.5651101.8259300.0067010.0078210.0005320.0021011.0572560.0012080.0054520.0032841.2838840.0203750.0620831.3558190.0320910.0219510.0193281.1002560.0192490.0307890.0252620.0121091.2387600.0185770.0163171.1763700.0244130.0057980.0301570.6794780.1340080.0078230.0135240.0074170.0057230.0128590.0169590.0148100.0055780.0196940.0144880.0127630.4555120.0285151.2448250.0321480.0172960.1114251.0036550.0025191.8244670.4758540.5482451.0072450.0017003.5276843.2446991.2727312.2624351.6024192.4669370.0067252.9122971.2382161.0685221.8286500.9405711.1250423.0336020.0293412.1742731.1241660.0242991.1441890.9607630.0279795.9018355.2323695.5904431.4191881.5392220.0093430.5575690.0228973.1902890.0160480.0179020.0351210.9050430.9075910.0171201.0097490.0077160.0128580.0045420.0061581.0846010.0081040.0039930.0079070.0094870.0006860.3294600.0078280.1988360.0081160.0006700.0153350.0006141.0169990.0085230.000626

*******************************************
EVALUATING PIPELINE 
Pipeline directory: /home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_e226a48c_2020-02-03_21-19-44qituzjrx/
With following parameter combination: {'batch_size_seq_length': 1, 'lr': 3e-05, 'lr_type': 'constant'}
EVALUATION OF CHECKPOINT /home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_e226a48c_2020-02-03_21-19-44qituzjrx/outputs/checkpoint-3
-------------------------------------------------------------
|           |   agree   | disagree  |  discuss  | unrelated |
-------------------------------------------------------------
|   agree   |    363    |    53     |    138    |    34     |
-------------------------------------------------------------
| disagree  |     0     |     0     |     0     |     0     |
-------------------------------------------------------------
|  discuss  |    344    |    91     |   1557    |    131    |
-------------------------------------------------------------
| unrelated |    55     |    18     |    105    |   6733    |
-------------------------------------------------------------
Score: 6944.75 out of 7516.5	(92.39340118406173%)
Accuracy: 0.8992932862190812
F1 overall: 0.5766797936951289
F1 per class: [0.5377777777777778, 0.0, 0.7937802702013765, 0.9751611268013615]
*******************************************


*******************************************
EVALUATING PIPELINE 
{'batch_size_seq_length': 4, 'lr': 3e-05, 'lr_type': 'cosine'}
INFO:__main__:Creating features from dataset file at /home/ubuntu/fnd_implementation/data/processed
  0%|                                                  | 0/9622 [00:00<?, ?it/s]  0%|                                        | 1/9622 [00:02<7:57:11,  2.98s/it] 21%|███████▋                             | 2001/9622 [00:03<4:24:36,  2.08s/it] 83%|████████████████████████████████▍      | 8001/9622 [00:03<39:23,  1.46s/it]100%|█████████████████████████████████████| 9622/9622 [00:03<00:00, 2539.07it/s]
  ******************************************* 
              Running Evaluation                
  *******************************************
 
  Length dataset evaluation: 9622
  Length dataloader evaluation: 301
  Number of epochs: 3
  Batch size: 32
  ******************************************* 
 
['/home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_e55e89d1_2020-02-04_02-36-598m93g___/outputs/checkpoint-3']
INFO:__main__:Evaluate the following checkpoints: ['/home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_e55e89d1_2020-02-04_02-36-598m93g___/outputs/checkpoint-3']
INFO:transformers.configuration_utils:loading configuration file /home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_e55e89d1_2020-02-04_02-36-598m93g___/outputs/checkpoint-3/config.json
INFO:transformers.configuration_utils:Model config {
  "architectures": [
    "AlbertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "down_scale_factor": 1,
  "embedding_size": 128,
  "finetuning_task": null,
  "gap_size": 0,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "inner_group_num": 1,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "net_structure_type": 0,
  "num_attention_heads": 12,
  "num_hidden_groups": 1,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "num_memory_blocks": 0,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 30000
}

INFO:transformers.modeling_utils:loading weights file /home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_e55e89d1_2020-02-04_02-36-598m93g___/outputs/checkpoint-3/pytorch_model.bin
HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=301.0, style=ProgressStyle(description_width='initial')), HTML(value='')))
0.0010210.0013450.0024440.1468910.7785790.3297310.1431950.0231270.0346530.0043210.2089270.0206000.0122930.1561310.0447880.0033790.2440650.1925150.0770500.2451660.2030790.2040380.2340540.7106720.1798770.0581950.0027810.0004450.1355950.1251510.0098090.2461140.2052160.5665300.2725520.0080410.3898960.2295280.0390530.0020920.0463800.2406210.1901370.0046920.0004600.0007030.0005780.0003010.0701520.0033450.0004260.0358450.2805060.0797450.0020370.0881120.2037170.0040820.0968020.0529700.5568720.3761370.0065330.0004990.2273970.0354030.1354350.2908360.2970770.1848810.0104970.0006320.5276860.1408930.2737740.0282000.4377840.3928860.1335210.0025470.0821780.1339900.0072840.0967950.0032230.0015190.0071790.0193850.0017870.0862070.1129261.4792520.4757980.6076770.5901080.2387000.0035570.0012630.0260530.0514400.3114500.0509410.5693180.1537860.1115020.2288440.0141830.0014630.1270420.0022610.2403170.2230700.2484800.3016310.0711990.5999680.2680440.0913650.0012090.3266290.1185860.3927942.1343620.0177110.5223250.0093310.0064660.1656870.3003320.2091950.0123950.1889050.1592970.0256900.2537530.7293530.0146270.1506450.1964970.4250040.1579640.0039170.0625610.1617460.4953570.1761070.3046680.2263980.1760320.0709910.0683560.0878061.1296860.0253800.0030620.0884050.0189090.0350410.0011881.4504121.7144460.2194960.0296940.2333031.3569940.0464560.0313300.0602410.0449950.4130280.0577120.1197800.0355070.1482440.1742080.4237391.3974600.1016000.0964870.0208190.6635163.5369840.8359850.1301530.4327540.4991670.3855311.9394761.2464820.4711470.2019160.0536190.0319590.2517770.1463110.0163190.3266280.3864120.4670461.0542670.7011630.0848490.1343600.8693030.3206690.1216240.0938860.6710791.5518491.5452930.1761930.0567540.0034930.4058120.4871340.0034710.0013000.0391860.0835760.0014380.0016940.0095360.0616440.0028180.0011620.6225210.1668620.0157040.2548420.0637500.5740890.0189350.0091960.0012390.0028630.0057120.3702530.0031791.1096610.1456410.0195610.2192910.0901930.4485290.9716310.0906680.1484550.0018140.0945730.1389960.0103520.1240860.1797530.1081181.0058781.0244990.5585850.0296740.3509490.2313250.3475361.8740240.3399510.0233640.4019330.2762010.2133210.2092970.6715370.1473830.1226250.0200210.0023390.0013010.1856340.0776060.0340620.1251280.0008400.0164650.1888181.1074780.4485040.2397860.2327000.2760261.5228100.2276140.3896650.1322940.0011220.0011670.0133840.4571080.2187760.4361630.4120700.0071060.0022710.0028790.003224

*******************************************
EVALUATING PIPELINE 
Pipeline directory: /home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_e55e89d1_2020-02-04_02-36-598m93g___/
With following parameter combination: {'batch_size_seq_length': 4, 'lr': 3e-05, 'lr_type': 'cosine'}
EVALUATION OF CHECKPOINT /home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_e55e89d1_2020-02-04_02-36-598m93g___/outputs/checkpoint-3
-------------------------------------------------------------
|           |   agree   | disagree  |  discuss  | unrelated |
-------------------------------------------------------------
|   agree   |    550    |    68     |    196    |    22     |
-------------------------------------------------------------
| disagree  |    18     |    41     |    25     |     0     |
-------------------------------------------------------------
|  discuss  |    175    |    44     |   1525    |    55     |
-------------------------------------------------------------
| unrelated |    19     |     9     |    54     |   6821    |
-------------------------------------------------------------
Score: 7088.25 out of 7516.5	(94.30253442426661%)
Accuracy: 0.9288089794221576
F1 overall: 0.7144076266832208
F1 per class: [0.688360450563204, 0.3333333333333333, 0.847457627118644, 0.9884790957177017]
*******************************************


*******************************************
EVALUATING PIPELINE 
{'batch_size_seq_length': 4, 'lr': 3e-05, 'lr_type': 'constant'}
INFO:__main__:Creating features from dataset file at /home/ubuntu/fnd_implementation/data/processed
  0%|                                                  | 0/9622 [00:00<?, ?it/s]  0%|                                        | 1/9622 [00:01<2:45:39,  1.03s/it]  5%|█▉                                    | 501/9622 [00:01<1:49:59,  1.38it/s] 21%|███████▋                             | 2001/9622 [00:01<1:04:20,  1.97it/s]100%|█████████████████████████████████████| 9622/9622 [00:01<00:00, 5222.15it/s]
  ******************************************* 
              Running Evaluation                
  *******************************************
 
  Length dataset evaluation: 9622
  Length dataloader evaluation: 301
  Number of epochs: 3
  Batch size: 32
  ******************************************* 
 
['/home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_e2d857c3_2020-02-03_22-44-43ujdinn7p/outputs/checkpoint-3']
INFO:__main__:Evaluate the following checkpoints: ['/home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_e2d857c3_2020-02-03_22-44-43ujdinn7p/outputs/checkpoint-3']
INFO:transformers.configuration_utils:loading configuration file /home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_e2d857c3_2020-02-03_22-44-43ujdinn7p/outputs/checkpoint-3/config.json
INFO:transformers.configuration_utils:Model config {
  "architectures": [
    "AlbertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "down_scale_factor": 1,
  "embedding_size": 128,
  "finetuning_task": null,
  "gap_size": 0,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "inner_group_num": 1,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "net_structure_type": 0,
  "num_attention_heads": 12,
  "num_hidden_groups": 1,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "num_memory_blocks": 0,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 30000
}

INFO:transformers.modeling_utils:loading weights file /home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_e2d857c3_2020-02-03_22-44-43ujdinn7p/outputs/checkpoint-3/pytorch_model.bin
HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=301.0, style=ProgressStyle(description_width='initial')), HTML(value='')))
0.0018470.0026350.0033540.1108540.4331540.1948480.2784170.0654440.0107630.0014310.1021440.0125720.0200880.0834540.0455070.0034940.2130910.0178210.1537330.4702020.0459580.5822110.2332260.8019040.2001180.0122060.0023160.0004110.0501070.0023820.0004320.2334030.1735070.4642950.2298240.0066940.2875000.3510220.1536830.0103930.0789490.2644630.2087500.0054220.0005830.0011430.0008600.0003810.0707470.0044070.0004560.0671520.2801310.1201220.0168530.4859950.2340360.0071560.0785660.0800680.6233050.7640660.0136820.0008660.2178610.0154900.1467200.2375350.4694820.3074490.0144950.0060070.4698290.1948210.3071520.4261840.6504120.4539140.2246630.0294690.1439160.1350010.0098390.0682790.0062100.0205330.0529410.0110030.0065860.0108500.1609061.9007220.6377770.3654230.7480520.3930510.0057170.0018510.1724990.0226850.5443710.2796430.3963400.1439060.1556640.2151830.0051370.0003250.0944460.0012420.4060620.2027440.2036091.0584630.0110550.9054320.4042560.0804330.0011040.3730940.1825410.1228821.0788480.0090340.0015270.0124100.0351180.2303940.1603280.1861190.0656450.1170460.1532880.1785450.3708920.8971030.3474170.5892990.4420960.7431620.1798340.0040850.1738520.0690660.8778160.2369490.1240120.0690290.1220750.0137000.0988260.0038621.3406020.0684890.0149730.1133720.1491160.0857300.0018410.4260741.2455150.2004770.0691190.0834711.2033630.0898840.2307300.1929500.5897740.5504390.0648280.0056200.0973110.0018020.1279850.2523141.1044040.0200140.0587550.0650030.6323832.9469110.0831730.3024630.0551860.0567060.0079710.2552240.8096730.2137380.1191640.1134400.0838650.4836790.6796030.0077880.0922780.1880030.4303681.0929060.5707450.0877520.1132681.5858530.3859380.0817160.1004030.7833220.7806790.8255300.1098430.0045120.0034320.4118460.3446830.0660870.0021830.0017980.0622300.0173940.0022490.0013320.0301740.0026180.0020290.0646300.3307530.0173190.2891650.0299800.6640060.1416430.3748560.0022970.0856800.0008990.2415810.0018351.2303460.1869690.0862590.3794280.0376790.4675560.8984950.0444170.1079380.0098520.1126130.1013350.0460970.0725960.0079620.1891191.2409460.9670450.5538200.0350660.4227562.4861140.2588991.3688200.5572460.3290491.3751110.3542120.2091850.3691980.2927440.1851910.0474520.0663360.0042100.0091940.0586080.0200000.0272940.2419700.0104810.0437250.2825230.7226310.8380790.2874540.3923140.6351431.3910620.0059540.2961830.1287680.0117080.0526900.0338050.7776160.1972700.3498190.7625430.0169820.0171000.0188700.012137

*******************************************
EVALUATING PIPELINE 
Pipeline directory: /home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_e2d857c3_2020-02-03_22-44-43ujdinn7p/
With following parameter combination: {'batch_size_seq_length': 4, 'lr': 3e-05, 'lr_type': 'constant'}
EVALUATION OF CHECKPOINT /home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_e2d857c3_2020-02-03_22-44-43ujdinn7p/outputs/checkpoint-3
-------------------------------------------------------------
|           |   agree   | disagree  |  discuss  | unrelated |
-------------------------------------------------------------
|   agree   |    452    |    31     |    115    |    18     |
-------------------------------------------------------------
| disagree  |    36     |    67     |    48     |    11     |
-------------------------------------------------------------
|  discuss  |    248    |    53     |   1566    |    56     |
-------------------------------------------------------------
| unrelated |    26     |    11     |    71     |   6813    |
-------------------------------------------------------------
Score: 7101.5 out of 7516.5	(94.47881327745627%)
Accuracy: 0.9247557680315943
F1 overall: 0.7242235603568954
F1 per class: [0.6560232220609579, 0.41358024691358025, 0.8412570507655117, 0.9860337216875317]
*******************************************


*******************************************
EVALUATING PIPELINE 
{'batch_size_seq_length': 3, 'lr': 3e-05, 'lr_type': 'linear'}
INFO:__main__:Creating features from dataset file at /home/ubuntu/fnd_implementation/data/processed
  0%|                                                  | 0/9622 [00:00<?, ?it/s]  0%|                                        | 1/9622 [00:01<3:01:11,  1.13s/it] 21%|███████▋                             | 2001/9622 [00:02<1:40:28,  1.26it/s]100%|█████████████████████████████████████| 9622/9622 [00:02<00:00, 4529.58it/s]
  ******************************************* 
              Running Evaluation                
  *******************************************
 
  Length dataset evaluation: 9622
  Length dataloader evaluation: 602
  Number of epochs: 3
  Batch size: 16
  ******************************************* 
 
['/home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_e414339a_2020-02-04_00-36-37pk2qy95d/outputs/checkpoint-3']
INFO:__main__:Evaluate the following checkpoints: ['/home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_e414339a_2020-02-04_00-36-37pk2qy95d/outputs/checkpoint-3']
INFO:transformers.configuration_utils:loading configuration file /home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_e414339a_2020-02-04_00-36-37pk2qy95d/outputs/checkpoint-3/config.json
INFO:transformers.configuration_utils:Model config {
  "architectures": [
    "AlbertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "down_scale_factor": 1,
  "embedding_size": 128,
  "finetuning_task": null,
  "gap_size": 0,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "inner_group_num": 1,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "net_structure_type": 0,
  "num_attention_heads": 12,
  "num_hidden_groups": 1,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "num_memory_blocks": 0,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 30000
}

INFO:transformers.modeling_utils:loading weights file /home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_e414339a_2020-02-04_00-36-37pk2qy95d/outputs/checkpoint-3/pytorch_model.bin
HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=602.0, style=ProgressStyle(description_width='initial')), HTML(value='')))
0.0003830.0004740.0003270.0001960.0001340.0049380.4205000.4424680.0556290.4636580.0467420.0050270.3857270.0297830.0872270.0062420.2947980.0193650.0011730.0018080.4527120.0217360.0522840.0025380.0077180.0005390.0001310.3760460.0140600.0177250.0007110.0001310.0000940.1952880.0738630.0113530.0008840.0200830.9065240.0234980.0079450.0004390.0436760.0779650.0596350.5155681.6258671.2607280.2423810.0795840.0017560.0021030.0008840.0001250.0001090.0001730.0020260.0170960.3774720.0065300.0797140.0013810.4678120.0109340.3337350.0060591.2094560.0181290.4785700.0519690.0008240.0000880.7892300.2644750.2860440.5954030.0285790.0004680.0001130.0006970.3957500.0049810.4903420.0066950.0002380.0787750.0009980.0000960.0000810.0000920.0005320.0002380.0000780.0001190.0001390.0001180.0048860.3550410.0046760.0004240.0001580.0001070.0004690.2690250.0318370.5109210.5271060.0050140.0002200.0083560.0035040.7992860.5036060.0046890.0001710.0004070.0009110.3401080.0134940.0956520.4391661.6384391.1463110.0225770.0003130.0002420.0000830.0001950.0494920.0168240.0008910.0134480.0003680.3720980.7400410.0084851.0612480.1152180.3635320.4972470.0060840.0002220.0001370.0001330.5433950.3099300.3430410.0026500.0022030.5387840.0379690.0023850.5368070.3153220.0021860.9850260.0064430.3185410.0025180.5032500.7130080.0049700.3338610.0134570.0008880.0010850.0009470.0017720.0001150.1222120.1407390.1835450.0013950.4306560.0720040.0006290.0004240.0004380.0042540.2304270.2767550.0018163.6559902.2472980.2054120.8218210.3788780.2863371.1424940.7564430.7897710.0081690.0009700.0003980.0004330.0010570.0052330.0826620.1652570.1094881.4335610.0079480.0007390.0166880.1372302.3262020.1630530.0020190.0005620.0298570.0029900.0287270.0003890.6127020.0059550.0001020.0720030.0004080.0000830.0003670.0192820.0297220.0004980.7046890.1086960.0061480.0013141.2740570.1919930.3228890.7065310.9972270.7999130.3064340.1883110.0013690.0001630.0000760.0001350.2492880.1379170.0010160.0002570.8195693.4734023.4800720.0143070.0001330.4485380.5959130.0244900.0917670.0020760.0018060.4195771.0672050.5730830.0515450.1566400.1968340.0018080.0012960.3178020.1194560.0503220.3111390.0029680.0024940.0008990.7031111.1751741.9991420.0264350.2962240.1588970.2891950.3494040.1477360.0006091.2705990.0046520.1124220.0005670.0010750.0000940.0087250.7123260.3487140.0019091.0912350.1863980.0007770.1472570.4828680.1167730.1803510.1222680.0004920.0003980.0390560.0012530.0070810.0006380.2895621.2422181.4311270.0061820.0010260.0005080.0003190.0173440.0004050.0005920.0001830.3621280.0022810.0179240.0004110.0531732.8790282.8912081.8079500.3933510.0042440.0009970.1681950.0025300.0900243.5054850.5438690.0132530.2102790.0164390.0036540.0059560.5407551.3001981.0453340.9454660.6993220.0256350.3118660.0016610.0512570.0252200.0007060.0002900.0079470.3904990.6275410.0141902.0618225.0455600.0585740.0059930.0181920.0019830.1944980.0013920.0005800.2261580.7515912.2927564.9867490.2518150.5759520.0831300.0006050.5688800.3099380.2662480.8758950.0027590.9367481.6467872.4256562.3271261.2274841.2594090.8180810.0025590.2364490.7498080.0021460.0000930.3201391.0735790.0035700.2391432.4163230.0293570.0012960.8458380.0028930.7633560.1512080.6082860.1734641.4186550.4762241.2737890.6073590.1363410.0442770.0005770.3662251.1880623.1404522.1168350.0524280.0003250.2625090.1822670.0005840.7312040.3214681.5074522.0547683.8084690.3808410.3334460.0262400.0003410.0007520.0054020.0003500.0009431.8460171.6295010.3513160.0009800.0002460.0003140.0002060.0002360.0899160.0004180.3141210.0009690.0001680.0002840.0003210.0003960.0003000.0132660.1325940.0004680.0004310.0002230.0003530.4843400.8240330.4754020.4093370.0019110.0430880.3148040.2783730.0017660.0039210.7655180.0534610.0004660.3644560.3729500.0048650.0001120.0001790.0021070.0000860.0000780.0421770.8650280.0030910.0007600.0003560.1866752.9767020.0608310.0063530.0001710.2006610.2611680.1691570.0116220.0177650.0061630.9784481.4790490.2976710.0076950.0013380.0971090.0011590.0007290.0000920.3786140.0010990.3626720.0015000.0019310.0013680.3373430.0063620.0006550.0662780.0292980.6584731.1378841.4185871.0003891.5586070.6907920.5211540.0025330.0011610.0004100.7870360.9951470.1773280.9300150.1069231.3516631.4509250.2829290.3804130.0555670.1299031.2029521.0142120.3495870.0104550.0473820.0128010.9463060.0023730.1143850.3859500.1538360.0008970.2419060.0006390.0002550.3593440.0010730.0004380.0003890.0002790.0296770.0001460.0078120.0201060.0128590.0078310.0008420.2321890.0005560.0000971.2088890.0023030.8225910.1705370.4622000.9108070.5606490.0352240.0021050.9851350.4436070.6375430.0085700.6429711.0789031.8038140.7393050.5224740.3373230.1109730.0007840.0087500.0004020.0011660.0003850.0002770.0002580.0009120.4215180.1156210.0611730.5121200.4638500.4339741.7487190.8519360.0023520.0005360.0026610.0037440.0005570.0005870.2516380.000821

*******************************************
EVALUATING PIPELINE 
Pipeline directory: /home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_e414339a_2020-02-04_00-36-37pk2qy95d/
With following parameter combination: {'batch_size_seq_length': 3, 'lr': 3e-05, 'lr_type': 'linear'}
EVALUATION OF CHECKPOINT /home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_e414339a_2020-02-04_00-36-37pk2qy95d/outputs/checkpoint-3
-------------------------------------------------------------
|           |   agree   | disagree  |  discuss  | unrelated |
-------------------------------------------------------------
|   agree   |    524    |    52     |    171    |    30     |
-------------------------------------------------------------
| disagree  |    14     |    55     |    24     |     7     |
-------------------------------------------------------------
|  discuss  |    201    |    45     |   1550    |    51     |
-------------------------------------------------------------
| unrelated |    23     |    10     |    55     |   6810    |
-------------------------------------------------------------
Score: 7101.25 out of 7516.5	(94.47548726135834%)
Accuracy: 0.9290168364165454
F1 overall: 0.7345163451495068
F1 per class: [0.6809616634178037, 0.4198473282442748, 0.8500137098985467, 0.9872426790374021]
*******************************************


*******************************************
EVALUATING PIPELINE 
{'batch_size_seq_length': 2, 'lr': 3e-05, 'lr_type': 'linear'}
INFO:__main__:Creating features from dataset file at /home/ubuntu/fnd_implementation/data/processed
  0%|                                                  | 0/9622 [00:00<?, ?it/s]  0%|                                        | 1/9622 [00:01<3:08:22,  1.17s/it]  5%|█▉                                    | 501/9622 [00:01<2:05:02,  1.22it/s] 21%|███████▋                             | 2001/9622 [00:01<1:13:08,  1.74it/s] 52%|████████████████████▎                  | 5001/9622 [00:02<31:02,  2.48it/s]100%|█████████████████████████████████████| 9622/9622 [00:02<00:00, 4287.29it/s]
  ******************************************* 
              Running Evaluation                
  *******************************************
 
  Length dataset evaluation: 9622
  Length dataloader evaluation: 1203
  Number of epochs: 3
  Batch size: 8
  ******************************************* 
 
['/home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_e2d857c5_2020-02-03_23-18-49ygk4jv45/outputs/checkpoint-3']
INFO:__main__:Evaluate the following checkpoints: ['/home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_e2d857c5_2020-02-03_23-18-49ygk4jv45/outputs/checkpoint-3']
INFO:transformers.configuration_utils:loading configuration file /home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_e2d857c5_2020-02-03_23-18-49ygk4jv45/outputs/checkpoint-3/config.json
INFO:transformers.configuration_utils:Model config {
  "architectures": [
    "AlbertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "down_scale_factor": 1,
  "embedding_size": 128,
  "finetuning_task": null,
  "gap_size": 0,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "inner_group_num": 1,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "net_structure_type": 0,
  "num_attention_heads": 12,
  "num_hidden_groups": 1,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "num_memory_blocks": 0,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 30000
}

INFO:transformers.modeling_utils:loading weights file /home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_e2d857c5_2020-02-03_23-18-49ygk4jv45/outputs/checkpoint-3/pytorch_model.bin
HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=1203.0, style=ProgressStyle(description_width='initial')), HTML(value='')))
0.0020950.0021550.0011370.0004190.0001410.0001010.0000720.0000520.0000460.0000440.0001120.1366210.1834790.0141440.9834420.0655910.0044040.0006060.0002580.4585140.6260140.0298380.0015020.0005550.0269220.3410690.0131600.0007870.0001200.0001870.0010790.0001270.0001060.0007350.0011900.0023850.0003680.0000880.0000490.0001361.4794760.0366490.0021740.0002350.0009940.0001180.0001440.0003140.0051320.0001760.0001860.0007650.0001240.0000530.8390770.0152930.0003260.7028840.0122700.0002380.0001160.0000300.0000980.0000290.0000280.0000290.0186230.0087400.1406580.0027680.0870600.0013460.0003200.0000440.5943990.1760620.6777250.8277660.0128720.0002120.0003810.0001890.0002360.0000610.0008770.0547440.2121680.0416890.0013530.0003160.0000591.0781230.0120702.5735770.0274340.1842460.4418560.5466100.0056220.0001300.0006940.0000750.0000530.0000570.0000640.0002350.0000410.0000530.0000510.0000390.0000660.0001000.0001760.0001370.0000460.6596040.6504260.4702960.0040410.0004450.0000340.0023080.0000480.0000291.1954850.0097270.0007590.0001841.6021620.0127030.0005290.0000351.7196150.6581440.0049430.0000670.7499760.8885020.0084310.0000930.0000290.0000450.0000350.0000330.8926220.9682220.0066670.1954540.1007170.0007050.5249430.6769410.0071810.0102060.0002530.0000330.0000320.0000360.0000320.0007900.0081070.5523080.0039800.0000580.0006781.0337670.0075590.0007340.0001660.0001540.8757750.0059440.0000650.0000380.0000400.0000390.0000970.0000300.0000370.0004290.0000380.0000320.0000320.0002090.0000390.0000310.0003870.0000310.0000390.0000300.0000380.0000920.0017950.0007640.0001940.8087240.0041750.0057430.0030710.0000510.0000400.0000570.0000380.0000521.0430590.0052150.0050960.0280090.0314160.3501891.2823230.1709970.5426520.0066660.0000600.0000310.0001760.0000330.0008520.0000560.1561690.0007490.1946010.0015150.0001441.0230610.0047740.0001370.0000590.0000590.0000510.0001630.0004100.0011780.0009460.0531680.0010790.0014930.0033540.0003420.8710280.1508583.0454531.8722382.1468992.3868860.0111470.0000820.0001420.0000300.0000980.0001670.0000300.0000310.0002000.0002150.0002270.1510840.0008890.0003850.0002730.0003000.0005490.0002530.0028020.0024320.0001450.6637560.3781630.7987630.0030590.0002870.4728660.5364310.6534980.5086790.3620240.0018361.1977710.6968470.0033680.0013840.0003790.0001060.0000310.0001460.0001000.0001690.3261520.7926260.0483240.0004070.0327630.1893150.0010420.0035040.0007510.0192730.0001311.0241120.0045640.3619000.1748620.0278410.0102371.4297060.0343050.6811850.0023510.0001700.9102400.7117400.0023630.0000840.7325190.0024050.0001010.0003610.0001870.0000950.4175010.0795870.0019570.0019120.2283920.0042830.0003200.0037520.0007520.0008210.0003890.0005430.0005160.0009880.0004930.0005550.0000300.0001491.6202640.2488680.0007830.0001020.0000370.0016220.0000420.0033170.3907111.0877410.0035270.0019040.0001300.0001450.0002550.0002800.0007650.0009920.0086730.0004370.5202740.0014830.7988630.0022500.0001740.0006451.8852190.4843610.0020041.8905220.0053130.5557960.0068671.5964021.0530870.0028571.6408900.0044060.2016090.7287431.7396180.0672981.9310540.0059700.0060500.0000450.0001070.0006100.0008220.0006580.0002450.0000280.0002280.0000290.0001960.0007180.2469160.0037290.0013100.0160580.0008520.1013700.2700961.3993360.0043830.0910200.4699670.0019240.0078430.0141810.0096940.6282540.0046261.5399650.0074040.1056380.0019250.0015920.0004080.6957230.8316681.2408900.9242310.0022310.6127910.0016740.0009110.0834670.0002460.0015550.0004840.0000430.0000300.0000350.0026080.0000520.0000290.0000280.0000280.0000290.0000300.0000570.1414320.0712290.0004340.4697000.0026640.5542750.6535490.6091540.5959220.9511840.0048950.0005540.0069150.0047670.1632390.6924040.0016580.0004710.6557760.0019200.6707890.9526230.7228840.9294611.0347610.7625190.0018120.6120260.0906510.0019330.0000430.0007970.0000330.0004590.0000300.0000300.0001710.0008060.8407070.9263300.0022030.9068730.3307020.0048050.0000470.0227840.0000961.0613993.0380782.9962544.6353271.8553640.0039370.0000470.0000470.0000380.0005100.0000440.0007610.0005230.0000810.0002380.9471960.0019430.0014010.0000820.0170990.3411220.0054570.5978070.2931281.5732841.8387710.0036160.0008890.0013040.0009940.6917560.7947770.0020850.0009640.0002140.4129870.0009170.1068350.0017140.0408800.0001080.0072520.0022470.3409670.5346060.0032880.0001190.0005050.0010640.0002160.0005140.8464891.5233822.8865932.2309573.1020450.8872750.0137950.0513500.0010380.0003590.0052150.7099780.0242680.0155970.0669300.0788660.8438920.8993990.0016460.0000791.4634291.4585210.0029150.0003540.7659910.0013990.0003500.0000310.0010160.0005930.0000690.0000310.0084710.0000460.0002770.8512620.0085780.5889860.0296700.0009301.5395980.6551341.0558190.5296730.0010390.0000500.0000502.7183440.5266050.0011160.0001970.8154430.7193300.7940830.0022670.0000360.0000320.0000410.0027420.0000350.3044480.0011170.0000380.0052230.0033510.0028170.0000350.0129100.7085700.0012130.1727612.0659142.8523970.0051140.4740250.0022780.0031220.0009660.0064470.0000490.0000430.0022070.0019140.5308300.0009390.0016900.7426930.0012210.0006100.0000430.0000330.0031650.0169970.0001070.0003320.0000360.0003640.0000470.0003760.0012441.9173474.4836883.0846632.5378832.0114881.2664330.0101000.0446320.0051980.0007100.0007700.0028450.2598390.8427931.2749582.4845770.8691321.6564401.2133693.2845120.2328670.0003860.4034440.0006390.0003960.0283270.0108240.0337160.0024610.0026690.0073310.0005490.0017140.0010600.0038470.0006130.0011570.0002270.0000590.1133991.5911821.5742910.0144260.0000650.8493790.0031570.0006110.0000420.0001070.4120410.0023020.0020480.0002020.0026500.0002320.0006540.0000760.0006520.0003420.4768810.0056580.1642070.2454740.0040280.0005251.0743412.6582963.6998460.0076660.0032040.0004750.0003980.5261950.0025410.0013300.0003770.0004090.6178680.0015790.6685310.0012450.0024150.7171470.0019271.3201231.4044750.0026760.0229780.0146600.1829183.3076281.4071651.6542892.1773622.0969980.0039120.0006360.0002320.6899430.5444850.0007920.6953610.0010140.0006911.7280240.0606530.0002530.0003610.0399661.6051523.2450670.2296623.1390923.3390081.6992782.1666681.5002871.4155571.4948770.8725571.5511560.0027020.0016730.0007780.0006660.0235390.0004230.0002650.0001760.0000330.0000290.0000320.0001300.9078631.0944150.8276100.0019410.0022250.2174700.5372202.7554240.9431600.0021910.0039380.0017520.0009520.7980910.8062720.0015900.0002550.8171540.6953660.0056770.7415550.9287590.6270320.0013790.4702932.3842150.9062820.7859430.0526012.6779930.4938211.4653310.2710660.0006710.0007000.0020450.2039080.0017570.0008640.0045420.7929001.7429540.6655784.0535747.0076275.9695640.0152990.0002010.0012600.0001660.0000870.0000300.7559910.6694750.0008430.0000310.0034222.1397640.9488580.6770930.0458361.4124060.6277201.5355241.0659052.2018370.3342650.0011170.8514790.6930090.0013190.4400740.0005520.0000400.0003700.0007750.0019150.0005360.0014810.0012270.0010980.0004790.0003221.7917770.8112632.3530520.8707051.3617510.0021140.0000350.0002500.0002580.0005340.0007360.0004230.0002020.0001410.0000940.0000770.0002990.0001930.0002470.0001970.0001880.9291640.0011130.0003650.0001940.0000310.0000440.0000400.0008720.0003970.0001080.0001130.0022030.0001680.0003900.7173470.0008380.0001710.0000590.0000340.0021570.0018670.0000360.0003300.0003390.0002890.0000421.6889921.8011400.0201280.1648980.0021771.7055180.0031750.0008960.0007830.0008810.0010700.6567970.0073120.0010420.3007850.0030250.0007780.0009840.5996401.0049120.7987150.9496910.0018250.0005880.0037101.2162370.0077700.0006920.0007580.0004630.0003480.0000310.0001660.0003400.0001730.0000300.8108130.0008960.0000330.0108080.0000430.0000320.0004471.7243690.0020780.0003760.0004830.0002870.0003410.0002150.0000410.0017870.6149673.3341351.0234030.7380370.0011190.0001800.0002170.0000310.0001720.0102100.0009050.5185790.2898890.3557580.6729120.0603200.0106730.0054160.0367100.0261960.0008310.7954751.2040853.7922301.4901401.0281530.0021340.0005310.0009010.0008220.0015120.0015790.0023380.0008760.0014310.0005130.0000820.0000390.0000380.0041080.6846290.0007420.0004960.7001640.0045320.0001190.0010230.0054070.0009770.4919590.7143630.3015111.7275490.5481650.0008970.0002830.0000290.0007740.0010430.0006930.0000290.0342670.6054791.6790342.7747392.8944551.1752730.0404250.3591031.4125850.0014450.0254300.0006730.0000401.8274790.0023130.0152890.0000500.0017470.0006110.0031360.4012041.7127991.1752960.7389330.4940850.0050080.2455291.0752560.0063720.6086410.9753633.6839640.1261601.5869000.8987901.1164120.1973200.0007440.6156430.0024750.0000490.0009070.4259760.5171990.0020020.0138191.1521040.0455340.1455850.1248080.2031800.6066460.0018420.3043710.5867090.8475230.0408010.0018320.5206770.2477522.0798861.0041990.0027380.3497340.1510410.0003940.0068051.1808110.0012210.0002530.0002900.0003000.5200050.2526540.0005160.0003920.0022590.0006240.0004260.0005030.0000440.0118790.0000410.0018180.0000380.0000340.0000350.0006360.0161540.0000430.0012370.0000290.1286770.3003430.0007340.0008110.2788970.0056790.0000440.0000820.0000430.0000460.0004270.0752590.0001020.0002040.0009930.3802510.0008390.0011720.0012600.0005821.1161170.0026771.7136353.9544390.4241090.0030250.0134580.0029550.7019430.6688020.4573730.5884460.3823560.0057310.7258240.0022910.5784020.0046351.4423371.3583911.5454361.4080570.0705830.0007370.3035040.0005950.0002521.1132600.0011190.6920840.0007050.0000330.8025680.0014510.0036680.0001690.0166980.0008970.0005470.0010100.0008800.0006040.0002360.0009800.0004750.0060911.7541480.6897610.7535100.0698060.7503430.6095820.1907531.9536220.7093491.2867321.2556690.2405960.0224610.7482190.0324810.0136830.0006980.0004350.0002410.0020310.0482470.0005190.0005270.0061230.0005770.0003140.0002110.0005380.0003460.0004370.000631

*******************************************
EVALUATING PIPELINE 
Pipeline directory: /home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_e2d857c5_2020-02-03_23-18-49ygk4jv45/
With following parameter combination: {'batch_size_seq_length': 2, 'lr': 3e-05, 'lr_type': 'linear'}
EVALUATION OF CHECKPOINT /home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_e2d857c5_2020-02-03_23-18-49ygk4jv45/outputs/checkpoint-3
-------------------------------------------------------------
|           |   agree   | disagree  |  discuss  | unrelated |
-------------------------------------------------------------
|   agree   |    535    |    61     |    189    |    22     |
-------------------------------------------------------------
| disagree  |    12     |    46     |    19     |     1     |
-------------------------------------------------------------
|  discuss  |    197    |    47     |   1553    |    67     |
-------------------------------------------------------------
| unrelated |    18     |     8     |    39     |   6808    |
-------------------------------------------------------------
Score: 7103.75 out of 7516.5	(94.50874742233752%)
Accuracy: 0.9293286219081273
F1 overall: 0.7254370634238894
F1 per class: [0.6819630337794774, 0.38333333333333336, 0.847707423580786, 0.9887444630019606]
*******************************************


*******************************************
EVALUATING PIPELINE 
{'batch_size_seq_length': 1, 'lr': 3e-05, 'lr_type': 'linear'}
INFO:__main__:Creating features from dataset file at /home/ubuntu/fnd_implementation/data/processed
  0%|                                                  | 0/9622 [00:00<?, ?it/s]  0%|                                        | 1/9622 [00:01<3:20:14,  1.25s/it]  5%|█▉                                    | 501/9622 [00:01<2:12:54,  1.14it/s] 10%|███▊                                 | 1001/9622 [00:01<1:27:56,  1.63it/s] 21%|████████                               | 2001/9622 [00:01<54:25,  2.33it/s]100%|█████████████████████████████████████| 9622/9622 [00:01<00:00, 4868.53it/s]
  ******************************************* 
              Running Evaluation                
  *******************************************
 
  Length dataset evaluation: 9622
  Length dataloader evaluation: 2406
  Number of epochs: 3
  Batch size: 4
  ******************************************* 
 
['/home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_e2d857c4_2020-02-03_23-14-31z6_1xrv8/outputs/checkpoint-3']
INFO:__main__:Evaluate the following checkpoints: ['/home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_e2d857c4_2020-02-03_23-14-31z6_1xrv8/outputs/checkpoint-3']
INFO:transformers.configuration_utils:loading configuration file /home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_e2d857c4_2020-02-03_23-14-31z6_1xrv8/outputs/checkpoint-3/config.json
INFO:transformers.configuration_utils:Model config {
  "architectures": [
    "AlbertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "down_scale_factor": 1,
  "embedding_size": 128,
  "finetuning_task": null,
  "gap_size": 0,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "inner_group_num": 1,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "net_structure_type": 0,
  "num_attention_heads": 12,
  "num_hidden_groups": 1,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "num_memory_blocks": 0,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 30000
}

INFO:transformers.modeling_utils:loading weights file /home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_e2d857c4_2020-02-03_23-14-31z6_1xrv8/outputs/checkpoint-3/pytorch_model.bin
HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=2406.0, style=ProgressStyle(description_width='initial')), HTML(value='')))
0.0021960.0023340.0012110.0005890.0001670.0000530.0000320.0000250.0000250.0005250.0000750.0000370.0000250.0004270.0001670.0000370.0000360.0000250.0000210.0000240.0003340.0000420.0144330.0006470.0001911.4630640.0562890.0021022.1313000.0736510.0024820.0000980.0000470.0001240.0048200.0001570.0003150.0000270.0001470.0011290.0011980.8408120.0200370.0004830.0003190.0000260.0026050.0000760.0027840.0000761.4746570.9734420.0187390.0003840.0000740.0000350.0000552.2630210.0394310.0007100.0017390.0000620.0000700.0000360.0000260.0004580.0009300.0000380.0009910.0005630.0001940.0001090.0000330.0000240.0000280.0000220.0000360.0000230.0000470.0000530.0004190.0068760.0399100.0005030.0001610.0000540.0003280.0001620.0000500.0001510.0000780.0000280.0000560.0000310.0030150.0000510.0250720.1534940.0015870.0000430.0001280.0000230.0000640.5920110.0058490.0000910.0000200.0000191.6178630.0151580.0001560.0000270.0000190.0000180.0000190.0043690.0000550.0001690.0000200.0000180.0000170.0002090.0000190.0000180.0000170.0002150.0000370.0000170.0000170.0000170.0000170.0000170.0013700.0026130.0014942.0213920.0149722.0752320.0151920.7417991.5550180.0111781.1609530.0082610.0022850.0005270.0000280.0000712.0817630.3272942.0864130.0138420.8421612.5307161.6087230.0104030.0004580.0001040.0002000.0000461.8671621.3736671.3994030.0086350.0001010.9252400.0056530.0000550.0000200.0002630.0002403.0720841.6611771.5133890.0087881.6028541.3081590.0082520.0008620.0000320.0000480.6976512.1904710.0119920.0008060.0000253.8606962.1408130.0114100.0000841.5414850.0104900.0018070.3033831.5612410.0080620.0000960.0000210.0001310.0002510.0000830.0012210.0000610.0004790.0001500.0000380.0000780.0084850.0002610.0779440.0018771.9304620.0092320.0000850.3335850.0016190.0001710.0000370.0000510.0000240.0003220.0000370.0003670.0000200.0003450.0000210.0001340.0004530.0000290.0000420.0089420.0004820.6155780.0026590.0018120.0000260.0000330.0000180.0000280.0013230.0000240.0000180.0000200.2086050.0008730.0000210.0000180.0000170.0000192.0444790.0081970.0000530.0023840.0003930.0000210.0000261.2374270.8795150.0037760.7770601.4189020.0055640.0000400.0000241.6258510.4888691.2936140.0048620.0000360.0000170.0000220.0000170.0000170.8132260.0032031.8325010.0082850.0000510.0000470.0000190.0000180.0000190.0000180.0000520.0000180.0000200.0000270.0000170.0000170.6239660.0021741.7132490.0058900.0000380.0000181.2535461.2596090.0042590.0000320.0000180.0000181.4431231.4929550.0049450.0000340.0134850.3438590.0011400.0000210.0003030.0000200.0000190.0000220.0000210.0000200.0000200.0000180.0000230.0019020.0000360.0000420.2479810.0007941.6397860.0050910.0001570.0000200.0000200.0001420.0024082.0968480.0064720.0000380.0036100.0001630.0004230.0001420.0001730.0000360.0002710.0001522.1021690.0061640.0001160.0000190.0000180.0000180.0000180.0000190.0000250.0000170.0000240.0000210.0000260.0000170.0000170.0000220.0000170.0000210.0000380.0000320.0000170.0000170.0000170.0000180.0000170.0000220.0001400.0000180.0000180.0000170.0000170.0000200.0000290.0000170.0000180.0000270.0000170.0000170.0000180.0000200.0000250.0001490.0000180.0000880.0022910.0000290.0002020.0001990.0002950.0000212.4562340.0062840.0000430.0017600.0008960.0013170.0000280.0000270.0000680.0000350.0000420.0000740.0000210.0000350.0000200.0000540.0000630.0002590.0007280.0003550.0000211.2903980.0031541.1477120.0027930.0000481.0404591.1225640.0026991.1207650.0036920.0003701.2085530.9960360.0023610.0002560.0000210.0000180.0000180.0000210.0000180.0000170.0003000.0000370.0000210.0002220.0000240.0000600.0000170.0000191.0759570.0024520.0000363.3369223.4899220.0104200.0000440.0012090.0000372.2561970.0051740.0012410.0000240.0000540.0002140.0000260.0000260.0000250.0000300.0000240.0000380.0000220.0000440.0008770.0010180.0000223.2489480.0086440.0000430.0000350.0000260.0003190.0357000.0535110.0001440.0001800.0004010.0000250.0000330.0000170.0086970.0002261.1202800.4489110.0054840.0005891.6729040.0044510.0020471.5416330.0036270.0309690.0003920.0000250.0000180.0002020.0000180.0000180.0000180.0000180.0001860.0002750.0000180.0000180.0000180.0000180.0000170.0003220.0000180.0000180.0002350.0000690.0001961.0971640.0021490.0000350.0003320.0002500.0005110.0000570.0012020.1940710.0004000.0000401.2525640.0024040.0014723.0357830.0057580.0831870.0003770.0023950.0002630.0005921.1380470.0022750.6838660.0211141.2560330.0023480.0305290.0004140.0002450.0000240.4351230.7280120.0029651.8208130.0035140.0010240.0000220.0000280.0019080.0002790.0001760.7108360.0055470.0098710.0000370.0000180.0002460.0000180.0030460.0003670.0001630.0002010.0000200.0000190.0000200.0000200.0001810.0002960.0000190.0014060.0000211.2055320.0021070.6328831.1545140.0020081.0652950.0018540.0000211.0734870.0018550.1680960.0004820.2611510.0009060.0005030.0000550.0008380.0000250.0005020.0008240.0000410.0002150.0002651.7136040.0151770.0620510.2455610.4453920.0040570.0025980.0017720.9245410.0018770.0007210.0004422.2831250.0055560.0005941.5226963.1804720.0053130.0003980.0000390.0002261.6930780.0029530.0000241.4310420.0026150.0000210.0001640.0000181.4487840.0023220.0001480.0000190.0000180.0003240.0000190.0001360.0000180.0028290.0003730.0000190.0022793.1495991.6806151.7755540.0072460.0638870.0011680.0000331.1356650.0036550.0007840.0003800.0000230.0005132.2964670.0035420.0005700.0008870.0005560.0006690.0003430.0002320.0002770.0003160.0006780.0000210.1066720.0001850.0202030.0000470.0016290.0001450.0000170.0000170.0000240.0002140.0021990.0011830.0022090.0404530.0004340.0000190.0000310.0000190.0000190.0000350.0000190.0039920.0000270.0000190.0000450.0000271.3548930.0019742.1046080.0031170.0013060.0000200.0013940.0002310.0000260.0002470.0000200.0001420.0001760.0001960.0000190.0001820.0024270.0001690.0005230.0137510.0531531.3004370.0019010.0017340.0000231.5483560.0021800.0000381.6839611.4992650.0020950.0000410.0002610.0000190.0004830.0002412.9757500.1773171.6440050.0029300.0006550.0006413.9529910.0056960.0000290.0003120.0002340.7223412.4914500.0048661.5656222.8163640.0041211.9274270.0026050.0000300.0000191.7126850.0023080.0000252.1931100.0080491.9571120.0026304.3190720.0057260.0006740.0001935.2841660.0069840.0000500.0000580.0000591.5970370.0021030.0000220.0001870.0000180.0006070.0005500.0005380.0005460.0005410.0005610.0005371.7055300.0022090.0000200.0235830.0000480.0000250.0000180.0000190.0005660.0001600.0002680.0003180.0167320.0003590.0004190.0000240.0009730.0003120.0001680.0006130.0027210.0005500.3078160.0049004.4522861.6593560.0090540.0000301.5083021.4766830.0018700.0001041.4507990.0018430.0003141.5593520.0025780.0000220.0317890.0000591.4850861.2508330.0015460.0000410.0040404.0369975.4439140.0066261.9420780.0025180.0034600.0000240.0054650.0032570.0002430.0003370.0004881.4348160.0031980.0033810.0000230.0058830.0015160.0000230.4011610.0004970.0000190.0000180.0017470.0002610.0002000.0000210.0002470.0003890.0000200.0000190.0000222.1141800.0038000.0007720.0000210.0000190.0000190.0000190.0000190.0000190.0000190.0015770.0000200.0000190.0000320.0000190.0000180.0000180.0000190.0000180.0000190.0000180.0000180.0000180.0000180.0000180.0002000.0000190.0037040.0056470.0961680.0011850.0000211.4847941.4511740.0021340.0004430.0000380.0000220.0000691.2947741.2605380.0014312.1956110.0045391.8744410.0236010.0018890.0018460.0012990.0004360.0002910.0017640.0000220.0014480.0029030.0183900.0032770.0001770.0000260.0000641.0955891.2396271.1115560.7299270.1042341.0383110.0251060.0001120.3488941.4079771.8814860.0026471.6628980.3885191.4775860.0994000.1312830.0047870.0000360.3740581.1846960.9596400.0017680.2902910.0004661.4771030.0015910.0000341.5179920.0016270.0000240.0000190.0000180.0002010.0000190.0000180.0000210.0000200.0000180.0000230.0001450.0000261.6003730.0016900.0000191.8187670.0021660.0002181.8438570.0019440.0000200.0060280.0000370.0012050.0000240.0000180.0000180.0013290.0000300.0000200.0001893.9599984.0758503.8854962.1726605.6078434.0992526.3284210.0094980.0021910.0003040.0000180.0000220.0000240.0000270.0001480.0000320.0000180.0000280.0009230.0000190.0000300.0054480.0010380.0000200.0010060.0001640.0000220.0001790.0000190.0003581.9210080.0021290.0000320.0010330.0017150.0001430.0000400.0009540.0021472.0037170.0021710.3921190.0004070.2915040.0003150.0003351.8612010.0021805.3794453.1648190.0248010.0000480.0000250.0000210.0012890.0009010.4554720.0014660.0029870.0002770.3256010.5181201.2972920.0062840.0014640.5869970.0028080.0000210.0003120.0005800.0093540.0000320.0003590.0000211.3983370.0134710.0000310.6472560.6549910.0006420.0000190.0000190.3630700.0003631.0314110.0079700.6676701.1834900.0011380.0000240.0169970.0003560.0000260.0074040.0000250.0000200.0056480.0005950.0000250.0069290.0000241.2553602.1626990.0020352.0994890.7461492.9246733.1936110.0041634.5954021.1648491.4907770.0017120.0000210.1763090.0025160.0094371.3619750.0699480.0004280.0008690.0126250.0090591.8400870.0096841.2729770.0790530.0004801.0316902.0282970.0019560.0000200.0023350.0008450.0014641.8964020.0047490.0000210.0000170.0000200.0000211.6647601.5804555.3120780.0049300.0000300.0002630.0000190.0000341.8041390.0016220.0000220.0000190.0000200.0010080.0000190.0000180.0020660.0000200.0010780.0010900.0000180.0000320.0000180.0000190.0000170.0001470.0000230.0000180.0000180.0008400.0023900.0314340.0035110.0053800.2738850.0029650.0008870.0011060.0017000.0000813.8592912.0109873.8073780.0036650.0002431.9367081.5030220.0019740.0002710.0000210.0000220.0000290.0000190.0000310.0000202.0302170.0017730.6165740.0012970.0067080.2790760.0002560.8188690.0007651.0499370.0009350.3115440.0002860.0002770.0000520.0000190.0000180.0000320.0000190.0000180.0000320.0043300.0000260.0000210.0000220.0000230.9482540.0008120.0029450.0000230.0000250.0000250.0111730.0076660.4367980.4839010.0004190.0000190.0000180.0000180.5481360.1408740.0001370.0000180.0000270.0006000.8709650.0007351.9192503.0403060.0097620.0003010.0002220.0003311.2124700.0023750.0013340.0000630.0021690.0012920.0000260.0009600.0000220.0000350.0000240.0000770.0000300.0022850.0000340.0000320.0025160.0218650.0060630.0001450.0000170.0001380.0000260.0003730.0000320.0000250.0000300.0001450.0008530.0000250.0003210.0000190.0000230.0002290.0004530.0000200.0025420.0000440.0000290.0001620.0000390.0000330.0000180.0000210.0010790.0000210.0000200.0011420.0000190.0016750.0000210.0007023.0143203.6723693.3228832.4171541.2040762.7333892.3746941.0787790.9650550.0123150.6025050.0022590.0245450.0037950.5565690.0050580.0047090.0005770.0008450.0005670.0008340.0015160.0007240.0011840.0017350.0012870.0001370.0004120.0003880.0004850.0004330.0003080.0001991.5612971.6118782.5146651.5024315.9791071.9579690.0418750.0000500.0000180.0000190.0000171.2714350.0009800.0000180.0003930.0002990.0000170.1426200.0070300.0030610.3829260.0281801.4163440.0049681.1564620.0008840.8337371.1969760.1776760.0069270.0798531.7571820.0013970.0006610.0004550.0020670.0100070.0002060.0000190.0002370.0009240.0000470.0004640.0000670.0016450.0000191.3570591.0619840.6944591.1825350.0115460.0000300.0000800.0000220.0014930.0021620.0000260.0012630.0000380.0000900.0000270.0000300.0007360.0000470.0000400.7628000.0006400.4116250.0003240.0008490.0002630.0000320.0013171.5652400.0011620.0000690.0000960.0009740.0000230.0000420.4209110.0003280.0013720.0003851.6614062.6637910.0425180.1409410.3442410.0066950.7461060.0008170.0001550.0004800.0281940.0001701.3908790.0041220.3047273.7218583.0344864.7213841.7322531.8436621.1945273.1026370.0022140.0011310.0000300.0010750.0000430.4875670.0018870.0000230.0027350.0005640.0003070.0004290.0004320.0003060.9351320.0010590.0003980.0005380.0004200.0004490.0001670.0003950.0007770.0003720.0018781.4394230.0014910.0004210.0097561.0680325.6897650.0043830.0000710.0004371.3974530.0016720.0007050.0010360.0007230.0000542.9927733.1634201.5474781.6184541.5573181.5653271.5519583.0618264.0756170.0039270.0020940.0009160.0012320.0012710.0009060.0002471.3736412.7957520.0019161.2431360.0008650.0000330.0003451.2945280.0009030.0000441.2731390.0008822.5801501.3114170.0009120.4869700.0003470.0000840.0000320.0000630.0012260.0006770.0007220.0013780.1553490.0019520.0009470.0029860.2545862.8803760.0032492.7565390.0025040.0001640.0004130.0001670.0001530.0004140.0005190.0001500.0001860.0024490.0002871.5305491.9271040.0018390.0005060.0007110.0008770.0009700.0005080.0006820.0002990.0009960.0005720.0007720.0002580.0002010.0000170.0003930.0003970.0000170.0001150.0000190.0000170.0000180.0000180.0000180.0009690.0002700.4489040.0003101.6974480.0011160.4941910.0003370.0016300.0001800.0008720.2385331.6219080.0014071.5366413.3709261.1006200.0039940.0025450.0001820.0000510.0086230.0041460.0042940.0009600.0005370.0040380.0015100.0003541.9673670.0015872.0456190.0016880.0022560.0003520.0001820.0003242.0765160.0017341.3399900.0085620.0013420.1226401.0856551.6532140.0023100.0001552.1015490.0016180.0001621.7943480.0014212.1699854.2102790.0029902.0979511.6526400.0011981.9841260.0013977.1051960.3322441.1170370.6559321.6810851.7010401.0109740.0009540.0003720.0000170.0004840.0005110.0012230.0000201.0624120.0015920.0012300.0000190.0001870.0001520.0001630.0000191.9373330.0012143.8351321.9462320.0016431.9752461.9253954.7385525.2129245.2341143.7046193.0832190.0022850.0002750.0001600.0003790.0004570.0000200.0002910.0000300.0001560.0000200.0000190.0000391.7122110.0010650.0002811.2714320.0008020.0000310.0000210.0000290.0000180.8182430.8453630.3506550.0148991.4049311.5321160.0009950.0004990.0001080.0000352.1137250.9326312.4426903.4165941.6408894.8904631.3261444.8022654.4523033.0087290.0018150.0000210.0010241.5141210.0009211.4009970.0008540.0000240.0017600.9938060.0006140.0000230.0000240.0000270.0000270.0000230.0015780.0018290.0005870.0008730.0027250.0003340.0004280.0002930.0005130.0003900.0002590.0002530.0006320.0000260.0005300.0001730.0003940.9317773.4762032.6356270.5639001.1671990.1061410.0013590.6153831.6783521.0640420.0013940.0001430.0000260.0000180.0006700.0002810.0003230.0006540.0007310.0007810.0012580.0007820.0005270.0008130.0001450.0007050.0001440.0006570.0000180.0001821.3862070.0008190.0003600.0003830.0003860.0002040.0004570.0001600.0001971.5593020.0009100.0003760.0001721.1589070.0006830.0003000.0003080.0003300.0000180.0003600.0031690.0000260.0000180.0001450.0000210.0000250.0028180.0002190.0000180.0008870.0000180.0001520.0010580.0000180.0001850.0000250.0000170.0004760.0013080.0005280.0001941.7120630.0009850.0000181.8317290.0010880.0000370.0000200.0000200.0000190.0010630.0000320.0021940.0000200.0000220.0000190.0000230.0010930.0010180.0000190.0009240.0000240.0000450.0000180.0046651.0907780.0020110.0068740.0032820.0098610.0013360.0033471.4477930.0044691.3508852.5716140.0027120.0012930.0015300.0028630.0009310.0019451.3018890.0017680.0021740.0015850.0018230.8289500.0023581.7049850.0033040.0064200.0006591.9611611.8121980.4159700.0010010.0007410.0006480.0006830.4654641.3134183.1785780.0048071.9336280.0032582.0913190.0035270.0009080.0010040.0011910.0007230.0002080.0006540.9955720.0009060.0004690.0008190.0002820.0004440.0005690.0002780.0005340.0003320.0002720.0002420.0000180.0000180.0000180.0002120.0002320.0001990.0001940.0000180.0000180.0000180.0002400.0001880.0000200.0000190.0000180.0000190.0001900.0000180.0000190.0000180.0000180.0000180.0001890.0000233.8869320.0020750.0000300.0003480.0006080.0013640.0012150.0021180.0005810.0002030.0004990.0015440.0002810.0014070.0000180.0000200.0033870.0051820.0086191.6800500.2024670.0977610.0057822.7003840.0029410.0001400.0001390.0001320.0001341.6707450.0008880.0001630.0000180.0000180.0000170.0001600.1191330.0000831.1477380.0023820.0013722.6312921.0135050.0074840.0000242.7153850.0089402.4762290.0037650.0046730.0096630.0211730.0056130.0197300.0022370.0133960.0000270.3087930.0012080.0007140.0004051.8821582.0574380.0039064.0529842.7513450.1013120.0058920.0044142.7968080.0053810.0003580.0002030.0026830.0033390.0003770.4139430.0006720.0029930.0026040.0039441.3331101.9736250.0018900.0049930.0032790.0013150.0048480.0000250.0031610.0000230.0000210.0000190.0000210.0000190.0000200.0000200.0087180.0038680.0000210.0000190.0000220.0000200.0079400.0033650.0011241.7331000.0009160.0000210.0001590.0006760.0013270.0007130.0023830.0008140.0010870.0008511.7865461.6382380.0008431.7569451.6631593.4098983.8299331.6668101.7366200.0010140.0002490.0000180.0009490.0000180.0000180.0005630.0107710.0104190.0011470.0005440.0000170.0000170.0000180.0047830.2233510.6058471.6102990.0094180.0047172.9129310.0034940.0003304.5638482.9667470.0014760.0000311.3974980.6085050.0003203.9962261.6804820.0008440.0000210.9969190.0005130.1136480.0000820.0000210.0000202.1045790.0010420.0001270.0000200.0074510.0023620.0000190.0000190.0131740.0026830.0000350.0030000.0000420.0030410.0000202.1652232.6709100.8411650.1230401.1945280.0022102.0125710.9761550.0469940.0038250.0025100.0020740.0011950.0019271.4722631.3961560.0006953.0388760.0020231.6184311.0377380.0026604.0007622.3089202.8218494.0678122.8534421.6531032.1575391.8092710.0017430.0010572.3171480.0011321.9585240.0012750.0001400.6589391.7714210.0008780.0015280.0000591.7267981.6332803.1679492.5538492.2048190.0012041.8586931.7704275.5739460.0026501.8315020.0042520.0006720.0007921.0381620.0007340.0009830.0006880.0012770.0005300.0035090.0000230.0101580.4809280.3865660.0030311.9728110.7246450.2306451.5616020.0010980.0075730.0000210.0260481.2579120.0479870.0003472.5489090.0020410.0091500.0086360.0014130.0024751.2484310.0045530.9603770.0043960.0008790.0000320.0017860.0027711.8711580.0008850.0001630.0000260.0003600.0001390.0003320.0001520.0003970.0003420.0002450.0062940.0002881.7554180.0023560.0000230.0000250.0005790.0004060.0004440.0090040.0090960.0209110.0012980.0002680.1827600.0001160.0000190.0000320.2773690.0001470.0000180.0222540.0000300.0000210.0000340.0000180.0000300.0000220.0000240.0015490.0000220.0000350.0041860.0000210.0000190.0001060.9759940.0004600.0000190.0006110.0007051.4823940.0006960.0007510.0001410.0000671.9284760.0010980.0369010.0015180.0015310.0000210.0000350.0001480.0005590.0000450.0000510.0000550.0000190.0032700.0000191.0789130.0007660.0000190.0000200.0000190.0016890.0035800.0000550.0000242.6697740.0012100.0002990.0002180.0007810.0045630.0007810.0004370.0006720.0052000.0005930.0007030.0007281.9901123.7822187.6689174.8742091.3188200.0034300.0000480.0057880.0027590.0018780.0018880.0023000.0011840.0153980.0000340.3993480.0106550.0002470.0704340.0000671.6981880.0008370.0000190.0003500.0002151.2837260.0005810.0026123.0759590.0177440.0011690.0001650.0001443.9962202.5407532.7402680.0017573.5110820.4111882.1553750.0445491.4554880.0006881.2005311.4611430.0009990.0007190.0334480.1489400.0000820.0862701.9378030.0008570.0001490.0000180.0086930.0000210.0003270.0000170.0000170.5997950.0005690.0027090.0002440.0006320.0023940.0000340.0000180.0029540.0001040.0006290.0005910.0020130.0009450.0008030.0019160.0014350.0043500.0002580.0003820.0018670.0000190.0007180.0000290.0029410.0000380.2486460.0013791.7608030.0230870.1403690.0198350.0000272.5191220.0022780.0180400.3402280.0091650.2291280.8870711.1265310.1328790.2457162.4077750.8290210.0360411.8862020.0028320.6000690.0846570.0067591.3096430.0077200.0087842.1220922.9013202.7998190.0040531.2008430.0111760.7461321.2826040.0005650.1581941.3997620.0011090.0004460.0005290.0037500.0065500.0005230.0009060.0001800.0008290.6320010.0007480.0005370.0009070.0010750.0000270.0013290.0008600.0018250.0008320.0000360.0016900.0000230.0019050.0008980.000026

*******************************************
EVALUATING PIPELINE 
Pipeline directory: /home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_e2d857c4_2020-02-03_23-14-31z6_1xrv8/
With following parameter combination: {'batch_size_seq_length': 1, 'lr': 3e-05, 'lr_type': 'linear'}
EVALUATION OF CHECKPOINT /home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_e2d857c4_2020-02-03_23-14-31z6_1xrv8/outputs/checkpoint-3
-------------------------------------------------------------
|           |   agree   | disagree  |  discuss  | unrelated |
-------------------------------------------------------------
|   agree   |    493    |    50     |    166    |    31     |
-------------------------------------------------------------
| disagree  |    17     |    47     |    23     |     7     |
-------------------------------------------------------------
|  discuss  |    233    |    50     |   1573    |    59     |
-------------------------------------------------------------
| unrelated |    19     |    15     |    38     |   6801    |
-------------------------------------------------------------
Score: 7102.0 out of 7516.5	(94.4854653096521%)
Accuracy: 0.9264186239866972
F1 overall: 0.7145526341204351
F1 per class: [0.6564580559254327, 0.3671875, 0.8468371467025572, 0.9877278338537506]
*******************************************


real	18m6.131s
user	17m8.681s
sys	6m13.169s
ubuntu@run-gpu-mg:~/fnd_implementation$ [Kubuntu@run-gpu-mg:~/fnd_implementation$ exit
exit

Script done on 2020-02-04 08:30:12+0000
