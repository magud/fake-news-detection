Script started on 2020-02-04 18:13:59+0000
ubuntu@run-gpu-mg:~/fnd_implementation$ tmux attach[K attach[Kcd fnd_implementationkillall --user=ubuntuexit[Ktime python3 test_separate.py --model=albbert --model_type=albert-base-v1M[C[C[C[C[C[C[C[Cls[K
[KM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Ctime python3 test_separate.py --model=albbert --model_type=albert-base-v1M[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C_separate.py --model=albe[1PM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C_separate.py --model=alber[1PM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C_separate.py --model=albert[1P --model_type=albert-base-v1M[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C_separate.py --model=albert [1P--model_type=albert-base-v1M[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Ce_separate.py --model=albert --model_type=albert-base-v1M[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Cv_separate.py --model=albert --model_type=albert-base-v1M[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Ca_separate.py --model=albe[1@rM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Cl_separate.py --model=alb[1@eM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C

/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/home/ubuntu/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/ubuntu/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/ubuntu/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/ubuntu/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/ubuntu/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/ubuntu/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
There are 2 GPU(s) available.
The following GPU is used:  Tesla V100-PCIE-16GB
INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/albert-base-config.json from cache at /home/ubuntu/.cache/torch/transformers/8eff152e0e6c9b5bca31d5ed10ab2b543d201465c907d1e7d6a8cedb28ec3a7f.422e3ad6212153abef6df151efafdff1939214d0acdbc8c8011e538a0c2a8e99
INFO:transformers.configuration_utils:Model config {
  "architectures": [
    "AlbertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "down_scale_factor": 1,
  "embedding_size": 128,
  "finetuning_task": "multi",
  "gap_size": 0,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "inner_group_num": 1,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "net_structure_type": 0,
  "num_attention_heads": 12,
  "num_hidden_groups": 1,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "num_memory_blocks": 0,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 30000
}

INFO:transformers.tokenization_utils:loading file https://s3.amazonaws.com/models.huggingface.co/bert/albert-base-spiece.model from cache at /home/ubuntu/.cache/torch/transformers/e941f532bbbf6d6b7c96efbde9c15d38fc236e7fb120158bfc766814e6170529.c81d4deb77aec08ce575b7a39a989a79dd54f321bfb82c2b54dd35f52f8182cf
INFO:transformers.configuration_utils:loading configuration file /home/ubuntu/fnd_implementation/albert/model_pretrained/config.json
INFO:transformers.configuration_utils:Model config {
  "architectures": [
    "AlbertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "down_scale_factor": 1,
  "embedding_size": 128,
  "finetuning_task": null,
  "gap_size": 0,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "inner_group_num": 1,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "net_structure_type": 0,
  "num_attention_heads": 12,
  "num_hidden_groups": 1,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "num_memory_blocks": 0,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 30000
}

INFO:transformers.modeling_utils:loading weights file /home/ubuntu/fnd_implementation/albert/model_pretrained/pytorch_model.bin
INFO:__main__:Loading initialized pretrained model from /home/ubuntu/fnd_implementation/albert/model_pretrained
  ******************************************* 
           Freezing Embedding Layers          
  *******************************************
 
name:  albert.embeddings.word_embeddings.weight
param.requires_grad:  False
=====
name:  albert.embeddings.position_embeddings.weight
param.requires_grad:  False
=====
name:  albert.embeddings.token_type_embeddings.weight
param.requires_grad:  False
=====
name:  albert.embeddings.LayerNorm.weight
param.requires_grad:  False
=====
name:  albert.embeddings.LayerNorm.bias
param.requires_grad:  False
=====
name:  albert.encoder.embedding_hidden_mapping_in.weight
param.requires_grad:  True
=====
name:  albert.encoder.embedding_hidden_mapping_in.bias
param.requires_grad:  True
=====
name:  albert.encoder.albert_layer_groups.0.albert_layers.0.full_layer_layer_norm.weight
param.requires_grad:  True
=====
name:  albert.encoder.albert_layer_groups.0.albert_layers.0.full_layer_layer_norm.bias
param.requires_grad:  True
=====
name:  albert.encoder.albert_layer_groups.0.albert_layers.0.attention.query.weight
param.requires_grad:  True
=====
name:  albert.encoder.albert_layer_groups.0.albert_layers.0.attention.query.bias
param.requires_grad:  True
=====
name:  albert.encoder.albert_layer_groups.0.albert_layers.0.attention.key.weight
param.requires_grad:  True
=====
name:  albert.encoder.albert_layer_groups.0.albert_layers.0.attention.key.bias
param.requires_grad:  True
=====
name:  albert.encoder.albert_layer_groups.0.albert_layers.0.attention.value.weight
param.requires_grad:  True
=====
name:  albert.encoder.albert_layer_groups.0.albert_layers.0.attention.value.bias
param.requires_grad:  True
=====
name:  albert.encoder.albert_layer_groups.0.albert_layers.0.attention.dense.weight
param.requires_grad:  True
=====
name:  albert.encoder.albert_layer_groups.0.albert_layers.0.attention.dense.bias
param.requires_grad:  True
=====
name:  albert.encoder.albert_layer_groups.0.albert_layers.0.attention.LayerNorm.weight
param.requires_grad:  True
=====
name:  albert.encoder.albert_layer_groups.0.albert_layers.0.attention.LayerNorm.bias
param.requires_grad:  True
=====
name:  albert.encoder.albert_layer_groups.0.albert_layers.0.ffn.weight
param.requires_grad:  True
=====
name:  albert.encoder.albert_layer_groups.0.albert_layers.0.ffn.bias
param.requires_grad:  True
=====
name:  albert.encoder.albert_layer_groups.0.albert_layers.0.ffn_output.weight
param.requires_grad:  True
=====
name:  albert.encoder.albert_layer_groups.0.albert_layers.0.ffn_output.bias
param.requires_grad:  True
=====
name:  albert.pooler.weight
param.requires_grad:  True
=====
name:  albert.pooler.bias
param.requires_grad:  True
=====
name:  classifier.weight
param.requires_grad:  True
=====
name:  classifier.bias
param.requires_grad:  True
=====

*******************************************
Evaluating the following pipelines 
['/home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_7e12e564_2020-02-04_13-08-441uoskr4l/', '/home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_7cf23c41_2020-02-04_13-05-23r05suqdz/', '/home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_7f4307e8_2020-02-04_15-41-10cm1if_kr/', '/home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_7e12e566_2020-02-04_13-43-29ycp_qh31/', '/home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_7c031cb2_2020-02-04_09-48-293e95l21m/', '/home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_7cf23c3f_2020-02-04_11-43-19t0q8o5ns/', '/home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_7cf23c3e_2020-02-04_11-13-29qpg9g36r/', '/home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_7c031cb4_2020-02-04_11-07-19g7f3zttt/', '/home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_7cf23c40_2020-02-04_11-47-359mix1_k7/', '/home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_7c031cb3_2020-02-04_09-48-29pa_7ve0h/', '/home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_7e12e565_2020-02-04_13-40-49aojt35um/', '/home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_7e12e567_2020-02-04_15-05-45hxiwycnb/']

*******************************************

*******************************************
EVALUATING PIPELINE 
{'batch_size_seq_length': 4, 'lr': 4e-05, 'lr_type': 'linear'}
INFO:__main__:Creating features from dataset file at /home/ubuntu/fnd_implementation/data/processed
  0%|                                                  | 0/9622 [00:00<?, ?it/s]  0%|                                        | 1/9622 [00:01<2:52:19,  1.07s/it] 21%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                             | 2001/9622 [00:01<1:35:33,  1.33it/s] 31%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                          | 3001/9622 [00:01<58:07,  1.90it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9622/9622 [00:01<00:00, 6148.81it/s]
  ******************************************* 
              Running Evaluation                
  *******************************************
 
  Length dataset evaluation: 9622
  Length dataloader evaluation: 301
  Number of epochs: 3
  Batch size: 32
  ******************************************* 
 
['/home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_7e12e564_2020-02-04_13-08-441uoskr4l/outputs/checkpoint-3']
INFO:__main__:Evaluate the following checkpoints: ['/home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_7e12e564_2020-02-04_13-08-441uoskr4l/outputs/checkpoint-3']
INFO:transformers.configuration_utils:loading configuration file /home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_7e12e564_2020-02-04_13-08-441uoskr4l/outputs/checkpoint-3/config.json
INFO:transformers.configuration_utils:Model config {
  "architectures": [
    "AlbertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "down_scale_factor": 1,
  "embedding_size": 128,
  "finetuning_task": null,
  "gap_size": 0,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "inner_group_num": 1,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "net_structure_type": 0,
  "num_attention_heads": 12,
  "num_hidden_groups": 1,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "num_memory_blocks": 0,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 30000
}

INFO:transformers.modeling_utils:loading weights file /home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_7e12e564_2020-02-04_13-08-441uoskr4l/outputs/checkpoint-3/pytorch_model.bin
eval_separate.py:214: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0
Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`
  for batch in tqdm_notebook(eval_dataloader, desc="Evaluating"):
HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=301.0, style=ProgressStyle(description_width='initial')), HTML(value='')))
0.0010580.0013010.0894510.2753300.2607160.0649880.1201490.0179400.014106
0.0018090.2404460.0388620.0236070.1484470.0677300.0048000.107379
0.0556050.0349570.4755220.0592830.5552490.2263221.1670840.3393130.0258340.0029150.0006040.0040060.0041170.0651680.2273210.2188870.2427020.2899170.0085960.3691760.4526930.0490210.0046030.0370610.2732580.1645860.0040360.0003380.0003550.0003910.0002170.0990570.0079710.0005550.0370720.3553810.0718530.0018010.3687780.2396520.0049310.0245340.1016240.4073410.6687280.0111770.0005430.2618190.0530050.3543860.2281390.6471220.4882290.0399340.0008600.0807570.1459160.2498730.0422540.3779130.5360740.2000010.1820130.0304620.1035960.0365870.5834150.0075780.0038430.0020630.0157710.0022840.2115080.2848782.0766260.3557120.4521861.1105300.3681840.0045600.0114140.3824030.0090640.5938010.4459310.3746030.0193590.1048110.0661250.0373070.0028610.0121890.0003870.2065730.2357090.2032710.8460460.1525070.8983780.5077200.1349040.0013890.3829570.1078730.2835302.2964580.0189010.1469950.0040400.0048450.4092860.2716680.1220510.0069600.1843270.1904660.0449910.4164481.0991410.0145090.0558030.3561180.8585400.2394670.0080030.0461180.2056280.5154000.1679340.5899990.3888600.1239700.0408850.0478170.1556161.3559290.0140500.0057460.0663820.0013730.1664910.0017931.0578551.8705380.0636360.0774090.1887120.8981890.1498700.2766050.0923850.0067210.6818990.0966650.1966360.1740280.0167690.2048561.0190532.2688140.1071500.0456580.1222130.8116372.2389521.0209290.3348590.2965560.2888530.3113672.1072561.1360380.3636540.2128510.0530390.2208430.5600600.0898780.0063420.0467180.1099920.6182511.4986720.8002740.0918370.0812560.6540230.2552780.1088030.1716440.4732851.3903881.7012250.2379880.0050700.0637180.6815570.8414070.0045280.0027590.0005600.0938050.0008050.0005920.0047400.0268160.0012990.0007490.8691900.2151580.0071420.2039580.1472310.7101860.0043890.0016860.0003170.0385680.0009370.7002830.1747541.9710560.1894210.0173730.2220880.0413360.4150210.9627960.0183810.0885210.0010950.1573960.2357090.2884030.1454480.1123980.1670151.1179961.0551450.6136790.0172590.5791130.5093330.3586651.7075390.6106150.1094731.0610460.1813760.2434350.5007640.4029970.1052150.1521200.1185530.0015740.0590010.0133820.0223910.0092270.0963670.0008770.3376620.5324161.3781910.4823570.1875090.4061050.4105941.4378940.0064460.1770760.1181640.0044100.0200170.0114360.2293370.8398630.6807991.0890770.0156520.034893
0.0049660.003803

*******************************************
EVALUATING PIPELINE 
Pipeline directory: /home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_7e12e564_2020-02-04_13-08-441uoskr4l/
With following parameter combination: {'batch_size_seq_length': 4, 'lr': 4e-05, 'lr_type': 'linear'}
EVALUATION OF CHECKPOINT /home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_7e12e564_2020-02-04_13-08-441uoskr4l/outputs/checkpoint-3
-------------------------------------------------------------
|           |   agree   | disagree  |  discuss  | unrelated |
-------------------------------------------------------------
|   agree   |    531    |    78     |    177    |    24     |
-------------------------------------------------------------
| disagree  |    19     |    40     |    44     |     1     |
-------------------------------------------------------------
|  discuss  |    195    |    36     |   1524    |    59     |
-------------------------------------------------------------
| unrelated |    17     |     8     |    55     |   6814    |
-------------------------------------------------------------
Score: 7077.25 out of 7516.5	(94.15618971595822%)
Accuracy: 0.9258989815007275
F1 overall: 0.7019550691263639
F1 per class: [0.6755725190839694, 0.3007518796992481, 0.8433868289983398, 0.9881090487238979]
*******************************************


*******************************************
EVALUATING PIPELINE 
{'batch_size_seq_length': 3, 'lr': 4e-05, 'lr_type': 'linear'}
INFO:__main__:Creating features from dataset file at /home/ubuntu/fnd_implementation/data/processed
  0%|                                                  | 0/9622 [00:00<?, ?it/s]  0%|                                        | 1/9622 [00:01<2:50:11,  1.06s/it] 21%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                             | 2001/9622 [00:01<1:34:22,  1.35it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                  | 5001/9622 [00:02<40:03,  1.92it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9622/9622 [00:02<00:00, 4560.05it/s]
  ******************************************* 
              Running Evaluation                
  *******************************************
 
  Length dataset evaluation: 9622
  Length dataloader evaluation: 602
  Number of epochs: 3
  Batch size: 16
  ******************************************* 
 
['/home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_7cf23c41_2020-02-04_13-05-23r05suqdz/outputs/checkpoint-3']
INFO:__main__:Evaluate the following checkpoints: ['/home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_7cf23c41_2020-02-04_13-05-23r05suqdz/outputs/checkpoint-3']
INFO:transformers.configuration_utils:loading configuration file /home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_7cf23c41_2020-02-04_13-05-23r05suqdz/outputs/checkpoint-3/config.json
INFO:transformers.configuration_utils:Model config {
  "architectures": [
    "AlbertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "down_scale_factor": 1,
  "embedding_size": 128,
  "finetuning_task": null,
  "gap_size": 0,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "inner_group_num": 1,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "net_structure_type": 0,
  "num_attention_heads": 12,
  "num_hidden_groups": 1,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "num_memory_blocks": 0,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 30000
}

INFO:transformers.modeling_utils:loading weights file /home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_7cf23c41_2020-02-04_13-05-23r05suqdz/outputs/checkpoint-3/pytorch_model.bin
HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=602.0, style=ProgressStyle(description_width='initial')), HTML(value='')))
0.0004170.0004750.0002920.0001780.0001000.4088040.3630700.5254830.0662280.1476360.0162870.0023000.4179560.0323870.0034710.0258840.0017670.0007730.0001130.0000840.0030430.0002550.0004590.0003450.0016970.0064070.0003300.4055630.0146680.0388620.0013800.0001190.0000530.1565540.0162970.4655160.0822480.0419181.2579430.0323830.0025160.0002460.7918281.2314030.0285590.4939011.5813350.5539990.4209670.0092550.0006590.0005480.0852820.0018560.0001310.0003310.0002510.3595600.2733380.0048900.0208860.0003940.4552750.0898230.6481070.0102340.9041250.0135660.1617550.5337210.0076950.0001790.1194780.4254000.5023971.0046800.1607040.0021680.0000790.0264090.3094240.0038970.4988250.0182790.0003460.4502420.0053070.0001920.0001430.0001110.0001060.0001770.0000580.0001400.0000730.0001040.1047690.3519180.0038470.0008280.0001620.0000800.0011990.0005200.0113760.3772330.2729070.0026190.0001630.0004330.0002361.4303370.5610490.0050870.0001080.0001060.0090820.0021850.0123600.0007810.0875561.0151730.4614600.0126760.0001830.0001320.0000550.0001620.0006400.0486590.0031110.0007400.1542800.3864060.9565330.3016900.6869750.5020880.0116080.2138020.0026880.0001550.0000800.0001201.2406900.4084150.2335060.0020820.0014190.5498110.0071020.0110430.1208720.2254590.0016080.3934860.0026150.2965430.0019690.0453190.0097250.0007540.0161700.0004730.0004920.0033140.0033480.1039780.0007030.0380530.1985170.4102420.0031310.4212150.0037170.0001200.0001690.0011730.0010040.1390570.2158110.0015994.6116152.2005740.2317441.6337170.4997010.2571601.9103940.6501760.7616250.1538410.0010510.0003950.0003760.0004230.0012630.0046330.0032100.0571090.9823940.0291260.0545230.0222280.0031772.4734470.1261360.0047540.0347290.0143290.0027420.2232370.0013030.6765790.4094990.0019670.4308940.0020420.0000680.0001040.0318800.5490210.0027610.6468940.6473540.0036380.0211452.1994670.0102260.0418551.2483811.1151311.0134880.3532350.3022470.0015650.0001200.0000610.0002060.8849340.5090350.0045720.0004130.9562193.8746622.7999610.0114810.0001100.4431631.1423830.0435410.0022890.0038980.0008060.0009800.9156040.6206490.0715290.2328830.3966210.0019790.0010250.2474770.2306900.0151290.1895440.0421220.0047160.0017681.1577951.5986721.4645020.3420680.1402010.7772440.0170920.0869780.3888680.0014581.0900670.0039720.3619480.0014730.0005250.0000650.0003280.3295510.0884090.0032061.7787440.6327220.0022550.2468880.2086650.3677500.2941960.4520560.0015790.0004010.3458890.0026180.0278940.0002190.0002221.3388561.4760110.0057200.0007950.0001620.0005570.0175880.0001640.0002150.0002370.3291180.0013180.0001550.0038830.1729252.5198782.3669041.9103740.3477760.0021230.0006350.1284110.0011410.7582943.1268980.0137480.0490820.2946080.2932560.0118790.2655090.0420540.0268240.0196910.0003750.4237630.0893920.0057480.0158270.0713150.1038880.0010180.0005890.3836560.0050650.0685220.0585131.9119905.1499890.0166030.0006420.1386380.0015650.0008260.0003430.7362562.0725272.0186074.3826306.5523611.4923301.5782561.2975890.0038250.0126420.1909310.0012290.0797750.0003931.4036602.2638063.8229692.5143331.9215921.2837780.7957260.0024230.0011720.0005770.0001280.0000640.0095100.9477550.0030910.3893702.8214220.0431950.0006670.0912530.0005460.2305850.2997980.7914920.4053501.9551070.7726841.5228900.7535060.0412120.2734970.0011120.3385871.6552775.3574622.5792070.0077280.0002070.2462410.1980340.0005861.5276390.3702841.2662162.1038093.1049230.4394580.4401020.2099500.0011720.0008700.0526070.0036530.0440430.9856680.6185290.2090030.0006090.0002740.0003600.0001600.0002750.0001960.0001940.0196000.0005090.0000940.0000560.0002930.0007180.0001530.5652890.0073010.0000790.0004240.0001570.0003010.2977860.4614400.1466810.3447160.0016520.0017830.0774290.3789150.0015932.1676913.4435911.9958820.0047640.7973880.0035510.1996960.0005340.0001770.0020540.0000600.0001010.0000861.0116810.0023910.0003650.0012580.0009513.7656270.4220810.3268830.0007770.0015010.0119410.0342540.0051360.0046540.0031730.7807711.3757510.2566430.0020880.0018950.0052140.0010350.0004550.0000560.0317190.0005830.1010750.0006260.0009090.0030690.1997830.0018030.0003160.0139720.0003321.1190220.9798071.4449610.7846321.3627670.6015260.6237830.0033360.0010830.0005601.0474130.2432670.0571190.9958610.5653701.0742792.5671321.4743190.8100490.3102830.1994221.4578511.8621290.5846620.1716790.4571960.0591190.9520060.0022950.1726170.5372980.2579490.0009910.5566800.0011710.0001990.6050780.0012750.0008230.0002760.0005690.0239720.0001150.1041830.0038340.0003380.0006960.0003910.3032320.0006060.0000590.9987560.0019041.0551450.0028710.0023100.3926854.9224630.1841150.0043940.9530080.4654340.5354900.0050640.2554640.9020581.1435130.5531370.0098640.2880090.0373000.0002010.3384250.0011690.0003150.0002880.0001910.0001830.0072081.0799410.2482060.0634470.5424180.6364480.2675220.5392570.2505750.0282120.0017390.0015530.0006560.0004640.0005520.0004410.001694

*******************************************
EVALUATING PIPELINE 
Pipeline directory: /home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_7cf23c41_2020-02-04_13-05-23r05suqdz/
With following parameter combination: {'batch_size_seq_length': 3, 'lr': 4e-05, 'lr_type': 'linear'}
EVALUATION OF CHECKPOINT /home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_7cf23c41_2020-02-04_13-05-23r05suqdz/outputs/checkpoint-3
-------------------------------------------------------------
|           |   agree   | disagree  |  discuss  | unrelated |
-------------------------------------------------------------
|   agree   |    507    |    61     |    155    |    37     |
-------------------------------------------------------------
| disagree  |    21     |    52     |    30     |     7     |
-------------------------------------------------------------
|  discuss  |    217    |    39     |   1561    |    48     |
-------------------------------------------------------------
| unrelated |    17     |    10     |    54     |   6806    |
-------------------------------------------------------------
Score: 7101.75 out of 7516.5	(94.48213929355418%)
Accuracy: 0.9276657659530243
F1 overall: 0.721968365223022
F1 per class: [0.6662286465177398, 0.38235294117647056, 0.8518417462482947, 0.9874501269495829]
*******************************************


*******************************************
EVALUATING PIPELINE 
{'batch_size_seq_length': 4, 'lr': 4e-05, 'lr_type': 'cosine'}
INFO:__main__:Creating features from dataset file at /home/ubuntu/fnd_implementation/data/processed
  0%|                                                  | 0/9622 [00:00<?, ?it/s]  0%|                                        | 1/9622 [00:01<2:55:46,  1.10s/it] 21%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                             | 2001/9622 [00:01<1:37:28,  1.30it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                  | 5001/9622 [00:01<41:22,  1.86it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9622/9622 [00:01<00:00, 6537.23it/s]
  ******************************************* 
              Running Evaluation                
  *******************************************
 
  Length dataset evaluation: 9622
  Length dataloader evaluation: 301
  Number of epochs: 3
  Batch size: 32
  ******************************************* 
 
['/home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_7f4307e8_2020-02-04_15-41-10cm1if_kr/outputs/checkpoint-3']
INFO:__main__:Evaluate the following checkpoints: ['/home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_7f4307e8_2020-02-04_15-41-10cm1if_kr/outputs/checkpoint-3']
INFO:transformers.configuration_utils:loading configuration file /home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_7f4307e8_2020-02-04_15-41-10cm1if_kr/outputs/checkpoint-3/config.json
INFO:transformers.configuration_utils:Model config {
  "architectures": [
    "AlbertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "down_scale_factor": 1,
  "embedding_size": 128,
  "finetuning_task": null,
  "gap_size": 0,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "inner_group_num": 1,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "net_structure_type": 0,
  "num_attention_heads": 12,
  "num_hidden_groups": 1,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "num_memory_blocks": 0,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 30000
}

INFO:transformers.modeling_utils:loading weights file /home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_7f4307e8_2020-02-04_15-41-10cm1if_kr/outputs/checkpoint-3/pytorch_model.bin
HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=301.0, style=ProgressStyle(description_width='initial')), HTML(value='')))
0.0016230.0019670.0377770.3600100.1164330.0268970.0982400.0244570.0055000.0008780.2131940.1010840.0520170.1253870.1076450.0075920.1127070.0934090.1914220.3019860.2134191.1003240.2831410.9757720.1027180.0457490.0163490.0034750.0564000.0420360.0397040.2043770.0748830.4053810.1727820.0054200.1078100.4084650.0364150.0019330.0873660.2050950.1396240.0034820.0003240.0010100.0013800.0003180.1163590.0074370.0007580.0778340.0575280.0187980.0007610.5821510.2347880.0045450.0983510.0913420.2894970.2841250.0050660.0004970.2223900.0076660.1260850.2509180.4451410.2502640.0046660.0004850.2366280.1171070.2209320.0172780.5751330.1647570.2045630.0036080.5458890.1460170.0102190.0183610.0018750.0014480.0025370.0392490.0043980.2628840.1589811.9803380.3952780.3233110.8615520.4380870.0055750.0010430.0603890.0060820.4246010.2317740.6005810.0141780.0246120.0015350.0190050.0025940.0736900.0012340.2272710.2054280.2103030.6526040.0182520.4280330.3090000.1076060.0012390.2732020.2207780.4279402.3275220.0193500.0238500.0032950.0037490.6733200.4231120.2163060.1749210.1721780.1693380.0262480.3341360.8667470.0525570.2999060.5083120.7738790.1627470.0067520.0050160.1853500.9001610.2414610.5387830.4584720.1123500.0569260.0880680.1233170.8393950.0386650.0057830.0820080.0719930.1540010.0048951.0881882.1500990.0908420.0883150.1235441.6304580.4050300.3394170.6256310.8039441.7275040.2114860.0022580.0177490.0114660.0995430.4792302.1109200.0586120.0317570.0398600.7018551.7829991.5573140.4385040.1453530.0298430.4879162.2618891.1587660.7737420.0389840.0013360.0251410.2124080.3108670.1067280.2475590.3154000.4693221.1665560.6906570.0955940.2197302.6887250.9607880.1597840.2315950.3124161.3595191.3709230.3018610.0026000.1893350.5085170.3568080.0024510.0012080.0531130.1520470.0012860.0007410.0003840.1820900.0026210.0011200.3152460.5237290.0087200.1487560.0722220.9188650.1305220.0682750.0015740.0884690.0007610.4294780.0024251.1980190.2361780.0401970.2638500.2224250.4206461.2486490.1814130.0933500.0025900.0502960.0696810.0033870.1333310.1847800.1017931.2138850.9184140.5748480.0165500.6111690.6199870.3354631.6774840.5542730.2182431.2994660.3628440.1390260.2733270.7033070.1144490.1587900.2269420.0019840.0372860.1698690.0066190.0246360.1540620.0012620.0619860.1800890.1632650.3227420.3232790.3331800.5780991.7934560.1426930.3001410.1083660.0017780.0410230.0381080.5792210.2373690.5093801.0675010.0067020.0072080.0145210.001909

*******************************************
EVALUATING PIPELINE 
Pipeline directory: /home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_7f4307e8_2020-02-04_15-41-10cm1if_kr/
With following parameter combination: {'batch_size_seq_length': 4, 'lr': 4e-05, 'lr_type': 'cosine'}
EVALUATION OF CHECKPOINT /home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_7f4307e8_2020-02-04_15-41-10cm1if_kr/outputs/checkpoint-3
-------------------------------------------------------------
|           |   agree   | disagree  |  discuss  | unrelated |
-------------------------------------------------------------
|   agree   |    486    |    59     |    161    |    13     |
-------------------------------------------------------------
| disagree  |    25     |    43     |    30     |     3     |
-------------------------------------------------------------
|  discuss  |    226    |    51     |   1556    |    69     |
-------------------------------------------------------------
| unrelated |    25     |     9     |    53     |   6813    |
-------------------------------------------------------------
Score: 7089.75 out of 7516.5	(94.32249052085412%)
Accuracy: 0.9247557680315943
F1 overall: 0.7028676532743392
F1 per class: [0.6563133018230926, 0.3269961977186312, 0.8406266882766072, 0.9875344252790259]
*******************************************


*******************************************
EVALUATING PIPELINE 
{'batch_size_seq_length': 2, 'lr': 4e-05, 'lr_type': 'cosine'}
INFO:__main__:Creating features from dataset file at /home/ubuntu/fnd_implementation/data/processed
  0%|                                                  | 0/9622 [00:00<?, ?it/s]  0%|                                        | 1/9622 [00:02<6:52:48,  2.57s/it] 21%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                             | 2001/9622 [00:02<3:48:54,  1.80s/it] 31%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                         | 3001/9622 [00:02<2:19:12,  1.26s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9622/9622 [00:02<00:00, 3391.64it/s]
  ******************************************* 
              Running Evaluation                
  *******************************************
 
  Length dataset evaluation: 9622
  Length dataloader evaluation: 1203
  Number of epochs: 3
  Batch size: 8
  ******************************************* 
 
['/home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_7e12e566_2020-02-04_13-43-29ycp_qh31/outputs/checkpoint-3']
INFO:__main__:Evaluate the following checkpoints: ['/home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_7e12e566_2020-02-04_13-43-29ycp_qh31/outputs/checkpoint-3']
INFO:transformers.configuration_utils:loading configuration file /home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_7e12e566_2020-02-04_13-43-29ycp_qh31/outputs/checkpoint-3/config.json
INFO:transformers.configuration_utils:Model config {
  "architectures": [
    "AlbertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "down_scale_factor": 1,
  "embedding_size": 128,
  "finetuning_task": null,
  "gap_size": 0,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "inner_group_num": 1,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "net_structure_type": 0,
  "num_attention_heads": 12,
  "num_hidden_groups": 1,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "num_memory_blocks": 0,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 30000
}

INFO:transformers.modeling_utils:loading weights file /home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_7e12e566_2020-02-04_13-43-29ycp_qh31/outputs/checkpoint-3/pytorch_model.bin
HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=1203.0, style=ProgressStyle(description_width='initial')), HTML(value='')))
0.0015850.0016620.0009430.0003730.0001640.0000960.0001180.0000850.0000710.0000680.0002650.7326670.4850830.0373720.8420890.0561990.0045030.0011080.0006450.0044760.0036700.0002300.0006900.0022960.0029171.1975120.0461150.0017800.0001900.0005160.0022720.0002970.0002100.0001000.0004280.0003970.0001090.0001160.0000830.0001860.9683810.0238290.0008160.0003510.3084620.3992800.0088290.0022740.0286670.0006830.0001460.0011080.0002730.0001030.7226970.0132020.0002920.0023480.0008330.0002110.0002850.0000580.0014420.0000740.0000540.0000540.0027590.4446160.6403570.0093620.0012060.0002700.0006240.0000620.6758410.8688870.2929960.6826680.0130220.0003080.0012910.0005480.0005120.0001390.0001441.6015521.6200500.7265090.0156060.0008680.0001410.9888270.0112632.7032730.0288741.4831260.4957370.4507390.0046710.0001430.6816960.0068510.0001660.0001830.0006530.0003810.0001090.0001660.0001130.0000690.0001140.0002690.0008880.0004490.0000930.0013520.3301680.0059690.0002610.0004330.0000560.0015840.0000650.0000531.0611670.0085520.0007070.0026180.0007340.0014030.0009200.0000631.4849310.7216600.0054430.0000930.6859540.8282790.7309080.0053760.0000900.0004720.0000720.0000540.6289540.8055780.0055800.7699020.7218830.0048960.7684710.5321880.0078100.0480650.0008920.0001670.0001840.0069590.0007270.2796061.2407990.7054410.0045810.0000810.0015460.9175790.0066590.0008890.0003950.0003970.5749170.0037310.0000780.0000540.0000580.0000550.0000630.0000550.0000520.0000890.0000740.0000580.0000530.0004490.0000550.0000540.0001060.0000540.0000540.0000520.0000630.0002730.0005140.0038250.0026170.5226540.0027350.0002440.0043240.0000750.0000680.0001130.0000540.0000650.0001910.0003810.1732570.2641640.5397670.5311490.5355800.6732510.6330320.0032950.0000660.0000590.0002590.0000650.0060840.0003740.0003970.0000632.3518920.0114370.0006400.9621650.0046200.0006380.0000580.0000630.0000590.0000810.0015870.1696710.0445320.2812340.0075650.0073820.0009440.0002770.8233060.3308400.5768721.0340610.5176710.2519950.0148370.0001140.0002380.0000560.0002390.0004160.0000600.0000560.0004690.0002740.0008230.5012950.0027570.0092030.0173710.0008190.2816290.0013211.0460470.0083720.2600710.5181121.1130091.6580000.0062140.0016980.1621430.9158310.8273000.0055180.0004930.0309210.5274630.0055660.0003820.0018130.0005770.0002300.0000560.0003230.0002660.0002570.5717451.5385150.7271430.0025680.7706110.0833270.0009720.0005510.0006490.0017740.0000730.9759320.0042470.8076230.0120090.0049820.0029341.8970270.3559331.0772480.0040930.0003270.6438670.4620390.0017210.0002270.1355390.0006580.0002500.0001830.0005190.0002791.0825221.6709960.0081060.0009851.3324840.0055080.0007600.0032270.0009540.0016050.0004870.0004600.0005080.0006670.0003130.0007020.0000550.0002460.0057950.0135670.0000980.0000570.0000590.0034030.0000630.0001070.0000610.0000890.0012420.0360010.0003730.0003720.0006620.0004140.0023750.0016090.0024310.0005960.3890130.0011720.6911020.0019950.0003010.0007911.9222080.3091850.0025352.4952500.0072450.2338120.9819672.2187280.7708110.0021460.3691290.0010701.5303470.8909311.7197960.0079851.4765960.0050390.0030160.0000690.0002650.0014680.0015150.0013060.0033430.0000590.0005220.0000610.0004400.6925290.1624680.0012340.0008720.1632040.0015920.6711551.1957771.1174260.0253200.0072420.0288080.0003060.0431710.0403730.2100270.0008780.5567140.1280130.4836090.0030840.0029610.0018780.0009940.0020930.0008770.0888890.0015850.0001000.0001000.0005770.0002890.0005370.0000680.0029370.0006100.0000580.0000540.0000560.0014070.0006060.0000560.0000540.0000540.0000550.0000530.0001030.0297740.0101180.0016360.3589500.0025640.0001410.6573530.5539500.0906910.1574740.0061200.0107160.0008590.0010492.6187261.6466960.0037190.0005700.0004830.0005740.2766630.3326560.3107960.1880500.1439460.0314210.0013660.2191050.0580080.4836440.0011350.0209430.0001010.0002780.0000540.0000550.0002860.0005300.7732080.9256530.0024650.9298670.0853470.4322680.0009640.5309460.0011470.9518522.6432962.6494423.7517242.9367050.0063150.0000680.0000730.0000600.0483930.0003300.2734950.0054450.0007670.1108140.4664290.0012260.0019320.0002840.0022430.2907800.0021910.9227360.0871211.8910971.6209370.0032280.0002450.0017200.0041530.2957601.6990510.0042510.0016530.0004160.5352720.0015490.5367940.0053560.3976540.0008190.0356240.2168950.0366300.4327870.2131800.0009500.0089180.0079560.0093020.0028151.5175581.5737732.3977971.0288663.4062681.4562730.7191222.9236890.8701560.0023290.6371822.3763720.4386890.0090600.7485710.0127170.0119300.4064310.0007850.0000890.8001171.6855740.0036510.0001320.0681510.0001800.0008390.0000620.0006770.0014780.0000630.0000600.0494870.0001440.0003941.1958330.4180160.6442980.6187200.0024202.1281371.5155480.9652600.0053510.0002830.0000590.0001392.0635251.1250970.0024280.5551000.7956100.4100600.7143820.0017650.0000640.0000980.0001450.0029160.0000610.4385690.0013110.0000640.0114450.0278270.5969840.0010410.0004710.0016430.0000720.0010061.2832162.0114760.0046600.6046570.0058760.0048050.0015330.0003460.0001780.0015810.0048650.9093940.5508710.0011080.0006440.7232170.0012220.0407180.0001770.0000660.0078060.0011470.0001020.0002870.0001150.0015240.0000730.0005720.6075471.3325660.9348221.3798071.8288711.2896080.3010830.0100090.0088280.0057150.0018540.0015360.0021770.0037460.0010600.0009450.0012190.0008760.3727431.5142933.0350310.0076440.0000620.0074580.0000650.0010670.0023150.0027810.0160810.6743290.1302110.0047620.0049340.2660080.0526160.0001490.0607140.0004670.0605590.0001730.0000684.6026895.8265851.5613530.0024120.4563620.0060980.0023490.0000580.6148550.0082510.2584420.0009860.0002330.0032200.0000860.0012540.0000670.3490700.0014530.0052260.0959341.1082450.6013900.0018440.0013070.0859702.5921352.5631080.0090450.0094130.0008290.0016280.8672800.0027280.0034170.0010110.0010490.5041110.0017050.0013630.0007720.0010090.2383700.4534811.1766451.6020610.0027790.0020620.0015690.0012190.4832550.0299830.0537060.9138721.9981420.0048200.0020600.0006030.3730510.0453150.0001180.0018770.0001100.0027090.1019850.0922110.0005980.0000720.0038370.0012850.0015630.7259270.1724980.1652450.0031740.0025470.0010410.0015010.0015600.7135831.2889150.0039450.0027720.0041860.0024460.0019460.0006540.0004750.0004230.0000730.0001140.0000600.0004320.6428420.9313820.7805810.0016810.0036370.5537131.1905742.2804821.1008410.1333400.0048690.0001140.0032430.4573790.0554600.0044480.0008730.7439840.0301230.0026660.4894560.4284820.6156930.0020510.6404151.7230160.6681290.6025040.5520212.2556100.0151860.7747000.0039500.0006760.0012820.0011160.0926340.0014540.0008510.0002690.7533092.3287110.7660004.2538615.9887365.2040540.9334230.0015060.0004400.0004900.0002540.0000580.5114071.0755590.0013610.0000590.0004803.0986041.1543210.6917080.0015181.5233121.3627600.9950162.1290633.9338861.1812430.1777440.7447010.7182470.0022930.4012980.0005350.0002100.0007110.0010850.0014150.0033630.0568200.0011290.0021000.2100160.0016242.1342871.1622060.4975190.7198170.6390390.0028010.0000610.0006430.0007120.0009880.0036010.0010650.0007250.0004020.0002100.0000850.0007360.0003890.0006020.0005380.0004330.7120040.0008710.0007080.0003620.0000610.0001130.0000650.0013380.0009700.0002250.0010410.0002500.0003660.0024780.0023480.0000550.0002120.0000560.0000570.0005800.0012420.0000620.0005310.0005940.0005180.0000600.6022050.0098950.4829940.5914320.0417381.3910020.0036680.0018980.0010940.0022380.0015680.6146810.0016420.0043500.0122120.0011660.0017380.0016520.5925360.7168370.5574080.0819470.0020870.0018210.0009170.9961480.0028540.0010500.0011500.0734360.0729830.0001330.0003030.0008160.0004380.0000550.7079480.0008160.0000580.0000980.0000550.0000550.0003761.7196260.0021670.0006650.0008560.0006310.0010090.0007830.0000560.0023400.9744793.2927962.0084030.5294280.0010910.0009280.0002840.0000570.0003480.2944040.0007260.3444180.4806570.7312270.6550330.0261010.8335840.0359180.3575640.4735930.0020751.2601871.5653582.6336130.6091821.2054250.9104810.0026890.0210910.0017560.0034290.0516060.5485830.0197970.0017770.0014250.0000570.0000580.0000550.0075380.7285300.0007880.0026390.5523070.0043820.0002500.0017850.0022180.0020330.0019070.0008140.0016380.5884790.0027640.0009840.0009050.0000580.0035480.0060410.0013970.0000590.0725780.1437450.1367970.0070852.2816221.1624010.9187020.0266781.3351800.0014160.1181480.1951090.0002480.8555440.4103660.0134910.0000670.1664460.0021780.0023491.1935411.3037021.6955050.8491221.5763970.0151811.0564800.8006040.3801541.2903640.4765633.5003311.9123762.8862431.7881991.5164970.9830590.7815960.0018970.6925020.0007490.7818732.1158350.2445640.8094142.5778441.9667990.0034370.0018230.0013550.0206330.0024210.0005220.5711480.6329290.5559720.1174720.0125560.2964420.0142050.5908330.0630450.0015920.7562950.3907730.0010330.0027600.9949550.0011330.0005650.0006270.0008350.0011480.0017530.0016020.0012760.0010990.0009790.0006090.0007290.0000600.1309760.0001750.5243250.0005480.0000580.0000580.0051790.6187830.0006140.0205630.0000740.0019200.0012970.0019350.0021880.7137010.0061130.0000670.0002060.0000740.0000760.0214181.4259690.0013340.0002840.0268920.7402500.0015960.0018510.0018340.0014140.9107910.0120222.1469905.3705740.5038250.0070930.0046830.0051200.5671030.0074030.0031140.0003651.2017950.0014640.4865020.6814662.3539910.0026701.9079532.1073151.7476350.6350310.0015050.0032870.0052260.0020120.0004370.9474350.0011050.6591620.0008980.0000570.5153830.0033540.0016470.0000580.0008560.0004530.0012350.0009550.0025940.0004460.0011950.0007560.0008040.0068671.8695970.6136451.3020650.0123561.0871021.0118650.7494401.3357360.4448591.1719100.3829330.4707230.0188671.4262301.8888900.4472270.0468210.0054890.0038790.0011580.0016330.0010160.0013290.0013430.0090660.0033370.0006430.0080920.0013421.0665480.001952

*******************************************
EVALUATING PIPELINE 
Pipeline directory: /home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_7e12e566_2020-02-04_13-43-29ycp_qh31/
With following parameter combination: {'batch_size_seq_length': 2, 'lr': 4e-05, 'lr_type': 'cosine'}
EVALUATION OF CHECKPOINT /home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_7e12e566_2020-02-04_13-43-29ycp_qh31/outputs/checkpoint-3
-------------------------------------------------------------
|           |   agree   | disagree  |  discuss  | unrelated |
-------------------------------------------------------------
|   agree   |    457    |    51     |    120    |    20     |
-------------------------------------------------------------
| disagree  |     8     |    34     |    22     |     2     |
-------------------------------------------------------------
|  discuss  |    274    |    66     |   1616    |    44     |
-------------------------------------------------------------
| unrelated |    23     |    11     |    42     |   6832    |
-------------------------------------------------------------
Score: 7137.75 out of 7516.5	(94.96108561165435%)
Accuracy: 0.9290168364165454
F1 overall: 0.6966783742531081
F1 per class: [0.64822695035461, 0.2982456140350877, 0.8505263157894737, 0.9897146168332609]
*******************************************


*******************************************
EVALUATING PIPELINE 
{'batch_size_seq_length': 1, 'lr': 4e-05, 'lr_type': 'constant'}
INFO:__main__:Creating features from dataset file at /home/ubuntu/fnd_implementation/data/processed
  0%|                                                  | 0/9622 [00:00<?, ?it/s]  0%|                                        | 1/9622 [00:01<4:21:11,  1.63s/it] 21%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                             | 2001/9622 [00:01<2:24:49,  1.14s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9622/9622 [00:01<00:00, 4945.66it/s]
  ******************************************* 
              Running Evaluation                
  *******************************************
 
  Length dataset evaluation: 9622
  Length dataloader evaluation: 2406
  Number of epochs: 3
  Batch size: 4
  ******************************************* 
 
['/home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_7c031cb2_2020-02-04_09-48-293e95l21m/outputs/checkpoint-3']
INFO:__main__:Evaluate the following checkpoints: ['/home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_7c031cb2_2020-02-04_09-48-293e95l21m/outputs/checkpoint-3']
INFO:transformers.configuration_utils:loading configuration file /home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_7c031cb2_2020-02-04_09-48-293e95l21m/outputs/checkpoint-3/config.json
INFO:transformers.configuration_utils:Model config {
  "architectures": [
    "AlbertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "down_scale_factor": 1,
  "embedding_size": 128,
  "finetuning_task": null,
  "gap_size": 0,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "inner_group_num": 1,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "net_structure_type": 0,
  "num_attention_heads": 12,
  "num_hidden_groups": 1,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "num_memory_blocks": 0,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 30000
}

INFO:transformers.modeling_utils:loading weights file /home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_7c031cb2_2020-02-04_09-48-293e95l21m/outputs/checkpoint-3/pytorch_model.bin
HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=2406.0, style=ProgressStyle(description_width='initial')), HTML(value='')))
0.2628660.2857490.1461620.0498830.0135091.4275770.2385030.0348390.0048200.0011970.0006960.0037270.0008180.0058470.0013920.0006780.0022780.0006890.0004760.0005850.0197250.0014721.2896710.0566790.0254780.0272570.0015020.0005200.7786880.0461251.6106900.0526640.0034520.0016540.3795750.0112840.0212470.0010120.0028780.0042570.5511831.4560710.0351450.0014780.0234200.0009540.0237200.0009331.5144060.0313361.7400470.0359850.0017580.0008850.0014000.0017500.0008910.0033980.0218940.0008100.7465460.0127930.0025040.0006660.0004430.0007990.0131290.0007430.0026260.0020241.1805030.0188060.0007120.0008040.0007490.0004640.0005940.0004740.0008250.0006110.0138530.0033220.0014420.0005290.0009870.0006300.0022540.0143090.0725870.0240720.0033580.0037351.3263710.0188010.0378870.0008300.8336790.8626380.0095880.0011060.0009801.1767270.0142970.0148550.0032990.0011540.0014960.0005040.0152160.0215240.0009910.1683690.0164670.0007120.0008700.0250930.0006501.5224060.0133340.0012560.0004450.0195530.0006210.0004950.0004670.0181640.0007690.0004400.0012010.0004500.0004630.0004580.0683790.0627110.7931461.3191860.0101611.2679460.0116160.0013201.2762050.0272110.0036800.0232450.7917310.0065960.0004940.0004921.2924820.0104722.7004180.0183162.1474560.0587490.0149360.0007790.0007690.0014810.9432560.0071170.0084871.6484340.6415690.0060130.0008641.5746940.0121420.0012730.0004800.0013360.0147761.5846160.8080340.7919610.0056180.7695850.7092810.0054810.0240960.0012490.0005640.0014111.3024890.7094060.0484550.0011391.9874510.8532050.0051220.0018382.0355651.1396330.0301921.0345700.7481020.0045260.0007450.0006111.4731460.0083540.0005500.0205730.0005930.0008030.0007180.0005080.0007030.0011411.3466640.0077350.0232710.0012850.0007980.0005520.0013940.0009680.0005960.0004980.0005660.0004720.0009540.0004600.0231790.0005530.0448470.0007310.0026200.4071150.0022460.0015080.7097590.0263300.0217720.0005300.0211110.0005320.0004430.0004410.0004340.0228780.0005850.0004360.0008700.0219890.0005230.0004400.0004440.0004400.0004350.0123920.0005290.0008920.7115910.7012630.0032930.0008371.5312850.0077610.0017330.0164880.0135800.3382770.0024510.0019330.7860821.6283620.0223930.0005190.0004580.0004290.0004900.0004290.0004420.6586130.0257970.8189471.4034310.0055050.0007700.0004580.0028740.0004520.0005460.0004330.0005240.0004980.0018900.0004470.0004320.6914220.0028220.6596590.0026970.0004540.0004290.5349460.0164610.0005010.0004300.0004510.0004380.0147230.0138320.0004790.0004310.7037672.7103523.0056383.0767311.6106142.8900191.5240312.8760551.5525944.0630821.7758351.0835250.0140250.8452630.0032330.0025102.0143170.0076180.6452560.0030490.0224750.0007290.0004570.0228880.8865901.5893270.0266210.0005100.2840680.0118570.0483330.0232700.0170120.0007680.0226240.0237760.8518550.0029240.0010610.0004390.0004400.0008830.0008550.0005060.0007410.0004340.0011370.0006450.0006710.0004490.0004910.0004780.0004630.0006320.0064820.0031600.0004440.0004690.0004440.0004550.0004400.0011140.0233290.0006790.0005950.0004510.0004340.0004660.0019440.0004390.0009440.0015900.0004390.0008700.0004800.0006630.0004820.0179140.0006700.0042450.0028950.0023691.4468710.0051760.0015340.0029780.9165900.0031160.0015570.0053330.0024830.4018770.0014940.0004340.0005510.0017080.0005960.0008470.0010880.0015400.0004320.0007581.1824700.0050351.1930530.0057720.0004450.0162250.0005361.6128820.0044360.0005100.7112360.7092600.0024000.7725970.0859220.0233140.6667800.6622310.0019980.0114820.0005990.0004640.0018591.3660560.0036300.0005310.0235120.0031380.0007020.0033340.0007160.0008750.0004340.0005830.0009900.0005070.0008490.0937612.8979131.6169150.0048190.0230480.6401191.4937280.0269510.0222470.0025920.0138890.0235020.0008310.0012500.0006030.0006000.0007790.0005190.0006150.0012990.0236621.1022780.0028641.4479290.7100980.0061080.0012040.0029370.0023790.6785271.9889460.0117230.0402801.7419680.1586970.0012800.0007250.0013521.4680661.3252663.0965682.0839981.9745130.1339212.7029092.0741542.5961120.0290900.5052440.0049080.0009360.0005060.0227770.0004880.0004830.0004480.0005350.0229460.0452440.0005300.0006160.0004730.0004290.0004340.0346590.0005050.0004390.0229200.0019260.0231010.0427520.0005550.0021630.0226870.0233940.0231880.0004960.0227870.0222500.0040600.0006470.0162540.0010300.0161520.0581780.0013790.0624890.0009831.0802800.3327700.7066131.1013522.1599520.4949790.0251040.8203220.0023160.0005170.0023460.1798610.0015030.5253820.7131501.6069901.2979261.3706660.0254210.0020380.0005170.0206261.5203861.4979061.6416800.0271580.0232540.0009950.0010680.7099560.0021950.0128400.0255301.5091320.0230250.0005130.0004720.0006310.0005790.0153790.0228950.0004720.0245410.0029810.0178900.0004760.0163700.0149850.0004600.0142300.0010450.0004320.0145230.0009532.5917280.0275310.0256100.0230500.8457960.0039871.3240730.0039910.0339842.8285810.0053810.0043120.0238291.5002990.0228250.0228370.6924061.9305350.7838350.0486180.0252420.0496140.4680621.2334470.0266004.9355640.4022280.0025973.0344291.0630510.0177510.0108080.0012060.0237720.6435360.0022710.0005370.8156570.0124170.0007990.0161210.0004810.8401620.0018430.0110500.0004560.0004320.0139840.0004740.0011930.0005580.0110680.0185990.0004980.8539701.4254591.4717660.7748550.0460880.0440050.1877400.0008770.1826700.0011890.1122670.0307210.0011130.0415280.6047910.9122470.0445860.0602410.0891080.0756470.0185280.0195140.0234900.0185060.0334440.0006300.0493050.0006560.0209670.0013070.0325960.0231440.0005520.0004810.0007670.0234530.0542800.0819610.0792110.0229900.0004940.0004340.0004360.0004360.0004330.0008480.0004620.0240960.0006930.0006940.0011050.0006560.0004460.0004320.0004310.0004890.0237660.0004650.0246060.0232001.5083240.0243440.0005100.0111930.0134630.0217710.0015920.0240731.4733240.0201200.0167340.0304360.0042000.0151700.0012920.0161410.0006061.3470080.0023550.0005110.7945570.6553600.0014981.5055210.0133760.0012330.0111000.0122071.5565061.6148070.1740070.0914980.0916700.0444953.3195000.0287860.0007880.0165290.0239940.6772900.0163510.0235240.6860991.8871030.0459002.4977692.7926940.0090332.3724281.5946690.2086680.0012150.0590710.0590791.0376140.0026092.0210610.0033000.0006230.0007552.0364820.0040820.0017890.0007250.0013241.3394640.0022000.0004890.0227620.0006240.0569590.0800900.0670190.0729000.0767940.0658560.0154060.0037660.0004400.0004570.0207300.0004770.0007840.0004540.0009660.0370440.0223361.5432900.0471491.3420910.1346690.0150310.0006382.5874020.0417141.2323270.9485761.5790410.0259250.5535000.0940002.3543923.9505360.0268270.0004930.0251221.4909520.0025401.0045940.0298561.0606560.0033550.0253020.1139210.0005842.0425680.0029421.2463600.0162710.0004750.0004361.2387442.2587763.1899560.0043430.0281721.2498351.5179250.0024303.2321671.6029320.0242910.0332550.0337781.1306820.7478520.7897570.0013860.7083000.7195940.0013780.6640270.0027560.0021120.0005790.0010070.0232070.0235150.0005860.0159521.5077780.0023530.0005750.0007120.0583100.0664910.0160110.0072201.3514960.0020040.0006680.0004330.0004360.0006170.5047560.0010230.0016910.0006230.0006280.0004360.0004290.0004330.0004290.0005650.0004320.0004550.0004310.0004290.0004340.0009990.0004470.7594451.3786332.4129230.7142660.0013040.3696060.8652860.0909240.0679630.8915950.0044900.0026342.2925390.7487262.6290991.0311120.0025561.1031930.0260800.0467300.0479811.1151130.0156110.0237300.0118930.0006890.0467850.0242901.6229731.5614380.0041610.0014460.0010620.6035280.0165360.0226930.0133770.0543470.0149190.0665270.0013270.0441680.0444230.0391830.0449000.0696081.5591510.0240600.0327210.0137350.0348510.0021650.0241650.0516760.0233880.0530430.0327480.1003920.0146450.0009010.0008480.0142370.0004760.0013330.0004480.0004320.0228470.0008690.0004310.0025190.0008570.0004720.0032110.0230780.0006340.6824120.0011620.0004331.2325400.0195890.0148611.2384130.0022380.0004340.7756320.0047330.7951420.0015570.0004820.0004290.7930780.0012930.0004410.0232081.9755731.8948211.9475861.2685911.9074611.9080763.1009140.6002121.4159270.0162330.0005270.0004490.0005630.0005130.0014700.0005690.0004440.0004350.1892810.0006470.0007730.4878760.0153690.0004550.0608460.0007870.0011301.5768520.0021581.3503181.2561780.0025620.0046080.6751681.5504981.3350031.4655180.6467051.5209701.4493300.0108691.3365340.0017671.9432820.0023821.6125370.0021320.0127733.1549711.5474800.0384620.0007490.0012580.0005120.0142040.6701260.6825980.6641800.7879441.3954261.0386480.8128142.0336240.0275280.0773940.0747850.0794340.0006330.0232830.0234190.8039700.0017810.0214290.0005572.4559830.6429080.0010541.2407071.2435790.0016220.0004370.0004431.8784590.0022350.6469990.7107391.2365961.2505170.0032720.0487801.2842410.0241580.0004680.6495120.0010980.0004620.6482660.0229800.0007130.6478320.0010491.2062391.3469420.0016942.4849541.8236642.2603422.0217170.2269772.6184592.7807941.3388331.7088030.0020020.7019060.8384402.1016110.7254821.6887280.0245890.0679910.6657281.4359801.3424080.7304140.2081600.0393560.0139780.0245871.4808260.0035650.0006410.3534630.0908380.0859640.7990200.0017970.0004420.0004390.0004320.0006040.8072410.7974001.5858640.0151760.0006360.0144810.0006950.0005520.8062630.0011530.0005060.0004390.0004670.0240690.0004570.0004881.3018830.0015790.0289160.0289800.0004860.0008960.0004280.0004500.0004430.0019270.0004560.0004460.0006180.0008870.8137932.8737030.7347400.8382500.2022430.8052390.0013590.7441130.0479550.0004861.4595690.7559281.4905250.0388940.0223190.7627541.0275320.0236161.5202220.0017350.0006520.0019210.0004600.0015090.0005453.7401390.0058291.2669660.0153020.0202650.0161380.0004751.2321370.0015061.2385050.0022721.2420280.0017251.3403871.3646790.0016200.0004370.0004370.0004910.0004410.0006360.0474250.0004720.0004610.0004380.0010721.0333620.0015760.0240470.0014070.0008220.0030111.3763241.4112711.3653462.2377900.0045150.0006000.0004990.0005800.0234830.0231110.0005920.0004550.0010460.0206500.0210010.0005471.4590922.1861041.4392870.0395930.0269180.0434740.7343141.0279310.0246230.0031130.7356790.0241590.0006350.0007910.0005150.0024660.0005750.0015591.0797350.0485520.0048890.0004651.0566461.3108670.7287220.0240170.0004870.0013250.0007573.1284900.0033120.0004720.0005330.0194170.0018080.0006640.0007060.0005300.0005211.3477830.0023980.0004910.0172890.0005530.0009760.0232650.0007100.0006940.0004620.0008990.0346960.0005020.0014650.0242050.0004931.3629340.0018671.2846532.7888610.0948570.0832530.0697520.0566671.4100442.1349391.4264301.5433820.7365750.0479880.0457750.0508230.0526920.0470760.0980310.1283670.0433960.0554510.0649430.0423260.0894670.0879420.0659380.0582330.0531420.0225600.0460060.0306550.0429770.0452220.0383880.0226331.5433850.3771121.3636601.9259622.9512592.5343290.2311200.0007240.0005680.0009130.0005701.4801050.0015490.0004670.0122400.0127260.0004790.0709460.0586470.0494470.0662141.5292031.6783603.2210810.0921340.0007060.9147020.5542570.0295000.0141040.5225171.5482510.1406660.0621751.6132052.5405022.9636760.0767600.0004971.5682990.0149990.0054210.0015650.0011201.6265411.4492953.1125192.0366815.4017664.3591932.4830300.0024470.0007430.0004331.6099030.0028110.0005000.0245570.0011570.0008900.0004320.0004600.0004280.0006270.0004340.0135000.0005801.0788580.0012130.0015010.0004330.0004500.0235871.8064900.0018050.0005850.0005560.0241070.0004620.0004420.0103790.0004851.2212700.0389771.9673941.1837850.7799131.4275571.2703790.8162652.1696540.0477730.0194660.0643540.0879850.0225841.4757061.5003033.4285142.8450862.8445442.8389410.6688050.7000261.0715441.3207870.0013620.0237390.0005550.0237910.0029651.0119480.0247060.0004660.8985530.0778460.0366780.0451540.0684420.0451620.4134410.0392600.0573451.5361780.0587620.0586240.0229870.0561641.2877040.0025180.0244871.2517740.0027870.0012362.0409280.0576740.6582210.0013670.0012320.0352143.3825600.2898450.3404713.1741210.0597050.0005571.4181923.0678370.7091162.8132870.1967860.7131120.7135231.8502722.8628930.5268820.0650690.0857020.0911740.0860160.0579360.0006580.0189851.8534720.0017020.0153970.0005470.0004400.0004960.0144560.0009640.0006281.6502640.0015600.7273820.0153720.0005020.0144630.0005260.0006510.0004480.0004831.3238790.0420160.0892380.0607140.0545630.0642421.2987870.0554510.0753190.0620080.0605891.3373080.0574740.0221260.0433120.0152840.0220790.0386440.0459700.0234620.0282400.0225790.0457490.6828361.6074010.0258760.0451390.0393790.0524140.0339680.0346000.0371840.0233210.0346200.0405080.1393680.0696550.0157750.0008570.0374620.0289240.0005950.0006250.0008630.0004370.0004310.0004830.0004330.0016251.5123490.6716070.0010011.3942310.0019740.6414250.0009110.0191800.0127330.0545010.7160510.7332630.0218250.6874402.7115553.8807990.5563760.0705210.0016520.0010400.0468271.5648361.4030770.0038260.0010360.0239520.0111450.0209201.5017280.0236191.4489190.0281090.0221490.0309890.0108690.0240081.4357250.0224990.0737650.0934630.0248271.0579972.4322321.5797400.0366080.0214440.8185730.0290840.0158161.3480170.0285221.3531882.1780380.0252480.7764130.7986730.0126290.7949050.0125894.1507931.4277210.7138753.1788940.0597041.4262180.1662000.0230570.0439540.0004650.0401560.0435210.0239020.0004431.0350760.0245550.0240760.0004500.0207480.0192200.0163370.0006580.6875130.0011671.3720022.1138010.1010010.6975550.7322553.1751803.1265003.1840223.1417522.5464620.0336570.0145271.1871660.0017971.4896070.0013480.0460981.4364170.0229050.0005100.0007950.0007821.1747410.0011711.3968272.0543910.0017730.0006110.0006090.0011730.0004820.0155994.4630834.0062001.3096651.4642860.0140490.0010760.0129420.0006960.0006520.0156090.3042161.3961760.0293490.5851741.4097530.0214961.2540601.2393690.7224830.0009900.0005030.6409471.0119560.0013571.2347490.0013630.0005480.0304601.8509240.0018370.0004300.0005090.0024590.0007840.0020930.0302410.6587290.0157160.0575050.0314590.0484220.0477200.0221351.2946100.0258520.0342610.0280270.0689700.0011390.0671780.0272010.0435542.0470100.3218282.9038450.4586602.5512071.5170470.0038422.4009901.7499552.6380181.2777370.0024800.0012110.0007630.0382341.6252590.0390730.0221480.0262760.0315010.0335640.0482680.9015030.0597500.0232730.0236300.0111770.0236490.0004530.0419180.0019800.0005800.0456370.0372450.0226020.0260020.0439510.0223660.0118030.0243300.0549070.0457500.0229100.0712510.0014670.0008110.0445200.0430120.0006020.0427470.0011890.0005330.0009100.0008540.0004570.0010430.0564150.0233240.0005630.0874110.0005060.0215540.0021630.0004680.0233010.0007400.0004340.0454971.4533960.0243280.0230770.0251890.0005610.0004390.0040090.0005960.0004640.0004430.0006520.0004301.0455460.0010142.0846340.0015930.0005980.0004700.0004360.0273530.7947890.0008700.0243030.0005020.0005190.0004480.0237030.7341780.0241290.0931442.6956410.7129752.8391040.8281670.6876732.1756202.4985332.0405380.8185260.7472280.7116021.5041350.6761220.7815200.6852170.6601740.6825130.6733851.3702631.6265880.6899980.0017881.2936461.3959500.3912961.4097330.0159780.0462040.0693470.0847940.0750240.0842612.4058891.9052060.0338350.0521560.0391980.0479101.6335561.4215880.0831670.0555210.0480710.0331810.0157901.7615762.1545681.2021610.0585800.0777220.0499020.0651420.1686751.5310590.0594800.0331980.0149960.0227180.0005360.0005130.0004490.0225670.2327970.0231490.0222020.0007980.0004500.0004290.0031652.6110750.0019950.0005220.0006360.0006161.4512620.0012110.0007830.0004340.0005420.0004440.0230200.0009702.9565020.0020021.5471940.0154200.0210290.0422381.5630630.0232630.0457850.1221740.0458810.0459130.0230970.0228780.0004490.0004450.0257950.0241290.7349460.0476491.3917542.0814930.7318982.2150571.8320430.0221690.0211500.0228260.0232450.0235650.0004560.0204880.0005990.0005830.0006940.0230940.0492430.0004720.6482800.0015320.7081040.9079270.0246580.1568190.0006300.6067421.0102100.1151940.9943771.2415131.0029891.1565332.0109501.7530701.0038912.2259400.0016521.0642370.0712520.0743990.0448090.7097750.7087880.0901291.4263972.1040031.4995001.4998192.2948304.3307742.4258911.8559900.0116491.6012721.4365941.8617730.7020260.0685541.5944581.4403500.9135001.6082571.3075680.0356810.7837040.7058610.6458550.0241420.0004590.0250570.0006700.0004710.0023160.0023420.0004340.0004460.0004970.0324580.7100470.5006530.0006970.0004570.0008880.0240930.8106360.6595580.0241240.0032170.0013620.0245450.0575940.0548540.2227750.0551610.0569600.0507700.0693880.6886410.1705090.0009580.8438710.7865050.9624362.0351390.0714500.8420760.0147400.5604100.0007340.0142050.0004600.0004290.0329100.0407140.0387390.0145620.0292780.0004430.0004430.0004470.4286431.9920661.7108211.0394950.1285762.2324823.6135042.1500832.0890253.0421931.1335100.0011600.0004591.4506451.2345460.0015192.8608541.0054400.0015210.0005501.0970830.0011960.7375920.0007970.0004460.0004642.9206140.0020150.0004700.0005571.4813560.0233870.0004540.0004420.7760950.6393980.0009070.7766290.0008960.7771330.0008712.6925291.5990980.0505951.5765450.8101490.0507811.5901892.0936222.2463921.5729151.3357500.0824490.0582981.4854841.4249082.2228150.0024311.3967790.1262560.7307290.7711945.2416303.3541001.6802132.8815582.9807161.3678760.0251810.1080820.0990330.0451970.0521350.9058480.0008730.0255980.0281230.0020740.0032030.5888450.0011250.0009590.0027590.9581740.0241701.6490900.9865900.0269220.0039720.0240070.0244201.2837740.0010623.4781900.0311310.9521580.0353720.0279840.0979352.1791102.1049000.0331130.0134590.0480770.0014172.2246091.3008191.4746040.7951532.9467650.8040580.7817590.0463450.0179360.0381180.0006610.8106561.3333320.0384690.0232211.5073900.0633671.0379291.0292980.7786021.5782251.4988011.5232251.4346072.0686001.1633210.0010662.1152462.0543522.5578410.0016110.5830430.0013250.0452530.0181850.0444400.0217411.5161740.0202770.0224220.0182390.0433611.5177470.0423660.0004511.4222880.0642080.0415330.0306270.4587070.0335280.0146780.0148860.0303000.0226640.0004850.0007240.0005990.7046060.0007620.0004300.7983280.0007980.0004740.0006470.0004290.0008480.0005230.0027200.8196860.0008060.0008060.6859510.0007400.0004300.0017330.0245931.0748030.0009180.0632230.0454930.7128240.0008610.0017770.0062080.0035840.0317790.0021551.7231850.0028750.0239830.0004650.0005850.0004990.0024460.0008260.0007060.0021540.0005590.1640750.0005860.6247900.0149750.0008380.0005880.0004790.0142850.0833790.0408940.0005960.1266700.0005900.0020181.3737020.0675190.0636350.0632900.0439470.0439901.4901541.3426790.7586350.0456500.8709041.6098383.0976832.2818111.5786960.0244080.0005720.0702381.5203580.0243390.0236120.0687040.0731120.3056381.3309540.0220081.4713000.0151530.0157931.2959930.9523480.0025510.0012350.0342290.0184221.5343000.0012700.6941010.6698080.7221070.0249850.0246410.0231602.5775200.6377501.4927800.0248223.1089480.0596320.9712480.0217120.0256660.0019150.0226550.6794500.0027770.0222160.0191640.2528790.0022930.0233851.5739920.0011390.0163340.0004541.6182650.0016560.0230620.0004490.0045291.6286020.0247360.0342840.0122990.0118590.0821500.0137820.0004820.0522850.0034930.0141920.0124000.0858190.0465100.0442180.0115220.0716020.0214980.0125240.0236000.0119070.0009200.0420170.0005730.0580510.0007330.3035360.0161633.4789450.3879252.0267170.8807300.0009562.3254210.0425080.8165432.0157531.0080342.0275860.0207152.1303671.2263451.2334101.8715031.4694670.7498441.8823580.0015221.9342291.0088800.0705771.0812211.6623080.0938453.3889971.8901091.6782582.7849180.1048750.0493160.0463341.0789062.8577860.0250151.5964090.0239290.0452471.1558110.0257640.2265450.0440930.0370820.0206010.0591470.0437550.0676380.0230090.0437780.0244820.0030820.0009700.0241860.0479390.0237300.0009170.0469030.0006040.6406700.0248200.001976

*******************************************
EVALUATING PIPELINE 
Pipeline directory: /home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_7c031cb2_2020-02-04_09-48-293e95l21m/
With following parameter combination: {'batch_size_seq_length': 1, 'lr': 4e-05, 'lr_type': 'constant'}
EVALUATION OF CHECKPOINT /home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_7c031cb2_2020-02-04_09-48-293e95l21m/outputs/checkpoint-3
-------------------------------------------------------------
|           |   agree   | disagree  |  discuss  | unrelated |
-------------------------------------------------------------
|   agree   |    276    |    52     |    120    |    23     |
-------------------------------------------------------------
| disagree  |     0     |     0     |     0     |     0     |
-------------------------------------------------------------
|  discuss  |    415    |    95     |   1566    |    164    |
-------------------------------------------------------------
| unrelated |    71     |    15     |    114    |   6711    |
-------------------------------------------------------------
Score: 6907.75 out of 7516.5	(91.90115080156988%)
Accuracy: 0.8889004364996882
F1 overall: 0.5487277220683656
F1 per class: [0.44768856447688565, 0.0, 0.7752475247524753, 0.9719747990441017]
*******************************************


*******************************************
EVALUATING PIPELINE 
{'batch_size_seq_length': 1, 'lr': 4e-05, 'lr_type': 'linear'}
INFO:__main__:Creating features from dataset file at /home/ubuntu/fnd_implementation/data/processed
  0%|                                                  | 0/9622 [00:00<?, ?it/s]  0%|                                        | 1/9622 [00:01<3:44:06,  1.40s/it]  5%|â–ˆâ–‰                                    | 501/9622 [00:01<2:28:45,  1.02it/s] 21%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                             | 2001/9622 [00:02<1:27:01,  1.46it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9622/9622 [00:02<00:00, 3542.83it/s]
  ******************************************* 
              Running Evaluation                
  *******************************************
 
  Length dataset evaluation: 9622
  Length dataloader evaluation: 2406
  Number of epochs: 3
  Batch size: 4
  ******************************************* 
 
['/home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_7cf23c3f_2020-02-04_11-43-19t0q8o5ns/outputs/checkpoint-3']
INFO:__main__:Evaluate the following checkpoints: ['/home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_7cf23c3f_2020-02-04_11-43-19t0q8o5ns/outputs/checkpoint-3']
INFO:transformers.configuration_utils:loading configuration file /home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_7cf23c3f_2020-02-04_11-43-19t0q8o5ns/outputs/checkpoint-3/config.json
INFO:transformers.configuration_utils:Model config {
  "architectures": [
    "AlbertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "down_scale_factor": 1,
  "embedding_size": 128,
  "finetuning_task": null,
  "gap_size": 0,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "inner_group_num": 1,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "net_structure_type": 0,
  "num_attention_heads": 12,
  "num_hidden_groups": 1,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "num_memory_blocks": 0,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 30000
}

INFO:transformers.modeling_utils:loading weights file /home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_7cf23c3f_2020-02-04_11-43-19t0q8o5ns/outputs/checkpoint-3/pytorch_model.bin
HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=2406.0, style=ProgressStyle(description_width='initial')), HTML(value='')))
0.0054140.0058560.0029580.0011690.0003680.0001240.0000460.0000310.0000320.0000280.0000300.0000400.0000280.0000320.0000320.0000300.0000270.0000270.0000260.0003260.0004020.0000450.0034240.0001740.0007061.1295660.0434690.0016351.8042220.0627690.0021190.0000930.0002040.0000710.0014740.0000690.0008280.0000480.0012511.8572720.0493850.0041380.0001240.0000290.0024180.0000820.0163650.0003800.3355630.0068771.5631300.6292320.0121630.0002830.0002750.0000300.0000270.7896570.0157560.0003181.0511340.0172670.0003590.0000350.0000350.0000421.9659170.0293690.0010290.0002060.0032280.0001130.0000280.0000650.0020410.0002940.0000320.0000751.8916890.0262441.7718523.4635450.0424920.0005731.3068080.0196730.4994300.0069180.0001310.0000880.0000330.0000300.0000740.0000780.0082130.0001170.0552770.0467080.0005240.0000470.0000440.0000990.0000390.5997950.0062010.0001040.0001050.0000301.2305040.0118860.0001350.0000370.0000420.0000250.0000250.0011370.0000371.4793580.0125640.0001300.0000260.0006380.0000300.0000250.0000260.0004230.0000400.0000240.0000240.0000240.0000240.0000240.0015480.0136400.0037430.4818210.0035720.0010270.0000440.0056061.7852170.0130150.0009830.0005540.0036570.0000540.0000290.0000330.6524610.2821900.0045160.0000590.0048782.2547301.2824730.0083120.0004250.0000770.0000750.0028790.0023511.3240320.0091350.0002000.0000860.0007240.0000610.0003670.0000310.0002330.0011332.8722961.4019171.4606280.0084481.4362580.2130010.0013610.0023240.0000460.0000300.0000461.9284310.0105660.1317850.0007473.4703821.8613170.0099310.0001052.1565170.0213190.0065900.8955361.1073440.0057060.0000630.0000270.0002260.0002410.0000710.1054940.0005930.0000580.0000510.0009640.0002480.0005050.0002830.0077830.0011100.0017690.8218360.0059180.0008350.0000380.0000620.0011400.0000380.0010090.0015910.0006380.0005930.0000290.0011170.0000310.0000570.0006450.0000310.0000360.0047160.0004100.0005880.0000290.0004630.0000270.0001090.0000260.0000250.0005280.0000270.0000250.0000260.0006630.0000280.0000250.0000240.0000260.0000262.0215290.0081110.0000570.0065270.0011370.0001290.0000260.0005860.0019900.0000950.0006480.0006180.0001850.0000260.0000360.8430850.7394900.6542040.0024750.0000400.0000240.0000260.0000250.0000271.3715090.0075491.5097530.9544240.0034770.0025510.0000360.0000280.0000270.0000240.0000260.0000250.0000260.0000250.0000240.0000241.4306930.0049671.7270340.0059400.0000440.0000281.3045420.9934430.0033710.0000370.0000250.0000261.2257421.1583130.0038480.0000390.0706181.1128000.0052500.0004030.0020430.0015220.0001190.0010030.0004280.0008940.0000330.0001870.0008280.0049730.0000600.0005450.8014060.0025381.7175920.0053280.0003870.0000250.0000250.0004400.0067701.8746900.0061380.0000430.0105820.0005400.0008200.0005490.0004140.0000280.0007390.0004391.2246570.0036070.0000410.0000250.0000260.0000280.0000260.0000270.0000290.0000260.0000290.0000300.0000280.0000260.0000270.0000280.0000270.0000270.0000290.0000260.0000260.0000260.0000280.0000250.0000270.0001510.0004820.0000290.0000260.0000250.0000270.0000280.0000910.0000280.0000250.0000270.0000280.0000260.0000260.0000270.0000260.0004690.0000270.0000430.0001570.0005770.0012050.0001550.0001950.0000242.0055430.0051400.0000400.0262951.7937321.4683660.0037560.0003240.0000320.0000400.0000340.0005650.0000280.0000340.0000260.0001280.0000460.0003840.0014250.0015920.0000320.2671720.0006980.4333810.0012360.0000450.9717671.0438670.0025261.0450090.0063400.0005271.0915021.1340490.0026930.0007840.0000270.0000260.0000250.0000290.0000250.0000260.0005460.0000290.0000260.0004440.0000260.0000280.0000270.0000280.0011020.0000270.0000291.4229304.8628760.0147650.0000610.0037780.0001541.7843920.0057650.0115940.0000530.0000760.0014790.0000480.0000300.0000300.0000350.0000300.0000300.0000320.0000780.0019480.0023720.0000342.5310470.9193940.0019850.0005740.0006860.0000951.0748731.2529890.0028570.0008030.0074670.0000440.0000270.0000250.0014220.0004811.2545280.9144533.1627521.7671320.0054550.5955823.0695071.9670770.0041650.0096800.0018150.0000450.0000280.0004400.0000280.0000280.0000280.0000300.0004230.0007660.0000300.0000270.0000300.0000300.0000270.0015400.0000330.0000290.0003700.0000421.0937151.1833410.0023260.0000331.1158370.0105581.2603080.0024521.1639331.2347400.0024420.0001180.8993280.0017440.0006951.8034910.0034360.0079590.0003170.0476040.0012390.3476580.8069730.0020750.1061470.0218520.5498220.0010450.0002110.0008180.1251000.0005120.2064050.1659051.7499370.0047690.0004350.0005310.0001370.0000550.0007761.5398011.0361301.8171130.0036920.0004270.0000650.0000260.0050390.0000330.0034980.0004590.0005100.0004170.0000250.0000250.0000240.0000260.0005470.0004010.0000250.0004790.0000311.1557240.0020311.1135811.0770680.0018841.1122420.0024450.0000301.0534170.0018360.6325020.0027001.1764930.0032860.0040280.0000660.0030860.0000380.0014260.5436120.0009520.0004470.0014832.1016120.0044810.0012961.2426423.7718911.2454850.0118230.0089970.0152390.0229000.0022130.0007002.4728320.2427850.0019011.6344750.6837170.0015010.0004330.0000260.0006421.6020790.0026630.0000301.5738440.0030050.0000300.0003810.0000261.6998700.0027270.0003990.0000260.0000270.0004050.0000260.0005300.0000260.0004370.0003800.0000250.0050312.3702461.4045550.7279930.0046810.0029140.0034480.0000402.5151440.0039020.0009720.0014550.0000270.0016730.0020880.0000300.0012090.0016860.0022590.0019640.0009990.0007530.0011040.0011270.0019640.0000280.0033690.0000320.0007650.0000270.0013150.0004300.0000250.0000240.0000270.0005430.0023980.0024660.0061320.0010520.0000410.0000280.0000330.0000300.0000290.0111960.0000430.0028390.0000390.0000290.0000800.0000300.2246720.0003540.0016710.0000300.0022910.0000320.0032220.0004990.0000580.0005500.0000260.0003960.0003980.0004200.0000420.0009390.0019680.0004360.0019700.0012840.0000500.3985220.0005830.0029460.0000301.6837970.0023730.0000301.6396631.2097680.0017020.0000290.0015950.0000270.0013270.0006491.8187030.0109210.0255270.0016260.0017240.4382943.3678640.0061060.0000440.0023120.0008161.0660671.1804670.0049010.6286692.4118400.0041541.7326880.0023970.0000430.0000382.7452580.0036920.0000300.0456320.0640520.1834700.0002880.4401600.0006300.0007760.0000371.5446410.0020620.0000330.0000540.0000360.2687840.0003750.0000260.0004970.0000260.0015810.0017240.0018780.0015360.0017400.0019970.0021500.0068650.0000370.0000290.0338680.0000730.0000760.0000390.0000270.0009110.0004380.0012440.0007990.0081740.0010010.0014510.0000810.0017540.0008110.0004790.0007650.0005730.0089160.0076430.0092991.8005331.8519080.5444480.0007050.1585260.1208510.0002240.0001560.5205540.0006820.0001670.8240830.0024770.0000390.6610210.0008460.4614060.4621370.0005960.0000450.1533843.5565243.5459550.0043351.9140730.0032130.0067020.0000390.0308750.0229720.0004590.0008710.0014220.3343810.0019170.0057540.0000350.0033811.3746040.0016630.0029060.0000360.0000310.0000280.0001900.0004820.0006020.0000970.0015630.0021850.0000310.0000330.0000260.0063970.0119290.0046390.0000350.0000290.0000290.0000280.0000280.0000290.0000300.0083940.0000380.0000300.0000290.0000290.0000280.0000280.0000280.0000270.0000280.0000290.0000280.0000330.0000290.0000270.0000570.0000300.0158482.1781710.0087060.0021970.0000281.1037710.0157800.0031110.0061620.2921310.0003740.0010741.2383081.0994630.0012901.6337361.7963221.6770971.4867110.0095850.0045680.0031350.0005190.0012860.0009410.0000390.7082320.0025905.1283743.3547480.0044280.0000390.0000290.0018010.0009400.0005840.0004440.0020150.0013340.0020040.0003380.0020620.0018600.0027020.0026420.0015440.0066510.0017080.0025250.0026040.0014380.0000250.0030400.0028550.0015050.0023310.0022650.0004320.0048540.0000340.0000331.2423240.0013420.0000270.0000270.0000260.0005860.0000250.0000280.0000260.0000250.0000250.0000330.0005390.0000301.5207430.0016130.0000271.8155790.0030540.0015411.5500120.0016580.0000270.0115520.0000540.6448880.0007020.0000250.0000240.5578850.0006010.0000260.0005343.7131733.4469033.4974261.8573174.9562073.4694065.3614394.4845092.9327280.0035290.0000310.0000390.0000270.0000280.0000370.0000840.0000250.0000340.0206440.0000480.0000600.0266500.0224390.0000490.0172060.0001530.0000490.1560670.0001861.8916051.7558380.0020230.0002160.0035800.0052130.0004440.0004080.0028130.0047321.8748780.0025650.9634410.0009821.5877280.0015881.4207730.0044530.0006504.7875213.2409940.0116670.0000410.0001040.0000290.0006010.0025980.0031610.0025291.8661720.7054400.3134830.0628241.7517130.0027640.0030150.0029900.0030530.0000280.0009000.0008480.0106290.0000600.0064680.0000351.4466610.0391400.0000640.6401510.6061260.0006040.0000270.0000280.7048550.0006940.0496520.9726190.6218500.7002880.0006980.0000980.0819320.0077020.0000360.0329250.0000570.0000280.0353830.6256520.0006150.0250980.0000521.4903801.7520390.0016532.6397510.9471711.9734812.5596100.0080234.0800061.5293302.5491180.0031700.0000291.1872433.4977134.2007491.5602170.0031900.0004760.0011040.8932250.0013642.5408440.8856960.0070670.9343580.0014710.0078810.0447460.0027580.0000310.0056680.0067460.0091611.0094420.0016500.0000270.0000260.0000260.0000291.0530160.8902291.5729570.0031740.0000350.0006790.0000350.0001861.0631990.0009760.0000310.0000310.0000300.0033770.0000320.0000310.0044640.0000310.0027210.0027240.0000300.0000400.0000280.0000310.0000260.0005730.0000300.0000310.0000320.0077300.0046562.2289380.8675940.0065720.9923791.0409530.0022680.0533410.0068290.0003062.8676781.7171822.8812190.0039920.0004881.3892161.4259360.0020340.0005360.0000390.0001060.0002410.0000350.0002050.0000292.4996960.0053572.1570570.0037260.0021020.0054130.0000370.9573050.0830250.5989370.0011720.8038500.0007190.0589350.0001780.0000350.0000270.0001150.0000460.0000300.0000670.0061850.0000360.0000300.0000310.0000481.3894800.0011890.0027210.0000320.0000330.0000402.4358111.4957640.8931811.6903140.0014320.0000310.0000370.0000300.0056631.1774180.0012930.0000340.0002300.0009101.1497380.0012715.0112304.8337872.0673510.0025020.0007060.0010691.0576400.0030960.0036080.0002971.1582520.0030940.0000490.0000380.0000340.0000310.0000330.0000310.0013700.0073470.0001660.0000310.0088591.2655710.0084180.0004030.0000240.0006710.0000291.1237660.0010750.0000310.0001600.0004740.0174670.0000460.0006630.0462520.0000630.0005630.0018150.0000600.0036550.0000410.0008680.0009110.0000380.0003400.0000260.0000960.0028500.0000480.0000880.0023590.0000320.6040040.0005060.0018783.8159633.3722854.6072783.2491491.4420881.2789542.6747991.6770602.7874700.5933850.0124710.0064420.0143990.0088210.0121030.0087390.0076310.0021670.0017450.0016920.0025400.6358190.0022590.0070160.0112730.0059680.0003720.0047240.0021140.0063210.0052590.0037540.0032791.3408242.4349641.3923560.2201433.7593050.4070140.0036200.0000350.0000240.0000250.0000240.0594240.0000700.0000240.0010820.0017590.0000260.0081150.0105480.5690990.0138110.2970051.2842980.0105950.0159400.0000391.8308650.4325542.8187351.8158060.0049040.0264070.0007400.0063400.0005730.0011711.4001920.0047180.0000300.0088050.0027460.7691100.0006581.7226710.0021480.0000320.9156961.9556810.7080631.2843270.9316400.0007160.0000900.0000300.0035320.0014040.0000310.0035670.0000660.0006640.0000310.0000300.0000860.0000730.0000300.0032820.0002700.0007880.0000280.0003170.0000300.5091620.0028340.0035340.0000320.0000420.0000390.0026810.0000330.0000550.0002070.0000300.0019370.0008040.6712771.4755891.1029161.1154842.9755710.7197841.3461200.0017730.0004400.0083290.0019080.0004692.2345482.1328934.8202192.9918302.5721793.8344371.0526421.0299950.8432312.0476890.0014760.0026700.0000340.0026350.0009331.4402150.0039110.0000310.0065160.0015120.0008440.0013440.0013100.0008350.0044050.0011730.0010950.0009180.0012510.0012460.0004170.0011310.7658590.0007930.0063392.4318810.0027960.0005780.7072912.0338646.3502642.8062120.0021960.0015150.0025110.0021680.0027500.0019930.0027500.0000290.0034640.0127620.0019861.5136180.0046210.0060100.0018040.0060914.4143831.6217310.0036660.0026630.0021320.0020460.0012170.0000360.0006490.4502870.0003340.0028540.0000730.0000250.0003290.0006680.0000280.0000410.1468770.0001240.0034850.0077060.0002070.0018170.0000260.0009720.0000300.0001920.0055340.0010230.0017720.7859572.4296831.1216540.0017430.0185401.2581001.2890481.1532481.4845660.7811440.0164390.7032270.0080380.0122140.1907160.3815270.0071050.0082790.9406210.0081961.7808393.1439330.0035250.0025260.0016660.0020420.0015680.0016270.0016080.0010400.0021810.0028570.0051630.0010030.0016380.0000260.0013720.0010040.0000250.0000420.0000260.0000270.0000230.0000250.0000250.0007590.0006491.5880100.0010541.3787010.0009241.6785440.0011280.0004440.0036960.0031981.3175351.4850220.0015291.2521493.3303892.0749540.0147340.0080340.0001140.0000651.1231821.5609010.9089790.0006250.0005040.5521180.0056020.0010180.0068980.0015680.0087660.0011250.0017940.0007590.0005430.0008021.7311780.0021880.0060050.0083490.0024630.4393161.5457951.8959000.0036620.0007191.5568050.0026040.0010131.8856150.0029961.9098723.2630160.0033411.6092031.5224960.0013811.5540860.0019074.4285960.0061520.0013320.7786971.2453030.0041910.0037700.0005470.0020210.0000260.2838940.0026140.0151100.0000340.7236490.0031980.2512560.0001800.0015040.0005300.0003730.0000291.5372850.0009722.9190131.5425850.0014701.4968641.6123426.6933785.0787446.7194585.4802964.8476840.0041660.0009490.0008190.0020770.0012880.0000280.0007750.0018560.0004710.0006840.0000270.0000311.4537370.0009140.0000881.4983830.0009370.0000290.0000300.0000310.0000280.2741450.5342071.2194820.0325902.5795950.6502180.0006211.1426130.0008090.0001942.5624390.0065971.1648940.4423010.0359941.4227591.2696932.7234322.3895692.2223500.0013590.0000370.0023001.4866940.0009231.4056650.0008670.0000290.0031921.4216770.0009500.0000290.0000320.0000500.0000350.0000370.0026570.0026740.0008780.0009980.0012700.0011340.0018270.0009080.0043340.0014910.0008960.0008710.0014410.0000290.0019990.0004330.0025941.7205172.4855121.2192150.6392770.9185550.9340480.6452521.1647371.0893922.0839870.0171100.0020570.0000480.0000240.0027300.0015320.0014010.0009020.0011790.0009490.0029870.0017530.0007770.0029370.0004050.0024140.0003830.0004470.0000250.0004170.0003690.0000250.0007760.0008180.0003730.0007700.0008900.0004150.0004570.0005130.0000240.0008030.0004430.0035230.0000270.0000600.0007790.0007120.0000240.0007530.0000290.0000260.0000230.0015440.0000260.0000360.0011530.0008840.0000260.0015480.0000260.0004210.0182310.0000350.0003990.0000350.0000250.0007191.1207510.0011580.0004232.8608540.0016380.0000280.0001330.0000640.0000350.0000270.0000310.0000330.0028420.0000320.0059460.0000310.0000390.0000300.0000310.0025740.0026420.0000330.0025340.0000320.0000330.0000301.0611640.0334301.1117410.5483090.7207160.0012720.0814590.9483631.9693063.1747551.7414842.2147900.0065471.1627080.0035170.0061200.0025140.0031520.0036090.0031260.0041610.0091820.0055820.4654540.0037120.0003090.0051220.0049980.0011480.0008190.0007560.0012110.0015730.0016360.0016070.0020461.3154691.8962883.7080162.1042161.0088451.0119450.0084470.7295270.0030680.0025970.0021430.0013340.0005730.0034952.0761690.0024620.0038980.0054190.0009100.0018260.0018320.0007950.0194950.0019540.0187550.0006870.0000270.0000260.0000240.0007290.0011310.0015750.0010680.0000260.0000260.0000250.0000290.4940350.0002900.0000250.0000260.0000250.0346870.0000440.0000250.0000260.0000240.0000240.0009840.0000273.6277190.0019450.0008840.0005850.0005320.0011000.0010610.0005190.0010880.0003840.0018410.0017300.0007100.0012430.0000260.0000260.0040090.0033112.6286650.0078412.3777453.5189391.5140843.8112230.7172260.0014760.0009160.0003860.0003760.0756500.0000630.0020500.0000250.0000250.0000250.0019590.6040010.0003420.2139960.0001910.2626650.2251080.4774600.5711960.0003240.8037550.0129570.5517990.0142760.0105730.0146510.0162760.0263080.0253470.0132970.0209390.0000380.7510000.0016340.0018790.0014161.5609461.5461110.0038023.4112223.7189040.8181261.9561401.9511781.9697010.0319361.4407080.0012780.0406870.0065410.0013230.0067040.1465801.0567160.0083660.0929300.0062190.2703350.0015560.0032900.0044120.0067630.0025750.0000290.0033690.0000300.0000300.0000300.0000300.0000300.0000270.0000310.0036841.3020720.0006830.0000270.0000260.0000260.0045930.0048311.2141120.0044980.0000320.0000290.0005580.0019800.0027840.0033810.0021500.0024180.0031980.0022640.0031290.0035940.0002230.0032140.0028840.0062651.4382260.0039040.0038370.0003640.0010500.0000260.0006550.0000260.0000250.0016700.0018040.0019290.0008590.0012630.0000250.0000250.0000260.0027440.0135870.0087520.0185780.0067000.0059052.7896340.0055260.0017023.5684932.7788920.0014890.0000370.0120960.0124690.0002452.0394320.0371260.0000660.0000370.3200700.0001951.2057810.0006140.0000300.0000292.6627670.0013270.0000530.0000320.0753640.7746780.0004030.0000300.2532660.1152430.0000960.0082860.0000380.0083990.0000352.6556272.8713610.0394581.7349840.7909610.0115652.2723872.1902940.8483030.0104370.0074360.0101290.0053950.0012721.5507001.3638910.0006882.8636390.0060631.5796891.5950460.0512794.0210860.5313020.0790852.8273321.8060961.1410472.2113650.6965380.0022680.0018651.4411570.0007130.2749130.1136130.0001080.0020072.4715330.0012000.0000400.0000302.7811311.0536673.5902270.5068801.1478600.0005740.6967882.1864665.4143970.0025801.6634390.0147090.0006140.0089370.0042060.0076571.0559720.0068830.0086080.0100670.0221600.0000391.6620321.3685051.8887750.7097293.0908530.8158481.3550490.0198910.0008820.0374940.0000430.8417391.2029970.0046120.0036992.8602680.0165690.0187580.0136750.0019370.0041741.2789820.0077391.3009990.0029500.0019040.0000340.0041780.7861102.0757920.0009850.0004300.0000280.0013030.0004520.0014180.0008470.0011330.0007580.0006310.0004660.0012521.4956630.0024810.0000260.0000270.0018400.0023970.0012290.0010400.0009030.0003791.7854880.0015610.0005080.0000320.0000300.0000560.5269010.0002690.0000310.0308450.0000420.0000360.0000330.0000300.0002220.0000380.0000380.0025800.0000330.0000400.0065930.0000300.0000290.0014630.0225700.0000450.0000290.0012470.0014121.1497640.0005540.0007020.0005300.0008200.3686270.0004191.6957410.0017640.0039350.0000280.0000340.0000430.0000590.0000920.0002070.0000400.0000280.0035450.0000320.0429851.1012690.0005220.0000320.0000280.7041020.0478690.0000740.0000281.1574820.0005460.5697480.0006530.0011820.0018160.0013980.0007890.0010270.0016940.0005280.0012680.0015910.0035461.3240871.2556100.5705811.4220690.0035280.0000320.0076361.1258160.0032030.0026720.0038830.0024570.0030890.0000410.7562640.0057870.0018260.0019220.0000452.7775880.0012550.0000490.0018520.0005282.2379000.0010111.4303711.3986200.5568500.0036720.0005960.0004763.6240742.6067992.9600470.0022714.3577260.3896720.2687010.0006050.0016240.0000420.0004510.0009080.0000770.0004290.9538390.0016520.0000260.0048051.7662590.0007920.0006310.0000280.1603380.0000940.0007540.0000280.0000261.3514680.0014630.0009920.0004940.0005610.0019530.0000340.0000250.0015660.0000320.0004170.0005030.0024020.0016960.0015140.0004650.0010250.0014260.0005720.0010780.0010260.0000240.0009680.0000250.0015660.0000300.1692040.0005703.3022130.2812441.5620371.8162130.0008022.2908140.3788160.3150810.5942190.4611720.7378480.4706620.4025220.0465560.0826852.0093490.1788160.9115311.9655130.0009461.5236521.0186680.0116111.3575661.6467840.0112275.2582284.4571586.3026791.0226470.9668080.0146420.0163400.0258640.0000430.0011260.0029670.0178370.0012191.4919980.0012900.0069660.0018520.0012160.0006390.0027140.0016500.0014320.0014990.0018180.0022780.0000330.0000360.0021910.0049530.0022230.0000330.0043700.0000340.0052980.0022640.000037

*******************************************
EVALUATING PIPELINE 
Pipeline directory: /home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_7cf23c3f_2020-02-04_11-43-19t0q8o5ns/
With following parameter combination: {'batch_size_seq_length': 1, 'lr': 4e-05, 'lr_type': 'linear'}
EVALUATION OF CHECKPOINT /home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_7cf23c3f_2020-02-04_11-43-19t0q8o5ns/outputs/checkpoint-3
-------------------------------------------------------------
|           |   agree   | disagree  |  discuss  | unrelated |
-------------------------------------------------------------
|   agree   |    404    |    50     |    150    |    29     |
-------------------------------------------------------------
| disagree  |     8     |    37     |     6     |     0     |
-------------------------------------------------------------
|  discuss  |    322    |    69     |   1601    |    77     |
-------------------------------------------------------------
| unrelated |    28     |     6     |    43     |   6792    |
-------------------------------------------------------------
Score: 7085.25 out of 7516.5	(94.2626222310916%)
Accuracy: 0.9181043442111827
F1 overall: 0.6852351714017789
F1 per class: [0.5792114695340502, 0.3474178403755869, 0.8276040320496252, 0.9867073436478535]
*******************************************


*******************************************
EVALUATING PIPELINE 
{'batch_size_seq_length': 4, 'lr': 4e-05, 'lr_type': 'constant'}
INFO:__main__:Creating features from dataset file at /home/ubuntu/fnd_implementation/data/processed
  0%|                                                  | 0/9622 [00:00<?, ?it/s]  0%|                                        | 1/9622 [00:01<3:05:46,  1.16s/it] 21%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                             | 2001/9622 [00:01<1:43:00,  1.23it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 7501/9622 [00:01<20:04,  1.76it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9622/9622 [00:01<00:00, 6444.77it/s]
  ******************************************* 
              Running Evaluation                
  *******************************************
 
  Length dataset evaluation: 9622
  Length dataloader evaluation: 301
  Number of epochs: 3
  Batch size: 32
  ******************************************* 
 
['/home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_7cf23c3e_2020-02-04_11-13-29qpg9g36r/outputs/checkpoint-3']
INFO:__main__:Evaluate the following checkpoints: ['/home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_7cf23c3e_2020-02-04_11-13-29qpg9g36r/outputs/checkpoint-3']
INFO:transformers.configuration_utils:loading configuration file /home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_7cf23c3e_2020-02-04_11-13-29qpg9g36r/outputs/checkpoint-3/config.json
INFO:transformers.configuration_utils:Model config {
  "architectures": [
    "AlbertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "down_scale_factor": 1,
  "embedding_size": 128,
  "finetuning_task": null,
  "gap_size": 0,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "inner_group_num": 1,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "net_structure_type": 0,
  "num_attention_heads": 12,
  "num_hidden_groups": 1,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "num_memory_blocks": 0,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 30000
}

INFO:transformers.modeling_utils:loading weights file /home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_7cf23c3e_2020-02-04_11-13-29qpg9g36r/outputs/checkpoint-3/pytorch_model.bin
HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=301.0, style=ProgressStyle(description_width='initial')), HTML(value='')))
0.0076520.0085780.0090560.1400370.1214950.0350250.1103640.0237910.0037130.0008850.0130910.0037920.0174780.0885260.1178800.0085340.0911790.1157510.1814070.2731140.0221100.2140560.2785100.6693300.1772260.1446630.1487410.0113910.0918520.1381270.1284450.0484980.0035370.2294800.3953050.0120910.2351060.3814980.1460480.0059790.1614380.1616910.0844230.0026250.0015600.0151990.0160020.0014370.2884460.0477410.0018000.2383520.0841130.0092820.0091370.1375020.1999100.0061540.2989840.0810680.2550990.1668640.0138190.0251780.1207020.1710960.4610220.5247720.6157420.4626850.0299740.0014550.3257270.1599030.2789930.2033530.4012470.0915100.0074760.1130310.1437280.2319400.0082760.0125550.0036370.0359840.1781980.0057330.0059200.2058530.1287331.5653170.5049750.0362870.8255870.3288550.0049620.0023200.3677430.0413850.3576910.1438490.2371130.0414370.3697150.0369580.0087020.0022330.0735370.0012560.2677740.1112570.0542010.8322740.0090940.7338470.3658980.0251970.0018640.1159070.0776270.1519730.8988820.0087320.6912940.0105930.1341290.4157430.2241490.2010400.1220830.1091120.1549730.0411150.1883800.4232280.0980930.3195810.1951100.5294800.0997530.0329480.0569130.2236160.4480820.0867620.0813810.3154280.0870870.0275340.1779770.0407491.1349830.0534380.0183670.0242950.0024680.0837190.0023201.2342601.5631950.1142710.0270230.1557090.6223500.1324590.1309170.2053500.0589440.2186450.0626750.0046680.1303470.0027230.1321270.5071121.3570720.0659780.0342800.1979320.7775452.8919271.3043430.2049520.2394630.1690680.0157540.3285050.9832590.3677750.0857970.0325900.1013130.3057830.1938870.4891060.2354650.1589460.4323931.2044520.8357910.1237110.2011861.6975270.7744810.0345580.0592230.3910840.9045090.9662860.1097440.0054730.0180130.3654540.2283160.0172990.0037940.0010730.0036080.0006840.0018720.0797100.1522800.0064550.0017060.7372830.1922130.0093540.0405150.4944901.1291770.1858340.1588610.0023760.0037260.0012010.4040170.1461600.3863720.0290860.0676620.3972110.1496640.2451050.3452730.2179480.0671930.0043220.1358160.1600460.2760880.0933950.2093670.3370541.3654041.0105930.6190340.0260260.6411931.4776040.3363991.1582000.6672670.1145300.3140940.1051080.2633170.4359360.5372400.1995700.2243410.1118570.1370340.1159920.0751780.0198180.0332730.0909930.0021420.0482330.1163090.0526582.0704850.4500380.2263350.1923310.4687950.0035370.2642850.0436210.0730920.0527430.0982870.6104350.1343310.3573410.5450810.0809420.2278100.0052700.085816

*******************************************
EVALUATING PIPELINE 
Pipeline directory: /home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_7cf23c3e_2020-02-04_11-13-29qpg9g36r/
With following parameter combination: {'batch_size_seq_length': 4, 'lr': 4e-05, 'lr_type': 'constant'}
EVALUATION OF CHECKPOINT /home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_7cf23c3e_2020-02-04_11-13-29qpg9g36r/outputs/checkpoint-3
-------------------------------------------------------------
|           |   agree   | disagree  |  discuss  | unrelated |
-------------------------------------------------------------
|   agree   |    473    |    33     |    120    |    10     |
-------------------------------------------------------------
| disagree  |    69     |    86     |    55     |     5     |
-------------------------------------------------------------
|  discuss  |    185    |    30     |   1552    |    56     |
-------------------------------------------------------------
| unrelated |    35     |    13     |    73     |   6827    |
-------------------------------------------------------------
Score: 7117.75 out of 7516.5	(94.69500432382092%)
Accuracy: 0.9289129079193514
F1 overall: 0.7439490311877925
F1 per class: [0.6766809728183119, 0.4562334217506631, 0.8567485509246481, 0.9861331792575473]
*******************************************


*******************************************
EVALUATING PIPELINE 
{'batch_size_seq_length': 3, 'lr': 4e-05, 'lr_type': 'constant'}
INFO:__main__:Creating features from dataset file at /home/ubuntu/fnd_implementation/data/processed
  0%|                                                  | 0/9622 [00:00<?, ?it/s]  0%|                                        | 1/9622 [00:01<3:05:53,  1.16s/it] 21%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                             | 2001/9622 [00:01<1:43:04,  1.23it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                  | 5001/9622 [00:01<43:45,  1.76it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9622/9622 [00:01<00:00, 6144.86it/s]
  ******************************************* 
              Running Evaluation                
  *******************************************
 
  Length dataset evaluation: 9622
  Length dataloader evaluation: 602
  Number of epochs: 3
  Batch size: 16
  ******************************************* 
 
['/home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_7c031cb4_2020-02-04_11-07-19g7f3zttt/outputs/checkpoint-3']
INFO:__main__:Evaluate the following checkpoints: ['/home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_7c031cb4_2020-02-04_11-07-19g7f3zttt/outputs/checkpoint-3']
INFO:transformers.configuration_utils:loading configuration file /home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_7c031cb4_2020-02-04_11-07-19g7f3zttt/outputs/checkpoint-3/config.json
INFO:transformers.configuration_utils:Model config {
  "architectures": [
    "AlbertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "down_scale_factor": 1,
  "embedding_size": 128,
  "finetuning_task": null,
  "gap_size": 0,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "inner_group_num": 1,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "net_structure_type": 0,
  "num_attention_heads": 12,
  "num_hidden_groups": 1,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "num_memory_blocks": 0,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 30000
}

INFO:transformers.modeling_utils:loading weights file /home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_7c031cb4_2020-02-04_11-07-19g7f3zttt/outputs/checkpoint-3/pytorch_model.bin
HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=602.0, style=ProgressStyle(description_width='initial')), HTML(value='')))
0.0019810.0020770.0011220.0004700.0002020.0018320.2858830.4099300.0566120.6710710.8750090.0801261.3912670.1074630.0112370.0280810.2883050.0170810.0010390.0004890.0147230.0008580.0002100.0005610.0743590.0036050.0002730.2252840.0086500.0004880.0004200.0138520.0005120.5309540.0157510.0011660.0003840.0002110.3687520.0103490.0018750.0004700.3318100.6031140.0339610.4436341.1496160.4494710.4171740.0087270.0036050.0003020.0003950.0003350.0001520.0002320.3153460.1185690.0682450.0013900.0058860.0001800.1226270.1053300.0064140.0005230.0867760.0013730.7466980.2716270.0039640.0001420.6722790.3481910.2623940.7572920.0416140.0010220.0001650.2000800.4648070.0059730.7150430.0094130.0005480.2257430.0027230.0001260.0001050.0001090.0001190.0048370.0001550.0021310.0001260.0001550.0008510.5621770.0059010.0573480.0006890.0000850.0057310.3546080.2651430.9325790.3341590.0032210.0002180.0014440.0008960.6132810.4779860.0048470.0001190.0006500.0022930.0016250.0083170.0229780.2562820.3902430.5542620.0219990.0005220.0006080.0000900.0016820.3160630.0190360.0994600.0020320.0019630.1802330.8201590.0545940.3761030.0255060.1205240.0361240.0023620.1981740.0016100.0021140.7981470.2333690.3504410.0035580.0025750.6172970.3612030.0096760.9311330.2629700.0020410.8430790.0056590.3963930.0078820.0003370.9462390.0071980.3583020.3287490.0616790.0011300.0009620.0007270.0002330.2500290.0016110.0055720.0034280.0001020.4395430.0036560.0077870.0010060.0115020.2832400.2353930.0037693.6110352.8206140.4135052.1902170.5131210.3772461.2698340.8531730.7837710.0077470.0024770.1141980.3273750.0020700.1296970.1898710.0038940.3426550.6680920.0040190.0009000.0464220.0798332.0621880.0560300.1139760.5055010.3946090.0032050.0011330.3515860.2902540.0152850.0001400.1835570.0009170.0000790.0000760.4357210.0215810.0013130.6985450.2632780.0037320.0032671.5286150.0071400.5443850.4330750.6052830.6648320.2230900.0164910.0013590.0004160.0000730.0003800.4704600.3673690.0202040.0027630.1525430.3324220.7249460.0033390.0000990.0195150.2124860.0015560.0017290.0014520.0052120.0476460.9638660.9207120.1737690.4952860.2568710.0050250.0383090.2779630.2427790.1458650.3213610.0034680.0131090.0010041.2470881.4182571.2299970.0231510.0144440.0023361.3360560.5644630.3080770.0011860.9929560.0037870.2541660.0015270.0030940.0000820.0021870.3021780.6044310.0031481.9248040.4542320.0017871.0651510.2993330.3038790.6670400.4371590.0015450.0007610.0675230.3645800.2070650.0061950.0067160.8844391.0009470.2221200.0039350.0002440.0574980.0453760.0067070.0045590.0002980.3921950.0078770.2405630.0010860.1516911.9833941.6313451.0258500.0314190.0270590.1980850.0345150.0059690.0240541.1373140.0048190.0023660.0912680.0460410.2272470.0933000.0083500.0886090.0028570.0249132.4190750.2685090.5340290.0031410.0010950.0005250.3521090.0013270.0000870.3545880.0161840.0852511.1382532.2946960.6038180.0032200.1066610.0362560.0041990.0039100.2574981.1489901.2361875.2566396.7893171.1163480.8753310.9836310.0043940.4977120.2951780.3158480.7361440.0033560.9667571.5943013.0906761.5740101.2811980.9889980.5938900.0037160.1961120.0014850.0002630.0000990.2618570.9351160.1589230.1955382.1005790.8168130.0051280.7164170.0031800.3655560.1449380.7458610.4461581.2769720.3931211.2233200.0249510.0220010.5937690.0039530.4232991.6227474.0992522.2717640.4414270.0018530.3423740.4626520.0016391.5728470.2120830.9273381.1928762.5857760.1755060.1478780.0551490.0005770.0223370.1966310.2755810.0147461.0344760.9912060.5759820.0018380.0012870.1481650.0009900.0093400.0007390.0006440.1574190.0008840.0002670.0001350.0012970.0245130.0146060.0966830.0006970.0000720.0012440.0003110.0004980.2697320.5888640.4834090.5888760.0026700.0014900.1103070.3819560.2507381.9844690.9635420.5580890.2757810.2955740.0041700.0680770.0007860.0058590.0014020.0001280.0401860.0010840.8338570.4008050.6291620.3015100.1392242.4944040.5505350.0197220.0004590.0023220.3445440.1705740.1519730.0829560.0713222.8835401.9433711.4371380.1890600.0066000.4597610.0097120.0015230.0000800.1100100.0012010.0301760.0021180.0069360.0026960.3909140.0017900.0003840.0020620.0005320.1146612.5013291.8220671.0209181.5443790.7217960.5729020.0810470.0016920.0014920.7235950.1901100.3992190.2654980.9548882.0994441.8622030.4493270.2423180.3160000.2389960.8590380.8359391.1356830.3440820.7726670.0969700.2846950.0105010.2644960.1240521.1844440.0030440.6579200.0016750.0379960.2236180.0017900.0011110.0012540.0062020.2033790.0015090.0099240.0174320.0032630.5591170.1908550.7727680.0014650.0000760.1184780.0011840.5289480.0313090.0287760.0046951.4534250.3247180.1123371.0108960.3971540.3064770.6392810.5397211.3176750.4843630.0034640.0009100.6419370.3571490.0013470.0024970.0022760.0029830.0030970.0012380.0768070.1204122.3548810.7727070.1663040.2397830.7901730.5882042.2111721.6576310.0086760.2682280.1014840.1068920.0020070.0014110.0014340.000817

*******************************************
EVALUATING PIPELINE 
Pipeline directory: /home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_7c031cb4_2020-02-04_11-07-19g7f3zttt/
With following parameter combination: {'batch_size_seq_length': 3, 'lr': 4e-05, 'lr_type': 'constant'}
EVALUATION OF CHECKPOINT /home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_7c031cb4_2020-02-04_11-07-19g7f3zttt/outputs/checkpoint-3
-------------------------------------------------------------
|           |   agree   | disagree  |  discuss  | unrelated |
-------------------------------------------------------------
|   agree   |    472    |    53     |    161    |    11     |
-------------------------------------------------------------
| disagree  |     9     |    31     |    10     |     3     |
-------------------------------------------------------------
|  discuss  |    215    |    62     |   1465    |    31     |
-------------------------------------------------------------
| unrelated |    66     |    16     |    164    |   6853    |
-------------------------------------------------------------
Score: 6999.25 out of 7516.5	(93.11847269340784%)
Accuracy: 0.9167532737476616
F1 overall: 0.683659903071688
F1 per class: [0.6470185058259081, 0.28837209302325584, 0.8200391827595858, 0.9792098306780024]
*******************************************


*******************************************
EVALUATING PIPELINE 
{'batch_size_seq_length': 2, 'lr': 4e-05, 'lr_type': 'linear'}
INFO:__main__:Creating features from dataset file at /home/ubuntu/fnd_implementation/data/processed
  0%|                                                  | 0/9622 [00:00<?, ?it/s]  0%|                                        | 1/9622 [00:01<3:48:22,  1.42s/it] 21%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                             | 2001/9622 [00:01<2:06:38,  1.00it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9622/9622 [00:01<00:00, 5380.84it/s]
  ******************************************* 
              Running Evaluation                
  *******************************************
 
  Length dataset evaluation: 9622
  Length dataloader evaluation: 1203
  Number of epochs: 3
  Batch size: 8
  ******************************************* 
 
['/home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_7cf23c40_2020-02-04_11-47-359mix1_k7/outputs/checkpoint-3']
INFO:__main__:Evaluate the following checkpoints: ['/home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_7cf23c40_2020-02-04_11-47-359mix1_k7/outputs/checkpoint-3']
INFO:transformers.configuration_utils:loading configuration file /home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_7cf23c40_2020-02-04_11-47-359mix1_k7/outputs/checkpoint-3/config.json
INFO:transformers.configuration_utils:Model config {
  "architectures": [
    "AlbertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "down_scale_factor": 1,
  "embedding_size": 128,
  "finetuning_task": null,
  "gap_size": 0,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "inner_group_num": 1,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "net_structure_type": 0,
  "num_attention_heads": 12,
  "num_hidden_groups": 1,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "num_memory_blocks": 0,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 30000
}

INFO:transformers.modeling_utils:loading weights file /home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_7cf23c40_2020-02-04_11-47-359mix1_k7/outputs/checkpoint-3/pytorch_model.bin
HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=1203.0, style=ProgressStyle(description_width='initial')), HTML(value='')))
0.0014450.0016810.0009070.0003680.0001480.0002980.0002230.0002970.0001030.0000650.0003300.0009040.3680550.0283560.8558290.0571030.0038760.0003230.0008840.0017670.0070640.0003830.0003090.0009920.2969581.0210740.0393350.0015230.6401610.0229780.6429710.0208620.0008780.7778100.0238410.0014680.0005540.0001010.0000620.0025770.0028240.0023110.0013110.0003570.0004800.0004070.0002520.0009860.0090700.0019530.0003480.0009270.0024870.0002600.7622120.0139300.0003160.0515050.0019550.0000910.0002930.0000510.0002780.0000570.0000510.0000460.0047721.1768190.0322850.0013000.0013830.0010040.6518650.0089800.4510120.0273431.9252310.6674450.0094480.0007320.0050880.0018830.0010650.0004270.0095501.2454280.7126290.4513560.4773040.0059770.0005841.0186140.0119512.6751350.0285311.2804110.4044520.7125590.0075590.0005130.0009280.0009630.0001080.0017470.0018480.0141210.0005350.0061880.0002790.0004730.0003690.0001990.0003410.0004830.0001630.0135970.2962611.0451350.0091790.0004470.0000550.0006740.0000550.0000470.8865200.0071670.0016770.0000911.6955890.0163980.0074320.0001390.3802510.5381960.0041240.0000800.7494030.7370010.2276910.0016880.0000580.0000630.0000600.0002300.0010260.6085590.0042170.7647950.7185640.0048660.7712640.7671180.0121450.0753830.0014650.0000630.0000560.0000520.0000500.0016260.4495980.7462100.0051210.0001090.0016650.7542500.0053230.0011150.0004190.0004020.6068450.0039840.0000720.0000600.0000520.0000680.0000520.0000470.0000520.0000700.0001060.0000470.0000460.0002650.0000480.0000440.0000640.0000490.0000510.0000490.0000560.0002550.0003800.0033160.0008500.7629170.0040410.0210360.0009790.0000860.0000740.0005130.0000670.0001610.7530220.0043160.0284550.5196090.5516190.5043811.3082210.4040110.6732380.0035420.0000630.0001040.0002870.0002350.0022390.0000990.0000650.0000773.6258020.0194380.0031720.7760010.0077580.0008300.0000670.0000980.0000600.0001030.0011040.8416360.0043590.0002350.5048120.0827350.6534080.0027910.4163610.8127220.8371290.8280720.2579921.2234010.0069980.0000960.0003390.0000490.0003200.0005820.0000550.0000530.0006180.0003310.0006230.0150190.0015530.0153460.0022100.0012130.0127850.0006881.4239340.0068170.0026070.4021090.0086610.6849560.0026430.0012900.3797330.8819640.7435990.0041700.0005500.0003840.6615700.0062270.0005540.0014620.0006690.0003210.0000530.0005170.0004400.0005910.0016040.0043260.0241520.0003550.0006940.1572820.0310300.1579180.0019570.4687990.0019830.9884800.0049960.9016990.0575250.7389360.0182261.9158430.0118541.5954060.0056780.0003850.8224500.7573340.0026380.0002400.7241100.0025440.0002600.0030160.0003670.0002841.1669971.4890190.0065870.0012200.7929620.0050370.0010180.0007530.0012520.0018520.0050330.0414000.0073970.5930400.6188700.4125760.0012800.0002340.1044790.6726390.0020290.0000870.0000540.0015350.0000530.0003070.0000540.0002730.0013570.1998140.0010940.0003590.0006540.0007260.0009640.0012530.0014300.0011780.9431750.0026821.3409290.0037930.0004020.0005940.9578831.1515640.0232991.5748250.0052360.2303820.0058341.5010970.1814450.0005520.0106450.0001171.5113390.2607331.2192070.0034921.0137770.0028380.3467200.0009550.0002190.0014210.0015280.0013860.0022640.0000520.4365100.0011840.0006860.0014000.5615580.0062960.0021030.5435160.0024170.1529410.0510421.3308880.0157240.0476960.0956520.0011980.0020650.6992720.1412230.0019810.6729891.8794250.6197870.0032750.0025790.0023820.0013330.5503190.0131950.6869640.1457420.0007750.0003160.0004640.0008690.3424190.0010421.4059400.0053730.0000620.0000530.0000580.2802400.0007470.0000600.0000510.0000600.0000480.0000480.0012620.0554422.6830780.4087220.6157390.0071670.0019700.6211910.5282070.5180750.1504900.0028260.0062970.0006480.0054232.4818701.6411780.0036890.0004710.0087080.0005690.0287670.0819920.8409720.4940250.5692800.1477140.0037230.2140800.0233440.2594590.0006260.2419590.0005610.0004110.0000470.0000460.0000500.0003840.8121660.9495170.0025120.8999720.0044750.0016550.0000940.0014420.0000610.9831953.1491992.2261183.9272223.5442320.0075520.0001270.0000780.0000700.0026090.0001620.0055540.0053670.0016150.0010610.0031760.0007440.0024440.0001250.0035340.2940930.0770390.6400900.0023291.4508101.0909430.0022490.0204310.0017390.0015070.1899220.3451640.0058030.0098220.0016930.7337500.0019330.3342930.0919190.1495790.0003350.0536500.0132040.2473030.6938950.0173320.0003330.0024910.0020610.0007550.0012590.2136060.6595222.0521851.2286661.5758571.3235920.0198171.4042661.5383720.0035770.0021430.7366410.2860920.0041970.0045060.0024370.0021880.7386250.0013890.0002591.3492191.3258590.0032470.0007440.5411610.0010190.0006220.0000530.0009850.0011880.0003240.0000470.0013060.0000580.0011260.8494620.0568030.1275540.9199460.0029372.0684421.3860970.7894900.5817340.0016710.0001080.0004281.5006131.2355310.0030820.0031160.4704330.2706650.3939610.0024480.0000970.0000640.0000680.0034890.0000510.5508650.0025040.0000701.0722881.3844291.0179010.0017320.0004000.0003210.0000490.0006292.1536362.7378230.0053320.0170500.0040990.0171530.0012460.0016880.0000720.0007920.0016590.2115170.6190570.0012440.0007680.0017530.0000980.0024990.0010040.0000750.0022130.0107420.0001820.0004880.0002060.6336890.0010980.0009850.3113571.2747554.0567092.5993242.5348082.1271690.1873520.0050960.0052350.0150020.0025650.0023430.0022600.0816350.0023910.0020930.0020380.0010540.0122960.2416211.8073590.0038490.0000550.0002760.0000460.0008400.0183160.0062420.0119980.2338580.4234940.5189950.0020450.4485060.0019900.2141420.0298070.0014440.0018030.0001330.1510493.7567295.3246140.2617870.0005450.1203180.5234000.0017790.0000540.0022440.0239210.0940140.0092920.0001980.0034120.0012210.0026580.0001080.0334410.0017100.2321580.3345680.6699180.5353010.0015490.0010150.7872421.7525353.4393770.4341040.5303270.0020040.0012460.3868130.0017890.0053360.0010780.0010470.8240060.0021710.0012150.0008040.0035360.1683830.0010600.8242912.3860410.0039740.0024990.0019010.0011541.8651880.7311861.2427041.9289882.6513780.0057880.0019860.0008520.6007540.0121260.0000660.3995230.0005910.2668521.0578730.0512640.0003290.0000670.7483981.5149423.0793792.0875342.7065863.0713101.5407651.8160881.5575650.8346610.3809990.3538361.4634570.0046850.0017790.0022790.0016530.0017010.0007610.0004640.0004360.0001300.0000460.0000530.0006140.7035880.9274400.8316370.0025990.0080740.2913870.1536342.2144940.0248640.0249960.2675080.0089820.0058520.6860840.5638790.0020500.0008140.7059390.9107580.0089600.6303860.4939730.7879350.0021600.8544062.4157760.8202930.7459150.7455302.5300290.7282640.9464510.0044450.0010670.0021560.0020540.5260380.0023880.0006450.0002280.8624532.5590690.8698473.7373855.6826284.4399790.0064670.0004680.0019910.0004690.0003200.0000580.6310140.7395660.0009680.0000480.0013890.8344230.7565040.7532110.0837741.3061791.7832631.5035771.9107263.7156951.2838230.5759250.7425820.7124450.0028040.5547910.0007020.0000820.0014940.0027320.0021380.0017700.0050070.0033180.0024680.0031230.0025992.0461690.9474751.1246550.6357010.6596030.0131040.0001670.0172760.0009910.0011890.0019780.0015120.0007620.0005270.0002470.0009610.0008070.0006010.0007810.0005990.0005210.6320350.0007750.0007840.0004320.0002030.0001680.0000640.0011840.0009590.0002640.0005750.0004030.0006050.0024160.1387580.0002040.3703170.0005350.0000490.0020440.0028710.0000640.0033620.0011880.0008620.0000531.0846001.7161580.2894820.0343381.9452281.9323610.0068720.0023200.0012100.0021710.0032990.6997640.0028720.0024830.0008510.0117140.0014320.0015680.7478950.7123610.7291070.5083020.0032010.0018820.0016290.8133100.0030020.0016050.0016650.0019650.0013150.0000530.0003720.0007950.0003460.0000500.0027570.0000570.0000530.0007120.0000530.0000470.0003141.5230590.0019050.0007740.0008210.0006130.0012570.0007720.0000490.0013990.7416952.4495101.0920460.5881360.0015380.0007940.0003520.0000460.0012910.3109590.0049611.1115880.4213170.5268900.4797340.0276640.1882410.0569110.0336050.1188310.0038600.7062790.8247743.1543980.5613381.6301831.3035050.0026490.8982060.0062460.0041250.0028760.0068240.0028740.0016780.0010000.0000500.0000500.0000470.0013790.7181180.0007690.0010650.6832940.0024500.0003551.3012290.0091350.0111590.7809000.7459631.5452353.2778251.4788490.0019230.0020060.0000490.0010710.0009690.0005170.0000470.0174370.3074350.0663700.8135082.9589850.9677120.1116560.0299930.3053730.0004680.2505820.0028260.0000501.2186700.0017670.0024130.0000480.0018240.0007750.0008160.3010791.6691030.6867730.8658810.3689950.0108130.0048690.7765710.5598561.3985661.0981882.5020151.2820883.3661302.3853660.6650621.2740370.7419770.6461851.1142390.0011491.1808182.5529601.9366690.8622233.5389380.7630370.0148470.0039460.0050530.6111970.3746390.0608210.4107710.6941190.7953430.0943300.0190930.4579840.0487311.2120780.0396992.3176172.0064180.8071590.0014550.9562920.1748810.0004210.0006950.0009980.0024960.0006260.8382750.0027120.0013650.0010520.0009600.0004550.0007150.0000600.5036430.0005100.0034910.0001300.0000580.0066510.0009680.0117360.0000590.0021720.0000620.0028740.0076050.0026870.2265440.7323280.0018330.0000590.0006290.0000670.0000980.0006110.4303250.0005350.0004360.0021301.0644810.0020230.3865770.0090610.0070860.7843180.0095051.1221044.5019530.5562480.0033370.0140170.0072980.6180910.7247040.4456570.0221940.5121040.6346590.3380370.0058490.3740120.1448271.4140290.7856311.4182290.3036760.3842710.0013320.0008930.4153560.0014780.8554070.0011990.3266990.0007900.0000490.4887850.0022550.0017350.0001270.0012640.0013740.0015680.0014110.0025560.0007720.0005980.0019600.0019240.0047422.1798631.4165900.1184470.1588880.1045810.3636950.1599110.6000950.3165601.2979020.3845720.6008810.1150774.1592683.2818430.0064700.0061320.0033450.0049060.0015070.8942600.0022340.0013650.6598200.0020040.0009880.0011600.0021380.0010780.7694110.001689

*******************************************
EVALUATING PIPELINE 
Pipeline directory: /home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_7cf23c40_2020-02-04_11-47-359mix1_k7/
With following parameter combination: {'batch_size_seq_length': 2, 'lr': 4e-05, 'lr_type': 'linear'}
EVALUATION OF CHECKPOINT /home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_7cf23c40_2020-02-04_11-47-359mix1_k7/outputs/checkpoint-3
-------------------------------------------------------------
|           |   agree   | disagree  |  discuss  | unrelated |
-------------------------------------------------------------
|   agree   |    433    |    56     |    158    |    14     |
-------------------------------------------------------------
| disagree  |    21     |    42     |    12     |     1     |
-------------------------------------------------------------
|  discuss  |    270    |    52     |   1566    |    49     |
-------------------------------------------------------------
| unrelated |    38     |    12     |    64     |   6834    |
-------------------------------------------------------------
Score: 7092.25 out of 7516.5	(94.3557506818333%)
Accuracy: 0.9223654125961338
F1 overall: 0.6966910866601863
F1 per class: [0.6085734364019677, 0.35294117647058826, 0.8381054321648381, 0.9871443016033511]
*******************************************


*******************************************
EVALUATING PIPELINE 
{'batch_size_seq_length': 2, 'lr': 4e-05, 'lr_type': 'constant'}
INFO:__main__:Creating features from dataset file at /home/ubuntu/fnd_implementation/data/processed
  0%|                                                  | 0/9622 [00:00<?, ?it/s]  0%|                                        | 1/9622 [00:01<3:30:53,  1.32s/it]  5%|â–ˆâ–‰                                    | 501/9622 [00:02<2:20:01,  1.09it/s] 21%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                             | 2001/9622 [00:02<1:21:54,  1.55it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9622/9622 [00:02<00:00, 3780.13it/s]
  ******************************************* 
              Running Evaluation                
  *******************************************
 
  Length dataset evaluation: 9622
  Length dataloader evaluation: 1203
  Number of epochs: 3
  Batch size: 8
  ******************************************* 
 
['/home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_7c031cb3_2020-02-04_09-48-29pa_7ve0h/outputs/checkpoint-3']
INFO:__main__:Evaluate the following checkpoints: ['/home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_7c031cb3_2020-02-04_09-48-29pa_7ve0h/outputs/checkpoint-3']
INFO:transformers.configuration_utils:loading configuration file /home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_7c031cb3_2020-02-04_09-48-29pa_7ve0h/outputs/checkpoint-3/config.json
INFO:transformers.configuration_utils:Model config {
  "architectures": [
    "AlbertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "down_scale_factor": 1,
  "embedding_size": 128,
  "finetuning_task": null,
  "gap_size": 0,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "inner_group_num": 1,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "net_structure_type": 0,
  "num_attention_heads": 12,
  "num_hidden_groups": 1,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "num_memory_blocks": 0,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 30000
}

INFO:transformers.modeling_utils:loading weights file /home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_7c031cb3_2020-02-04_09-48-29pa_7ve0h/outputs/checkpoint-3/pytorch_model.bin
HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=1203.0, style=ProgressStyle(description_width='initial')), HTML(value='')))
0.0070170.0073360.0042340.0016520.0006990.0004840.0003490.0003250.0003170.0003920.0011620.6096620.6576350.0508110.0167130.0013070.0002880.0002400.0032850.0016240.7839560.0375180.0115800.0034750.2934480.8798860.0340680.0014920.4665180.1627270.0080380.0004920.0002350.7088380.0211900.0008950.0002610.0002280.0002150.6361560.8404930.0207420.0007540.0017110.0002800.0002100.0002200.0033980.0370600.0010020.0002870.6233650.0122700.0004600.7068540.0130890.0004490.0016860.0012970.0002740.0015180.0002170.0542500.0010570.0002030.0001930.0143630.0272740.3779170.0060970.0019700.4227270.0085760.0004320.4060850.6231330.6813560.4978460.0066880.0004110.0039430.0030990.0050770.0004360.0002880.5209360.7928070.1606310.5041130.0083810.0003580.7956350.3304562.5044700.0268591.1151680.4858890.7209910.0079600.0015280.0041060.0063570.0005600.0040160.0191950.3537210.0110420.0012280.0018180.0006450.0005570.0015300.0041430.0157930.0005460.6370590.0209630.0030340.0002510.0122090.0003110.0062540.0002480.0002060.0268540.0004330.0590020.0007200.0106020.0336850.0034920.0002550.5836720.6208680.0048540.0002440.5698980.1471330.1064500.0010370.0002420.0004210.0003160.0002710.5618380.0170990.0003760.6941440.8782230.0061130.6847680.6873300.0557970.2223580.0026320.0002390.0002170.0002270.0002310.0182630.0963850.0050400.0010050.0002110.0063620.5917470.0071840.0035750.0023220.0024390.1766560.0014640.0002440.0002460.0002570.0002100.0002580.0001990.0002110.0030010.0002270.0001980.0002080.0011470.0002050.0002030.0002820.0001990.0002080.0001940.0002100.0011800.0002860.0002930.0003241.1276350.0059630.4921320.0106990.0002650.0003600.0002280.0002270.0009510.0004500.0002700.0190240.3268620.5189970.5019990.5346680.4183210.3087520.0860540.0005840.0002110.0020590.0002150.0002150.0001950.0002760.0001850.0550100.0214860.0019350.7144750.0052590.0015110.0002390.0002220.0002210.0002170.0044860.0950370.0036790.0002630.0144550.0043230.0199290.0003400.0007750.3562281.4595051.4121791.0121361.3084090.0112220.0002700.0010850.0001950.0019190.0020390.0002010.0001920.0021850.0013100.0240250.9224800.2461200.7428860.1087510.5894670.1275490.0019360.6280460.0767500.5208810.8918890.1290680.1862830.0012510.0046600.0809900.7725770.0088480.0251950.0075100.0014880.6128190.0049720.5825000.0036630.2931840.0023200.0002210.0017760.0011910.0010680.6433160.9442880.6161050.0023440.6410360.3863040.0065190.0202220.0055230.0180710.0003570.7330000.0150030.3112780.2410400.3758500.0808721.5392170.0088421.3707880.0069890.0010680.6643530.6848910.0033870.0014640.7001870.0038470.0011020.4635190.0042550.0012650.0791210.0931970.0076580.0050910.9352820.0108250.0145770.1292590.0050570.0098910.2265900.4746840.7323860.7122640.3146440.1108870.0005350.0012271.3857641.3982640.0043680.0002630.0002940.0052370.0002530.0002680.0002300.0002690.0022850.9817030.0039800.0010410.0026450.0015920.0031510.0052800.0019220.0019570.2877090.0010900.5342640.0058320.0093080.4778331.7276342.0398021.3055852.2426450.5499920.4935431.7837782.3018050.7852530.0030530.0105290.0067741.2878820.9476621.2232230.5010301.9577940.0054920.0088450.0002030.0011490.0590050.0107400.0106820.4977630.0015080.6328550.0022550.0029750.0046480.0092010.4573200.0227590.0137710.0512360.0786420.2723911.6778060.3966570.4115610.4094980.0067440.2794220.2437370.2734740.0779090.3567943.9621100.4046090.0087750.0079430.0077170.0048700.8372720.0054270.0069880.0027640.0002360.2898160.0036120.6134081.1268820.0039360.0737250.0163770.0002540.0002200.0004610.0050700.0002660.0002200.0002080.0002170.0002300.0002170.0026050.4868170.3176230.0542190.7500000.0098240.0002610.3864750.2512030.0009181.3414820.4469590.0919900.4912400.3610310.3071640.2427610.0007110.0018520.5085700.0032440.7053020.3224831.0707370.1272030.4632610.6355490.1370170.5855910.3784400.6757610.0016620.6531420.0016050.0668520.0003420.0002010.0002190.0055160.2139320.3749230.1125670.7192040.0048040.0031560.0002290.0032100.0002360.9314742.1632592.1599753.0095481.0756720.3668730.0009620.0002300.0002130.6385280.0015101.2725141.1493640.0047070.0009731.4294370.0046090.0764460.0004520.0141500.5947210.3398710.7993080.0061950.3630940.7162240.0016100.0054540.0059350.0045720.0391491.0789550.0072460.0081270.0123920.1711970.0051040.9072010.0593230.9639210.0020530.4343230.0541610.7597490.2242740.0075430.0031410.0036220.0062190.0277950.0035920.2800210.3142861.0413231.0136140.7236541.0288900.0077690.0126211.2914820.0110090.0059070.0065100.6906180.0111270.0557360.0080430.0096010.3780450.0008910.0002350.1604350.4846580.1864430.0005760.0054620.0002210.0025030.0002040.0071370.0049280.0002430.0002100.0014600.0002140.0002701.4104740.0178140.5237460.0042080.0048371.3933930.9112990.4129580.8645660.0030720.0002480.0002631.0623480.9326890.0197740.3884780.5162360.3835980.5569450.0746870.0003360.0002050.0002490.0153610.0002450.4508410.0089920.0002370.0704860.1158751.0524130.0019950.4796090.6577590.0013450.6201922.3452743.3320730.0130160.5726210.0094410.3278940.0094760.0071610.0002520.6983740.0094201.0403450.1962810.0014670.0003330.0020370.0002400.0011090.0003490.0002120.0084270.1516940.0004800.0013880.0002460.0038490.0002900.0028760.0172442.0300214.1779762.5998062.8095422.4116980.7200620.0972130.3547390.0262380.0184690.0133910.1158602.8977330.0306470.0056920.0049090.0036810.6860810.6269420.1628860.2165800.0005360.0041670.0002030.0245751.5117741.0884471.0519120.1103620.0197840.0164130.0033610.2584870.5284170.0010060.3034870.1679900.2877750.0031700.0003181.0931900.9949520.6008980.0011330.7108990.9673010.0018030.0002080.0002360.0002990.0073970.0003110.0002240.0045730.0002270.0023140.0002200.0005760.0067820.8562330.0543401.1358201.0161010.0079840.0077840.9156763.8539374.0684790.0115670.0385300.0089150.0029311.3239860.0216440.0212860.0068460.0054370.9544500.0077130.1139640.0056910.6348180.9150200.0016741.2146782.4023010.0252840.5043730.5286490.3407452.7326861.4926231.3835412.0662193.2421090.1023130.0139110.0049581.4466460.6012600.0011160.9820040.7104600.0877401.8664400.5870860.0031550.0412510.6685751.2089092.3320261.1262622.7297922.4359891.6550061.9025111.9085311.2621391.2612610.2706250.1055660.0906760.0062940.0054380.0076331.3733770.4844170.0354770.0030560.0002290.0002050.0001960.0014360.5255290.7606190.6758660.0040330.3190420.8653811.5875780.0780570.0063160.0049820.0610300.0006020.4605510.0705660.7352200.0047690.0029310.6368960.0103180.0141051.1109270.5623360.7195470.0038790.7878132.2861270.7240220.7171970.7211853.4517951.8784931.0173050.3711810.0026270.0055330.0064000.3401200.0084220.0039660.0018380.6555021.9099530.6606672.9941293.2565932.0368090.0102570.0016580.0025220.0041590.0018760.0002230.5081250.4082110.0007110.0002650.4929861.2048300.8497330.6537940.3236321.3771632.1840291.2312911.3116532.6204400.9750060.0037420.4672600.3624230.0067930.3385110.0006210.0002440.0046300.0739410.1613200.1381200.3676280.1397580.0447730.0147990.0129340.4100890.9282380.8341531.0134121.0248610.2441550.0004860.0035830.0051630.0093580.0085530.0120670.0038530.0057630.0016690.0002430.0050820.0027740.0041090.0023430.0024760.9682790.0013170.0129190.0028280.0002430.0002540.0002300.0048740.0061000.0014010.0002170.0452780.0025470.0042080.0046980.0002300.0002830.0002270.0002350.0024270.0053560.0002560.0021730.0020330.0019930.0002450.2370010.2109420.1300893.3203020.3687982.1776280.4432670.0117850.0068910.0078010.0088340.9276010.0062210.0097400.0438960.0677380.0091420.0093771.5283950.7835780.4091060.0273540.0240010.0100630.0041950.0881290.0069800.0065510.0062410.2619340.2606600.0004730.1554180.3213180.0172220.0002100.6251720.0008650.0002000.0002090.0001940.0001950.0042411.5053750.0031860.0023430.0026250.0028470.0033030.0018550.0001840.0070060.6560781.0248641.1726730.0073240.0025290.0024020.0012490.0002250.0010770.2354110.1668350.1571310.4435990.1470080.0937070.1903390.0652160.1431510.2126720.2615280.0069680.6302990.7299092.0724510.5497841.6673302.1620180.0076100.9958010.2264680.0133510.0115750.0100990.0082960.0054960.0031890.0002610.0002950.0002200.0081760.6446480.0008520.0033950.6316180.0056400.0014830.0088640.0470750.0687330.0098810.0047910.0096000.4556000.0105440.0112900.0189680.0002010.0135000.0136910.0550830.0002340.0154970.0150520.1775650.6046061.3665060.8226360.5719380.2052981.1034610.0015600.3154100.0897160.0003060.7709100.0009600.0603140.0002580.0496580.0037010.0036630.4828281.0268670.8472360.6969640.4417360.3933052.9431570.9675020.5340290.4615990.7563424.2255902.2138771.4908770.5891480.8678610.5835240.0132510.0933850.0471620.0002770.0224920.4120150.1934130.0088310.0741772.0122160.0072170.0046160.0069780.0046480.0063430.0068790.3013151.2205710.5675230.1484980.3246060.3053100.0073481.6143291.9307460.0084560.6916730.4636890.0024570.0120570.7806200.0023390.0044230.0037660.0037820.2764260.6205350.0033400.0063070.0050960.0058110.0031020.0037140.0002180.5527020.0007150.0401840.0002590.0002260.0002380.0032140.0171160.0002260.0044530.0002150.0069950.2690520.0005770.0127270.9774980.0038000.0002240.0002430.0002760.0002490.3819580.6582390.0008020.4898150.5002090.0658400.0009491.4511141.9945571.5298981.9512803.0952411.5065871.6080510.3731190.0131570.2575180.0139990.6077020.4710290.5992790.3097310.2642550.0088770.5853410.4326010.0567180.0774740.2912130.7481560.6247921.3958571.0626030.0542050.0053450.0038680.0288940.9017190.0017550.0071440.0011390.0002090.2750810.0038160.0111850.0002150.0050570.0022140.0076260.0060930.0057710.0138830.0011860.0032760.0058390.0076022.0776622.7212300.0100691.8251620.5401940.6523760.5677120.2538920.4313991.0418351.3279830.4189890.1569140.8973390.1778550.5553560.4389980.0692900.0194871.1631271.6661900.4396401.6047910.0128600.0044820.0021100.0022900.9470820.0047991.1060750.004057

*******************************************
EVALUATING PIPELINE 
Pipeline directory: /home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_7c031cb3_2020-02-04_09-48-29pa_7ve0h/
With following parameter combination: {'batch_size_seq_length': 2, 'lr': 4e-05, 'lr_type': 'constant'}
EVALUATION OF CHECKPOINT /home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_7c031cb3_2020-02-04_09-48-29pa_7ve0h/outputs/checkpoint-3
-------------------------------------------------------------
|           |   agree   | disagree  |  discuss  | unrelated |
-------------------------------------------------------------
|   agree   |    586    |    92     |    351    |    40     |
-------------------------------------------------------------
| disagree  |    18     |    21     |    26     |     2     |
-------------------------------------------------------------
|  discuss  |    128    |    37     |   1354    |    29     |
-------------------------------------------------------------
| unrelated |    30     |    12     |    69     |   6827    |
-------------------------------------------------------------
Score: 6951.25 out of 7516.5	(92.4798776026076%)
Accuracy: 0.9133236333402619
F1 overall: 0.6547951264665792
F1 per class: [0.6400873839432004, 0.18340611353711792, 0.8088410991636799, 0.9868459092223186]
*******************************************


*******************************************
EVALUATING PIPELINE 
{'batch_size_seq_length': 1, 'lr': 4e-05, 'lr_type': 'cosine'}
INFO:__main__:Creating features from dataset file at /home/ubuntu/fnd_implementation/data/processed
  0%|                                                  | 0/9622 [00:00<?, ?it/s]  0%|                                        | 1/9622 [00:01<3:52:40,  1.45s/it] 21%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                             | 2001/9622 [00:02<2:09:02,  1.02s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9622/9622 [00:02<00:00, 4052.21it/s]
  ******************************************* 
              Running Evaluation                
  *******************************************
 
  Length dataset evaluation: 9622
  Length dataloader evaluation: 2406
  Number of epochs: 3
  Batch size: 4
  ******************************************* 
 
['/home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_7e12e565_2020-02-04_13-40-49aojt35um/outputs/checkpoint-3']
INFO:__main__:Evaluate the following checkpoints: ['/home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_7e12e565_2020-02-04_13-40-49aojt35um/outputs/checkpoint-3']
INFO:transformers.configuration_utils:loading configuration file /home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_7e12e565_2020-02-04_13-40-49aojt35um/outputs/checkpoint-3/config.json
INFO:transformers.configuration_utils:Model config {
  "architectures": [
    "AlbertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "down_scale_factor": 1,
  "embedding_size": 128,
  "finetuning_task": null,
  "gap_size": 0,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "inner_group_num": 1,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "net_structure_type": 0,
  "num_attention_heads": 12,
  "num_hidden_groups": 1,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "num_memory_blocks": 0,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 30000
}

INFO:transformers.modeling_utils:loading weights file /home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_7e12e565_2020-02-04_13-40-49aojt35um/outputs/checkpoint-3/pytorch_model.bin
HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=2406.0, style=ProgressStyle(description_width='initial')), HTML(value='')))
0.0057600.0063470.0033500.0013450.0004380.0001620.0001030.0000820.0001120.0001920.0000880.0054360.0005270.0016730.0009180.0001480.0001270.0001050.0000800.0000690.0013000.0001611.0705500.0466120.0028310.0065350.0003160.0000791.6842220.0605510.0021000.0001450.0007040.0008830.0024860.0001530.0022620.0001390.0024540.0004500.0038300.0088070.0002860.0000740.0011530.0000940.0057070.0002010.8688030.0177991.4427160.0375920.0007910.0000920.0000990.0000730.0000860.0023870.0015160.0018660.0054970.0020990.0005710.0001620.0001200.0009331.9487400.0294540.0043940.0047840.6033970.0101470.0002230.0006040.0003780.0001910.0002090.0004411.8818430.0483041.0824031.8321480.1019150.0013260.0014130.0028060.1043590.0068880.0004670.0015150.0002990.0003200.0013940.0001460.0088450.0001590.0280920.0913960.0010410.0003350.0009070.0014220.0023600.0109100.0062150.0003280.0003060.0001491.1791870.0134300.0001940.0011050.0039060.0001040.0001680.0119580.0001651.3668970.0116480.0001690.0000630.0017250.0000790.0000640.0000650.0019440.0000990.0000660.0000660.0000670.0000650.0000650.0024710.0086960.0078670.0021860.0000950.0035400.0013780.0012700.0073360.0007130.0755451.0683150.0117140.0003440.0000730.0003090.0066510.0551520.0369480.0003100.0051740.4305130.3769140.0025691.3371490.0094120.0005900.0001170.0927030.0030160.0027190.0002820.0003210.1180330.0020040.0001610.0000670.0003300.0017770.5997501.1092490.5051520.0045590.8186800.9438830.0301870.0029080.0001140.0003541.2104131.9423310.0111430.0096700.0001302.1621581.5284030.0081950.0002061.9126520.0189680.0047891.0474391.0944110.0129590.0040780.0001390.0034311.2001070.0085320.0765300.0004830.0045430.0010360.0005680.0023120.8534380.0061970.8720050.0058131.1290480.0057410.0032530.7728930.0039220.0005880.0001260.0007980.0000870.0019610.0001660.0008160.0000750.0022960.0003110.0024030.0057540.0001850.0006580.0045120.0009810.0033210.0000780.0033810.0000770.0002150.0000640.0000670.0016810.0000710.0000600.0000700.0016800.0000730.0000600.0000640.0000650.0000622.0959650.0087650.0001040.0212910.5526340.0022570.0001471.1336401.5447150.0063280.0870480.0401970.0005220.0000680.0003501.7154650.9679521.1768750.0044630.0001170.0000570.0000580.0000580.0000680.8898800.0055931.1510181.2747350.0047060.0009130.0000730.0000760.0000700.0000880.0002030.0000890.0001040.0022460.0000720.0000810.6230360.0023210.2100610.0008580.0000750.0000951.1615290.3250710.0011670.0000660.0000590.0000641.1336111.1250440.0037790.0000730.9916622.2851170.0085270.0001330.0088610.0001250.0002290.0002840.0000770.0007590.0000660.0000730.0001440.0067880.0001370.0007581.0674130.0034061.3685150.0043350.0013820.0000890.0000760.0010450.0084591.6134300.0054980.0000930.0161680.0006670.0021540.0006240.0006060.0001630.0010580.0006191.5335510.0045600.0005240.0001010.0000770.0000820.0000780.0001550.0001800.0000730.0001480.0000760.0007080.0000750.0000760.0000910.0000740.0000810.0007140.0000800.0000740.0000760.0000760.0000810.0000820.0005130.0006060.0000780.0000750.0000740.0000770.0000740.0003180.0000770.0000730.0001990.0000720.0000740.0000740.0000920.0001460.0006210.0000760.0010640.0012150.4374580.0978240.0020180.0008650.0000701.7091460.0044300.0001670.1077490.1228670.0087770.0001740.0001900.0001130.0002440.0000920.0015410.0001060.0002340.0000780.0003460.0001730.0020020.0006810.0022320.0000840.0042620.0001860.0578560.0006770.0000681.0393630.1165210.0003480.1177800.0044600.0015611.5788891.6473010.0039520.0008160.0000760.0000740.0000710.0001640.0000790.0000690.0010890.0001740.0000920.0246550.0001330.0001630.0000730.0000780.0006930.0004250.0001302.1934173.3580910.0113300.0005250.0009770.0005242.0393270.0052840.0010070.0001610.0008460.0008930.0001400.0012610.0001620.0002660.0001060.0001010.0001950.0006830.0027820.0028200.0000852.6385111.3430700.0030470.0006190.0004650.0008941.5786151.5492670.0033930.0046271.2507860.0030300.0001410.0000681.1897680.0031781.5295551.8041992.2244311.0431971.3827901.9924381.0030732.3461940.0073110.1386090.0016420.0001260.0000770.0006110.0000940.0001120.0000880.0001310.0006130.0011080.0000900.0000880.0000940.0000850.0000930.0016130.0000940.0000940.0005830.0005450.0023080.0046260.0000870.0000880.0022400.0033100.0017750.0001190.0016110.0022400.0000830.0001040.0205000.0001070.0028260.0153590.0000890.0819010.0013830.0003890.0021790.0035211.4203790.0041600.7125640.9267601.3066010.0024840.0001600.2008810.0026920.0000710.8249701.1870420.0113340.0015680.0007950.0013750.0008510.0007110.0008710.0075910.0014820.0047970.0018160.0013320.0002910.0001160.0105310.0000900.0013300.0013290.0009440.0009920.0000660.0000650.0000640.0000650.0007880.0009010.0000680.0010840.0002311.1177110.0020081.0786090.7621740.0013770.5491510.0015260.0000630.8976410.0016430.8552621.0110341.4128371.0945540.0053891.2368350.0074060.0004000.0060981.4429590.0029320.0084800.0008261.6385210.0046770.0016291.2318933.7157801.2926780.0116360.0239500.0139820.9556250.0053810.0015421.8842181.9214430.0057001.3313490.8908600.0019920.0005690.0000840.0005701.6963940.0031350.0000791.6864300.0032910.0000780.0005410.0000741.6620010.0027130.0005500.0000690.0000710.0005440.0000760.0002830.0000780.0008520.0005870.0000731.8436033.4891111.0881120.0595390.0042690.0037340.0040050.0000832.3074080.0037320.0040730.0043990.0000820.0050341.1661090.0019260.0021230.0039140.0030940.0028330.0006810.0008210.0014300.0008580.0012640.0000820.0017720.0000930.0009350.0000650.0019120.0008700.0000720.0000690.0000720.0007360.0076570.0044670.0086670.0013220.0000650.0000610.0000660.0000640.0000680.0000910.0000630.0064960.0000730.0001080.0014610.0000850.0000670.0000720.0004530.0001070.0037600.0000730.0383930.0015120.0031490.0023360.0001290.0013450.0028600.0008290.0007390.0030060.0039110.0017280.0019380.0026700.0012830.0017560.0000801.1495140.0016881.6316530.0023800.0001111.5349391.4942310.0021580.0005100.0013670.0000740.0010050.0017910.0074080.0094640.0048370.0030010.0021320.0039284.1369990.0071390.0000810.0018820.0019731.7505630.0073220.0027171.2280832.4788340.0049720.2160510.0003680.0000670.0000920.2073660.0003540.0000852.3737931.5027442.2327690.0033972.2423490.0030611.8893200.0025912.2152690.0031970.0001170.0002270.0003210.4015610.0005960.0000730.0018290.0000780.0026480.0039400.0055530.2726250.0030160.0027750.0013620.0032440.0000760.0000710.0294440.0001330.0003460.0000790.0000680.0022740.0009080.0025180.0022511.3481480.0039630.0041400.0002990.0027190.0040780.7313130.0042010.0011510.0057470.7319160.0165791.2614212.5117300.5324080.0007390.9916580.8601020.0011551.6966351.0094991.8583770.0026330.9471210.0161040.0001140.3835240.0009520.2240520.0104050.0000780.0009320.8112764.8161334.4826600.0055150.9689700.0039290.0089410.0000930.0152960.0090180.0006280.0011000.0011580.0608460.0071360.0071940.0000791.1799031.2701390.0015951.1624640.0015860.0000780.0000751.2814150.0026270.0011150.0002230.0014900.9444750.0012090.0000950.0006400.0086850.0151230.0030800.0000720.0000650.0000660.0001630.0000600.0000710.0000970.0073820.0000710.0001070.0001560.0000760.0000610.0000620.0000650.0000610.0000650.0000640.0000730.0000620.0000600.0000630.0012430.0000730.0394561.3208894.7564401.2912840.0015381.0709320.0133190.0071410.0064380.0001750.0000860.0002160.7568780.5667750.0007590.9824360.0013300.6883883.6032410.0095640.0068150.8464050.0020740.0031370.0011250.0001000.0104600.0083120.0183870.0148350.0001190.0000740.0000730.0022160.0010021.2449880.0022210.0010730.0016850.0043780.0003820.0039150.0035130.0048480.0027570.0304611.3642620.0038170.0017830.0023860.0021830.0000790.0017780.0038400.0014720.0029140.0016890.0006070.0018970.0000670.0001210.0056280.0000840.0000930.0000780.0000710.0011780.0001030.0000720.0000770.0000770.0000710.0000810.0006310.0001461.4475110.0015800.0000691.9033750.0026490.0007641.8665720.0020210.0000660.0862920.0009450.2315780.0004520.0000760.0000620.0491180.0001420.0000760.0009793.0287743.2140373.2982661.7617424.5606773.2989925.0137411.2194270.0120490.0113750.0000820.0000710.0000710.0000720.0000780.0000880.0000710.0000730.0017210.0000750.0000950.0016320.0023970.0001140.0044610.0005870.0004160.0384480.0001150.0061211.9309330.0043340.0025660.0394790.0070881.9154580.0036100.0170860.0068041.6443450.0032701.0373590.0011301.9268500.0020920.9269621.8598190.7023534.5960252.9572800.1515620.0002330.0019730.0004070.0022271.1627540.7454491.1064100.0102030.2614220.2012040.1041170.2116480.0009590.0027700.0029820.0028940.0000870.0024050.0012151.5105740.0016350.5571330.0006131.9805810.0182380.0000780.5325870.4340240.0005310.0000730.0000691.1112340.0011230.1499921.0778560.2448401.1510590.0011880.0000780.0665260.5386330.0005860.0103100.0001400.0000650.0455160.6570400.0007120.0078070.0000750.6950430.0070050.0001482.0482631.6151892.1995871.3080340.7647722.4798600.3827562.1354720.0070820.0000920.0091641.2172721.5096901.1356370.2687720.0014120.0021550.0063941.3778851.0071720.0075240.0066590.0252380.7580650.0052190.0137680.0006810.0000640.0021950.0020160.0020401.3103960.0041320.0000720.0000680.0000630.0001841.1905921.2314142.0074580.0035530.0002110.0069930.0000750.0005231.2545680.0011880.0005760.0000760.0000670.0034550.0000950.0000650.0071170.0000910.0038400.0038660.0000700.0012640.0000730.0000690.0000681.7581780.0016370.0000670.0001270.0028690.0088100.5155890.0058981.4528881.1063040.0088960.8217920.0066820.0063460.0013892.6913141.3377562.6880290.0056440.0013271.3168900.9319980.0031620.0012080.0002810.0000980.0002470.0001750.0022860.0004303.5091710.7433401.7906560.0080151.0400990.7614840.0007581.1188850.0014131.1523860.0023081.1565480.0011591.0592250.0027980.0000980.0001210.0001680.0000900.0001050.0002110.0060610.0000710.0000720.0000730.0005601.3002210.0011550.0030460.0000820.0001510.0013041.8220031.9373182.1959351.1248060.0013430.0000730.0000770.0000620.0044961.0622760.0011670.0000860.0006880.0027940.0045360.0000913.7265834.0236581.5586720.0029690.0026320.0019061.2350870.0073620.0034820.3052241.2190600.0039540.0001700.0297720.0001040.0001200.0000860.0001570.2438980.0089240.0001690.0000991.1955701.7568760.0118080.0009700.0000670.0095590.0000930.0613350.0002970.0000700.0001050.0007370.0030070.0001810.0005600.0001030.0000761.1657070.0038560.0000980.0053690.0001030.0007130.0007320.0010930.0006780.0000800.0000830.0032020.0001890.0003550.0029190.0000740.1030480.0001590.0002952.2948270.4568030.0159310.0126740.0063902.3514813.2389981.1921312.1778740.5429140.0056410.0041830.0052110.0041660.0040180.0185500.0585410.0027270.0030880.0023030.0026400.0026430.0023580.0124960.0161520.0146160.0014020.0041340.0024900.0096690.0040660.0029390.0044601.4636380.0208271.3322822.0738880.4489970.2192330.0068220.0000640.0000620.0000860.0000650.0050190.0000670.0000710.0006220.0011460.0000680.0125260.0114330.4023560.0132900.0173931.2701960.5131051.4226970.0011341.5280050.3369800.0047770.0012600.0046500.0043710.0003420.0053040.0442290.0269960.0437960.0007480.0000700.1090150.0029400.0025120.0001280.0004911.4569230.0011552.0076511.0201362.6886893.0450451.0920930.0009640.0010990.0001900.0402770.6764570.0006291.7471520.0024100.0006260.0001200.0000770.6762720.0013410.0001751.8597240.0023580.0029540.0000960.6329740.0012860.0005060.0028210.0248560.0001160.0036190.0048230.0029310.0000980.0010450.0500310.0002850.0019580.0017971.4384440.1314150.0050700.8287560.6598420.0095181.5709560.0021920.0005810.5596250.0047490.0006241.6765781.1453022.2728183.7630192.1533433.1114731.5124521.4482081.3006283.0903290.0022500.0034260.0000850.0029091.2594911.2879580.0058510.0000890.0079950.0023710.0011800.0018110.0015850.0026021.4336630.0027990.0014990.0016520.0015930.0018970.0007510.0015960.5429440.0043040.0065770.9656320.0027400.0017420.5596840.5395811.6834640.0027490.0004410.0028510.9836530.0035320.0040110.0038130.0048370.0001242.1920982.2304701.0362051.1948061.1132061.1529441.1717102.1121875.1636621.1830380.0032490.0025900.0028660.0024720.0041220.0001140.0035050.0288040.0002810.0024260.0000940.0000830.0012130.5797650.0004860.0001440.0065180.0001150.7978310.0626470.0002410.0024940.0000750.0005050.0001060.0002011.9433880.9909960.0038102.4369802.3100782.1977901.2708481.3933281.8810591.2147312.2490722.3067481.2104750.0031990.0025280.0009550.0011630.0025390.0026180.0007140.0012750.0023920.0016781.5709782.8424620.0049970.0049450.0044460.0035630.0023880.0037410.0027120.0026190.0038200.0730220.2963260.0220580.9403370.0006800.0711400.0012550.0000790.0003800.0000720.0000590.0000590.0000620.0000650.0005610.0013171.2461640.0009311.4075310.0010231.3328510.0013750.0026880.0016800.0054040.7290691.8580040.0036571.2197593.5707883.7611522.4940461.3151230.0017130.0001580.0102000.1979770.1846530.0032620.0021320.0060170.3980070.0024210.0132950.0021480.4349960.0018920.0021840.0028920.0014150.0022851.2886800.0032430.5556620.0173440.0068251.0213392.1437691.3460560.0079240.0019561.2327510.0031260.0016251.6919690.0040731.6890372.9720850.0059431.2062191.2855450.0018711.1740970.0030094.8435210.4393510.8863871.9434320.8412330.7698341.0157790.0021580.0039440.0000760.0021860.0035230.0042970.0000721.2621681.7497780.0049290.0000790.0015830.0012340.0010370.0000851.4407150.0009712.8251531.4499110.0016771.3669071.4179666.7358725.3311066.8518015.3875875.1336850.0047420.8219500.0015610.0004210.0016400.0000780.0010680.0013870.0006130.0000970.0000920.0002091.1346330.0007590.0071442.4609070.0015750.0000790.0000750.0001270.0000870.0034315.4050934.4023761.5162331.1390791.0934240.0007671.0988340.0009880.0000953.0408620.4958951.6880651.6357482.1544733.3058870.5309321.6123362.9691611.9552660.0012430.0000730.0035131.3073360.0008581.2104960.0012340.0001160.0027621.3408290.0009310.0000730.0001270.0015310.0008100.0001270.0026290.0026250.0013120.0014260.0014220.0019470.0017460.0006090.0013560.0018700.0012380.0011720.0020490.0001830.0027360.0008250.0020440.9182281.1489240.7163310.3323090.3444902.1841510.0095092.4841780.3167130.9457210.5067040.0005050.0000690.0000810.0017430.0004140.0012290.0010390.0011800.0014240.0017140.0017260.0013790.0018300.0005670.0011210.0005630.0006680.0000690.0006090.0154910.0001110.0014991.0602710.9854890.0012501.1059450.0020290.0010820.0090610.0000680.0022420.0011701.3330260.0008320.0001870.0019950.0011140.0000680.0011280.0016660.0000670.0000700.0010400.0000910.0002910.0039300.0014680.0000900.0112550.0000680.0015150.0013130.0000650.0010260.0000910.0000640.0032080.0022900.0042100.0008310.2452140.0003890.0000690.1421430.0013560.0003040.0000770.0001510.0000760.0064590.0000800.0105780.0000740.0001300.0000980.0001010.0035700.0042440.0003720.0034170.0000940.0004170.0000841.1972971.1998241.1849443.3465042.1373010.0898001.2983620.8290492.4789580.0175711.1378301.1698001.1992000.0274071.5219290.0092530.0048250.1726021.0931970.0046770.0105430.0079501.6463021.9678840.6215070.0010400.0065011.1289270.0034860.5632520.0026480.0017020.0021400.0039770.0020630.0058083.4138601.5915631.6228871.3235571.9700391.7956720.0137251.3335820.0035620.0048870.0045360.0018280.0012060.7624211.5751230.0035900.0072800.0059540.0040850.0055330.0051440.0033160.4026670.0037010.4000430.0017260.0001080.0000640.0000670.0014520.0012640.0019360.0013040.0000640.0000650.0000630.0002711.0755820.0006810.0000640.0000710.0000780.0007270.0000680.0000640.0000630.0000750.0000610.0012320.0001383.4193940.0018760.0000940.0011950.0007880.0011660.0014050.0009360.0016190.0006070.0014170.0012230.0006820.0005870.0000670.0000660.0057980.0046621.2091740.0109311.3292941.6791121.1119782.9719100.0090370.0008940.0008650.0005680.0005500.0008550.0000690.0009010.0000780.0000740.0000680.0007070.6295760.0005111.3969400.5700090.5192962.2865880.2437260.1308310.0001653.1274580.8692811.8734600.9497210.1833490.3596170.4027951.5152581.4691770.9423901.1132320.0006341.1210400.0076820.0029560.0029301.8679261.6797160.0092413.0571912.5682730.1440060.1007180.5983313.4705990.7363171.4403560.0077480.0097210.8796340.0121530.2485880.0048380.7748600.4496841.6644391.0948431.6052720.0073160.0581401.4229990.0082930.1527950.0001460.3479670.0005780.0000700.0000820.0000850.0000620.0000610.0000600.7018000.0150390.0001110.0000650.0000690.0000640.1300470.9152940.3516520.7658060.0009300.0002760.0013850.0056170.0071950.0045720.0054910.4400600.4405070.0061370.0047930.0052400.0007460.0050230.0049540.0101131.2210270.0058300.0056470.0024250.0021640.0000640.0027590.0000670.0000600.0044680.0017660.0019640.0015380.0034260.0000640.0000660.0000660.0054160.0099460.0057740.0068570.0288510.1699022.5207330.0137530.8392132.8467801.0961450.0006410.0004200.2581550.7227470.0007232.5563770.4357300.0007990.0009010.3371490.0002530.1672960.0001740.0000610.0000781.2769720.0006930.0000960.0000760.0099060.3371260.0002250.0000640.0291000.0295570.0006120.0039500.0005810.0039680.0000663.4182572.7326250.0071642.5071771.4045900.0055412.6033242.9934721.3759650.0269080.0184400.0094100.0057710.0043311.1469951.2547410.0006772.7203020.0033120.3169220.8540531.3187783.8483131.2905860.1199202.7530550.2069350.6360920.7348611.8175290.0042210.0031081.4239430.0007441.0253581.2135810.0008090.0011750.0068020.0000750.0001090.0003471.6531250.0050301.8948501.2669661.1691080.0009120.0771491.7086681.8338150.0009382.8137780.0090170.6684850.0063040.0050780.0042160.0055461.4169160.0063550.0028120.0177580.0001820.5096131.6937172.3436091.2793734.1452460.6456801.3625050.0050110.0015970.0054340.0000691.3059641.5967080.0038390.0025372.6863600.0097940.0144780.0318050.0322540.0095520.5676840.2315690.3776690.0041870.0027740.0000810.0055180.0113271.9271580.0009670.0016800.0000710.0043260.0024660.0040470.0019000.0050770.0087610.0022610.0020040.0036150.9770680.0053740.0000680.0000970.2474910.0042230.0031570.0028530.0032780.0013240.0015720.0020310.0012480.0001280.0000900.0001400.0072210.0000650.0001361.3885930.0007310.0000600.0004370.0000580.0003010.0001010.0000760.0062890.0000830.0008760.9706340.0004970.0000600.0009461.0494610.0005390.0000610.0033910.0020421.2187620.0006710.0025460.0032470.0031760.0204720.0014940.5079290.0232610.0036830.0000800.0000810.0001650.0012340.0002350.0003600.0002310.0000730.0079490.0000980.8643610.0867030.0001290.0000680.0000740.0038750.7973680.0914530.0001080.8581230.0007920.0012600.6803750.0035800.0063850.0038750.0020521.0509971.5676761.8319970.4908400.0047291.2728571.7895614.9523573.9188791.2764810.0047160.0001070.0103431.1677560.0043070.0033790.0052611.5195730.2494990.0004710.4625710.5009220.4701540.4975690.0003631.1914750.0005940.0002660.0070950.0010991.8987460.0009241.4789651.4813100.4721730.0048980.0044360.0025673.6652541.4218342.2348780.0063493.1499791.2932162.3520070.8507260.5183790.0008340.0085940.6678940.0007240.0028850.0016430.0067030.0000710.0085381.5694460.0007470.0006310.0000691.1891920.0005810.0013860.0000700.0000690.4209770.0014110.0016450.0007790.0009350.0028290.0001810.0000810.0022570.0001030.0010630.0010470.0027660.0014690.0020060.0008250.0018140.0011280.0009830.0007310.0007810.0001020.0012460.0001480.0027720.0001151.0510231.1067360.9625070.7773560.0065241.1265970.0005532.4068620.0214180.5632612.0809151.0949651.6359940.7697271.7734760.5341870.7047390.3287540.4698811.0515691.6348170.0013102.3101801.2448640.0115951.2767701.1699160.0130445.4271125.6680335.4607241.9642610.0042920.0043970.0095330.0069730.0002070.0026290.0032280.0024010.0015530.0863320.0025140.5991550.0024470.0026520.0008240.0031320.0942030.0026580.0160740.0033500.0046280.0000850.0044050.0031400.0724240.0029580.0003690.0054200.0001031.5643810.0035460.000102

*******************************************
EVALUATING PIPELINE 
Pipeline directory: /home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_7e12e565_2020-02-04_13-40-49aojt35um/
With following parameter combination: {'batch_size_seq_length': 1, 'lr': 4e-05, 'lr_type': 'cosine'}
EVALUATION OF CHECKPOINT /home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_7e12e565_2020-02-04_13-40-49aojt35um/outputs/checkpoint-3
-------------------------------------------------------------
|           |   agree   | disagree  |  discuss  | unrelated |
-------------------------------------------------------------
|   agree   |    432    |    91     |    190    |    55     |
-------------------------------------------------------------
| disagree  |     5     |     4     |     4     |     2     |
-------------------------------------------------------------
|  discuss  |    289    |    57     |   1538    |    56     |
-------------------------------------------------------------
| unrelated |    36     |    10     |    68     |   6785    |
-------------------------------------------------------------
Score: 7005.75 out of 7516.5	(93.2049491119537%)
Accuracy: 0.9103097069216379
F1 overall: 0.6039776658611934
F1 per class: [0.5647058823529412, 0.04519774011299435, 0.8224598930481284, 0.9835471479307095]
*******************************************


*******************************************
EVALUATING PIPELINE 
{'batch_size_seq_length': 3, 'lr': 4e-05, 'lr_type': 'cosine'}
INFO:__main__:Creating features from dataset file at /home/ubuntu/fnd_implementation/data/processed
  0%|                                                  | 0/9622 [00:00<?, ?it/s]  0%|                                        | 1/9622 [00:01<3:22:48,  1.26s/it] 21%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                             | 2001/9622 [00:01<1:52:27,  1.13it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9622/9622 [00:01<00:00, 6332.29it/s]
  ******************************************* 
              Running Evaluation                
  *******************************************
 
  Length dataset evaluation: 9622
  Length dataloader evaluation: 602
  Number of epochs: 3
  Batch size: 16
  ******************************************* 
 
['/home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_7e12e567_2020-02-04_15-05-45hxiwycnb/outputs/checkpoint-3']
INFO:__main__:Evaluate the following checkpoints: ['/home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_7e12e567_2020-02-04_15-05-45hxiwycnb/outputs/checkpoint-3']
INFO:transformers.configuration_utils:loading configuration file /home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_7e12e567_2020-02-04_15-05-45hxiwycnb/outputs/checkpoint-3/config.json
INFO:transformers.configuration_utils:Model config {
  "architectures": [
    "AlbertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "down_scale_factor": 1,
  "embedding_size": 128,
  "finetuning_task": null,
  "gap_size": 0,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "inner_group_num": 1,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "net_structure_type": 0,
  "num_attention_heads": 12,
  "num_hidden_groups": 1,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "num_memory_blocks": 0,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 30000
}

INFO:transformers.modeling_utils:loading weights file /home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_7e12e567_2020-02-04_15-05-45hxiwycnb/outputs/checkpoint-3/pytorch_model.bin
HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=602.0, style=ProgressStyle(description_width='initial')), HTML(value='')))
0.0004500.0005930.0004910.0004940.0023190.0123210.3389900.3613870.0455930.2956270.3398830.0315760.3758060.0290650.0023510.0005510.0002610.0011490.0001880.0001280.0259410.0014080.0015710.0006770.0029310.0020820.0002370.3474960.2591300.1075730.0037330.0002720.0001140.6693220.0855490.4087700.0126040.0697500.5762250.0180350.3994940.0101100.7925390.9340700.0215100.5256191.4734591.2863030.4301000.0090660.1086780.0028790.0015370.0002110.0001520.0002310.0004160.0010180.0004780.0002550.0003500.0001110.4755400.0092450.3637670.0059330.4177990.0063640.4482000.0142390.0003290.0001620.8596530.4213240.2587060.8166970.2239380.0031880.0001500.0011560.0462650.0007360.3931740.0061260.0003330.2055140.0025180.0002010.0001750.0001990.0001220.0006900.0001140.0003870.0004450.0001410.0005350.1784780.0039520.0009690.0025350.0002040.0012210.0411030.1727790.4764100.2766170.0027200.0002730.0011440.0024980.2312120.4222780.0040530.0009620.0002140.2711580.0053170.0040270.0571520.5450880.5824320.0274850.0438480.0005340.0002830.0001610.0003080.0321570.0015310.0010080.0134130.1246770.2827630.5792480.0046840.5556210.3179420.0324080.1890870.0106270.0003310.0001700.0001880.7714800.0889400.3610810.0034220.0013120.5326690.0119760.1840270.3410050.2223400.0017500.2898970.0020470.0091650.2046790.1202470.1291130.0022210.0631350.0023430.0006640.0409400.0293060.0340610.0003590.0008800.0003690.0074040.0010960.0015500.0009280.0003340.0003830.0013690.0603580.2255040.2987350.0022512.8868061.0662020.1034870.8197800.1820580.0184471.3668560.4614810.8167950.0058670.0005530.0009150.0004660.0005600.3300700.0025820.0003690.0620940.5249200.0092480.0015840.0469560.3229371.1030300.0075030.0016520.0441030.6774190.3713150.4551390.0024320.3947500.1065480.0006180.0353280.0002770.0001200.0002230.0314120.1048490.0011040.7275640.4266540.0037280.0010922.4201280.0112410.0005520.7990720.7957990.6375090.3653960.0350790.0004890.0001790.0001300.0125770.8868280.4895200.0059780.0004070.8939943.5291002.2804730.0094640.0001660.0146200.1222970.0016440.0125980.0012280.0015110.3721440.4437091.0284790.0105700.1535320.1112780.0011380.3778110.2635150.1514430.0890840.2960180.0077400.0260520.0051450.4922230.9763431.3486180.0179770.1057260.0023830.9516790.5150370.3864240.0015310.9499200.0037180.3071510.0015630.0023030.0001240.0119390.3479460.1934510.0031381.9161840.4444740.0017171.1068250.2624870.4191040.7183570.3212960.0012030.0018970.0351370.0120570.2623700.0015150.2491161.1837181.5653850.3568490.0023950.0001850.0006170.4745760.0022490.2271520.0199410.2404730.0110770.0003290.0004930.0010102.5951862.9424751.8290350.3151140.0040870.0021000.0107400.0007721.0683531.6451210.3075550.0037220.0099620.0418200.0076760.1114540.1376390.6084270.3047460.1407383.9918340.6399000.0039920.0002630.0003500.4156780.0030780.0004400.0006500.2105450.4675260.0989880.8701412.9765610.1441220.0051570.0737520.0021190.2098510.0023030.0030640.3976770.6585682.9782585.0388931.9149931.8302870.1237750.0009080.7969050.2951150.1974831.1398840.0032350.5164101.3636611.8910861.1144711.3435370.7584490.0868850.0008760.0245350.0668920.0007580.0001340.3784581.0193570.0148560.0407540.2161160.0042630.0025070.0553820.0808840.2321370.0816020.2379410.1118910.9695170.1511071.1354120.4876260.0640960.0572700.0018220.4753121.6934315.2925082.6826690.1747300.0008200.2569680.2962610.0011112.7980060.3295721.2344532.0450923.3769850.3975670.3807200.0580040.0007540.0009170.0008060.0005600.0005141.1494241.0389990.4477300.0013290.0004770.0006160.0003360.0005100.0004050.0003590.3522130.0011700.0002100.0002060.0007280.0002380.0002960.0013420.0003540.0001350.0012690.0003150.0005530.2304770.4340110.0815140.1667140.0023010.0028880.3133690.1800010.0032850.7195682.2532680.5008550.0538290.3124210.0013540.0005180.0002990.0007070.2417780.0006330.0001440.0002070.9912380.0149820.0026330.0005510.1817632.6686810.3776610.3735920.0010080.0258320.0520490.2446050.0217670.0092570.0323950.9391781.2808720.3232890.0065610.0020200.0029750.0024290.0018660.0001110.3619360.0012150.3859710.1013600.3215600.0033600.2719440.0023010.0803020.6829400.0910010.1393711.3072191.4062120.9981801.5879430.6811310.4489000.0038080.0059370.0022740.7062640.3918490.3127500.3049850.0901711.9409061.9080180.2269360.2188480.0562520.0310930.3009910.0993230.3985640.0049040.1734260.0594791.0083830.0121010.2160910.0395020.1122450.0015010.8484890.0018130.0004440.4286800.0011950.0010850.0007360.1775570.0174630.0016720.0005410.0089040.0059680.0275630.0032390.0506270.0002880.0001650.1861210.0007390.0847750.0018810.0025780.3524584.8448280.2065080.0022770.4482590.4627410.3829490.0192360.5077311.5096441.4039160.0084580.0235580.5205370.3572270.0012040.2830840.1142950.0157960.3220310.0904360.1541370.0020210.6095920.1556310.1258830.5323090.3560330.5152800.4462020.0957060.0043620.0011120.2116030.0774320.0008210.0009530.0009840.000957

*******************************************
EVALUATING PIPELINE 
Pipeline directory: /home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_7e12e567_2020-02-04_15-05-45hxiwycnb/
With following parameter combination: {'batch_size_seq_length': 3, 'lr': 4e-05, 'lr_type': 'cosine'}
EVALUATION OF CHECKPOINT /home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_7e12e567_2020-02-04_15-05-45hxiwycnb/outputs/checkpoint-3
-------------------------------------------------------------
|           |   agree   | disagree  |  discuss  | unrelated |
-------------------------------------------------------------
|   agree   |    540    |    50     |    191    |    12     |
-------------------------------------------------------------
| disagree  |    22     |    46     |    16     |     4     |
-------------------------------------------------------------
|  discuss  |    183    |    56     |   1535    |    54     |
-------------------------------------------------------------
| unrelated |    17     |    10     |    58     |   6828    |
-------------------------------------------------------------
Score: 7101.5 out of 7516.5	(94.47881327745627%)
Accuracy: 0.9300561213884847
F1 overall: 0.7243767687996028
F1 per class: [0.6945337620578779, 0.368, 0.8461962513781698, 0.9887770617623634]
*******************************************


real	31m10.690s
user	26m16.665s
sys	10m3.753s
ubuntu@run-gpu-mg:~/fnd_implementation$ 
ubuntu@run-gpu-mg:~/fnd_implementation$ 
ubuntu@run-gpu-mg:~/fnd_implementation$ 
ubuntu@run-gpu-mg:~/fnd_implementation$ exit
exit

Script done on 2020-02-04 19:02:01+0000
