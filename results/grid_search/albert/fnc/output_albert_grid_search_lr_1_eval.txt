Script started on 2020-02-04 21:59:22+0000
ubuntu@run-gpu-mg:~/fnd_implementation$ tmux attach[7Pexittime python3 test_separate.py --model=albbert --model_type=albert-base-v1M[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C_separate.py --model=albe[1PM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C_separate.py --model=alber[1PM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C_separate.py --model=albert[1P --model_type=albert-base-v1M[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C_separate.py --model=albert [1P--model_type=albert-base-v1M[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Ce_separate.py --model=albert --model_type=albert-base-v1M[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Cv_separate.py --model=albert --model_type=albert-base-v1M[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Ca_separate.py --model=albe[1@rM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Cl_separate.py --model=alb[1@eM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C

/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/home/ubuntu/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/ubuntu/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/ubuntu/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/ubuntu/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/ubuntu/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/ubuntu/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
There are 2 GPU(s) available.
The following GPU is used:  Tesla V100-PCIE-16GB
INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/albert-base-config.json from cache at /home/ubuntu/.cache/torch/transformers/8eff152e0e6c9b5bca31d5ed10ab2b543d201465c907d1e7d6a8cedb28ec3a7f.422e3ad6212153abef6df151efafdff1939214d0acdbc8c8011e538a0c2a8e99
INFO:transformers.configuration_utils:Model config {
  "architectures": [
    "AlbertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "down_scale_factor": 1,
  "embedding_size": 128,
  "finetuning_task": "multi",
  "gap_size": 0,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "inner_group_num": 1,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "net_structure_type": 0,
  "num_attention_heads": 12,
  "num_hidden_groups": 1,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "num_memory_blocks": 0,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 30000
}

INFO:transformers.tokenization_utils:loading file https://s3.amazonaws.com/models.huggingface.co/bert/albert-base-spiece.model from cache at /home/ubuntu/.cache/torch/transformers/e941f532bbbf6d6b7c96efbde9c15d38fc236e7fb120158bfc766814e6170529.c81d4deb77aec08ce575b7a39a989a79dd54f321bfb82c2b54dd35f52f8182cf
INFO:transformers.configuration_utils:loading configuration file /home/ubuntu/fnd_implementation/albert/model_pretrained/config.json
INFO:transformers.configuration_utils:Model config {
  "architectures": [
    "AlbertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "down_scale_factor": 1,
  "embedding_size": 128,
  "finetuning_task": null,
  "gap_size": 0,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "inner_group_num": 1,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "net_structure_type": 0,
  "num_attention_heads": 12,
  "num_hidden_groups": 1,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "num_memory_blocks": 0,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 30000
}

INFO:transformers.modeling_utils:loading weights file /home/ubuntu/fnd_implementation/albert/model_pretrained/pytorch_model.bin
INFO:__main__:Loading initialized pretrained model from /home/ubuntu/fnd_implementation/albert/model_pretrained
  ******************************************* 
           Freezing Embedding Layers          
  *******************************************
 
name:  albert.embeddings.word_embeddings.weight
param.requires_grad:  False
=====
name:  albert.embeddings.position_embeddings.weight
param.requires_grad:  False
=====
name:  albert.embeddings.token_type_embeddings.weight
param.requires_grad:  False
=====
name:  albert.embeddings.LayerNorm.weight
param.requires_grad:  False
=====
name:  albert.embeddings.LayerNorm.bias
param.requires_grad:  False
=====
name:  albert.encoder.embedding_hidden_mapping_in.weight
param.requires_grad:  True
=====
name:  albert.encoder.embedding_hidden_mapping_in.bias
param.requires_grad:  True
=====
name:  albert.encoder.albert_layer_groups.0.albert_layers.0.full_layer_layer_norm.weight
param.requires_grad:  True
=====
name:  albert.encoder.albert_layer_groups.0.albert_layers.0.full_layer_layer_norm.bias
param.requires_grad:  True
=====
name:  albert.encoder.albert_layer_groups.0.albert_layers.0.attention.query.weight
param.requires_grad:  True
=====
name:  albert.encoder.albert_layer_groups.0.albert_layers.0.attention.query.bias
param.requires_grad:  True
=====
name:  albert.encoder.albert_layer_groups.0.albert_layers.0.attention.key.weight
param.requires_grad:  True
=====
name:  albert.encoder.albert_layer_groups.0.albert_layers.0.attention.key.bias
param.requires_grad:  True
=====
name:  albert.encoder.albert_layer_groups.0.albert_layers.0.attention.value.weight
param.requires_grad:  True
=====
name:  albert.encoder.albert_layer_groups.0.albert_layers.0.attention.value.bias
param.requires_grad:  True
=====
name:  albert.encoder.albert_layer_groups.0.albert_layers.0.attention.dense.weight
param.requires_grad:  True
=====
name:  albert.encoder.albert_layer_groups.0.albert_layers.0.attention.dense.bias
param.requires_grad:  True
=====
name:  albert.encoder.albert_layer_groups.0.albert_layers.0.attention.LayerNorm.weight
param.requires_grad:  True
=====
name:  albert.encoder.albert_layer_groups.0.albert_layers.0.attention.LayerNorm.bias
param.requires_grad:  True
=====
name:  albert.encoder.albert_layer_groups.0.albert_layers.0.ffn.weight
param.requires_grad:  True
=====
name:  albert.encoder.albert_layer_groups.0.albert_layers.0.ffn.bias
param.requires_grad:  True
=====
name:  albert.encoder.albert_layer_groups.0.albert_layers.0.ffn_output.weight
param.requires_grad:  True
=====
name:  albert.encoder.albert_layer_groups.0.albert_layers.0.ffn_output.bias
param.requires_grad:  True
=====
name:  albert.pooler.weight
param.requires_grad:  True
=====
name:  albert.pooler.bias
param.requires_grad:  True
=====
name:  classifier.weight
param.requires_grad:  True
=====
name:  classifier.bias
param.requires_grad:  True
=====

*******************************************
Evaluating the following pipelines 
['/home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_0e88ccd5_2020-02-02_14-32-588ds1qj1k/', '/home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_0c6bb2e8_2020-02-02_09-19-060hupu8cb/', '/home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_0fbd2562_2020-02-02_15-09-01bq808q18/', '/home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_0d5a1d52_2020-02-02_10-44-062m6rinje/', '/home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_0d5a1d53_2020-02-02_11-14-02sum7sgrs/', '/home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_0e88ccd4_2020-02-02_13-14-14zrziive6/', '/home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_0c6bb2ea_2020-02-02_10-38-00rih7mkyq/', '/home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_0e88ccd3_2020-02-02_13-11-27u2h630uo/', '/home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_0d5a1d55_2020-02-02_12-36-0117xcau5c/', '/home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_0c6bb2e9_2020-02-02_09-19-07jz_todo1/', '/home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_0e88ccd2_2020-02-02_12-39-28qgod6khq/', '/home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_0d5a1d54_2020-02-02_11-18-1325qlp8wp/']

*******************************************

*******************************************
EVALUATING PIPELINE 
{'batch_size_seq_length': 3, 'lr': 1e-05, 'lr_type': 'cosine'}
INFO:__main__:Creating features from dataset file at /home/ubuntu/fnd_implementation/data/processed
  0%|                                                  | 0/9622 [00:00<?, ?it/s]  0%|                                        | 1/9622 [00:01<2:44:03,  1.02s/it] 21%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                             | 2001/9622 [00:01<1:30:58,  1.40it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 7501/9622 [00:01<17:43,  1.99it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9622/9622 [00:01<00:00, 6083.77it/s]
  ******************************************* 
              Running Evaluation                
  *******************************************
 
  Length dataset evaluation: 9622
  Length dataloader evaluation: 602
  Number of epochs: 3
  Batch size: 16
  ******************************************* 
 
['/home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_0e88ccd5_2020-02-02_14-32-588ds1qj1k/outputs/checkpoint-3']
INFO:__main__:Evaluate the following checkpoints: ['/home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_0e88ccd5_2020-02-02_14-32-588ds1qj1k/outputs/checkpoint-3']
INFO:transformers.configuration_utils:loading configuration file /home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_0e88ccd5_2020-02-02_14-32-588ds1qj1k/outputs/checkpoint-3/config.json
INFO:transformers.configuration_utils:Model config {
  "architectures": [
    "AlbertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "down_scale_factor": 1,
  "embedding_size": 128,
  "finetuning_task": null,
  "gap_size": 0,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "inner_group_num": 1,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "net_structure_type": 0,
  "num_attention_heads": 12,
  "num_hidden_groups": 1,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "num_memory_blocks": 0,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 30000
}

INFO:transformers.modeling_utils:loading weights file /home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_0e88ccd5_2020-02-02_14-32-588ds1qj1k/outputs/checkpoint-3/pytorch_model.bin
eval_separate.py:214: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0
Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`
  for batch in tqdm_notebook(eval_dataloader, desc="Evaluating"):
HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=602.0, style=ProgressStyle(description_width='initial')), HTML(value='')))
0.0030960.0035390.0022020.0014390.0010720.0129460.2889260.3772230.0504280.4586210.4847800.0474240.2418410.0195280.0138530.0039340.0016270.0132510.0015470.0005670.0125440.0015760.1867120.0122990.0140520.0303820.0019930.2233540.7557850.0275420.0015910.0008250.0006250.5322700.0188590.0074460.0075450.1753780.9366510.2280010.2715040.0280170.2228210.7594510.0212750.4332321.1441360.196286
0.4903060.0114000.1809490.0041500.0009770.0004570.0006420.0006230.0817160.1395780.0380410.0013560.0029130.0003930.3654370.2043580.2673300.0060940.6739690.0105860.1835860.2155840.0034180.0004430.6911860.2711470.0218840.3545850.2024480.0030820.0004660.0102760.1500760.0023250.4277020.0092960.0014360.3488520.0044670.0007130.0004820.0003980.0003660.0008440.0003440.0005190.0006420.0007610.0267990.4706860.0136370.0130810.0007780.0004740.0030410.2875760.0058460.3481770.3170640.0033580.0011800.0006940.0017750.4468420.4225630.0045890.0004500.0005670.2967600.2437180.2586640.1211500.6508411.0283070.4423960.0071600.0006030.0009530.0003220.0012900.2227090.2400940.1100360.0046900.3694520.1037950.4154690.2310280.3363630.3240360.0536030.0798130.0797260.0021480.0011000.0006731.1139450.2217280.3368220.0046600.2167540.4613660.4510220.0441820.3900170.4967630.0041890.7793410.0056700.3789320.0033870.0056720.4399800.0062710.4977310.0178120.0052240.0128050.1634330.3531920.0036550.0497470.0823970.0308950.0023830.3606880.0679220.0020830.0200390.0370570.5046980.2915170.5965780.0061961.8474141.2101130.2145750.7225990.1922480.3895280.3303380.3992900.4517650.0108550.0022040.0032250.0067690.0009490.0044910.0866150.3426210.4261480.7346340.0460440.0151780.0733410.1777521.1747330.0390690.0121860.2175920.2365870.1317020.0065260.0055680.0309100.0019640.0003470.1612500.0010960.0003780.0014520.2668820.3814130.0054330.4528000.4529250.1659880.0776640.5130350.0108630.0200200.1147140.2803110.1226280.0291150.0953390.0072940.0012570.0004200.0007680.6581390.3421650.0050830.0019880.2433531.5055301.2770170.0057860.0004180.1467530.0428630.0010830.0028050.0117440.0070430.0256870.7287680.5760840.0750010.2466460.1464340.0057250.1820580.2775350.1919030.1596580.5031750.0487530.0161060.1978200.5057670.7863171.6190580.5705140.1326840.2299400.0713500.0044500.2956810.0014150.1147900.0010130.1010530.0027310.0081130.0008620.0802590.6247730.2769250.0150661.6284440.4477480.0022480.5803030.6388790.2919890.2903000.4130290.0017630.0023750.1905760.0306160.1816030.0308360.0848450.6178320.8629540.3741940.0571540.0092540.0027260.2751300.0084160.0065410.0043480.1941880.0784180.0016990.0019240.0155191.4032261.9395281.7691550.1399900.0144820.0046790.0450260.0068090.0503022.8112940.0433120.0205930.0942900.1881350.4090170.0351960.0287180.0423040.0141690.0013410.7812290.0782170.2097360.0017810.1582490.0023920.0056430.0020520.0028100.7251610.8151640.1869870.5562362.7109430.0870980.0229910.2296910.0190320.2251090.0131930.0400130.2290410.6212972.7081435.0312701.4677331.4540860.6864650.0113360.3408080.0066940.3265000.0346080.0014070.4823811.1240671.4284431.3542360.8716080.6331180.4669540.0042480.2823690.2826820.0019180.0006610.0787350.7832740.0429570.2520640.5503290.7373610.1283370.7309850.0056860.6587670.5503570.8338150.3929881.1513790.6760901.4486530.1817520.1396660.2385370.0045700.2515650.6289432.6421371.1427370.2407050.0015020.3022010.2619300.1063801.1011270.1306720.6848381.2796112.0455550.2352270.2065450.2065670.0020650.9133100.0103240.0019740.0025150.6963530.7857480.4578940.0258280.0022920.0075280.0016060.0023430.0020600.0028420.2882750.0020570.0006470.0005570.0068660.0007290.0011190.0941380.0760120.0007630.0051850.0011600.0018490.2557940.7974410.7058720.3598430.0107440.1016670.4165370.4247490.1012850.1213980.4467100.1647420.1360340.3294280.0137350.1225310.0010030.0013060.2628170.0010560.1346690.0754650.9101290.0287040.0026850.0007540.3024461.6793690.0571710.0883970.0064720.1952350.5483140.5493980.4558850.6450510.2221140.8525171.8340540.5267400.1793740.1459340.4082070.1726800.0055670.0003930.0471740.0278840.1487430.0608320.0636750.0477530.3366410.0501710.0025380.0783880.0136810.7360321.3818581.5852550.7758001.2706300.5896040.5786840.0467680.2733770.0054811.2202751.2698290.4008181.1993870.1851571.2295541.2920940.5742670.2204350.1350880.0038600.6936660.4763230.9213120.2555250.5572820.6081371.3080300.0195000.4183390.8833660.1934460.1386920.2282830.0015230.0017430.0088030.0022480.0562860.0027570.0436530.1161680.0010930.0453380.0281790.0679730.1341630.0183860.0842100.0013720.0007280.0638390.0022110.0640410.4115900.6597860.7739030.6319670.2105990.0248240.4431820.3364450.5756790.4402461.0846881.7111391.5262660.4957020.5559400.7132650.0786230.0874330.0809860.0020230.0016840.0026720.0059020.0016560.0177581.1505730.7302590.4535270.2892450.9082650.7437651.4876621.0247260.0043370.0029090.0038170.2105940.0049430.0046090.3314870.003212

*******************************************
EVALUATING PIPELINE 
Pipeline directory: /home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_0e88ccd5_2020-02-02_14-32-588ds1qj1k/
With following parameter combination: {'batch_size_seq_length': 3, 'lr': 1e-05, 'lr_type': 'cosine'}
EVALUATION OF CHECKPOINT /home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_0e88ccd5_2020-02-02_14-32-588ds1qj1k/outputs/checkpoint-3
-------------------------------------------------------------
|           |   agree   | disagree  |  discuss  | unrelated |
-------------------------------------------------------------
|   agree   |    491    |    86     |    224    |    17     |
-------------------------------------------------------------
| disagree  |     4     |    13     |     2     |     1     |
-------------------------------------------------------------
|  discuss  |    234    |    53     |   1495    |    65     |
-------------------------------------------------------------
| unrelated |    33     |    10     |    79     |   6815    |
-------------------------------------------------------------
Score: 7015.5 out of 7516.5	(93.3346637397725%)
Accuracy: 0.9160257742673041
F1 overall: 0.6423526428565401
F1 per class: [0.6215189873417721, 0.14285714285714285, 0.819851933095695, 0.9851825081315504]
*******************************************


*******************************************
EVALUATING PIPELINE 
{'batch_size_seq_length': 1, 'lr': 1e-05, 'lr_type': 'constant'}
INFO:__main__:Creating features from dataset file at /home/ubuntu/fnd_implementation/data/processed
  0%|                                                  | 0/9622 [00:00<?, ?it/s]  0%|                                        | 1/9622 [00:01<3:25:39,  1.28s/it] 21%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                             | 2001/9622 [00:01<1:54:02,  1.11it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 7501/9622 [00:02<22:13,  1.59it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9622/9622 [00:02<00:00, 4736.78it/s]
  ******************************************* 
              Running Evaluation                
  *******************************************
 
  Length dataset evaluation: 9622
  Length dataloader evaluation: 2406
  Number of epochs: 3
  Batch size: 4
  ******************************************* 
 
['/home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_0c6bb2e8_2020-02-02_09-19-060hupu8cb/outputs/checkpoint-3']
INFO:__main__:Evaluate the following checkpoints: ['/home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_0c6bb2e8_2020-02-02_09-19-060hupu8cb/outputs/checkpoint-3']
INFO:transformers.configuration_utils:loading configuration file /home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_0c6bb2e8_2020-02-02_09-19-060hupu8cb/outputs/checkpoint-3/config.json
INFO:transformers.configuration_utils:Model config {
  "architectures": [
    "AlbertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "down_scale_factor": 1,
  "embedding_size": 128,
  "finetuning_task": null,
  "gap_size": 0,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "inner_group_num": 1,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "net_structure_type": 0,
  "num_attention_heads": 12,
  "num_hidden_groups": 1,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "num_memory_blocks": 0,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 30000
}

INFO:transformers.modeling_utils:loading weights file /home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_0c6bb2e8_2020-02-02_09-19-060hupu8cb/outputs/checkpoint-3/pytorch_model.bin
HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=2406.0, style=ProgressStyle(description_width='initial')), HTML(value='')))
0.0008760.0009370.0004830.0001890.0000650.0000300.0000270.0000170.0000170.0000410.0000160.0000740.0000190.0007440.0000840.0000400.0001060.0000270.0000140.0000160.0000830.0000442.2203360.0965500.0040950.2024950.0077990.0003042.3188600.0800140.0026790.0000980.0000430.0000200.0001390.0000160.0001330.0000150.0040780.0003890.0005280.6089200.0145100.0003491.9342030.0429940.0019130.0001040.0018490.0000501.9168900.2465850.0047580.0001180.0004070.0000650.0000440.0752660.0025350.0001230.0005750.0000260.0000170.0000160.0000200.0000290.0097210.0001590.0001640.0000920.0007150.0000940.0000280.0000360.0000250.0000170.0000140.0000150.0000260.0000150.0000480.2384340.0030050.0000550.0000300.0000310.0000200.0000580.0000960.0002350.0001300.0000410.0022140.0000440.0006070.0000190.0300460.0040670.0000690.0000190.0001180.0000310.0002920.0001120.0000730.0000300.0000160.0000211.7944190.0165380.0001630.0000160.0000140.0000120.0000150.0005070.0000170.0000780.0000140.0000130.0000110.0000570.0000130.0000130.0000120.0000600.0000120.0000110.0000120.0000110.0000110.0000110.0001220.0275292.0671911.2239110.0090190.0026290.0000500.0001180.0002040.0000770.0000730.0000780.0011010.0000260.0000740.0000170.0003690.0010250.0010430.0000220.0015871.4695650.5406680.0035170.0002320.0000620.0000880.0000160.0000360.0000880.0000650.0000480.0000330.0000880.0000340.0000190.0000110.4189240.0025263.7595782.2929022.1857570.0126181.7529940.0100350.0001600.0002070.0000240.0002560.0004882.3390420.0127950.0005160.0000184.3695452.3849640.0126980.0000810.9344700.0288050.0356590.0148981.5153520.0077940.0000570.0000130.0000230.0000290.0000322.0449230.0101360.0000750.0000160.0000220.0000330.0000340.0000320.0000340.0000420.0000370.0000130.0000170.0000360.0000170.0000600.0000130.0000150.0000120.0000300.0000160.0000450.0000120.0000800.0000130.0000310.0001010.0000120.0000241.6318070.0071150.0000930.0000120.0000830.0000120.0000400.0000110.0000150.0000550.0000110.0000120.0000160.0000590.0000110.0000100.0000110.0000110.0000112.1274190.0085220.0000490.0001760.0013790.0000510.0000410.0058540.0011700.0000480.0001070.0001120.0000180.0000130.0000130.0889901.2702970.1721630.0006560.0000150.0000100.0000130.0000110.0000100.7873530.0031092.2266701.9830200.0071750.0001030.0000130.0000120.0000110.0000120.0000280.0000140.0000150.0000130.0000110.0000121.3986380.0048371.7491480.0060060.0000350.0000151.7289390.7626800.0025810.0000220.0000120.0000151.3919971.5498910.0051270.0000300.0028300.0211820.0001010.0000390.0000560.0000160.0000640.0000150.0000270.0000230.0000110.0000130.0000170.0142190.0000660.0001470.0253370.0000982.1741760.0067220.0001230.0000110.0000120.0000650.0477522.4758970.0075290.0000350.0007070.0000590.0000970.0000500.0000480.0000190.0000830.0000521.7728590.0051950.0000380.0000110.0000110.0000120.0000110.0000110.0000150.0000130.0000130.0000120.0000180.0000120.0000110.0000110.0000110.0000110.0000290.0000420.0000110.0000110.0000100.0000110.0000110.0000210.0000450.0000120.0000110.0000110.0000110.0000140.0000330.0000120.0000110.0000160.0000110.0000110.0000130.0000130.0000150.0000670.0000140.0003540.2339360.0006200.0003670.0001230.0001390.0000121.6290750.0041680.0000270.0002200.0009000.3319420.0008530.0000180.0000170.0000150.0000120.0000340.0000120.0000180.0000120.0000240.0000150.0001250.0001290.0005300.0000140.0002320.0015571.1767580.0029760.0000310.0299440.0012340.0000140.0011720.7299610.0017830.1141531.0720120.0025360.0002040.0000120.0000110.0000110.0000140.0000110.0000110.0000800.0000130.0000120.0006670.0000130.0000200.0000110.0000110.0001800.0000180.0000282.3107442.9809860.0069870.0000340.0001020.0000242.1772870.0049190.0000860.0000180.0000830.0000940.0000520.0000200.0000340.0000170.0000220.0000680.0000260.0002120.0002270.0004310.0000241.0422400.0032990.0000610.5186560.0011800.0010380.8003371.6358060.0111360.0031580.0002360.0004230.0000390.0000130.8537880.0023262.0242072.1130054.1995460.0088362.1530990.0051022.2357692.4972370.0608720.0458140.0003900.0000170.0000110.0004570.0000120.0000110.0000110.0000110.0003920.0002060.0000110.0000110.0000120.0000110.0000110.0002220.0000120.0000110.0000790.0000710.0001620.0006240.0000120.0000140.0001170.0000660.0006150.0000150.0001010.0002360.0000180.0000161.4020700.0026780.0001282.1681190.0041101.0113320.0019480.0000620.0003030.0001602.9731050.0057611.0743741.1698652.2087710.0041180.0000730.6832290.0155530.0000441.2954561.3537892.2948392.2488140.0044910.0000910.0000160.0000130.0015480.0000742.0507582.3777580.1073460.0006790.0000190.0000120.0001130.0000120.0002000.0000660.0001530.0000690.0000160.0000150.0000170.0000150.0000730.0000730.0000180.0000840.0000171.5527650.0027030.9880791.7900260.0030971.5559270.0028270.0000561.7242210.0029600.0625460.0001950.0002300.0001540.0001270.0000220.0001610.0000170.0002580.0003640.0000160.0000230.0002182.4055921.6613990.0028480.0087290.0029740.0011460.0006000.0003800.0013640.0039140.0002910.0003012.0933370.0047020.8467693.7240033.6760260.0060210.0000770.0000550.0000612.0954130.0034740.0000211.8402460.0030190.0000170.0000570.0000122.1011880.0033530.0000710.0000160.0000120.0000580.0000120.0001680.0000140.0002780.0000720.0000120.0006481.5739910.4120101.7808900.0029490.0001800.0248560.0000532.4829010.0038370.0003070.0004350.0000120.0001990.5836340.0009060.0003450.0001300.0001740.0001690.0045060.0000630.2140650.1318380.0036670.0000200.5519180.0008400.3607200.0005500.0027450.0000720.0000120.0000110.0000120.0000850.0002460.0002800.0002840.0000860.0000140.0000120.0000170.0000140.0000120.0000160.0000140.0008390.0000160.0000150.0002230.0000220.0000210.0000120.0000540.0000230.0005130.0000130.0009870.0004460.0000450.0002530.0000130.0001100.0000880.0023280.0000250.0006480.0005900.0001000.0017160.0002710.0001520.0009390.0000220.0017470.0000161.7508920.0024520.0000181.4790452.0800780.0028930.0000190.0000920.0000180.0000990.0002320.6262691.1437612.8023600.0040390.0001980.0065104.2277870.0058470.0000190.0001420.0000950.0261770.6198870.0009080.6850582.8783300.0040032.0801940.0028030.0000160.0000123.0930020.0041360.0000203.2507962.1354952.2625310.0030510.7961510.0010930.0670430.0002792.2109470.0030330.0000610.6417250.0008740.0076410.0000240.0000140.0000840.0000140.0001880.0001980.0001990.0001950.0001730.0001640.0001180.0000890.0000120.0000110.0004130.0000110.0000120.0000110.0000110.0000860.0000490.0001280.0000860.0001690.0000600.0000570.0000230.0000940.0000980.0000740.0000980.0038540.0006591.4566650.0033265.2256742.8630870.0042940.0000190.0010180.0019050.0000220.0001630.0294760.0000650.0000240.0014280.1805260.0002731.6929060.0023361.3047350.0017950.0000220.0003382.0980982.3630612.2134690.0026991.9357010.0023700.0009690.0000140.0032600.0095010.0000640.0001150.0001102.0269150.0026241.9041760.0022862.1069132.0869040.0024962.1866220.0026180.0000160.0000110.0001320.0000550.0000520.0000180.0001610.0001810.0000250.0000250.0000173.4777991.2718291.4550190.0017100.0000150.0000120.0000130.0000110.0000110.0000141.1015780.0012850.0000160.0000180.0000140.0000110.0000120.0000110.0000120.0000120.0000110.0000120.0000120.0000130.0000120.0005170.0000150.6876661.9626990.0025960.0000960.0000131.2570410.0035140.0002120.0003380.0005460.0000220.0004671.8257311.8373080.0021480.0195410.0000610.0010520.0003991.4358060.0020130.0002600.0040860.0001850.0015250.0000180.8785990.0017586.2450344.1203710.0050220.0000320.0000330.0001020.0001760.0000820.0001430.0001050.0000831.1054090.0012890.6670290.6062620.7182160.0020970.8675660.4698041.8031131.1132771.7740680.0140460.0000300.0110291.2949760.0091930.1077180.9818360.0011040.0002250.0000110.0000270.0005980.0000120.0000140.0000140.0000110.0003150.0000120.0000110.0000130.0000130.0000120.0000280.0001200.0000152.3559800.0024900.0000152.3113220.0024800.0000612.1395150.0022360.0000140.0005970.0000360.0016500.0000240.0000110.0000110.0005620.0000120.0000600.0059940.1640600.3168300.0352790.1016310.4414700.3651270.1672940.0015411.7638570.0020270.0000200.0000270.0000190.0000210.0000320.0000260.0000180.0000161.4628140.0014900.0000301.3882960.5602330.0005741.3449260.0016780.0000150.0001010.0000120.0001260.0008850.0001480.0000230.0002810.0007000.0000390.0000550.0003110.0006530.0003850.0001670.0000870.0000121.5289960.0015130.0000730.8333510.0009293.0605132.8013380.0107870.0000250.0000240.0000130.0007840.0025480.0003740.0006560.0026190.0171171.6521790.9882110.2980960.0003470.0002110.0001950.0002430.0000150.0002300.0000920.7117930.0007240.0001680.0000240.7052450.0026000.0000180.0047630.6060900.0005950.0000160.0000150.0029350.0000210.0012810.0008740.0126901.2888160.0012260.0000210.0021800.0001130.0000730.0007720.0000140.0000260.0009560.4507260.0004480.0005980.0000161.5815701.1611320.0010942.3406031.5820862.8571172.8349160.1371104.6216850.9224040.0057330.0171590.0000320.0215620.0004300.0255680.0005820.6731650.0006990.0002020.0005120.0000830.0009990.0003761.4666090.0043630.0002500.1656760.0063630.0001890.0000151.4350900.0014850.0001910.8969120.0010850.0000120.0000150.0000180.0000130.4734700.7266962.6503400.0024750.0000260.0009350.0000190.0000280.3920330.0003620.0000150.0000160.0000140.0432590.0000520.0000120.0007020.0000150.0004740.0004800.0000120.0000820.0000120.0000130.0000110.0332380.0000450.0000140.0000130.0011400.0011201.3585400.0015991.2852671.6907580.0030540.0009430.0002910.0004500.0000261.7875872.0183011.8938150.0023840.0000971.8674561.4537090.0013460.0000610.0000130.0000240.0000280.0000160.0000330.0000126.6022250.0056752.0690170.0018550.0000750.0001620.0000202.0268950.0017882.0993350.0018372.1534640.0018350.0001360.0000950.0000140.0000150.0000140.0000120.0000120.0000170.0050370.0000150.0000120.0000130.0000190.0281840.0000340.0004490.0000140.0000200.0000373.5674831.4894591.8387571.6038260.0013820.0000240.0000160.0000121.5667280.0395860.0000780.0000210.0001560.0006930.1327710.0001456.8450785.5350902.4190480.0020710.0007020.0000880.0169020.1222640.0039830.0000160.8833182.0488210.0016920.0000990.0000130.0000190.0000130.0000180.0000150.0783950.0000800.0000150.0015600.0117600.0020470.0000550.0000120.0001560.0000150.0001370.0000230.0000120.0000130.0000640.0000740.0000130.0000160.0000110.0000180.0008300.0000270.0000130.0002160.0000170.0000220.0001780.0000240.0000190.0000120.0001260.1068490.0001050.0000920.0005830.0000120.3123340.0002620.0001074.8611636.2175395.9867403.8674993.7270003.6031575.6886171.2977323.8329842.3078751.9205730.0071630.8123400.0210140.2241450.0089090.0018900.0001580.0001510.0001620.0001530.0006300.0001850.0002710.0003451.7252950.0014330.1943710.0004220.0008571.2812740.0013770.0001440.0022951.5889024.1371892.2249038.4570560.1351780.0002710.0000100.0000130.0000140.0000100.8140010.0006270.0000130.0000930.0001120.0000120.0054450.0006240.0033280.0213541.3524590.0022780.0011790.0006110.0000110.0016280.0002770.0005200.0001430.0003670.0002150.0000120.0001450.0000980.0002560.9319230.0007590.0000130.0010830.0000710.0001320.0001140.0000180.0021930.0000146.4360125.9805906.4860528.8536654.2721400.0031610.0000730.0000160.4896561.2736090.0012200.0006620.0003850.0003580.0000380.0006020.0010670.0000340.0000590.0001220.0003821.2360760.0009230.0012270.0006390.0001710.0001940.0002480.0000290.0000390.0002250.0019370.0000290.0000890.0029030.0000810.0001580.0000950.2935342.4819790.0036270.0123991.2177980.0013350.0002910.0000670.0000500.0001130.0001580.0000461.9144140.0182212.2456233.2269742.3304063.2592240.0029510.0484470.3745410.0364530.0000370.0003750.0000150.0004440.0000200.3558220.0022580.0000140.0007670.0001540.0000890.0001220.0001100.0000881.3308550.0010710.0001250.0001030.0001150.0001300.0000490.0001350.0006340.0021510.0378961.6053330.0022320.0004760.0046471.6869284.7734850.0040620.0002810.0001600.0745790.0003710.0002910.0002890.0011240.0000170.0003650.0003010.0001411.7121420.0013200.0001290.0001430.1098244.9606170.0070000.0001860.0001540.0001730.0001710.0001300.0000390.0000880.8665980.0006100.0002400.0000160.0000150.0008630.0675050.0000680.0000191.2204810.0008360.0048022.3032060.0025890.0002260.0000110.0001930.0000170.0000281.8934830.0014100.0001853.5328083.7414133.8189601.7235651.4863652.0317333.1504983.8083163.3060783.5716931.7071933.6426280.0054890.0001322.3813091.8733550.0013480.0082871.9300560.0014512.2373964.3310710.0029560.0001410.0001430.0001510.0001240.0001390.0001160.0001440.0001240.0047210.0012000.0000990.0001600.0000120.0001810.0000860.0000160.0000150.0000190.0000250.0000110.0000210.0000140.0000841.4923691.7328800.0011672.5635670.0016812.2523450.0017710.0000670.0048850.0002511.5625271.4117550.0009750.9871655.8716547.6010007.6641175.6636930.0041460.0000210.0005420.0021040.0074200.0000780.0000380.0003460.0000700.0002322.1007950.0014551.8395410.0012600.0001000.0051740.0000640.0002411.9246020.0013370.0030250.0028680.0005280.0319280.0212710.7222670.0020170.0001182.1438650.0014510.0000781.9849620.0013602.3463034.5351540.0030442.1268062.2694760.0014672.2247610.0014887.0152700.3744501.7749421.6432520.0015021.4836650.0204520.0004620.0108190.0000170.0835500.0138920.0003280.0000100.8043360.0008200.0003940.0000120.0000860.0002230.0000660.0000122.2883550.0014234.5694872.2885230.0015992.2952512.2914148.2569176.1285658.5964126.8492636.1270970.0038730.0000630.0000680.0003161.1403340.0007090.0000900.0000380.0000590.0000150.0000130.0000321.5994390.0009870.0000421.9027550.0011760.0000160.0000130.0000160.0000110.8548100.8838682.6601170.6239761.6768960.3319620.0002250.0003060.0000420.0000181.4472000.0233150.8912131.8212641.4144893.4051731.9873655.6669095.5702583.6433800.0021860.0000130.0007521.7756210.0010681.7173190.0010380.0000110.0134100.3086890.0002060.0000110.0000130.0000140.0000120.0000110.0006830.0012450.0010660.0001210.0001400.0002530.0004720.0000720.0001320.0001870.0001020.0001140.0002260.0000170.0006940.0000630.0002370.0558524.1381701.5161760.2900210.6399660.8820280.0006440.1339070.1195430.0410650.0013390.0000700.0000110.0000120.0001460.0000170.0000900.0000900.0001000.0000960.0001330.0001450.0001250.0001340.0000470.0000960.0000530.0000490.0000110.0000560.0000250.0000120.0001150.0001300.0000600.0000730.0001210.0000710.0000610.0000760.0000140.0001260.0000662.1289280.0012270.0000290.0001470.0001230.0000120.0001280.0000140.0000140.0000100.0000140.0000120.0000260.0001870.0000820.0000130.0002100.0000120.0000790.0000240.0000120.0001340.0000150.0000130.0006240.0002340.0000750.0000662.1578340.0012260.0000110.0000290.0000150.0000180.0000110.0000140.0000110.0005810.0000120.0006520.0000110.0000120.0000130.0000120.0003120.0003240.0000140.0002630.0000130.0000140.0000121.9711081.2177481.8299494.9367021.6336920.0010602.4830365.1798060.9262160.0110330.5591120.1101110.0061640.0005840.0003820.0010260.0004080.0004680.0015040.0004200.0007080.0004920.1579103.0700640.0023150.0007010.0007430.0041920.0003380.9996550.0192120.0008420.0001840.0002210.0001800.0001865.4085052.1564532.2785642.9017553.2068082.8364811.9364203.4301180.0021680.0002370.0001390.0001030.0000700.0001630.0003910.0002100.0002060.0002440.0001330.0005040.0002760.0000930.0001660.0001070.0000620.0001230.0000140.0000100.0000110.0001420.0003610.0000830.0001980.0000120.0000110.0000110.0000570.1169210.0000750.0000110.0000130.0000150.0000150.0000110.0000120.0000110.0000120.0000110.0001010.0004502.3357170.0012470.0000130.0001820.0000990.0001990.0001990.0001430.0001530.0000580.0004050.0004090.0001320.0024700.0000120.0000100.0009430.0010721.8564590.0074973.7777755.4651912.0123854.3145621.4873800.0013560.0001480.0000670.0000710.0002810.0000110.0005180.0000140.0000110.0000110.0032870.1881760.0001240.0001710.0000380.0006331.3447511.0359520.0041070.0000182.1815720.6031821.0323800.0206290.0120890.0031140.0165220.0646720.0308740.0407810.0110170.0000210.4192050.0005620.0003220.0038441.6500851.9536312.3899613.9037592.3512730.3933190.4770672.0316272.4067391.7691612.4673710.0013700.0008320.4323611.8069260.0015240.0001560.0012200.0009030.1577170.0010290.0009580.0001390.0005130.0117450.0004160.0042670.0000240.0009770.0000130.0000170.0000130.0000150.0000110.0000160.0000120.0011431.1329380.0005870.0000110.0000150.0000170.0006840.0006051.4541260.5595920.0003060.0000180.0000590.0001730.0003610.0003680.0002020.0002050.0001770.0001710.0006740.0003660.0000870.0003640.0003990.0009711.5226710.0012040.0005960.0001070.0000500.0000110.0000620.0000120.0000120.0000880.0000960.0000960.0000500.0000960.0000120.0000130.0000141.9367961.4711151.2719134.3100223.2652601.2930691.7604010.0013900.0001125.0079533.0536750.0015210.0000700.8183980.0041090.0000253.0408561.8139770.0009190.0000310.1268650.0000760.0018970.0000160.0000260.0000193.8431600.0018850.0001110.0000190.0015680.0027120.0000140.0000130.0019020.0032760.0000170.0012260.0000420.0012520.0000162.2703340.3683950.4642120.3775220.0022090.0102370.4248920.1424240.9991661.7294070.0197740.1349590.0012700.0108771.4830540.0304500.0000420.0063830.0002751.5542212.3013711.4008494.8004890.0134420.7118493.8801701.5336091.2046432.1124791.7369150.0013410.0003972.6132760.0012570.5176940.0022100.0000420.0000162.3072390.0011080.0000170.0000182.2570070.2864572.4417761.9361481.7939900.0008650.0003852.2497623.4853140.0016562.1452781.7670391.9231091.7125581.4796390.0007811.8383043.1359401.6882361.3473165.2335860.0024711.4429760.4094510.2357500.0009703.0859340.0262320.1315190.0833430.1413460.4006260.0001990.0767311.1742860.0011010.0001320.6522070.0008710.0010060.0008690.0101870.0328342.3953601.0196650.8465710.0011050.0002930.0000150.0006100.0012620.9115230.0004390.0000760.0000110.0000920.0000620.0001060.0000450.0000950.0001070.0000472.0449750.0010250.4204910.0002850.0000100.0000140.0001500.0001590.0001450.0001410.0001930.0000620.0000720.0001040.0005540.0000150.0000130.0000130.0002890.0000180.0000111.0050810.0004700.0000160.0000170.0000100.0000170.0000110.0000110.5928250.0002850.0000200.3442160.0001670.0000120.0000460.7179280.0003370.0000140.0003040.0142320.0008380.0000410.0002250.0007190.0001880.1281870.0004081.1407670.0172740.0016070.0000170.0000330.0000610.0009300.0000240.0000730.0000780.0000150.0007860.0000190.8250380.0005990.0000170.0000300.0000130.0006400.0154330.0001000.0000191.6734090.0007690.0002430.0003020.0001940.0001570.0003600.0001140.0007552.1755770.0534120.0677870.0002632.1172414.0537148.5180746.0066001.6161710.0011860.0000460.0018230.0008600.0005380.0004510.0007340.0004240.3623670.0001921.8274511.3110910.0158631.0903240.0004912.0337410.0009090.0000110.0001720.0000872.9963370.0013241.7562421.3871591.7566580.0009080.0001210.0000766.1186402.0655282.9136220.0017432.8931900.0030730.0003500.0002940.0005650.0000170.0118101.9282250.0009570.0001730.0000770.0004960.0000100.0001302.3578840.0010330.0000530.0000110.8173640.0003640.0000500.0000130.0000112.2460470.0010860.0001310.0001290.0005800.0002220.0000190.0000130.0001610.0000340.0009450.0000750.0002140.0001250.0001730.0000840.0001450.0001150.0001130.0000600.0000810.0000120.0001120.0000280.0001640.0000150.0544410.0001874.7161260.0060720.0006491.2536410.0005472.0615480.0023790.0320150.0482400.0061360.4665710.0006630.0464680.0006640.0499901.6814950.9123391.3689743.6332210.0015981.3296580.0041330.0045361.6011990.0027110.0036124.1975386.0279205.7604871.0063120.4118910.0047870.0011430.0025430.0000280.0001390.0002500.0006330.0002500.0002800.0001961.1782640.0009700.0002090.0001130.0132720.0007220.0003700.0001430.0002790.0005390.0000140.0002640.0002350.0039170.0002180.0000990.0004240.0000132.1699830.0011200.000033

*******************************************
EVALUATING PIPELINE 
Pipeline directory: /home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_0c6bb2e8_2020-02-02_09-19-060hupu8cb/
With following parameter combination: {'batch_size_seq_length': 1, 'lr': 1e-05, 'lr_type': 'constant'}
EVALUATION OF CHECKPOINT /home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_0c6bb2e8_2020-02-02_09-19-060hupu8cb/outputs/checkpoint-3
-------------------------------------------------------------
|           |   agree   | disagree  |  discuss  | unrelated |
-------------------------------------------------------------
|   agree   |    448    |    41     |    131    |     6     |
-------------------------------------------------------------
| disagree  |    28     |    54     |    64     |     6     |
-------------------------------------------------------------
|  discuss  |    242    |    51     |   1559    |    48     |
-------------------------------------------------------------
| unrelated |    44     |    16     |    46     |   6838    |
-------------------------------------------------------------
Score: 7104.75 out of 7516.5	(94.5220514867292%)
Accuracy: 0.9248596965287882
F1 overall: 0.7050481004660463
F1 per class: [0.6455331412103746, 0.34394904458598724, 0.8427027027027028, 0.9880075133651206]
*******************************************


*******************************************
EVALUATING PIPELINE 
{'batch_size_seq_length': 4, 'lr': 1e-05, 'lr_type': 'cosine'}
INFO:__main__:Creating features from dataset file at /home/ubuntu/fnd_implementation/data/processed
  0%|                                                  | 0/9622 [00:00<?, ?it/s]  0%|                                        | 1/9622 [00:01<3:26:05,  1.29s/it] 21%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                             | 2001/9622 [00:01<1:54:16,  1.11it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9622/9622 [00:01<00:00, 6095.90it/s]
  ******************************************* 
              Running Evaluation                
  *******************************************
 
  Length dataset evaluation: 9622
  Length dataloader evaluation: 301
  Number of epochs: 3
  Batch size: 32
  ******************************************* 
 
['/home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_0fbd2562_2020-02-02_15-09-01bq808q18/outputs/checkpoint-3']
INFO:__main__:Evaluate the following checkpoints: ['/home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_0fbd2562_2020-02-02_15-09-01bq808q18/outputs/checkpoint-3']
INFO:transformers.configuration_utils:loading configuration file /home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_0fbd2562_2020-02-02_15-09-01bq808q18/outputs/checkpoint-3/config.json
INFO:transformers.configuration_utils:Model config {
  "architectures": [
    "AlbertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "down_scale_factor": 1,
  "embedding_size": 128,
  "finetuning_task": null,
  "gap_size": 0,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "inner_group_num": 1,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "net_structure_type": 0,
  "num_attention_heads": 12,
  "num_hidden_groups": 1,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "num_memory_blocks": 0,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 30000
}

INFO:transformers.modeling_utils:loading weights file /home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_0fbd2562_2020-02-02_15-09-01bq808q18/outputs/checkpoint-3/pytorch_model.bin
HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=301.0, style=ProgressStyle(description_width='initial')), HTML(value='')))
0.0097600.0112100.0160120.2450800.2852780.1788170.1611200.0408510.0278260.0060200.0218290.0988500.0941360.1010270.2169900.0169740.2701770.0753050.1576550.4238940.1206870.3295180.1790560.4682470.2007480.0737340.0053000.0020140.1562820.0997710.0126290.2344800.1528230.3485400.1713750.0059820.1462320.1200010.2045880.0920550.1633450.1724080.1119560.0041480.0016100.0026230.0024540.0024790.2251120.0298470.0023460.1869530.4844690.1591620.0064640.2916220.1986600.0060060.2215990.4648540.7018110.2759130.0089880.0060140.2709320.0879990.1196390.2081070.3345150.0608660.0468690.0034900.2681060.1221210.3293770.1764380.5015690.1696190.1332900.0115040.1791310.2435030.0494950.2355760.0728260.0718220.0806570.0302950.0306470.2624950.2257671.0792290.3708460.1287460.3804860.1822980.0165740.0149710.1408300.2486570.4621740.1391660.3280500.0672320.2478690.0929350.0293530.0080160.0709920.0042100.2958280.1778970.2220160.2461940.0566430.3167970.0708210.0156270.0022870.2514850.1578050.1321371.2827230.0136210.1589000.0130060.0589350.3393400.3523190.1805810.1686780.2742700.3350370.0362250.2365930.7754710.1933040.1754110.1155880.0795200.0328010.0293360.0017920.4428880.4992530.1266360.4469380.2219780.0982080.0978960.2244730.1467820.9448230.1755200.0122220.1963470.0182090.0413800.0360740.5018231.4391430.2049460.1428250.0943470.8573570.0869310.2118610.0770410.2135400.6546560.1394980.0648260.0132030.0060450.5764810.3584951.0983760.0950700.1880380.1552520.4792442.9342350.7652490.2739710.2592010.2501940.1532350.6853620.8855470.3725310.1425540.0674480.0466110.3131970.3499460.1463560.1611270.3715490.4410930.7032100.8663540.2048460.0858861.3180920.5961520.1037810.1577100.6377470.9285990.7578330.1660640.1539130.0179410.4087870.6268290.0107070.0096560.0254060.0581850.0035060.0087840.0090420.2050890.0539040.0141830.4779720.5126180.1962060.4102420.0465590.4569810.1236030.0568510.0090120.0498360.0037630.3716060.0119200.7450610.0439780.0761310.4354820.5836640.3820401.0105350.1556570.3184010.0071440.0622390.1356320.0727860.1724220.0717410.1949601.2947360.9279270.4563700.0697200.4021950.5876810.5295850.9626670.4018920.1717360.7125410.3103280.4780060.3495330.6155680.1910660.1360270.0219350.0418170.0179670.0870570.0554700.0988100.0605620.0046620.1038340.3154701.0909270.8184290.1647450.2262320.2393740.8629220.2239960.2556280.1118970.0068420.0118300.0879940.7119700.3732500.5650610.8930830.0193850.1049640.0178750.182003

*******************************************
EVALUATING PIPELINE 
Pipeline directory: /home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_0fbd2562_2020-02-02_15-09-01bq808q18/
With following parameter combination: {'batch_size_seq_length': 4, 'lr': 1e-05, 'lr_type': 'cosine'}
EVALUATION OF CHECKPOINT /home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_0fbd2562_2020-02-02_15-09-01bq808q18/outputs/checkpoint-3
-------------------------------------------------------------
|           |   agree   | disagree  |  discuss  | unrelated |
-------------------------------------------------------------
|   agree   |    483    |    72     |    246    |    14     |
-------------------------------------------------------------
| disagree  |     2     |    13     |     6     |     0     |
-------------------------------------------------------------
|  discuss  |    244    |    68     |   1456    |    74     |
-------------------------------------------------------------
| unrelated |    33     |     9     |    92     |   6810    |
-------------------------------------------------------------
Score: 6977.5 out of 7516.5	(92.82910929288897%)
Accuracy: 0.9106214924132197
F1 overall: 0.6345386309995744
F1 per class: [0.6125554850982878, 0.14207650273224043, 0.7995606809445359, 0.9839618552232337]
*******************************************


*******************************************
EVALUATING PIPELINE 
{'batch_size_seq_length': 4, 'lr': 1e-05, 'lr_type': 'constant'}
INFO:__main__:Creating features from dataset file at /home/ubuntu/fnd_implementation/data/processed
  0%|                                                  | 0/9622 [00:00<?, ?it/s]  0%|                                        | 1/9622 [00:02<6:10:06,  2.31s/it]  5%|â–ˆâ–‰                                    | 501/9622 [00:02<4:05:37,  1.62s/it] 21%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                             | 2001/9622 [00:02<2:23:40,  1.13s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9622/9622 [00:02<00:00, 3393.48it/s]
  ******************************************* 
              Running Evaluation                
  *******************************************
 
  Length dataset evaluation: 9622
  Length dataloader evaluation: 301
  Number of epochs: 3
  Batch size: 32
  ******************************************* 
 
['/home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_0d5a1d52_2020-02-02_10-44-062m6rinje/outputs/checkpoint-3']
INFO:__main__:Evaluate the following checkpoints: ['/home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_0d5a1d52_2020-02-02_10-44-062m6rinje/outputs/checkpoint-3']
INFO:transformers.configuration_utils:loading configuration file /home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_0d5a1d52_2020-02-02_10-44-062m6rinje/outputs/checkpoint-3/config.json
INFO:transformers.configuration_utils:Model config {
  "architectures": [
    "AlbertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "down_scale_factor": 1,
  "embedding_size": 128,
  "finetuning_task": null,
  "gap_size": 0,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "inner_group_num": 1,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "net_structure_type": 0,
  "num_attention_heads": 12,
  "num_hidden_groups": 1,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "num_memory_blocks": 0,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 30000
}

INFO:transformers.modeling_utils:loading weights file /home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_0d5a1d52_2020-02-02_10-44-062m6rinje/outputs/checkpoint-3/pytorch_model.bin
HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=301.0, style=ProgressStyle(description_width='initial')), HTML(value='')))
0.0031660.0037710.0032080.2817080.2615060.2200090.1663190.0302180.0135340.0021480.1496170.0259380.0740060.0513090.1871420.0131450.1030690.0417760.1410940.3690430.0324610.5038660.2144620.8232730.1921800.1500220.0066690.0010190.0343720.0392130.0028730.1934150.2220100.2680960.3167900.0094790.3083120.1501230.1462040.0231180.0984460.2682970.1608570.0043310.0006520.0011510.0019500.0008650.2209570.0384060.0025630.1451230.1808980.0920540.0069290.2720520.1922110.0058350.2078790.1159870.4593280.3727630.0072150.0013920.1045830.0143630.1546700.2655190.2786500.0630160.0966420.0021730.2844030.0958020.3942780.2225870.4507930.3477610.1781060.0235700.2325130.2941430.0690550.3378130.0583870.1024170.0109270.0455470.0067010.2522520.1642111.2726510.3649970.2748520.2962520.1638620.0051270.0036490.0762150.1616340.5309230.1911510.5830230.0982510.4134830.3541790.0182700.0017960.0736890.0023760.4088390.1691100.2771590.7463880.1272770.2371270.0152740.0025890.0008030.2589380.2275670.1701151.7596470.0151590.1024080.0148920.0541890.3873810.3138020.2183450.2104430.1718660.3368980.0605640.2747631.2872050.8087330.8036480.3987070.6041910.1162580.0258750.0008130.7514670.7110110.1444460.6166750.2195800.1545680.0789910.2515730.0040090.6332230.0606400.0125270.0923200.0074520.0973740.0051080.3649621.1353550.0427890.1314070.0084811.2425400.1281980.1719560.1453220.1405020.5432610.1223360.0349790.0328640.0221550.7098620.9790371.6389090.0849030.0249120.0338010.4241682.7802090.2162320.1670970.2025190.1839390.0224540.2205070.1847730.3518230.0274110.0063960.0368840.3883991.2001270.5525530.2778830.3867520.5306541.0607770.9336530.0823740.1399751.5956440.4124360.1115700.1021920.9559200.5676280.8845670.1898210.0107580.0059360.2836130.4482620.0038090.0023170.0020210.0325200.0013610.0016940.0098660.2362870.0867260.0210760.4654970.8885730.2373520.3746860.2038971.0400530.0215930.0522110.0012810.0062190.0042680.4044480.0163011.2631070.1814940.0620880.3967110.4614910.4757191.3861050.9117640.7210010.0057520.0539380.0737390.2067620.5242590.0094680.5183511.4020320.9361130.4570460.1495670.6629552.3720360.3961451.1744920.5320470.0737830.7493080.1366430.5645570.7698420.5708480.2634740.1458410.0135230.0554600.0221060.0524820.0289430.1069390.0923840.0028600.0908970.3520310.9680091.3317990.1659120.3208700.6290161.4665920.1373690.2890860.1985610.0030100.0123980.1205730.8113780.4571310.6154901.8631540.0124840.0445560.0146480.167586

*******************************************
EVALUATING PIPELINE 
Pipeline directory: /home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_0d5a1d52_2020-02-02_10-44-062m6rinje/
With following parameter combination: {'batch_size_seq_length': 4, 'lr': 1e-05, 'lr_type': 'constant'}
EVALUATION OF CHECKPOINT /home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_0d5a1d52_2020-02-02_10-44-062m6rinje/outputs/checkpoint-3
-------------------------------------------------------------
|           |   agree   | disagree  |  discuss  | unrelated |
-------------------------------------------------------------
|   agree   |    331    |    62     |    78     |    11     |
-------------------------------------------------------------
| disagree  |    12     |    22     |    31     |     2     |
-------------------------------------------------------------
|  discuss  |    385    |    69     |   1607    |    68     |
-------------------------------------------------------------
| unrelated |    34     |     9     |    84     |   6817    |
-------------------------------------------------------------
Score: 7066.5 out of 7516.5	(94.01317102374776%)
Accuracy: 0.9121804198711286
F1 overall: 0.6318218002414313
F1 per class: [0.5321543408360129, 0.19213973799126638, 0.8180198523797404, 0.9849732697587054]
*******************************************


*******************************************
EVALUATING PIPELINE 
{'batch_size_seq_length': 1, 'lr': 1e-05, 'lr_type': 'linear'}
INFO:__main__:Creating features from dataset file at /home/ubuntu/fnd_implementation/data/processed
  0%|                                                  | 0/9622 [00:00<?, ?it/s]  0%|                                        | 1/9622 [00:01<4:56:02,  1.85s/it] 21%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                             | 2001/9622 [00:02<2:44:09,  1.29s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9622/9622 [00:02<00:00, 4429.58it/s]
  ******************************************* 
              Running Evaluation                
  *******************************************
 
  Length dataset evaluation: 9622
  Length dataloader evaluation: 2406
  Number of epochs: 3
  Batch size: 4
  ******************************************* 
 
['/home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_0d5a1d53_2020-02-02_11-14-02sum7sgrs/outputs/checkpoint-3']
INFO:__main__:Evaluate the following checkpoints: ['/home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_0d5a1d53_2020-02-02_11-14-02sum7sgrs/outputs/checkpoint-3']
INFO:transformers.configuration_utils:loading configuration file /home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_0d5a1d53_2020-02-02_11-14-02sum7sgrs/outputs/checkpoint-3/config.json
INFO:transformers.configuration_utils:Model config {
  "architectures": [
    "AlbertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "down_scale_factor": 1,
  "embedding_size": 128,
  "finetuning_task": null,
  "gap_size": 0,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "inner_group_num": 1,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "net_structure_type": 0,
  "num_attention_heads": 12,
  "num_hidden_groups": 1,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "num_memory_blocks": 0,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 30000
}

INFO:transformers.modeling_utils:loading weights file /home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_0d5a1d53_2020-02-02_11-14-02sum7sgrs/outputs/checkpoint-3/pytorch_model.bin
HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=2406.0, style=ProgressStyle(description_width='initial')), HTML(value='')))
0.0005330.0005880.0003130.0001310.0000560.0000320.0000320.0000360.0000220.0000250.0000200.0000410.0000230.0000400.0000260.0000240.0000310.0000230.0000200.0000970.0000690.0000330.0063940.0003030.0000861.9411880.0746850.0027852.1773470.0751300.0025240.0001000.0005700.0006250.0000410.0000200.0001850.0000241.8325130.0475590.0109240.0008610.0000390.0000190.1689670.0037730.0006190.0000400.0015010.0000491.9525310.0391550.0007710.0000340.0000350.0000340.0000220.0001940.0000540.0001240.0003620.0001930.0000490.0000350.0000300.0135510.7599410.0113661.5925531.8516651.5643060.0248770.0004871.2544750.0170180.0002510.0000300.0000220.0000520.0000331.7888991.3406160.9595580.0115860.0001730.0001040.0001400.0000660.0000940.0179200.0218560.0002940.0002020.0000480.0004460.0000230.0006960.0003910.0000750.0000240.0000770.0001320.0002070.0007110.0002460.0000530.0000470.0000301.8837680.0174170.0001810.0000310.0000210.0000200.0000221.5196370.0131200.0002200.0000340.0000230.0000200.0000460.0000190.0000200.0000210.0000500.0000230.0000240.0000200.0000220.0000260.0000250.0001260.0009051.9915260.0152140.0001342.1336050.0155580.0003132.1358070.0151960.0002440.0000550.0003510.0000300.0000200.0000292.0450490.0143832.5227910.0167302.2913810.6608651.7653410.0114160.0001400.0000470.0000790.0000860.0000510.0001000.0001100.0000390.0000450.0003330.0000380.0000220.0000190.0002120.0000741.8024371.4253851.6834090.0111650.3868650.0022850.0002560.0002330.0001710.0000690.0000342.2564700.0123490.0002250.0000234.6783082.5398750.0135310.0000940.0637121.2247320.2382932.0507301.7296740.0089040.0000830.0000200.0000430.0000340.0000761.4913620.0074180.0001130.0001020.0000240.0000880.0013990.0000500.0066640.0002740.0044990.0000420.0000270.0011000.0000280.0000500.0000200.0001080.0000210.0000380.0000220.0000490.0000200.0000820.0000200.0000370.1428270.0006440.0000290.6032580.0026580.3940370.0017080.0018260.0000260.0000550.0000180.0000200.0000640.0000180.0000200.0000240.0006680.0000210.0000170.0000190.0000190.0000181.9162100.0076840.0000480.5393320.0067210.0000560.0000461.7718372.0618040.0080380.0002260.0002410.0003360.0000200.0000420.0123551.3850871.6595450.0062330.0000620.0000180.0000210.0000180.0000170.0003540.0000532.1267131.4318990.0051890.0000470.0000170.0000170.0000170.0000230.0000250.0000230.0000210.0000840.0000160.0000181.6496460.0057131.3080730.0045290.0000340.0000161.6421650.8234580.0031700.0000270.0000160.0000161.6959931.6303860.0053970.0000340.2878330.0404690.0001540.0000280.0000540.0000200.0000240.0000220.0000210.0000220.0000180.0000180.0000200.0009230.0000260.0000321.8190680.0056710.0096960.0000490.0000820.0000180.0000200.0000610.0007042.4935460.0075860.0000410.0006540.0000590.0001010.0000510.0000470.0000290.0000730.0000532.0214230.0059290.0002780.0000200.0000180.0000360.0000190.0000180.0000220.0000190.0000280.0000190.0000680.0000180.0000180.0000210.0000190.0000190.0000790.0000240.0000180.0000210.0000180.0000180.0000200.0000360.0000620.0000200.0000170.0000200.0000180.0000180.0000470.0000200.0000180.0000210.0000180.0000180.0000200.0000190.0000190.0000610.0000191.5842470.0045610.0000340.0000880.0005760.0004530.0000331.8652340.0047820.0000600.0053960.0006740.0002780.0000440.0000290.0000230.0000350.0000170.0000420.0000200.0000400.0000260.0001140.0002940.0006490.0001370.0004840.0000250.0001440.0000511.2639860.0030740.0000281.3142710.0043880.0000290.0014211.3598830.0032990.0213431.3502220.0031970.0001350.0000170.0000180.0000170.0000250.0000190.0000180.0000960.0000300.0000180.0000990.0000260.0000390.0000200.0000170.0000420.0001500.0000281.5060800.0049080.0003530.0000190.0001760.0000332.4236560.0054890.0001100.0000320.0000270.0000810.0000230.0000250.0000220.0000200.0000200.0000330.0000180.0001470.0002170.0002230.0000210.0010070.0003260.0001081.0531040.0049390.0001870.0006160.0002780.0000810.0023060.0004380.0000440.0000330.0000201.5575620.0034320.0299830.4011252.2492380.0065093.1099203.9813842.0003723.4691521.0540950.0025230.0001220.0000230.0000170.0000910.0000180.0000180.0000180.0000190.0000900.0001200.0000180.0000190.0000190.0000170.0000180.0001290.0000180.0000180.7548960.0015390.0004540.0004490.0000190.0000190.3153990.0006761.1599540.0022480.0001060.0012020.0001890.0000210.0144960.0000450.0000482.4864880.0047200.5710200.0010990.0000310.0000900.0001452.6819790.0052680.7755230.0033781.6518260.0030790.0000260.1305350.0003720.0000220.7719331.1474401.1094482.1291470.0039370.7851310.0014440.0000201.8888600.0035550.0004240.7181991.7927870.3555420.0006590.0000200.0001010.0000200.0015970.0000630.0000690.0000400.0000190.0000210.0000190.0000350.0000670.0000540.0000190.0000440.0000210.0027380.0000250.0009361.5811530.0027440.2752820.0007090.0000250.0618800.0001260.1934670.0003970.0077590.0002640.0003300.0002290.0002540.0000250.0002070.0049160.0000460.0001830.0000622.3302810.0039600.0000730.0026960.0009370.0009730.0006270.0003830.0012430.0001260.0002060.0145681.4807880.2502290.0013471.1160520.9753200.0016460.0000500.0000430.0000602.2304571.6638810.0026931.1563460.0019000.0000210.0000540.0000171.9389330.0031000.0000570.0000180.0000170.0000520.0000170.0002930.0000191.0397080.0016860.0000210.0006160.5151471.1135890.0028360.0001630.0001630.0003050.0000261.7648020.0027430.0001580.0001530.0000220.0001580.0000620.0000510.0000810.0001010.0001610.0001430.0000860.0000540.0000980.0001770.0001500.0000270.0005190.0000200.0264800.0000560.0001230.0000680.0000160.0000180.0000180.0000600.0032800.0002590.0002590.0001180.0000370.0000190.0000240.0000180.0000210.0000220.0000260.0004850.0000640.0000190.0001270.0000220.0000390.0000210.0000410.0000310.0003860.0000210.0020620.0004430.0000350.0002050.0000200.0000620.0000950.0001250.0000350.0006420.0002840.0000470.0002920.0002430.0000330.0295560.0000630.0003130.0000281.1837350.0016810.0000331.8280661.5967590.0022370.0000380.0001030.0000200.0001700.0000600.9269363.1140781.6803640.0048780.0002890.0003214.0252900.0055650.0000360.0000570.0000670.0062360.0001420.0000700.0192172.6642820.0036732.3492910.0032920.0003570.0000573.8300820.0052190.0000263.4235451.8031711.9519080.0026103.5081240.0046610.0000420.0000213.5938510.0047440.0000360.0000620.0000280.0012390.0000230.0000210.0000700.0000230.0001230.0001310.0001370.0001230.0001190.0001220.0000480.0004880.0000180.0000180.0000530.0000170.0000190.0000180.0000200.0000940.0000630.1168830.0002400.0001260.0000760.0000830.0000310.0001430.0001630.0000930.0001290.0004910.0108510.0775100.0011210.5071062.2673290.0029450.0000220.0012590.0058210.0000660.0000250.0121500.0000420.0000500.1678070.0003470.0000220.7922700.0009931.9116620.0025010.0000230.0000581.9897733.8022005.3990340.0065720.5218440.0006520.0008630.0000190.0010970.0006300.0000520.0001180.0001101.5925940.0020502.3085510.0027752.1132082.1574380.0025852.2413120.0026820.0000200.0000170.0000350.0000730.0000590.0000330.0000750.0001140.0000260.0000200.0000190.0035870.0005150.0008440.0000210.0000190.0000170.0000180.0000180.0000180.0000181.0984500.0012880.0000200.0000190.0000180.0000190.0000190.0000180.0000190.0000190.0000190.0000190.0000170.0000190.0000170.0003250.0000180.0309150.0012840.0003860.0001350.0000201.3577090.0144470.0001670.0001440.0000420.0000180.0000621.7794621.8132360.0020451.6707750.0018880.0061250.0002200.0029320.0004150.0003030.0001440.0001030.0035100.0000210.2259450.0009606.6213894.6143990.0061070.0000420.0001130.2335620.0003730.0000801.3174780.0017940.0000780.0002720.0002010.0005710.0006701.2750920.0014990.0002190.0004371.6595670.7449741.0883200.0012960.0000200.0001950.0014700.3742350.0005431.0324390.0011510.0007320.0000190.0000230.0002730.0000190.0000200.0000190.0000180.0000830.0000190.0000200.0000180.0000180.0000210.0000220.0000660.0000231.5807860.0016770.0000202.1266450.0023240.0000522.2782520.0023870.0000200.0004580.0000380.0006160.0000310.0000160.0000200.0004830.0000190.0000260.0001332.4452733.8128802.8552442.1889185.9309044.3275915.6102870.0075560.0006740.0000480.0000170.0000180.0000170.0000170.0000200.0000180.0000160.0000190.0001310.0000180.0000240.0000850.0000820.0000160.0004100.0000420.0000180.0009400.0000180.0001230.0000300.0000540.0000190.0002320.0004050.0000280.0000250.0002430.0004160.0000430.0003000.0000340.0000181.7425050.0017280.0000520.0128960.0000664.5023202.4469810.0034600.0000200.0000170.0000171.4598610.0016600.0002570.0002740.0006660.0027970.2368810.1728330.3481730.0004000.0002160.0002610.0002750.0000230.0108680.0001050.0017440.0000260.0001160.0000261.2035060.0114060.0000290.5500070.6852190.0006700.0000170.0000170.0268530.0000430.0026870.0015200.9592261.5788060.0015040.0000280.0030780.0000680.0000300.0008630.0000190.0000270.0012850.0001680.0000250.0010840.0000181.6698490.1236560.0001381.1298201.3305233.6545162.1913350.0034955.5616201.5707940.0021610.0001730.0000260.0747950.0003700.0016300.0003620.0004110.0000530.0001190.0592160.0047891.2555840.0014750.0005070.0008990.0001540.0003940.0008770.0000870.0000210.0002440.0002280.0001992.0258990.0019410.0000190.0000170.0000210.0000252.1282991.9572534.1666910.0037790.0000310.0000590.0000180.0000312.0379520.0018290.0000210.0000210.0000210.0003990.0000200.0000210.0004560.0000200.0002780.0002910.0000200.0000580.0000170.0000180.0000180.0002970.0000200.0000210.0000190.0006640.0012401.3307450.0059920.0194881.4139390.0021020.0001490.0005570.0006310.0000923.7521382.0861953.1436000.0031400.0000882.2049350.6314230.0006200.0000470.0000190.0000280.0000330.0000200.0000490.0000184.4897940.0038841.2647350.0011500.0246130.0002400.0000211.5880600.0013711.6625340.0014421.5135010.0012980.0003320.0000870.0000260.0000180.0000240.0000170.0000190.0000220.0006760.0000180.0000180.0000220.0000621.3440040.0011400.0005110.0000200.0000510.0000211.2208620.1054611.4353593.5824390.0029970.0000280.0000180.0000211.8559750.5318610.0004620.0000530.0001650.0000970.0002180.0005096.3751505.4389343.3489530.0028280.0012490.0000890.0004840.2163200.0012070.0000321.2962090.0014370.0000220.0002310.0000200.0000240.0000240.0000420.0000220.5051020.0004710.0000211.2388940.0025730.0014610.0000590.0000200.0249230.0000510.7282430.0006180.0000260.0000320.0000610.1556520.0001640.0000630.0026750.0000361.1281200.0010280.0000470.0003840.0000310.0001740.0000830.0000340.0000960.0000190.0000270.0002580.0000190.0001600.0002620.0000190.0045200.0000250.0000384.8470754.7516395.2573913.4209413.3264232.7874155.0473351.8643162.9332851.2176981.7199860.0015450.0012480.0005670.0015940.0011130.0008560.0001180.0001270.0001390.0001562.5948400.0021430.0001780.0001970.0006820.0000580.0001860.0001990.0002100.0002010.0001640.0001280.0001382.0437003.6010521.7966974.0630581.9542280.0019380.0000190.0000180.0000180.0000180.0050270.0000210.0000180.0001330.0006530.0000180.0011340.0007150.0007760.0009520.0471080.0014680.0012210.0009980.0000190.0013200.0018330.0002400.0000260.0003090.0002310.0000240.0001010.0006330.0991740.0003560.0000510.0000211.5954270.0014240.0000790.0000530.0000240.0001330.0000200.2683490.3107130.0685090.0295010.0415960.0000510.0001490.0000230.0011810.0065770.0000450.0023570.0000700.0003110.0000250.0000390.0000730.0000340.0000300.9685000.0007830.0006770.0000250.8473760.0006510.0000300.0002980.0002770.0016010.0000280.0000750.0002670.0000490.0000412.0187670.0014880.0001330.0001130.2958550.0643440.0012650.9550752.0797850.0020002.1295380.0015930.0000470.0001090.0001380.0000470.6882462.1922655.8678954.4598682.7422274.2180700.0032610.0004970.0003470.0004730.0000180.0003630.0000190.0003480.0000390.1307600.0005160.0000190.0006250.0001530.0000920.0001140.0001110.0000781.7918910.0013550.0001060.0001180.0001190.0907150.0001500.0001110.0008430.0082960.0029951.7857020.0013690.0077070.0005892.9029035.0760520.0085270.0002710.0001180.0010860.0001830.0001830.0002270.0022740.0000243.5510243.7527091.5347730.0317081.1145661.8224151.6636983.2782755.3900930.0038920.0001900.0001690.0001740.0001440.0001280.0000330.0001942.1448820.0014862.9514620.0020220.0000220.0000781.6625060.0012170.0000190.9128620.0006342.8199781.5572120.0010690.2462520.0001850.0003020.0000230.0000281.8593870.0013510.0001683.6061153.7000033.8065130.8862971.7541863.7577323.7389453.6823273.6516953.7146911.7552913.3965941.5097730.0990983.3827423.3873830.0023141.4313831.7655280.0013211.6291981.9415180.0013920.0001280.0001420.0001850.0001220.0001320.0001660.0000890.0001421.8127491.4576250.0010530.0001060.0000170.3919400.0003810.0000180.0000770.0000220.0000220.0000160.0000200.0000190.0000760.0000910.0043610.0000252.1098930.0013882.0150800.0013320.0001980.0001100.0002900.1416071.7214330.0011870.0813982.0690261.0391780.0016990.0008630.0001560.0000350.0039810.0005960.0003040.0000540.0000320.0005720.0006770.0001121.8923650.0012981.8229500.0012390.0003050.0001220.0000590.0001212.0554820.0014010.0016270.0010150.0002250.3982780.0588560.5384870.0006670.0000482.2902370.0015360.0000682.4210600.0016142.5732434.7617520.0033462.3290302.3720330.0015372.0590170.0013438.9173080.5917071.4983852.4324831.3927420.5168431.7624640.0011740.0001310.0000170.0000860.0001790.0002430.0000171.5310170.0011900.0002780.0000180.0000590.0000490.0000510.0000202.3427360.0014634.3900682.3816850.0018632.1707271.9302703.9520675.3268435.5356484.5287374.6605420.0029640.0000620.0000700.0001380.0001140.0000220.0000870.0000420.0000510.0000190.0000200.0000191.6772620.0010400.0000502.1264630.0013070.0000230.0000170.0000240.0000200.0195030.9119711.6379030.0100870.0976751.8971500.0011750.0000920.0000410.0000321.4710331.0483635.4102202.5205650.8956413.8851811.9340475.3882505.6915773.8910990.0023420.0000220.0004071.9597290.0011851.8409780.0011150.0000190.0009111.4684420.0009060.0000180.0000200.0000320.0000260.0000180.0004380.0009230.0013280.0007481.3215480.0008740.0001260.0000560.0001200.0001070.0000930.0000800.0001280.0000270.0001510.0000590.0001111.2289924.3836861.1101550.0012941.1083350.2007360.0007650.2367200.7553251.1582780.0020460.0000410.0000180.0000210.0000980.0000240.0000840.0000760.0000830.0000950.0001310.0001050.0000910.0001300.0000550.0000750.0000460.0000490.0000180.0000620.0000250.0000200.0000670.0000710.0000840.0000480.0000700.0000490.0000500.0000510.0000190.0000750.0000441.6463740.0009640.0000270.0000680.0000750.0000190.0000690.0000210.0000230.0000190.0000650.0000200.0000310.0001060.0000570.0000210.0001270.0000200.0000500.0018860.0000210.0000960.0000240.0000190.0000750.0009060.0000490.0000471.9883550.0011440.0000170.0009690.0000260.0000210.0000180.0000190.0000170.0003020.0000200.0006980.0000180.0000180.0000180.0000170.0003940.0002930.0000180.0002580.0000180.0000200.0000162.2206152.1359402.1879887.6581992.2104710.0013030.0001560.0371530.0014860.0054721.5630352.5619580.0017830.0003000.0003250.0006750.0002310.0003210.0014790.0002720.0003320.0004740.0460851.9412880.0014720.0000310.0005120.0005420.0002361.9693860.0011820.0001270.0001200.0001300.0001260.0002115.7250661.9023081.0245595.7687731.3374711.5939923.5870032.8800700.0017690.0001860.0001510.0001240.0000730.0001600.0002230.0001130.0001570.0001980.0000970.0001830.0002080.0000980.0002990.0000950.0001710.0000560.0000190.0000170.0000170.0000530.0001060.0001990.0000580.0000180.0000170.0000170.0002061.4046490.0007710.0000180.0000180.0000200.0000340.0000180.0000190.0000170.0000180.0000170.0000490.0000473.2351230.0017290.0000230.0000770.0000490.0001140.0001470.0001630.0000790.0000490.0001090.0001300.0000710.0001010.0000170.0000170.0003550.0003381.9319250.0100674.0269576.2917242.2528035.8775821.3749050.0010100.0001930.0000710.0000810.0000880.0000190.0002430.0000180.0000200.0000190.0000810.0060530.0000580.0000970.0001080.0000952.5490420.3576370.0019180.0000232.7094650.0047710.0030810.0020640.0113760.0021510.0736190.0039960.0061570.0016970.0060180.0000210.0028610.0001430.0002050.0004042.4808882.4800241.0220555.0086502.5154010.0022422.8105430.0041564.0738550.0039721.8415430.0010640.0005650.0007350.6449180.0007570.0002410.0007700.0006060.0106210.0007150.0013430.0003130.2282970.0005030.0002650.0003350.0000230.0003400.0000190.0000180.0000170.0000210.0000190.0000180.0000160.0005641.5339790.0007930.0000170.0000190.0000180.0002930.0005041.5177120.0313310.0000520.0000230.0000750.0002260.0004590.0004660.0005210.0003090.0003070.0002150.0006150.0005320.0001130.0004650.0004120.0009761.6178270.0012530.0003940.0000540.0000590.0000190.0000930.0000200.0000190.0001100.0001350.0001300.0016890.0002030.0000190.0000200.0000201.7738370.9586520.3315483.2542681.6075340.2207830.5896610.0006690.0002294.1049622.8718820.0014290.0000312.2342910.1967490.0001223.0526902.7228630.0013700.0000241.9312110.0009630.0003560.0000410.0000520.0000352.5424520.0012610.0008920.0000240.0011810.0004650.0000200.0000330.0008130.0003620.0000320.0004000.0002840.0004510.0000294.4327074.0667960.0023953.2579122.1003250.0012444.1652934.3129211.5432330.0028010.0164531.3391490.0016640.0016592.2878470.0044500.0000490.1655000.0001880.3613582.2708632.9902374.7155901.3170580.1325314.3341930.9544122.0593822.3049092.0645200.0012450.0002090.7399750.0003730.0002880.0002330.0000390.0000841.0270220.0005100.0000190.0000340.0003660.0002381.8792491.3873231.5065030.0007500.0002420.4207251.0178130.0004982.2423611.2166630.0317090.0001880.0019760.0000700.0060302.2161470.8688791.4398043.0935000.0014730.2201271.1473470.0361480.0011560.3331910.0043421.9062410.1195680.0001080.0003530.0000181.8331391.3048580.0008870.0000914.0620480.0024291.7544370.0021650.0003490.0005191.3334080.0024160.0003040.0002630.0002610.0000250.0006340.0007531.4257460.0006780.0000450.0000180.0000820.0000410.0000980.0000460.0000810.0000720.0000490.2914470.0002132.4794480.0012780.0000180.0000430.0006230.0001480.0001150.0001800.0001510.0000800.0000980.0000920.0004490.0000190.0000200.0000190.0003640.0000340.0000180.0014500.0000220.0000250.0000260.0000200.0000270.0000220.0000300.0016660.0000190.0000310.0005990.0000190.0000170.0000320.3212970.0001630.0000210.0001160.0001410.0005640.0000410.0002630.0003840.0000980.0006340.0000501.7266230.0019730.0003040.0000340.0000440.0000730.0002770.0000400.0000470.0000730.0000190.0007310.0000201.6223720.0008180.0000210.0000210.0000180.0020160.0006730.0000320.0000201.9162910.0008790.0004240.0004460.0004040.0001710.0009490.0002290.0032662.1433150.9704170.0027721.9782140.0027680.1175951.3279420.9314650.9234510.0009810.0000690.0022260.0007170.0007840.0007880.0007440.0003821.6518040.0007881.7812471.7313880.0010161.6675470.0007661.9897770.0008970.0000200.0002040.0000760.1034730.0000781.8630282.1968120.0022480.0001590.0006210.0000574.5526222.0278461.2766780.0006734.2923450.0028200.0011060.0107523.1000740.0015250.0147601.6265881.1706190.0010530.0001212.2312450.0009860.0069692.0979860.0009280.0000700.0000210.0242740.0000300.0000610.0000210.0000202.0624940.0009830.0004910.0000730.0002490.0003570.0000220.0000210.0001850.0000300.0000610.0000490.0001840.0001710.0001450.0002640.0001260.0006770.0000720.0000580.0001400.0000180.0002510.0000370.0002750.0000200.0017210.0001121.1407810.0025330.9101930.0020060.0000181.4364970.1460970.0091630.0097540.0032760.0269190.0002050.0131700.0098530.0116671.3084990.7717871.0009312.5645850.6157341.5915861.7193730.0023360.8512910.0020520.0019502.5418554.9742985.9977670.4978740.0003860.0002850.0001670.0001040.0000270.0000770.0000660.0000520.0001470.0001080.0000500.3826070.0002680.0000870.0000640.0002650.6285400.0003830.0000890.3609940.0007010.0000220.0029050.0002110.0005100.0002420.0000240.0003960.0000192.4369700.0012380.000029

*******************************************
EVALUATING PIPELINE 
Pipeline directory: /home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_0d5a1d53_2020-02-02_11-14-02sum7sgrs/
With following parameter combination: {'batch_size_seq_length': 1, 'lr': 1e-05, 'lr_type': 'linear'}
EVALUATION OF CHECKPOINT /home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_0d5a1d53_2020-02-02_11-14-02sum7sgrs/outputs/checkpoint-3
-------------------------------------------------------------
|           |   agree   | disagree  |  discuss  | unrelated |
-------------------------------------------------------------
|   agree   |    528    |    60     |    174    |    24     |
-------------------------------------------------------------
| disagree  |    20     |    48     |    19     |     3     |
-------------------------------------------------------------
|  discuss  |    184    |    41     |   1563    |    55     |
-------------------------------------------------------------
| unrelated |    30     |    13     |    44     |   6816    |
-------------------------------------------------------------
Score: 7111.5 out of 7516.5	(94.61185392137298%)
Accuracy: 0.9306796923716483
F1 overall: 0.7272403577091915
F1 per class: [0.6821705426356589, 0.38095238095238093, 0.8580839967060115, 0.9877545105427143]
*******************************************


*******************************************
EVALUATING PIPELINE 
{'batch_size_seq_length': 2, 'lr': 1e-05, 'lr_type': 'cosine'}
INFO:__main__:Creating features from dataset file at /home/ubuntu/fnd_implementation/data/processed
  0%|                                                  | 0/9622 [00:00<?, ?it/s]  0%|                                        | 1/9622 [00:01<3:15:38,  1.22s/it]  5%|â–ˆâ–‰                                    | 501/9622 [00:01<2:09:50,  1.17it/s] 21%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                             | 2001/9622 [00:02<1:15:57,  1.67it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9622/9622 [00:02<00:00, 4279.97it/s]
  ******************************************* 
              Running Evaluation                
  *******************************************
 
  Length dataset evaluation: 9622
  Length dataloader evaluation: 1203
  Number of epochs: 3
  Batch size: 8
  ******************************************* 
 
['/home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_0e88ccd4_2020-02-02_13-14-14zrziive6/outputs/checkpoint-3']
INFO:__main__:Evaluate the following checkpoints: ['/home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_0e88ccd4_2020-02-02_13-14-14zrziive6/outputs/checkpoint-3']
INFO:transformers.configuration_utils:loading configuration file /home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_0e88ccd4_2020-02-02_13-14-14zrziive6/outputs/checkpoint-3/config.json
INFO:transformers.configuration_utils:Model config {
  "architectures": [
    "AlbertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "down_scale_factor": 1,
  "embedding_size": 128,
  "finetuning_task": null,
  "gap_size": 0,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "inner_group_num": 1,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "net_structure_type": 0,
  "num_attention_heads": 12,
  "num_hidden_groups": 1,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "num_memory_blocks": 0,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 30000
}

INFO:transformers.modeling_utils:loading weights file /home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_0e88ccd4_2020-02-02_13-14-14zrziive6/outputs/checkpoint-3/pytorch_model.bin
HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=1203.0, style=ProgressStyle(description_width='initial')), HTML(value='')))
0.0005990.0007580.0004600.0002720.0001490.0001900.0001680.0001460.0001580.0001440.0002490.0003760.6873880.0530620.9779860.0652780.0046240.0004460.0002940.0001841.0987420.0523900.8747080.0385160.0024270.8865120.0341930.0014230.9942920.0345310.0016540.0001890.0002180.0002730.0067950.0007520.0001500.0001470.0000890.0001581.1167570.0277290.0015380.0038390.0012910.0009700.0004080.0015880.0044190.0003690.0003740.0002160.0002160.0001270.8162470.0150010.0003640.0068690.0002990.0001030.0001320.0000820.0018720.0001050.0000730.0007090.0028640.9426520.9095250.0135220.2519320.0041690.0006080.0000990.9031351.8635821.3817260.8186700.0110570.0003970.3166700.0041920.0004940.0001840.0008950.9793421.4902050.0343910.0009570.0002440.0001521.0847770.0123283.0634170.0326901.6029540.1878490.6464920.0067350.0002740.7777230.0081100.0003110.0003350.0011650.0006230.0000940.0001490.0001290.0002940.0001720.0001460.0001910.0296160.0003450.5457930.9976020.2789580.0024840.0002270.0000860.0002350.0000710.0000781.1195910.0091260.0012110.0003332.5126460.0206490.0033370.0001731.4205750.8131740.0061670.0001310.0034680.9314830.1489340.0012270.0000930.0023340.0000970.0001840.4808180.7773540.0054330.8122670.8595340.0058340.7848270.9211660.0854590.3964410.0027660.0000860.0000720.0000770.0000740.0066900.9299050.2386540.0016810.0000860.0015300.9823020.5210510.0038090.0002280.0002150.0633110.0008030.0000800.0000800.0000780.0000770.0001150.0000670.0000740.0001310.0000880.0000760.0000760.0002700.0000750.0000710.0001660.0000750.0000790.0000740.0000820.0001750.0004600.0002010.0003801.0518540.0054610.0073100.0004170.0000870.0000830.0001270.0000890.0001231.0226060.0057940.0805130.2050930.1018380.5153080.6368760.7475290.7842960.0039890.0000890.0000840.0002350.0001010.0009990.0000890.0001160.0000820.5062960.0030110.0002681.0356070.0047810.0002120.0001020.0001240.0001090.0003500.0014510.2926790.0017900.4409260.0109190.0016110.0010800.0003350.8151960.3404221.4140870.2067360.9646480.6814240.0038200.0000950.0001870.0000700.0001830.0002700.0000720.0000700.0002720.0002280.0003250.0005150.0001790.0003040.0001850.0002720.0007500.0002060.0149850.0004790.0002210.3486030.7056680.9740760.0036920.2325640.7343860.6284380.8521590.0234590.3583820.0018550.0414020.0010260.0002080.0008360.0002740.0001280.0000740.0001670.0001520.0002250.1762980.3485780.5382550.0022730.2198080.5257990.0030440.0004560.0003560.0012240.0003351.1364910.0040790.0188120.0030720.0127060.0112971.2564490.1049181.0423020.0036000.0001920.9950810.7339280.0025660.0001470.8008450.0026790.0001740.2040330.0007810.0001760.0036090.2666040.0015270.0015090.5835010.0027300.0003580.7293430.0029970.0005520.0003990.0006290.0045180.1031930.2448880.0044070.0000830.0001490.9073251.0460700.0032070.0001030.0000960.0004920.0002090.0004840.0000860.0001470.0003110.0039300.0002250.0001440.0008360.0004880.0005920.0007300.1612180.0049950.7356830.0021341.7785220.0050300.0002060.0003691.5433250.5983780.0051601.7515740.0050290.0066020.0005511.9201580.9227890.0026541.3592910.0038760.2733720.7911571.4220350.0038381.4709820.0039850.0030710.0000910.0001980.0006250.0006720.0006360.0004300.0000780.0002620.0000830.0002930.0006520.7707740.0025280.0004950.0007390.0005380.4239850.3053710.9608260.0061290.0112570.0024800.0001500.2023010.4614010.1473710.0012150.0918922.1221100.0184170.0070510.0017160.0078690.0005031.0118450.0045461.7882910.8648540.0021890.0002110.0002560.0002050.0008580.0000810.0258300.0213200.0001270.0000740.0000790.1461790.0004320.0000760.0000740.0000790.0000760.0000750.0002190.0617860.3940260.0012330.7810940.0024240.0002050.7895590.7174690.7287190.0971210.0039870.0005560.0003560.0230482.0125921.9224250.0044530.0062920.0372840.0576130.0005620.0005460.0008290.0004590.5353510.0236800.0004640.0201090.0010260.0510590.0002260.0199590.0001190.0001640.0000800.0000800.0000870.0002210.7872670.9961630.0023600.9527040.0484730.0204730.0001290.0052900.0000921.0158751.8743401.9414852.0542092.3747400.0050910.0000840.0000880.0000700.4256460.0009560.9362200.3273370.0008490.0001390.0003770.0003740.0014310.0001460.0013440.8353520.0017580.1922940.0047611.4789831.2333430.0024830.0003320.0012920.0012180.4831970.5055150.0015900.0012660.0002070.0011140.0001960.4226040.0308640.2041790.0004690.0878360.0248480.8523830.2601700.0363460.0002800.0131030.0068940.0002780.0069510.9671650.4629141.8850511.3664743.2898230.7502470.6148711.1052060.0462350.0004130.4853071.7983590.6863270.2705901.0083270.0022050.0006130.8946340.0016830.0000821.6619031.6854510.0032040.0000960.8169490.0015340.0003530.0000800.0007670.0007760.0001030.0000860.0003870.0000980.0010631.4911490.0837340.5762980.0042020.0010411.0782770.9498830.7501960.0965430.0003110.0001640.0001491.0806600.5930040.0015890.0124220.3982270.3673770.3785440.0014110.0000840.0000720.0001230.0008690.0000840.4134350.0015980.0002420.6386750.7990850.6904920.0012200.1594750.3796670.0009940.3834351.7281892.5040440.0046210.0153520.0193030.0623730.0114060.0006730.0000900.0001330.0160160.0369570.0649660.0002530.0022010.0101080.0000980.0010840.0001390.0000820.6249960.0146070.0001720.0001840.0001410.0003660.0002700.0003090.0075242.0607112.6010132.1453792.9185571.9868110.0466620.0050320.0097710.0031050.0008720.0008520.0010650.0009300.6796240.0077980.0020380.0007250.0727682.1285373.8399990.0159540.0001040.4127570.0006980.0005450.0153110.0009670.0540170.0609810.0015530.0022450.0005540.0004750.0002150.0001510.0002300.0002320.0001680.0001400.0001711.8055811.0707110.0633320.0001950.0461030.0466120.0007270.0008060.0162790.0003440.4479550.0025750.0002390.0006710.0001740.0004890.0001570.8125300.0858532.0808340.1406410.8769400.7844550.0014570.0003630.6440771.8967603.6245270.0061160.0027230.0003190.0002710.6283120.0020610.0011580.0004890.0004370.0072890.0004610.0011420.0003550.0931240.6153770.0178130.8054211.7061880.0029090.0030410.0009620.0036380.0071390.8020130.0023360.0024542.4633290.0041900.0007750.0003331.0487650.4094090.0006720.4058590.0006430.0078281.0224520.1407670.0007140.0001070.2144601.1457323.2258011.1571071.9854702.5745741.6975840.4569100.5048630.0612130.8221980.8476591.7506420.0031350.0007970.0009510.0006801.4469530.0356110.4650950.0008540.0001760.0000720.0000760.0001760.7658380.9434260.8341750.0017410.3156890.5541210.7462434.0892131.9467020.0060410.0283800.0002290.0022701.0487821.0286720.0017680.0002920.9924150.7773930.0023130.1033630.3773640.9204390.0016260.9683372.8892860.9637630.8538150.9357763.6424491.4383240.9535080.1431160.0003960.0060910.0006310.5979470.0028000.0003720.0001600.9558472.8127520.9283674.3520965.6664964.4737970.0059140.0002330.0018100.0002780.0002000.0000780.7933960.4435210.0006250.0000790.0010103.3909941.2086610.7264560.0012420.0201542.2379801.2971832.6151874.5594101.8393790.0292070.6661540.5723010.0023990.4155620.0005680.0001510.0003480.0023300.0006960.0004730.0005310.0004380.0004220.0003800.0003451.2645660.2757530.3586130.3071041.0386150.0019720.0001220.2697690.0006610.0004240.0005040.0004360.0003270.0002830.0005100.0001830.0003560.0003090.0002930.0002940.0001900.8220910.0010430.0003160.0002080.0001520.0002090.0000960.0008500.0003950.0001590.0002280.0003610.0002210.0004770.0099860.0001090.0004010.0000900.0000820.0003380.0005660.0000770.0003370.0003100.0002750.0000950.0096730.0405460.0017170.0518460.0556930.9013620.0018200.0019140.0015830.0064920.0592480.9292160.6676960.0091950.5947850.2695030.0012560.0008491.9812631.7159931.9197541.0126190.0021870.0005430.0008580.3517860.7927990.0050390.0005720.7550170.7553900.0008950.0001820.0003800.0001800.0000690.4030160.0005140.0000840.7810750.0009050.0000740.0002301.7261600.0019970.0003210.0006310.0012610.0004330.0003080.0000710.0009730.8910684.0887982.4419960.5846540.0015710.0003920.0235220.0000990.0004780.5843360.0037441.2408561.1610961.3183750.5506040.0205760.0153270.0455900.0131570.3908030.0011020.8682891.0621853.3487840.8665572.0601010.9035280.0048450.0991380.0108490.0046600.0253071.2426920.6420250.0043750.0017770.0000820.0000800.0000790.0009730.4301800.0005070.0008261.0213210.0231210.0001810.7653540.4578950.7680300.0051420.0071890.0039440.4711810.0112650.0007170.0022940.0000830.0013210.6506090.0015130.0000830.5332871.0973781.0176930.8623653.0097711.3487781.1849260.2424173.0520410.0030670.6352060.0045440.0000921.7528510.0023940.0148200.0001120.0840660.0012040.0012331.1380191.5862060.6172130.5837410.6769010.0159750.5596571.0062680.0273360.6026802.2323773.5595900.0169293.3848812.7550720.9318360.7538360.0031650.1496480.7593300.0008820.0009210.8557861.3147080.0079020.9852801.0628280.0024160.0118160.0061350.0167470.3238540.2417120.5127171.3338560.2504190.7989070.5871470.7758570.7101471.5535000.3864760.0029030.0104480.0717440.0004390.0391320.2789550.0004110.0003260.0003400.0005190.0057750.8417360.0011040.0004000.0007070.0014600.0006690.0019830.0000930.0021750.0000830.2916350.0003850.0000890.0001390.1362200.0068440.0000900.1903530.0002580.0005580.0167770.0055670.0007390.8070150.0014970.0000960.0002840.0001210.0001860.0022040.5503420.0005790.0002010.0051310.5389790.0007580.0009320.0009370.0014930.1587890.0010692.4500135.4187760.7312800.0018120.0012900.0010220.4148440.1828090.6169730.3050970.0480700.0002460.9947490.0556110.4637910.0006081.5803721.1449561.8528950.0064571.6145330.2403050.8070390.0137300.2315721.0495770.0010600.4593680.0011070.0000760.9167860.0011720.0080230.0001010.0005260.0002180.0005090.0010890.0005130.0002270.0001620.0003400.0003220.0050761.4098980.9399791.4596220.0130830.0822940.2743200.0717590.3241670.6367151.0419340.9250830.8267360.0029843.5048442.7155160.0056760.0005290.0002210.0002500.0004950.1153790.0004660.0004750.8880180.0011350.0007720.0002650.0010380.0003760.9451060.001127

*******************************************
EVALUATING PIPELINE 
Pipeline directory: /home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_0e88ccd4_2020-02-02_13-14-14zrziive6/
With following parameter combination: {'batch_size_seq_length': 2, 'lr': 1e-05, 'lr_type': 'cosine'}
EVALUATION OF CHECKPOINT /home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_0e88ccd4_2020-02-02_13-14-14zrziive6/outputs/checkpoint-3
-------------------------------------------------------------
|           |   agree   | disagree  |  discuss  | unrelated |
-------------------------------------------------------------
|   agree   |    492    |    54     |    167    |    13     |
-------------------------------------------------------------
| disagree  |    19     |    44     |    17     |     3     |
-------------------------------------------------------------
|  discuss  |    217    |    49     |   1563    |    58     |
-------------------------------------------------------------
| unrelated |    34     |    15     |    53     |   6824    |
-------------------------------------------------------------
Score: 7101.75 out of 7516.5	(94.48213929355418%)
Accuracy: 0.9273539804614426
F1 overall: 0.713896572498932
F1 per class: [0.6612903225806451, 0.35918367346938773, 0.8478437754271766, 0.9872685185185185]
*******************************************


*******************************************
EVALUATING PIPELINE 
{'batch_size_seq_length': 3, 'lr': 1e-05, 'lr_type': 'constant'}
INFO:__main__:Creating features from dataset file at /home/ubuntu/fnd_implementation/data/processed
  0%|                                                  | 0/9622 [00:00<?, ?it/s]  0%|                                        | 1/9622 [00:01<3:12:13,  1.20s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                 | 5001/9622 [00:01<1:04:37,  1.19it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 7501/9622 [00:01<20:45,  1.70it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9622/9622 [00:01<00:00, 6523.66it/s]
  ******************************************* 
              Running Evaluation                
  *******************************************
 
  Length dataset evaluation: 9622
  Length dataloader evaluation: 602
  Number of epochs: 3
  Batch size: 16
  ******************************************* 
 
['/home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_0c6bb2ea_2020-02-02_10-38-00rih7mkyq/outputs/checkpoint-3']
INFO:__main__:Evaluate the following checkpoints: ['/home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_0c6bb2ea_2020-02-02_10-38-00rih7mkyq/outputs/checkpoint-3']
INFO:transformers.configuration_utils:loading configuration file /home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_0c6bb2ea_2020-02-02_10-38-00rih7mkyq/outputs/checkpoint-3/config.json
INFO:transformers.configuration_utils:Model config {
  "architectures": [
    "AlbertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "down_scale_factor": 1,
  "embedding_size": 128,
  "finetuning_task": null,
  "gap_size": 0,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "inner_group_num": 1,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "net_structure_type": 0,
  "num_attention_heads": 12,
  "num_hidden_groups": 1,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "num_memory_blocks": 0,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 30000
}

INFO:transformers.modeling_utils:loading weights file /home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_0c6bb2ea_2020-02-02_10-38-00rih7mkyq/outputs/checkpoint-3/pytorch_model.bin
HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=602.0, style=ProgressStyle(description_width='initial')), HTML(value='')))
0.0009740.0011420.0006970.0004590.0002710.0008140.2010350.4121410.0567630.3183700.5725570.0539860.6355550.0494140.0153640.0028460.0296130.0064400.0007840.0002500.4552990.0226330.0023390.0011170.0291080.0019120.0003540.2266310.5270900.0194130.0008810.0002170.0001780.9108460.0361630.0391180.1167690.0543860.8966340.0234720.0119530.0008030.9622521.5275110.0354060.4676931.4648640.6563900.6598450.0139380.0461620.0346370.0012760.0004110.0002920.0002450.0003490.0563950.0369460.0016020.0006180.0000970.5890350.0099061.0870530.0195090.8993580.0135620.3490730.2131170.0031830.0001650.6934480.1377620.0354990.1294050.5606040.0076170.0001970.3673540.4861330.0061590.4767100.0091530.0003360.4483760.0052950.0001630.0001000.0001190.0000970.0009070.0000890.0002760.0001060.0001190.2239730.1199570.0056680.0020840.0001690.0001740.0011730.1972110.0137060.7836920.4648600.0044550.0003290.0017370.0003451.0129850.5931050.0056030.0002290.0002270.4334520.3284460.4887830.0098920.4940011.2411941.0999380.2873880.0024680.0002620.0001000.0266560.0015230.0055980.0015490.1663070.1713650.1817430.6112740.1565090.3222030.2775140.1109080.5091230.0148880.0003180.0001740.0001810.6103020.2611180.3316820.0027080.0748670.5694041.2335630.4878190.1436760.5692590.0039390.9978450.0067710.4566010.0032440.1729910.6707310.0053460.5004540.0041940.0010540.0012210.0016480.0027890.0001330.0012250.0004220.0036610.0014020.0003590.3663460.0027250.0007540.0024170.0382990.2578260.5567740.0036393.0301331.7821720.0870640.8088470.3999450.6567860.2365660.5599231.0469080.0115800.0003900.0004950.0004710.0001970.0938180.6293920.0051550.0238690.7022380.4347290.0896210.2041880.0090322.1256180.0971370.0066950.0873100.7362170.3563190.0725040.0021600.0005330.0002040.0000950.3858070.0018660.0000990.0015780.0407491.1230620.0058490.5643420.4446560.0062060.2956502.2215520.0101710.3909290.6119620.6966090.6347930.3639020.0083330.0003020.0002070.0002070.0013760.9689860.3664130.2422000.0195690.8527413.0373892.4674790.0101810.0001570.0010880.0043360.0006740.0009500.0052640.0117450.0002321.4252790.9670480.0619330.1519290.2300560.0057830.3503950.6546250.3777170.2573190.6878940.0041420.0043200.0020140.3341350.6904611.5762260.2098820.0041270.4243110.7379240.6651270.2582680.0010430.9822120.0036720.1731750.0013480.0030310.0001630.0273710.7498920.2084500.0037431.8421730.2372380.0010170.6644350.3015070.0824750.1700720.4046250.0014860.0028680.1031130.0116950.3092960.2627290.0011920.7471821.2377280.0684630.0172860.0011580.1062680.1410340.0008440.0027940.0003350.3840290.0094120.1264830.0018440.0035960.9998091.6360911.3426580.1286440.1042830.0013960.2071250.0250510.0021693.1614440.0099450.0166890.0399530.4050760.5997350.3296970.2900051.2226060.5727660.3999572.2619240.2838830.4677660.0017110.0002010.0003530.0010970.0005570.0013510.3797460.5858830.1517200.6551103.1019890.0374770.0010400.2769450.0048480.2486310.0014400.0440470.5110500.8645342.0666184.3490640.3740650.0203351.2505570.0045090.3962250.0016830.1955440.0022810.0008260.6019521.5788051.9335121.3616620.8845360.5626990.3775570.0342510.2104400.0656630.0005100.0001800.5006131.0626800.4930020.1302541.2852090.4800850.0023810.2457770.0133820.2703370.3325780.5656780.6521241.9234760.9409431.8821650.3665090.0109880.2364500.0043660.5006291.9394625.2719212.8150220.1315380.0005020.2869320.2483450.0009552.4246290.3593800.5725471.2204272.2528690.4436820.2686040.1943370.0029050.0814530.0010330.0005050.0012520.8903940.7933330.6569290.0017870.0003260.0004750.0002530.0009840.0003290.0003210.3621010.0011260.0001500.0001260.0014600.0004680.0004200.2367330.0019740.0001300.0123790.0013110.0122570.9547062.1290830.3971750.6228240.0066880.0325100.3950170.0061380.2394940.4455190.8350460.4835970.1980230.1549280.0159440.0006790.0001400.0003900.0858690.0003040.0001160.0052280.5977290.0054270.0066210.0008380.1995171.8628690.3571390.0010170.0001680.2025020.5509340.7260060.2978220.0624190.1388430.8237622.1568851.6288820.0610600.4329190.4333900.1005260.0036530.0001030.2810110.0096710.4594990.0056180.0088550.0020710.2783730.0023540.0010650.0013690.0001680.5364101.1721651.2539570.8437371.4649940.6468240.6392300.0160970.1508140.0041021.1650200.5535520.6883180.6840640.9885073.7033701.5436791.1826470.4910460.4076280.0646521.5555351.1639480.4613610.1284370.4543120.1173110.5409660.0030240.0970850.6100120.6138070.0107490.6351190.0013790.0003220.0604610.0011770.0088320.0048700.0005020.1740790.0004920.2621340.0236900.0192820.0101550.0724000.1885880.0008100.0002090.4234570.0010880.5559250.2089930.6043700.6673423.9572750.2428820.0050490.8027290.4263020.4571760.6711250.3880422.5070050.9198620.0463350.0718720.5952500.2549870.0007680.4896800.0020590.0005250.0004480.0004340.0008960.2445141.4598730.3791360.0646890.1872570.5268920.7556511.1008521.2236130.0026410.0386700.0006220.3033340.0026360.0039590.5139510.002661

*******************************************
EVALUATING PIPELINE 
Pipeline directory: /home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_0c6bb2ea_2020-02-02_10-38-00rih7mkyq/
With following parameter combination: {'batch_size_seq_length': 3, 'lr': 1e-05, 'lr_type': 'constant'}
EVALUATION OF CHECKPOINT /home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_0c6bb2ea_2020-02-02_10-38-00rih7mkyq/outputs/checkpoint-3
-------------------------------------------------------------
|           |   agree   | disagree  |  discuss  | unrelated |
-------------------------------------------------------------
|   agree   |    383    |    45     |    120    |     8     |
-------------------------------------------------------------
| disagree  |    10     |    32     |    20     |     0     |
-------------------------------------------------------------
|  discuss  |    322    |    72     |   1574    |    52     |
-------------------------------------------------------------
| unrelated |    47     |    13     |    86     |   6838    |
-------------------------------------------------------------
Score: 7073.25 out of 7516.5	(94.10297345839155%)
Accuracy: 0.9173768447308251
F1 overall: 0.6690355766394247
F1 per class: [0.5811836115326252, 0.2857142857142857, 0.8240837696335078, 0.98516063967728]
*******************************************


*******************************************
EVALUATING PIPELINE 
{'batch_size_seq_length': 1, 'lr': 1e-05, 'lr_type': 'cosine'}
INFO:__main__:Creating features from dataset file at /home/ubuntu/fnd_implementation/data/processed
  0%|                                                  | 0/9622 [00:00<?, ?it/s]  0%|                                        | 1/9622 [00:01<3:34:44,  1.34s/it] 21%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                             | 2001/9622 [00:01<1:59:04,  1.07it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9622/9622 [00:01<00:00, 5733.02it/s]
  ******************************************* 
              Running Evaluation                
  *******************************************
 
  Length dataset evaluation: 9622
  Length dataloader evaluation: 2406
  Number of epochs: 3
  Batch size: 4
  ******************************************* 
 
['/home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_0e88ccd3_2020-02-02_13-11-27u2h630uo/outputs/checkpoint-3']
INFO:__main__:Evaluate the following checkpoints: ['/home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_0e88ccd3_2020-02-02_13-11-27u2h630uo/outputs/checkpoint-3']
INFO:transformers.configuration_utils:loading configuration file /home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_0e88ccd3_2020-02-02_13-11-27u2h630uo/outputs/checkpoint-3/config.json
INFO:transformers.configuration_utils:Model config {
  "architectures": [
    "AlbertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "down_scale_factor": 1,
  "embedding_size": 128,
  "finetuning_task": null,
  "gap_size": 0,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "inner_group_num": 1,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "net_structure_type": 0,
  "num_attention_heads": 12,
  "num_hidden_groups": 1,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "num_memory_blocks": 0,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 30000
}

INFO:transformers.modeling_utils:loading weights file /home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_0e88ccd3_2020-02-02_13-11-27u2h630uo/outputs/checkpoint-3/pytorch_model.bin
HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=2406.0, style=ProgressStyle(description_width='initial')), HTML(value='')))
0.0004290.0004840.0002760.0001880.0000750.0000370.0000370.0000690.0000320.0000290.0000270.0000630.0000300.0001380.0000680.0000310.0000340.0000280.0000240.0001840.0000790.0000712.0005410.0870080.0037370.3843830.0148800.0009252.1816020.0752800.0025370.0001070.0002670.0002620.0000810.0000280.0001140.0000260.0000630.0001690.0003372.6845510.0639420.0015100.0008140.0000420.0006530.0000450.0005090.0000352.8416340.0566570.0011140.0000510.0000480.0000290.0000321.8166620.0314180.1762070.0034260.0001940.0003050.0000850.0000680.0014510.0004630.0000480.0046910.0087080.0031410.0004550.0001960.0004670.0002360.0000650.0000390.9989080.0130170.0002561.8158930.0540971.7431090.0210630.0003392.1349320.7679100.0088940.0004000.0013080.0002960.0001170.0003300.0001680.0004280.0000300.0027760.0013910.0000890.0000340.0000960.0000600.0000631.4647110.0141400.0001720.0000480.0000351.9944920.0189280.0002000.0000340.0000570.0000280.0000510.0010500.0000310.0002050.0000240.0000250.0000220.0000560.0000250.0000250.0000240.0000940.0000240.0000220.0000210.0000240.0000220.0000250.0001380.0006390.0039190.0432710.0003450.6681080.0048770.0006610.5240630.0037750.0002860.0000760.0003090.0000290.0000270.0000361.2383120.0101432.3404900.0155250.0009190.2881831.5754910.0102380.0003570.0001030.0000640.0000520.0001760.0001270.0000710.0000750.0000720.0002200.0000500.0000240.0000230.3446140.0022880.6939970.0409660.0294620.0009520.0052920.0000880.0000420.0001640.0000290.0000550.0771632.4242190.0132760.0001850.0000284.5618012.4954420.0132990.0001161.0980260.0615070.5091730.9506441.4403140.0074230.0001180.0000270.0000420.0000470.0000451.4374460.0071440.0001290.0000490.0000260.0000680.0000400.0000420.0001550.0000900.0000870.0000270.0000410.0000640.0000300.0000480.0000270.0000490.0000250.0000550.0000350.0000710.0000270.0001270.0000490.0000570.0001450.0000280.0000670.0145510.0001360.2320260.0010171.1070510.0047330.0000580.0000210.0000240.0000720.0000250.0000280.0000290.0008320.0000250.0000210.0000230.0000240.0000232.3063490.0092520.0000600.0100020.0809350.0003700.0000400.0157200.7156610.0028450.2352150.0071640.0001270.0000240.0000290.0045162.6198970.5809720.0021990.0000680.0000260.0000330.0000280.0000261.5493680.0058232.1779990.0095530.0000760.0000430.0000240.0000270.0000260.0000270.0000280.0000280.0000240.0000310.0000220.0000230.8633860.0030022.0868560.0071760.0000570.0000272.0059521.5670930.0053270.0000420.0000210.0000241.9532122.0568740.0068090.0000440.1588120.0130660.0000700.0000330.0000540.0000250.0000250.0000270.0000320.0000260.0000240.0000250.0000350.0008360.0000460.0000500.9518500.0029922.0031540.0062090.0000780.0000250.0000300.0000520.0005722.3376240.0072540.0000440.0210030.0001340.0001350.0000530.0000490.0000420.0000840.0000592.1109370.0061950.0001190.0000240.0000260.0000280.0000240.0000230.0000500.0000230.0000340.0000260.0000490.0000240.0000230.0000260.0000250.0000250.0001140.0000270.0000230.0000250.0000220.0000230.0000220.0000940.0000720.0000250.0000230.0000230.0000230.0000240.0000660.0000230.0000220.0000260.0000220.0000230.0000230.0000240.0000240.0000530.0000240.0003420.0051240.0000410.0001500.0015030.0011510.0000362.3469160.0060140.0000570.0007680.0002120.0003290.0000360.0000240.0000260.0000710.0000630.0000340.0000280.0000280.0000240.0000350.0000420.0000670.0274310.0003060.0000250.0000980.0000310.5881740.0014500.0000270.3032550.0008400.0000230.0002071.4854130.0036010.0035440.3972150.0009640.0000730.0000240.0000220.0000220.0000280.0000240.0000230.0000640.0000380.0000270.0020390.0000270.0000430.0000220.0000240.0005390.0000400.0000420.1689061.3408860.0031970.0000320.0001680.0000312.5297950.0056770.0000910.0000330.0000390.0001040.0000260.0002420.0000420.0000330.0000330.0000940.0000300.0001820.0001580.0001660.0000290.0177840.0003930.0001010.0068510.0001060.0003360.0054930.0013180.0008760.0002310.0295980.0001480.0001030.0000311.6749110.0037380.3221510.8881462.2117140.0049692.2748750.0057812.2869212.5986370.0060620.0024400.0001680.0000360.0000230.0002970.0000230.0000220.0000220.0000230.0001490.0003040.0000250.0000240.0000240.0000230.0000260.0001480.0000250.0000240.0002170.0002330.0004250.0019990.0000290.0000270.0001360.0000610.0067290.0000380.0000990.0002490.0000400.0000360.0004070.0000300.0000590.0012950.0000310.0002400.0000340.0000700.0001090.0001662.4756510.0050491.2990700.3192402.4058470.0044810.0000410.0200330.0004100.0000291.0482291.2217230.0023461.2324330.0023350.0056730.0000470.0000271.3334020.0033850.0000940.3130490.0070820.0003600.0000540.0000360.0001630.0000280.0051410.0000760.0000490.0000530.0000240.0000230.0000220.0000260.0000550.0000680.0000260.0001300.0000310.2463490.0004510.0970221.4719760.0025630.0150580.0001800.0000340.0097690.0000440.9148620.0016470.0001970.0001010.0012060.0000600.0001670.0000260.0098800.0522870.0001190.0000940.0000642.1356790.0083980.0000800.5142980.0038030.0008110.0095880.0004840.0008660.0001100.0002622.1312343.8677200.1764120.0009410.5353433.5085180.0057500.0000760.0001150.0001382.0153940.0033130.0000310.0050910.0000760.0000270.0000660.0000240.5842180.0009530.0000620.0000230.0000220.0000780.0000230.0001790.0000380.0000870.0000890.0000260.0009780.0144080.0105680.0018380.0001410.0001680.1122490.0001993.3780960.0052460.0001660.0003600.0000380.0001510.0012250.0006490.0000940.0001570.0001700.0002000.0000640.0000560.0000930.0000920.0001380.0000290.0003560.0000340.0001730.0000260.0001800.0000640.0000240.0000280.0000340.0000570.7256561.4572681.2708040.1792410.0003200.0000330.0001090.0000320.0000310.0000550.0000290.0009750.0001360.0000260.0013530.0000320.0000340.0000320.0000300.0001070.0002980.0000230.0003700.0001960.0006140.0004090.0000270.0000830.0000900.0000670.0000880.0021540.0002450.0000630.0006220.0004520.0001920.0022940.0000460.0007930.0000660.7711170.0011050.0000381.1347340.0238030.0000750.0000360.0000770.0000360.0001480.0000731.3798342.3044171.8052120.0026070.0001510.0002774.3283560.0060630.0000370.0001370.0000800.0010880.0012160.0000690.9878212.7929030.0038402.1469350.0029410.0000380.0000472.8627460.0038710.0000341.8163910.5652601.6990890.0022793.0967430.0041170.0000380.0000373.6384160.0048150.0000490.0001010.0000390.0038260.0000300.0000250.0002700.0000270.0001990.0001860.0001800.0001960.0001430.0001590.0000820.0014690.0000260.0000240.0026590.0000310.0000300.0000250.0000300.0001340.0000980.4962470.0007450.0011950.0001790.0002350.0000240.0005660.0001300.1543130.0009480.0000800.0017122.0271830.0037381.9576242.7503321.6141440.0020310.0024380.1332660.0001960.0000460.0005780.0000340.0001220.0233720.0002810.0000430.0240630.0001010.0096120.0029260.0000290.0000850.0116834.3489246.3879410.0077790.0002660.0000380.0015060.0000280.2858180.0015650.0000630.0000790.0000782.5697110.0032821.5007510.0018172.0991812.1243180.0025512.1301290.0025640.0000300.0000200.0000430.0001290.0000890.0000350.0001210.0001750.0000260.0000270.0000240.8065130.0013700.0009130.0000320.0000270.0000220.0000260.0000230.0000230.0000262.1943440.0025600.0000290.0000260.0000270.0000240.0000220.0000240.0000230.0000250.0000230.0000240.0000250.0000230.0000250.0004500.0000240.6723670.2779490.0009720.0002680.0000251.2398460.0520970.0002120.0001360.0003420.0000300.0008861.6774441.5177540.0017591.6245740.0018450.0015570.0002400.0459070.0003770.0003360.0001540.0001100.0000850.0000320.0010090.0011725.0487263.4395850.0042380.0000910.0002501.5117100.0143010.0420890.0040540.0004880.0001530.0001990.0004530.0004090.0002171.4505340.0016770.0001490.0004201.6568570.9226321.4666960.0017040.0000360.0001150.0119550.3740240.0005130.2869510.0003990.0001200.0000240.0000310.0001160.0000260.0000300.0000250.0000250.0000950.0000240.0000240.0000230.0000260.0000290.0000430.0000820.0000301.2030380.0012890.0000262.2513840.0024740.0000572.1910060.0023000.0000240.0005210.0000410.0003520.0000260.0000220.0000210.0002890.0000220.0000290.0002260.0569380.0261470.0466400.0101980.0302100.7494020.3005240.0012290.0017880.0000690.0000320.0000270.0000260.0000290.0000570.0000260.0000230.0000251.5439420.0015810.0000511.6641201.0762300.0011051.7582940.0018560.0000370.0000590.0000470.0001930.0003460.0000580.0000390.0005380.0006290.0000520.0000350.0006990.0005302.0003210.0022390.0004870.0000300.0004010.0000320.0001300.0001310.0000804.0718932.6417750.0032550.0000270.0000360.0000250.0001040.0002530.0003640.0002720.9637680.0010550.2826060.7127501.6584680.0016580.0002250.0002870.0003140.0000320.0002370.0001210.0024350.0000660.0000630.0000350.5005960.1863670.0002060.0145960.9229740.0009070.0000340.0000330.0117670.0000420.0156420.0063200.1909881.2832190.0012360.0000390.0024240.0000710.0000330.0008090.0000280.0000320.0029380.0004880.0000520.0007870.0000591.3255470.0988320.0002552.9677731.6330463.4697702.7878800.0028453.2114170.6140270.0015020.0001190.0000230.5733430.0009560.0061180.4992930.0007660.0000570.0001090.0485671.3323020.4829960.0009200.0006881.6915290.0018300.0003410.0011150.0001150.0000270.0002070.0001830.0001511.5320540.0019250.0000250.0000220.0000250.0000290.0005030.0167230.8417700.0008720.0000280.0000740.0000230.0000420.5133770.0004810.0000270.0000270.0000250.0002520.0000240.0000250.0004730.0000270.0003360.0003540.0000220.0000640.0000240.0000270.0000230.0003270.0000410.0000250.0000250.0012780.0131721.5097410.0024770.0025701.7423310.0021020.0002810.0022230.0004610.0000362.5327771.1749961.8422900.0030010.0000970.8979971.1891680.0011100.0000620.0000220.0000290.0000490.0000280.0000490.0000293.3349740.0029410.9958520.0009270.0003160.0001960.0000291.5251720.0013231.2638860.0011141.3897040.0012090.0009230.0001190.0000240.0000270.0000230.0000220.0000300.0000810.0004660.0000240.0000300.0000320.0000360.1445380.0001440.0003030.0000340.0000730.0000360.0025980.0026250.0172430.8314550.0007180.0000450.0000300.0000300.8592280.0008800.0001110.0000790.0002800.0000970.6210690.0006807.2498515.3658323.0462460.0025740.0009780.0000861.8453870.0019310.0005250.0000440.0038870.0004280.0000340.0218220.0000470.0000600.0000270.0000580.0000520.0010460.0000700.0000420.8498340.0046620.0015120.0000740.0000240.0004030.0000280.0002990.0000420.0000260.0000300.0000910.0008730.0000290.0000720.0000350.0000270.0136980.0001360.0000470.0004110.0000330.0000830.0001780.0000290.0000660.0000260.0000320.0003120.0000250.0001660.0002570.0000240.0004770.0000290.0003554.5122865.6346325.8990423.8811443.9319892.4693204.7050231.5052633.3759430.9436880.3975100.0007230.0058690.0073951.4385190.0032180.0008020.0001320.0001770.0001500.0001660.0002570.0002330.0004520.0002970.0004040.0000970.0002300.0001850.0003490.0004270.0001480.0001890.0002061.9309932.7984031.4580656.1589811.1630480.0044820.0000270.0000240.0000290.0000220.0019380.0000240.0000220.0004690.0011210.0000230.0093980.0002710.0004790.0008020.0020450.0042630.0009041.2899630.0009920.0008571.1356980.0012540.0000530.0005030.0001290.0000280.0000800.0000290.0002240.0001550.0000710.0000240.0002340.0000840.0000720.0001980.0000310.0001830.0000241.7598322.9492071.7363112.3816720.2001400.0002220.0000670.0000340.0015762.1456800.0016260.0005250.0012050.0004740.0000350.0001610.0005230.0000630.0000420.0008340.0002390.0002050.0000430.0003710.0001730.0000620.0002530.0002590.0000400.0000740.0001010.0002790.0000420.0000640.2257200.0002310.0002080.0001802.0164902.3693250.0046600.0255561.7208900.0053701.3619800.0010560.0000600.0003020.0002010.0001052.0060630.0020831.7748063.7992014.2287324.5370560.0034580.0005060.0007020.0004520.0000250.0002760.0000300.0002680.0000310.1237110.0005600.0000320.0005760.0003010.0001290.0009820.0002000.0000881.0921370.0008840.0001160.0000910.0001941.5360970.0070170.0001310.0001350.0003310.0004441.7904780.0014630.0002730.0033200.1657762.8980200.0021910.0000810.0001351.7357440.0013400.0001490.0002070.0011090.0000420.0028370.1171730.0003731.4890310.0012540.0009570.0008500.3318995.5118010.0040220.0002530.0001360.0003020.0001320.0001080.0001290.0001520.9175770.0006472.0897500.0014430.0000330.0004061.3376850.0009840.0000271.0884370.0007580.7519793.4330940.0037531.5729160.0010790.0006850.0000340.0000391.5910280.0011750.0001873.0905154.0229573.8159992.0160071.4561593.9541831.9020603.8588553.8319413.9184792.0016874.0642551.9098100.0014104.0860644.0349890.0029422.0148352.0333530.0017011.3136791.7535300.0012820.0001470.0001320.0001690.0001370.0001250.0001370.0000920.0001330.9414040.5127480.0004240.0038170.0000260.0565260.0001820.0000230.0000460.0000250.0000230.0000230.0000280.0000230.0000520.0000921.9342410.0012822.4540550.0016152.0289360.0013360.0001000.0024330.0009242.0118692.2819170.0015522.0814514.3385841.4540230.0019480.0006010.0000730.0001110.0006610.0031680.0499030.0000710.0000530.0005830.0001570.0001132.3214000.0015712.1902420.0014831.0012770.0007780.0000590.0001312.1312060.0014622.1927260.0021500.0002450.0286700.0163601.6283970.0012730.0000572.2300400.0014910.0000562.0569970.0013962.6417954.7219990.0031632.1544332.3027310.0015032.2600300.0014617.6972921.5182320.5674804.7976941.9458681.1551040.8362410.0005990.0001000.0000240.0001100.0001230.0002390.0000230.5452200.0006420.0003450.0000240.0000960.0000740.0000600.0000272.3635520.0014844.7454342.3728380.0016942.3529072.2981695.4862625.5821156.5779094.4421781.9228020.0013350.0001890.0000770.0001541.4318640.0009090.0001060.0000660.0000630.0000280.0000270.0000381.4733040.0009500.0002050.1378650.0001170.0000420.0000270.0000800.0000240.0005914.4423353.4270041.7950291.2963971.7829310.0011490.0001130.0001450.0000491.6542870.9746784.0332752.0731272.7516844.0778311.9380974.9629015.9237323.9670310.0023890.0000260.0006181.7302630.0010531.5875350.0009690.0000260.0007040.2731410.0002110.0000230.0000330.0000390.0000580.0000280.0003550.0015070.0000760.0001000.0001730.0000940.0001600.0000660.0001880.0001150.0000870.0000790.0001210.0000270.0001720.0000580.0001111.8525870.2967782.2157080.0015311.3229750.7520170.0005010.9460860.5908770.7256240.0013010.0000780.0000830.0000290.0000990.0001220.0000810.0000760.0000770.0000950.0001110.0001120.0000850.0001080.0000540.0000840.0000600.0000470.0000230.0000670.0000730.0000250.0000870.0000960.0000670.0000940.0000880.0000680.0021060.0000820.0000240.0000900.0000561.3623880.0008060.0000660.0000880.0001000.0000330.0000900.0000250.0000310.0000310.0000690.0000340.0000780.0001480.0001220.0000270.0001510.0000270.0000540.0735720.0000680.0000830.0000360.0000250.0001050.0022010.0000630.0000561.6037460.0009580.0000220.0000530.0000730.0000290.0000350.0000260.0000240.0003470.0000250.0005010.0000240.0000280.0000260.0000210.0002180.0001980.0000250.0001950.0000250.0000350.0000251.5581691.9845251.7058125.9041710.3240800.0002570.0005720.0011510.8214940.0033980.7530501.6428440.0018230.0002670.0006210.0005090.0003430.0004730.0007550.0009632.0142270.0016600.0016831.6281020.0014000.0004370.0005760.0007180.0008821.9212260.3188092.1846940.0013580.0001590.0001430.0001810.3484631.8966750.0156661.8451590.0211910.4202370.5860820.9466150.0007080.0001450.0001070.0000830.0000690.0001700.0001780.0001010.0001250.0001630.0000960.0001250.0001470.0001250.0001450.0000840.0000680.0000610.0000280.0000210.0000260.0001060.0002080.0001170.0000950.0000250.0000220.0000230.0000781.3386450.0007430.0000240.0000230.0000450.0000690.0000230.0000230.0000220.0000250.0000230.0000541.2377172.4453940.0013160.0000260.0001710.0000660.0001840.0001880.0002080.0000900.0000580.0000820.0001670.0000570.0002350.0000220.0000230.0007130.0003931.9612580.0021063.1273194.8295211.6895512.9254351.1407051.7338941.3083050.0007300.0000490.0002520.0000241.1014550.0005970.0000230.0000240.6443810.8454360.0004690.0000710.0000850.0000582.6050622.3203141.2307900.0006672.7793381.3446542.3155760.9456650.0036451.7586320.0043071.8226462.4478860.3508231.0740080.0005771.7841250.0013070.0002410.0007132.4385632.4308250.4640124.9930422.4558770.0025681.6494450.0018684.1642030.0044281.6625340.0009530.0013480.0007290.2129610.0007200.0001470.0012150.0007520.0012570.0015462.6873060.0017580.0364220.0020980.0003400.0004220.0000330.0005340.0000310.0000310.0000570.0000340.0000260.0000270.0000250.0013261.8961400.0009890.0000250.0000430.0000270.0004210.0008241.5336200.0065570.0000470.0000420.0000780.0002790.0003960.0003350.0004080.0003310.0003800.0002060.0008000.0009320.0001720.0006590.0006040.0013141.4345780.0015150.0009570.0000550.0003750.0000220.0001150.0000220.0000210.0002920.0003230.0002650.3124120.0003820.0000220.0000220.0000220.1525030.6921592.3486202.3657053.1784270.0436670.2848391.2765570.0028035.3217762.7675280.0013840.0000370.9634130.0060380.0000352.8407772.4157070.0012140.0000300.0287030.0000440.0100580.0000830.0001550.0000302.4818880.0012400.0001770.0000530.0017120.1362760.0000950.0000300.0083040.0007540.0000370.0002960.0002140.0052260.0001032.6169702.9537570.3751763.0754871.9650540.0011853.1066393.8162572.1531340.8080930.2622141.2977100.4770560.0003153.2692090.0027320.0000380.9933980.0007840.0242580.7779424.2224266.5511691.6481690.0612702.1738722.6639912.0742700.2206541.4426080.0008790.0001772.6062890.0012750.0011251.1569280.0006940.0000602.4103030.0011780.0000440.0000400.0189500.0002812.8449520.8638190.1684900.0001350.0002620.1087802.3506020.0011402.1094000.0036080.0004190.0005070.0146450.0003920.0002270.0007340.0005090.0001300.1160400.0007370.0002061.4781510.0023260.0010011.8137960.0021341.5780971.2496700.0006450.0008170.0000230.5755441.3675620.0500130.0001130.1294012.7378566.6507494.3496340.0026510.0008190.0017370.7218330.0006840.0002850.0002410.0000410.0004560.0009391.8346470.0009010.0000570.0000290.0004150.0000510.0001740.0000560.0006100.0080960.0000610.0281030.0001012.3595660.0603710.0000530.0002190.0002350.0001510.0001630.0001520.0001780.0000810.0001050.0001060.0008240.0000390.0001040.0000350.0001910.0000250.0000241.2967880.0006150.0000320.0000460.0000240.0000530.0000280.0045380.0948950.0000750.0001560.1359670.0000840.0000250.0001560.1976120.0001150.0000300.0001470.0001740.0032130.0000420.0001820.0001670.0005110.0003550.0000781.0824350.0019960.0003170.0000270.0000490.0000690.0003120.0000360.0000680.0001280.0000380.0003870.0000320.1519520.0001760.0000350.0000330.0000290.0029800.0010010.0000670.0000430.0700330.0000610.0003100.0011030.1773800.0317460.0024180.0002500.6262211.5501080.7882640.0018640.5575212.4740583.7463916.7112673.0981721.4578010.0012250.0000410.0011740.0004920.0007030.0008020.0007730.0001870.6011750.0003020.6385230.3955940.0002750.2283470.0001230.0006380.0000250.0000210.0000940.0000600.0015390.0000280.4889621.7209200.0011210.0000610.0000600.0000521.5177191.5136332.0342210.0009442.4768070.0014300.0001560.0027142.9642850.0015781.9667842.2610690.0012700.0004590.3430070.0027420.0000240.0010062.1204160.0009430.0000790.0000291.5683780.0007020.0001350.0000240.0000242.1310340.0010080.0004510.0001040.0001090.0026840.0000880.0000250.0035670.0000380.0001460.0000630.0002010.0005130.0002660.0034060.0000990.1224610.0001410.0001560.0002320.0000320.0002050.0000290.0003610.0000440.8979680.0004862.2992770.0110910.0003460.7111560.0003281.4672990.0331490.0025190.0437730.0022080.0167000.0008270.0267340.0024920.0066831.1365101.1191971.3793422.6585060.0011712.0430461.7772760.0022881.5656080.0069540.0015041.2190920.8178500.5502481.0772540.0020750.0021000.0009560.0004880.0000250.0004960.0001480.0000580.0002230.0001440.0000640.0379360.0002670.0000930.0000920.0003811.2632870.0006740.0001140.8875030.0007850.0000320.0000700.0001610.0004870.0001680.0000300.0003130.0000252.2520620.0011220.000097

*******************************************
EVALUATING PIPELINE 
Pipeline directory: /home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_0e88ccd3_2020-02-02_13-11-27u2h630uo/
With following parameter combination: {'batch_size_seq_length': 1, 'lr': 1e-05, 'lr_type': 'cosine'}
EVALUATION OF CHECKPOINT /home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_0e88ccd3_2020-02-02_13-11-27u2h630uo/outputs/checkpoint-3
-------------------------------------------------------------
|           |   agree   | disagree  |  discuss  | unrelated |
-------------------------------------------------------------
|   agree   |    523    |    53     |    186    |    19     |
-------------------------------------------------------------
| disagree  |    24     |    43     |    18     |     4     |
-------------------------------------------------------------
|  discuss  |    186    |    51     |   1552    |    41     |
-------------------------------------------------------------
| unrelated |    29     |    15     |    44     |   6834    |
-------------------------------------------------------------
Score: 7111.5 out of 7516.5	(94.61185392137298%)
Accuracy: 0.9303679068800665
F1 overall: 0.7161568856022351
F1 per class: [0.677900194426442, 0.3426294820717131, 0.8550964187327824, 0.9890014471780029]
*******************************************


*******************************************
EVALUATING PIPELINE 
{'batch_size_seq_length': 3, 'lr': 1e-05, 'lr_type': 'linear'}
INFO:__main__:Creating features from dataset file at /home/ubuntu/fnd_implementation/data/processed
  0%|                                                  | 0/9622 [00:00<?, ?it/s]  0%|                                        | 1/9622 [00:01<2:58:28,  1.11s/it] 21%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                             | 2001/9622 [00:01<1:38:58,  1.28it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 7501/9622 [00:01<19:16,  1.83it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9622/9622 [00:01<00:00, 6366.61it/s]
  ******************************************* 
              Running Evaluation                
  *******************************************
 
  Length dataset evaluation: 9622
  Length dataloader evaluation: 602
  Number of epochs: 3
  Batch size: 16
  ******************************************* 
 
['/home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_0d5a1d55_2020-02-02_12-36-0117xcau5c/outputs/checkpoint-3']
INFO:__main__:Evaluate the following checkpoints: ['/home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_0d5a1d55_2020-02-02_12-36-0117xcau5c/outputs/checkpoint-3']
INFO:transformers.configuration_utils:loading configuration file /home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_0d5a1d55_2020-02-02_12-36-0117xcau5c/outputs/checkpoint-3/config.json
INFO:transformers.configuration_utils:Model config {
  "architectures": [
    "AlbertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "down_scale_factor": 1,
  "embedding_size": 128,
  "finetuning_task": null,
  "gap_size": 0,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "inner_group_num": 1,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "net_structure_type": 0,
  "num_attention_heads": 12,
  "num_hidden_groups": 1,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "num_memory_blocks": 0,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 30000
}

INFO:transformers.modeling_utils:loading weights file /home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_0d5a1d55_2020-02-02_12-36-0117xcau5c/outputs/checkpoint-3/pytorch_model.bin
HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=602.0, style=ProgressStyle(description_width='initial')), HTML(value='')))
0.0023230.0026210.0015870.0008780.1735060.1612000.3228800.3742250.0495650.2898990.3852250.0381140.4307030.0337070.0056560.0019460.0088690.0289820.0021970.0006050.2192900.0114990.0111800.0045260.0067960.0029160.0005360.2352800.2384990.0200510.0010530.0004260.0002860.7996560.0251290.0046020.0064090.0254340.8860920.1348240.5125870.0194860.5450991.0544190.0262090.4201431.3285230.3763220.4895530.0103410.2660800.0057090.0007820.0003650.0004530.0004490.0133760.1715730.0355130.0019040.0045710.0003290.4163860.0825390.4517880.0078200.6547950.0100920.0630160.2863260.0043670.0003310.7053340.0115340.0010760.3233470.5102120.0069750.0005870.0022760.2796240.0041070.1106220.0049920.0009160.4180450.0051340.0004570.0003740.0003060.0003230.0018620.0002660.0013500.0003030.0003700.0780920.4075470.0133790.0287500.0006570.0003710.0068140.3402560.0345490.4849630.3580620.0036260.0006760.0008710.0010340.4249250.4009080.0056440.0005500.0006560.2475290.0118500.1034750.0767880.5845670.8187920.6377430.0120180.0011810.0022830.0002750.0043410.3101540.5351780.2101300.0047660.3597640.1215120.3201130.2388760.4495760.4377200.2129100.2382910.1460600.0015710.0003870.0005260.2958690.0453300.2040150.0030770.2711590.4576300.1086270.0471660.3034570.5451750.0044090.4724080.0036850.3156630.0043220.0192650.3637500.0040750.4338010.0082470.0115030.0450250.2539450.2550800.0019110.0656510.1381450.0041740.0010260.0130840.0980830.0048120.0023610.0060560.2459990.1976530.5699290.0052392.0205480.8716290.1279250.6443300.3103530.4576560.3991250.5338390.4818410.0059650.0009480.0014290.0027390.0004860.0047530.2903200.2625220.2529770.7987370.1478430.0235690.1960730.1596991.5876750.0876980.0092530.4074740.2994090.1787880.3732480.0035200.0173190.0015010.0002630.1882450.0011220.0002610.0008530.0359250.1193690.0016320.5667080.3375600.2605440.1498901.7646340.0101580.0052540.3560500.6243340.2032780.0172240.0073780.0012410.0003890.0003460.0004670.7630260.3759630.0153890.0046870.4448202.2072561.7126090.0075270.0002880.1541750.0420720.0612630.0027070.0057730.0052690.0124740.6110510.5354560.2309860.1368620.1395430.0067140.5686750.3267390.2872210.1380410.5225680.2125620.0129610.1959730.3413200.6975300.8582480.0478500.0043640.0301150.0690760.0138610.2491630.0011710.3965730.0019080.1051310.0035440.0057730.0005630.0003760.4802490.6288110.0081361.5176240.4105360.0017810.6161310.2874110.2240140.3886770.3771590.0015720.0024160.1930810.0685990.4422850.1787550.2832051.2773231.4075840.3948490.0060020.0022630.0022220.4285380.0051140.0012780.0020030.0652250.0378590.0007420.0021480.0694952.8109692.8492811.8560260.2683900.0116630.0039940.0191540.0210660.3606482.9590710.2049760.0492580.0324920.0478350.1759690.0245410.0242770.0936840.2500790.0354430.8714410.1163260.1714710.0018480.1715840.0079970.0031260.0016800.0095180.5930720.5223300.1541390.3898473.2508720.1445130.0029950.2493500.0102110.2844800.0182180.0532860.2620100.6719533.0929525.1681491.9633141.6050570.7033390.0072700.4565540.0363890.3825460.0999870.0010460.7650951.4743001.7805941.7335731.2302120.8172210.2615270.0023060.6514130.2769700.0014080.0003390.1894750.8003860.0559330.1539060.3880250.1638930.0156210.6154370.0420640.2998410.3344910.8524760.3815221.3109490.7983421.7447040.3841510.1998170.2298480.0060210.2854671.1236842.9988861.2126400.0275950.0007260.2524620.2238370.0300561.4867030.2832570.5304461.4520442.4388460.2973260.2490820.2122000.0017860.6526890.1651080.0039160.0031080.6966460.8624050.6318000.2095010.0018090.0045920.0007390.0304380.0011540.0018620.3170700.0017620.0004330.0003540.0024910.0004250.0008140.0406530.0334680.0004710.0075640.0011830.0019960.2481030.6329300.2342880.2539930.0101420.0689100.4283850.0566710.0118880.2770550.6632810.2494140.0427850.0046900.0023420.0030400.0003790.0008370.0917170.0004950.0058180.1883690.8255430.0035140.0038970.0006150.4166751.9747680.0573420.0012010.0008270.2226590.5489900.6024470.5946470.4118430.2558400.8198481.7604950.6248130.0455430.0522140.2301320.0156660.0021910.0002690.3577310.0024130.3586810.0028270.0241430.0050070.2491270.0405990.0163540.4767630.0140000.6319141.9168811.7920990.8803991.4587680.6171910.5151730.1293860.1550070.0037061.0554181.2596980.4172790.7164000.2815932.1590641.9845731.3100120.1624410.2873090.0058610.7026590.2384140.7638190.4266371.4782720.4827270.6283870.0373260.2638851.0607350.2783210.2068830.5136410.0015250.0007840.0034980.0010370.0116820.0046200.0036520.0245300.0004810.0132830.0056010.0331020.0367180.0194930.2335280.0010660.0005770.1355410.0092640.1248100.4036621.2697101.4239271.7385620.2203980.0428560.3424260.3795150.4672630.9302230.6805481.7428011.4426530.6862200.5887810.5030570.2019570.0935200.2923880.0013340.0008390.0010720.0022690.0008380.0099690.9972501.0774790.4708380.2839720.5753490.5846741.4936491.0087510.0590200.0044410.1104120.2252200.0106520.0027130.4201120.002481

*******************************************
EVALUATING PIPELINE 
Pipeline directory: /home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_0d5a1d55_2020-02-02_12-36-0117xcau5c/
With following parameter combination: {'batch_size_seq_length': 3, 'lr': 1e-05, 'lr_type': 'linear'}
EVALUATION OF CHECKPOINT /home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_0d5a1d55_2020-02-02_12-36-0117xcau5c/outputs/checkpoint-3
-------------------------------------------------------------
|           |   agree   | disagree  |  discuss  | unrelated |
-------------------------------------------------------------
|   agree   |    499    |    71     |    226    |    17     |
-------------------------------------------------------------
| disagree  |    10     |    22     |    15     |     1     |
-------------------------------------------------------------
|  discuss  |    212    |    59     |   1475    |    61     |
-------------------------------------------------------------
| unrelated |    41     |    10     |    84     |   6819    |
-------------------------------------------------------------
Score: 7009.0 out of 7516.5	(93.24818732122664%)
Accuracy: 0.916129702764498
F1 overall: 0.6613949357466022
F1 per class: [0.6336507936507937, 0.20952380952380953, 0.8178541724424729, 0.9845509673693329]
*******************************************


*******************************************
EVALUATING PIPELINE 
{'batch_size_seq_length': 2, 'lr': 1e-05, 'lr_type': 'constant'}
INFO:__main__:Creating features from dataset file at /home/ubuntu/fnd_implementation/data/processed
  0%|                                                  | 0/9622 [00:00<?, ?it/s]  0%|                                        | 1/9622 [00:02<5:30:26,  2.06s/it] 21%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                             | 2001/9622 [00:02<3:03:13,  1.44s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9622/9622 [00:02<00:00, 4007.35it/s]
  ******************************************* 
              Running Evaluation                
  *******************************************
 
  Length dataset evaluation: 9622
  Length dataloader evaluation: 1203
  Number of epochs: 3
  Batch size: 8
  ******************************************* 
 
['/home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_0c6bb2e9_2020-02-02_09-19-07jz_todo1/outputs/checkpoint-3']
INFO:__main__:Evaluate the following checkpoints: ['/home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_0c6bb2e9_2020-02-02_09-19-07jz_todo1/outputs/checkpoint-3']
INFO:transformers.configuration_utils:loading configuration file /home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_0c6bb2e9_2020-02-02_09-19-07jz_todo1/outputs/checkpoint-3/config.json
INFO:transformers.configuration_utils:Model config {
  "architectures": [
    "AlbertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "down_scale_factor": 1,
  "embedding_size": 128,
  "finetuning_task": null,
  "gap_size": 0,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "inner_group_num": 1,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "net_structure_type": 0,
  "num_attention_heads": 12,
  "num_hidden_groups": 1,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "num_memory_blocks": 0,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 30000
}

INFO:transformers.modeling_utils:loading weights file /home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_0c6bb2e9_2020-02-02_09-19-07jz_todo1/outputs/checkpoint-3/pytorch_model.bin
HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=1203.0, style=ProgressStyle(description_width='initial')), HTML(value='')))
0.0013470.0014480.0008180.0005230.0002030.0001250.0003210.0002330.0001220.7224460.0725090.9167230.2920750.0225720.6693850.0446910.0029520.0002530.0008190.0002171.2208600.0581950.6727820.0298010.0026301.0652920.0410670.0017430.9151590.0318080.0020920.0002510.0212490.3580630.2224870.4439000.0125460.0007660.0004930.0878070.0400360.0119840.0062860.0006190.0005960.0002090.0003440.0007870.0027750.0002130.0002900.0011950.0006120.0001040.7630400.0139670.0003160.0018160.0002200.0000780.0001100.0000850.0001440.0000750.0000770.0001160.0017961.0659890.3920300.0061240.2492090.0036550.6988440.0096750.7708411.1012581.2379260.8314170.0116600.0002770.0001940.0001710.0084290.0002220.0019960.3239500.1618350.0652030.0009600.0004110.0000851.0014200.0111753.1501080.0335900.7523560.0141710.3049570.0032630.0002640.6387570.0064470.0001930.0005990.0004810.0003230.0001110.0002400.0020890.0001010.0001570.0001230.0001780.0002010.0001300.0573130.8493351.0987980.0096570.0004080.0000940.0207400.0002260.0000641.1630930.0093620.0004100.0000691.1666720.0110480.0178170.0002091.4402560.7815420.0058920.0001010.0029220.8532910.3052480.0022780.0000840.0001300.0000640.0000630.0013860.0059210.0001780.6708490.0988480.0007300.5860320.7369150.0136060.2949900.0023110.0001680.0001150.0003160.0002560.2763820.4497250.0566500.0004580.0000770.0011191.0292650.8028320.0050900.0001570.0001370.9357170.0056260.0000970.0000810.0000650.0000850.0001910.0000660.0000630.0001380.0001900.0000620.0000590.0001500.0000710.0000620.0001250.0000610.0000880.0000690.0000580.0001130.0015100.0004840.0010030.8891040.0046280.0014500.0022710.0001020.0000740.0001340.0000900.0001810.5793840.0039420.0359210.0890990.2524210.4430971.6798650.4624090.3249090.0017790.0000710.0000920.0002550.0000920.0001180.0001220.0013210.0000850.3938430.0034200.0006521.0350330.0048100.0002490.0000890.0000940.0000900.0002570.0007470.5360030.0879320.0095690.0018690.0009490.0008090.0003370.4771900.1927851.0829830.0176320.7777420.9593190.2201670.0009600.0001560.0000580.0001380.0002250.0000610.0000610.0015660.0008660.0002190.0002420.0001310.0002240.0001510.0004560.0198860.0002340.8687030.0302100.0005140.6187000.5144860.7107780.0027270.0005320.3439330.5737490.8095610.0637670.4964050.0026000.6483870.2890270.0015680.0009470.0002270.0001000.0000550.0002400.0001050.0001250.6572271.3445430.6343230.0025980.6568010.3222600.0015340.0001660.0003480.0004270.0001261.1093430.0062360.2237460.0063680.0110290.0008161.5072580.0056150.6333630.0022040.0001660.7885390.0053150.0001320.0001160.9867760.0032330.0001600.0001780.0002090.0001220.7579650.0250610.0005840.0006170.9909810.0039290.0004270.0003170.0003430.0004300.0001870.0002700.0002870.0018180.0009140.0009060.0000580.0001021.2967040.4017290.0012740.0020590.0001960.0043580.0001330.0006910.0005400.0007220.0004510.0023960.0005570.0002520.0002530.0004080.0006060.0006300.0010180.0006280.7072010.0020611.4022980.0039690.0001820.0003111.3102400.4996580.0219961.8649410.0053700.0041210.0877041.4823601.1236080.0031040.5338220.0015021.9871611.2295481.6880950.0046931.8070770.0048871.2298750.0032770.0001480.0003620.0003900.0003220.0008470.0000590.0001390.0000710.0001360.0003490.1740750.0006070.0002170.0003320.0010780.8684340.5745411.1579640.1693910.8055061.0012050.0027100.0043020.0056610.0041210.0005660.0016504.2903010.0108760.0251160.0020820.0184450.0006880.6092340.9119032.7736770.9343030.0022910.0000860.0005230.0003080.0733330.0002391.9640860.0168140.0000970.0000580.0000710.9824570.0023370.0000660.0000590.0000580.0000580.0000640.0002260.0062400.7610420.0061421.6303690.0041610.0001320.6140910.6300950.1330530.0021680.0242340.0008110.0003530.2191980.3058040.8740710.0020700.0002580.9343210.0026000.6224871.6398261.1623240.6464990.9602760.3051750.0008690.2747060.1280950.0005790.0000610.0487940.0001800.0001290.0000680.0001400.0000840.0001230.6297121.0548390.0024490.9788630.0027430.0004430.0000720.0005700.0000661.1356541.6074121.7816992.4735330.3065340.0007510.0000810.0000960.0000680.6558120.0014251.0294970.0148420.0002030.0001120.0003730.0000850.0026400.0001380.0042690.2948230.0006910.0016440.0004372.3083921.8001410.0035870.5466240.0033450.0012360.3261071.7932260.0040740.0010110.0005620.0064640.0001660.3532210.0038060.8394120.0016640.2471670.6321100.5028900.2692170.0117460.0001450.0008900.0041230.0001580.0007470.5973750.3512440.9843250.9175352.3737030.8600190.0939200.8207090.4187480.0009870.8313650.8114980.6082750.0380011.7096980.0033640.0003860.8018960.0014970.0000701.5155881.7397490.0032550.0000680.0029430.0000860.0007320.0000590.0027960.0009990.0001560.0000700.0001360.0001010.0029330.8540100.6118600.4601250.0024300.0008962.9802341.9075351.0062020.5945070.0011800.0001390.0001071.5536450.5186970.0011550.0006570.3683540.6386310.6285460.0013990.0001150.0000730.0001320.0015560.0000620.0273570.0019450.0000880.0050000.4107070.0033600.0000760.0007360.0027610.0000990.0007741.3373731.8074230.0033970.0021330.0030120.0093040.5694020.0013300.0000900.0000940.0021050.6437020.0036890.0001290.0024200.0005640.0000930.0006420.0001670.0000810.8686140.0114300.0001630.0003780.0001750.0006220.0001380.0005030.1099891.9730320.0046850.0057933.3599252.7075511.6771620.0067740.3372400.0565140.0023190.0007370.1029290.0026350.0003690.0002910.0018410.0002450.6743422.8378124.8689740.0080740.0000940.1800430.0003360.0008180.0416160.0035270.1243760.2476780.0304520.9078790.0023900.0036700.0004460.0059680.9211310.1702210.1154600.0005470.0316200.0806500.7691290.0203790.0001070.7955360.0120790.0005690.0000780.0224990.0002820.4705650.2183780.0005060.0114500.0001650.0007990.0001520.0413880.0014411.5616460.0134880.9373410.6337370.0011100.0002540.4856242.8243183.7832930.0067570.0026680.0006490.0006070.0016380.0011360.0016420.0002940.0002500.0035450.0003230.0057040.0003370.0009520.4289550.0020910.0092521.7287440.0028340.3496060.0011230.0057730.5045000.2544370.8097890.0050942.0095580.0860310.0007120.0001861.8530320.6761280.0009790.7236950.0010400.3038351.9675780.5595760.0011330.0000700.5705651.3709002.7614590.8292731.9946622.5088941.2742481.2712731.1867180.7777950.4687650.3216281.6416550.1263070.0006940.0005900.0005641.0358560.0015560.0029570.0001800.0000870.0000810.0000650.0003530.8448311.0965550.9713450.0428460.3924750.0121101.1377052.5099130.8070940.0018720.1364710.0003750.0006650.7890150.8459530.0013230.0003850.8020560.0035140.0024240.0034750.0414940.9508890.0014330.9344963.0655600.9896961.0241380.8546133.0863510.4014180.0694960.1429310.0004230.0004570.0026510.4102070.0075470.0004200.0000990.9690982.8647710.9436042.1993181.8130311.3499360.0033240.0001550.5182940.0008660.0001690.0000800.3314621.3537130.0018660.0000810.0023480.7154131.2137560.7769390.0011560.0435592.2082471.3825582.3143774.4459411.3710100.0033390.5904750.3766910.0166480.3563920.0004820.0000940.0020100.1620990.0004510.0003360.0025290.0078310.0003310.0003130.0002310.6094830.8476930.8876730.4143701.0733590.0020460.0000810.0002570.0002240.0002540.0004480.0258990.0001890.0001590.0001420.0001840.0002570.0002060.0001830.0001780.0001770.8189650.0010140.0005620.0001410.0000730.0000700.0001020.0003990.0002680.0000960.0001260.0006460.0001230.0003410.0011340.0000690.0002030.0001640.0000740.0015630.0013490.0000790.0004720.0005560.0003590.0000910.0339960.2547420.0047110.0296490.9600680.3059840.0211060.0039810.0021020.0205960.0121731.0721650.0022950.0026390.0032280.0014590.0011250.0028811.5226841.7564822.0651791.8935010.0052760.0005190.0005060.0028060.4641910.5670280.0018780.3885900.3886120.0004860.0001050.0003110.0001540.0000580.4161550.0005110.0000660.0000840.0000620.0000730.0001941.6608400.0019620.0002480.0002860.0002510.0003880.0003120.0000690.0036720.8256422.6351621.3745040.4796130.0008670.0002850.0007580.0000680.0007380.0030800.0004461.2365790.0733590.6106060.8216740.0041510.1988610.0228920.0062230.0060330.0010710.8740781.0252964.4114920.8118171.2506330.4170460.0028710.0101190.0124270.2097670.0286170.4154300.0363200.0015460.0005320.0001180.0001380.0000670.0035960.1352210.0002420.0007310.8394880.3304220.0005900.1015520.0010460.0121400.0013990.0011970.0017210.6867770.0037240.0001770.0001840.0000670.0004130.0004350.0001850.0000560.3449930.9464102.7438001.5015842.1909391.4176271.1999350.3497001.6036590.0016530.9452900.0023960.0000941.7629750.0026790.0018570.0000700.0023260.0006200.0012790.6832221.0402941.2459320.7926062.4570815.6595940.0248051.4522570.0261820.7551641.0351062.2556230.8295663.1948381.5015350.6483110.4629330.0011150.3393290.0177580.0001120.0009620.6246530.4736490.0011850.6540621.0829480.0301640.4021000.2944111.1387361.6964100.0837240.5035641.2062830.7275380.0044700.0006060.1808730.0021860.6828070.4789530.2620040.4898700.0038960.0003910.0050650.2121120.0003140.0002090.0003000.0003230.0028690.8929120.0011020.0005120.0006480.0007730.0003110.5325460.0005860.0008730.0001411.7458310.0017030.0000880.0001150.9010140.0601580.0001460.7896560.0008230.0004710.0070030.2600730.6402830.7533450.0025050.0001040.0009530.0001250.0001200.0024440.9237250.0009210.0002890.9024480.7870550.0011520.0217630.0051070.0118790.0116570.0045370.2022152.1145040.2228120.1779360.0034560.0033150.0010710.3497620.1454260.0307820.6141320.0012900.0173630.0305441.7407880.0017821.0964391.8218681.8997300.0023450.8001310.6175990.7738280.5738030.4272760.7423890.0007800.5991130.0006980.0000590.5027440.0011600.0009660.0002470.0038550.0003380.0003520.0007950.0005200.0002680.0002130.0002280.0005040.0923052.5672752.4545681.0800560.0040160.0028450.0857130.0051380.3203860.4378701.1020210.0073540.4394290.0132093.7625783.2140720.0074840.0010150.0012030.0002830.0002980.2571370.0005780.0004930.5290550.0019700.0016660.0005980.0030690.0007120.8605340.001373

*******************************************
EVALUATING PIPELINE 
Pipeline directory: /home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_0c6bb2e9_2020-02-02_09-19-07jz_todo1/
With following parameter combination: {'batch_size_seq_length': 2, 'lr': 1e-05, 'lr_type': 'constant'}
EVALUATION OF CHECKPOINT /home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_0c6bb2e9_2020-02-02_09-19-07jz_todo1/outputs/checkpoint-3
-------------------------------------------------------------
|           |   agree   | disagree  |  discuss  | unrelated |
-------------------------------------------------------------
|   agree   |    486    |    43     |    149    |     4     |
-------------------------------------------------------------
| disagree  |    19     |    61     |    40     |     0     |
-------------------------------------------------------------
|  discuss  |    222    |    47     |   1551    |    50     |
-------------------------------------------------------------
| unrelated |    35     |    11     |    60     |   6844    |
-------------------------------------------------------------
Score: 7118.0 out of 7516.5	(94.69833033991884%)
Accuracy: 0.9293286219081273
F1 overall: 0.7348579749975507
F1 per class: [0.6731301939058172, 0.4326241134751773, 0.8452316076294278, 0.9884459849797804]
*******************************************


*******************************************
EVALUATING PIPELINE 
{'batch_size_seq_length': 4, 'lr': 1e-05, 'lr_type': 'linear'}
INFO:__main__:Creating features from dataset file at /home/ubuntu/fnd_implementation/data/processed
  0%|                                                  | 0/9622 [00:00<?, ?it/s]  0%|                                        | 1/9622 [00:01<3:26:59,  1.29s/it] 21%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                             | 2001/9622 [00:01<1:54:47,  1.11it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9622/9622 [00:01<00:00, 5039.72it/s]
  ******************************************* 
              Running Evaluation                
  *******************************************
 
  Length dataset evaluation: 9622
  Length dataloader evaluation: 301
  Number of epochs: 3
  Batch size: 32
  ******************************************* 
 
['/home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_0e88ccd2_2020-02-02_12-39-28qgod6khq/outputs/checkpoint-3']
INFO:__main__:Evaluate the following checkpoints: ['/home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_0e88ccd2_2020-02-02_12-39-28qgod6khq/outputs/checkpoint-3']
INFO:transformers.configuration_utils:loading configuration file /home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_0e88ccd2_2020-02-02_12-39-28qgod6khq/outputs/checkpoint-3/config.json
INFO:transformers.configuration_utils:Model config {
  "architectures": [
    "AlbertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "down_scale_factor": 1,
  "embedding_size": 128,
  "finetuning_task": null,
  "gap_size": 0,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "inner_group_num": 1,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "net_structure_type": 0,
  "num_attention_heads": 12,
  "num_hidden_groups": 1,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "num_memory_blocks": 0,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 30000
}

INFO:transformers.modeling_utils:loading weights file /home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_0e88ccd2_2020-02-02_12-39-28qgod6khq/outputs/checkpoint-3/pytorch_model.bin
HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=301.0, style=ProgressStyle(description_width='initial')), HTML(value='')))
0.0068300.0080150.0072320.2153280.2093120.2202930.1559730.0709710.0216510.0051570.0424530.1357980.0908590.0722830.3291240.0240060.2785740.1144110.2607570.4767210.1122810.4759660.2204850.6414990.2084880.0476800.0087860.0027620.1230630.0602650.0391230.1916470.2707120.2779420.1797760.0060700.1565410.2393770.2580550.0867440.1285790.2114940.1604670.0050270.0017040.0018940.0016410.0017900.2056870.0220580.0015480.1610110.3190210.1334150.0058170.3343000.1976340.0049310.3322480.3532950.7001990.3722300.0104500.0064570.4123950.1344800.0916520.2705510.3855160.0853790.0445660.0030690.2765580.1411280.3451490.1639760.5247090.2599760.1677720.0373320.2626860.2834220.0747460.2491730.0882740.0589580.0183940.0633070.0394050.3207220.3047371.2216500.3709430.1523960.3169640.1934560.0135060.0045370.1745590.3267000.2922370.1252750.4738700.0611410.3336850.1285420.0320080.0039660.0622340.0018080.2154650.1921920.1675840.3648690.0491640.2729460.0756400.0532340.0020670.1397540.1453820.1237071.0166580.0100130.0688880.0099450.0293910.4388990.3445030.2219400.1901790.2851590.3798370.0956320.2319060.8210190.2330000.1395200.1306570.2282180.0485430.0203800.0165640.3928940.6235190.1856540.3858400.1856700.1289480.0823510.1716120.0811180.7877100.1851980.0108330.2152390.0108460.0510780.0135280.4992691.1288970.0821380.0542400.1137260.8610370.1105790.3666450.1069200.0964320.7776870.2183260.0111350.0077400.0107720.4779150.2360711.2622380.0952010.0392440.1679280.6593932.5701550.9645420.2856250.1847120.1749350.0838550.5956380.9554780.3495750.1305560.1635000.0504340.2122820.2342600.1252680.2674580.4936750.4901570.8450080.7569100.1138070.1121861.2119530.3889010.1042080.1777730.5217050.6013440.6889950.1872790.0314580.0133770.3420510.6602150.0405920.0097940.0373200.1174970.0036650.0138080.0068180.2933680.0234820.0085360.4259500.3187960.2477270.3683710.1246560.4308330.2010220.0500580.0071110.0824280.0022860.4261980.0083570.7062570.0449920.0872250.4238840.5117990.3486670.9036180.3701320.4432030.0096410.0240250.1765150.0781060.2185350.1025870.2605771.2602780.8990190.4788340.1525740.3948530.7291460.5454580.9837130.4008100.1427900.6369520.2485150.4081300.2995730.7351970.2315330.2689340.0096880.0323470.0205400.0809270.0407040.0905940.1104860.0024150.0984310.4266671.5862320.6988240.1634440.3574920.2782960.9113330.2789450.2397870.1537160.0052920.0156690.0314310.7424460.3934130.5944510.8447700.0407130.1150250.0189910.271081

*******************************************
EVALUATING PIPELINE 
Pipeline directory: /home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_0e88ccd2_2020-02-02_12-39-28qgod6khq/
With following parameter combination: {'batch_size_seq_length': 4, 'lr': 1e-05, 'lr_type': 'linear'}
EVALUATION OF CHECKPOINT /home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_0e88ccd2_2020-02-02_12-39-28qgod6khq/outputs/checkpoint-3
-------------------------------------------------------------
|           |   agree   | disagree  |  discuss  | unrelated |
-------------------------------------------------------------
|   agree   |    477    |    66     |    227    |    13     |
-------------------------------------------------------------
| disagree  |     4     |     8     |     2     |     0     |
-------------------------------------------------------------
|  discuss  |    253    |    79     |   1485    |    85     |
-------------------------------------------------------------
| unrelated |    28     |     9     |    86     |   6800    |
-------------------------------------------------------------
Score: 6989.25 out of 7516.5	(92.98543204949112%)
Accuracy: 0.9114529203907712
F1 overall: 0.6236659257307403
F1 per class: [0.6174757281553398, 0.09090909090909091, 0.8022690437601296, 0.984009840098401]
*******************************************


*******************************************
EVALUATING PIPELINE 
{'batch_size_seq_length': 2, 'lr': 1e-05, 'lr_type': 'linear'}
INFO:__main__:Creating features from dataset file at /home/ubuntu/fnd_implementation/data/processed
  0%|                                                  | 0/9622 [00:00<?, ?it/s]  0%|                                        | 1/9622 [00:01<4:05:57,  1.53s/it] 21%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                             | 2001/9622 [00:01<2:16:23,  1.07s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9622/9622 [00:01<00:00, 5085.62it/s]
  ******************************************* 
              Running Evaluation                
  *******************************************
 
  Length dataset evaluation: 9622
  Length dataloader evaluation: 1203
  Number of epochs: 3
  Batch size: 8
  ******************************************* 
 
['/home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_0d5a1d54_2020-02-02_11-18-1325qlp8wp/outputs/checkpoint-3']
INFO:__main__:Evaluate the following checkpoints: ['/home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_0d5a1d54_2020-02-02_11-18-1325qlp8wp/outputs/checkpoint-3']
INFO:transformers.configuration_utils:loading configuration file /home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_0d5a1d54_2020-02-02_11-18-1325qlp8wp/outputs/checkpoint-3/config.json
INFO:transformers.configuration_utils:Model config {
  "architectures": [
    "AlbertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "down_scale_factor": 1,
  "embedding_size": 128,
  "finetuning_task": null,
  "gap_size": 0,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "inner_group_num": 1,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "net_structure_type": 0,
  "num_attention_heads": 12,
  "num_hidden_groups": 1,
  "num_hidden_layers": 12,
  "num_labels": 4,
  "num_memory_blocks": 0,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 30000
}

INFO:transformers.modeling_utils:loading weights file /home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_0d5a1d54_2020-02-02_11-18-1325qlp8wp/outputs/checkpoint-3/pytorch_model.bin
HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=1203.0, style=ProgressStyle(description_width='initial')), HTML(value='')))
0.0008390.0009950.0005700.0002810.0001290.0000980.0001150.0002110.0001440.0001050.0001760.0235220.8526160.0657280.9860030.0657970.0043220.0003280.0003250.6339570.3353060.0160360.9663070.0426090.0035710.3714960.0143600.0006870.7131620.0247530.0022370.0002010.0003100.0001620.0037270.0058350.0003400.0001790.0000820.0057080.6888710.0172530.0049260.0007360.0010590.0006950.0007090.0009080.0063760.0003670.0004450.0006670.0002630.0000880.9307980.0169870.0003720.0109190.0003730.0000660.0001350.0000690.0001700.0000680.0000700.0000640.0013781.0495760.6998280.0112000.3394500.0051100.0039640.0001221.0835851.2219240.7333070.6457730.0127120.1358980.7540960.0094890.0010220.0001160.0097710.1049270.7028410.0550330.0011920.0003640.7616771.0951740.0127813.1103520.0331621.4326280.5688240.8434660.0087890.0001960.7146840.0071870.0001590.0001280.0002280.0003130.0001020.0001900.0000830.0001430.0000760.0001360.0002540.0002320.0001130.0870740.4543850.0107180.0001710.0001820.0000650.0004690.0000620.0000641.1094940.0089390.0010450.0000870.7954870.0066270.0019650.0000890.9788730.1909660.0015110.0000760.0032790.9492100.3023290.0023170.0000810.0000680.0000610.0000950.0036050.0109740.0001470.9190650.8059250.0054720.8857800.8552400.3752980.3705060.0025620.0000820.0000640.0000750.0000690.2607480.3716380.5328580.0037850.0000910.0013800.9652850.0099030.0020210.0001920.0002060.8277190.0064920.0001180.0000810.0000860.0000930.0001720.0000710.0000750.0001310.0000830.0000770.0000750.0002130.0000750.0000850.0001300.0000800.0000710.0000800.0000840.0001570.0020700.0004610.0003910.8799840.0045800.6545600.0037250.0000920.0056230.0001900.0003220.0001730.8599320.0049550.0009600.3010180.2986910.1033080.6895620.6895340.5834530.0036060.0000830.0000640.0001670.0000880.0000870.0000750.0002600.0000740.8422750.0041680.0002401.0690320.0049340.0001940.0000750.0000840.0000770.0001660.0006030.1746740.0015410.5560360.1647130.0019070.0009800.0001761.0287010.2683151.2768210.4555241.0378270.8497310.0066370.0000930.0001610.0000690.0001740.0002260.0000710.0000660.0002790.0004010.0003910.0097430.0005950.0012860.0004030.0171820.0024550.0001810.9603670.0042850.0003080.5723930.3174910.4588860.0017690.0009360.1647710.9050450.1305580.2668470.2682780.2028641.0555360.2006350.0019350.0006550.0002570.0001250.0000600.0001750.0001430.0001790.8338541.6673580.7952320.0028430.4495540.1102370.0010940.0004240.0002370.0011590.0001161.0145100.0038170.5773260.0037840.0055510.0022260.5742070.1507971.5686680.0054190.0002340.9526920.0149640.0003990.0001590.7455990.0025160.0001670.1647180.0006750.0002640.0740430.1343230.0012460.0006080.9176500.0104360.0005440.0004370.0006450.0008540.0031240.7872060.4918461.2832650.7098380.2854390.0009090.0003030.9025881.1895880.0035670.0000730.0000640.0007910.0080350.0004330.0000620.0000780.0009340.0095080.0007150.0002490.0003390.0005260.0007760.7126060.4317960.0061340.9257020.0026591.6190480.0046090.0002920.0002611.6730930.6784130.0025091.9931390.0057040.0061550.0044681.3038200.9361380.0025811.3683460.0037200.5276640.6420090.5755030.0016920.5515200.0015770.0379690.0001770.0001820.0005110.0005390.0005690.0005310.0000650.0002200.0000640.0002150.0005800.0125390.0009520.0016660.0003720.0004490.9741610.7114901.3601580.1175520.0638770.2669130.0008990.0234770.5428430.2854280.0753530.1324452.8732650.0090090.0025210.0016760.0129080.0007491.1164610.4695811.8334270.9702410.0023930.0000750.0002500.0004050.0117230.0000960.6482500.0875330.0002840.0000700.0000750.3123170.0007990.0000760.0000790.0000730.0000740.0000690.0003200.0398050.5416350.0060371.0039020.0029630.0005680.7015220.4326380.9773170.0180490.0114070.0010730.0010550.0026681.8713841.4343840.0033070.2180700.0019450.0016690.0013080.0077310.0472410.0026400.5012180.0047390.0003050.0190200.0243290.0009500.0001900.0073490.0000830.0001720.0000690.0000630.0000710.0002860.9094870.7940310.0021880.7829640.0082040.0014340.0000690.0009960.0000690.7012980.9055010.8120601.7364553.6500330.0075760.0000790.0001000.0000610.0137330.0000910.0080800.0005200.0001580.0003180.0008520.0001180.0019790.0001150.0025780.8574650.0018470.0997980.0254401.7789801.0964820.0022410.0016850.0317660.4891110.2250610.1812780.0037690.0047150.0004580.0032070.0012151.0662160.0273001.0259820.0020110.4719600.0153460.2939690.4196560.0050650.0002390.0016140.0030510.0026940.0016860.7014601.0641052.0078661.1604182.5360221.6474310.3376931.4057180.9136870.0020220.0010351.5324460.0098270.0013960.1202400.0011320.0013950.8205070.0015470.0000760.4968420.8965660.0017950.0000960.0629760.0001760.0003530.0000770.0012930.0006150.0003420.0000680.0001600.0000720.0029410.8828030.0532570.7585500.3723800.1745282.5034301.4855840.8212800.6157310.0011930.0000840.0001501.7916330.2716370.0007600.0002790.4641780.4936340.5333100.0015610.0000680.0000590.0000700.0010960.0000860.5466280.0018660.0000900.0349820.0983680.8092050.0014200.6768830.9476060.0019180.6367232.5757173.0223570.0053590.0320220.0046450.0043670.0006470.0205470.0006450.0008190.0026350.1614720.0044200.0001980.3063460.2708530.0005090.0238410.0004770.0001180.3359580.0300110.0003470.0005690.0005040.0006130.0003940.0005760.0012861.4030101.5768842.7947712.8655192.4244370.4414330.0037640.6268340.0073200.0011670.0088840.2857450.0016190.2761270.0092220.0976210.2268270.5788542.7220294.4839670.0088140.0000840.5730340.0009360.0016110.0056380.0878140.0184330.6648860.1031640.1186870.0007590.0265560.0007870.0019430.7043640.0021420.0009290.0002450.0012532.1524053.1985650.5873680.0009390.0723760.0024460.0006580.0000750.0021770.0001650.0007090.0212100.0001980.0007350.0001540.0003800.0000830.6471340.0066551.2443680.5267540.9570380.5712840.0012880.0005220.8126731.9855713.5467760.0066670.0160610.0006220.0005170.6290490.0031160.0615560.0498530.1804790.2294230.0018810.0268590.0077680.0040830.4596870.0010241.2553442.4794150.0042860.0011590.0010080.8315190.0070850.0005160.0009750.0012222.0344390.0035020.0007820.0003400.4569670.2537370.0004280.4656660.0007190.2338620.3733540.0860980.0006840.0000910.3808081.3941193.5441261.0777333.0596343.1140261.6191590.6741100.4173080.0157940.7750380.6212540.7841950.0020250.0011540.0012530.0008441.0977160.7541750.0026150.0002240.0001330.0000630.0000610.0002470.7924741.0055400.9593750.2230250.9493150.3782560.7096152.3792140.6034501.2429161.1734420.0018800.6442370.9747790.9468510.0016390.0003420.8963550.8286280.0093451.0883800.6824010.9027050.0017180.8553192.3474580.9344290.8976560.7069393.9660362.4235381.1764910.6840760.0010810.0009740.0014260.2288230.0027440.0003840.0001581.0077483.0010791.0075954.8850686.9612725.5455130.0072430.0002720.0018050.0002350.0001410.0000690.7090840.5542530.0007520.0001250.0007534.4027721.5025220.0526300.0003420.0014012.0488812.4067922.7527724.8766951.8553310.0031590.7418740.7284460.0027780.5841750.0007650.0000830.0006330.0008050.0005990.0003650.3295120.0007260.0004060.0004860.0002970.4467600.3951520.5737760.6437181.2970110.0028000.0000700.0797980.0004130.0004190.0008930.0004790.0002580.0002130.0003110.0001090.0003610.0003090.0002760.0002330.0002120.7294380.0009480.0003140.0001920.0000800.0001140.0000890.0004100.0003790.0001450.0001790.0001520.0002290.0005920.0013890.0000760.1132790.0001930.0000720.0003270.0005220.0000650.0002860.0002740.0002620.0000661.8114854.2604910.8927510.1018480.1375590.8788540.0058360.0025430.0014470.0183530.0105590.9265790.2998840.0029700.0111650.0114110.0008920.0009312.2515442.1701082.3302512.4417920.0040410.0005130.7508380.4036830.0470660.0005490.0011330.2778810.2778930.0003680.0011260.0004200.0001680.0000640.8188300.0009430.0000720.0001050.0000670.0000620.0002741.6798140.0019400.0004330.0046940.0004060.0004380.0003140.0000670.0016880.7015813.9699043.0731381.1651130.0094340.0003250.0008950.0000700.0084860.3491180.0007790.3652020.7507530.7501790.3684350.0647880.2605960.1886300.1625700.2675480.0012740.9186431.0316483.6206470.3775980.9249451.1573530.0030890.9940020.0037400.0032460.0278180.0240850.4112790.0035630.0011300.0000640.0000680.0000670.0069810.0006070.0000700.0014030.0020510.1826370.0003510.0009180.0013030.0010260.0017100.0060830.0010830.5760920.0038510.0020590.0005670.0000680.0008130.0091030.0005830.0000680.6143110.8636461.2650181.0037553.0556081.2867551.2899490.3778242.7734060.0027801.3056020.0022430.0001101.6263550.0019990.0047880.0000680.2534030.0023180.0038161.0097612.3813491.0783770.7269691.0669970.0385550.0034511.0145820.0031901.0057612.7662411.8720980.0960242.8652961.2592150.5612980.5093030.0013100.3985390.2857160.0004070.0065970.7221711.2066010.0019330.9893350.9212550.0035800.0075870.0125740.0612470.6547930.0130340.4975460.9847330.7167010.7934730.2862261.7483490.7515272.0118600.9502390.7764221.6870360.1629100.0005370.0036330.3769940.0004840.0003020.0003280.0006580.0002570.8733960.2195750.0007190.0006190.0005340.0014710.6071040.0006290.0002440.0000670.8287150.0008310.0000890.0000900.1463980.0051320.0000690.3351020.0003740.0020970.4406900.0600800.0131400.0082540.0195620.0001340.0005210.0001210.0001540.0007210.0065750.0000700.0003100.0014100.9397620.0011930.0448490.0067320.5220481.1386740.0354662.1182734.6690600.6060200.0021200.0017920.0015350.1208120.2281550.2844660.0026290.1446710.0003530.0684500.2093530.6480840.0008090.6393130.7562291.8615870.0277890.7842920.1256061.1311740.4705980.4045800.9176110.0009540.2747770.0005270.0000790.6721100.0009440.0006650.0000850.0004950.0002380.0006150.0005050.0003800.0002640.0001840.0002760.0003330.0275401.6582570.3920901.2582230.0290120.0835360.1126540.0481970.4016480.6196920.9846171.3032220.6898530.0041920.9429490.8403470.0011360.0003530.0001780.0002530.0023410.3130830.0014120.0006020.7275640.3718410.0016760.0005080.0015380.0004841.0960330.001451

*******************************************
EVALUATING PIPELINE 
Pipeline directory: /home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_0d5a1d54_2020-02-02_11-18-1325qlp8wp/
With following parameter combination: {'batch_size_seq_length': 2, 'lr': 1e-05, 'lr_type': 'linear'}
EVALUATION OF CHECKPOINT /home/ubuntu/fnd_implementation/albert/grid_search/results/pipeline_0d5a1d54_2020-02-02_11-18-1325qlp8wp/outputs/checkpoint-3
-------------------------------------------------------------
|           |   agree   | disagree  |  discuss  | unrelated |
-------------------------------------------------------------
|   agree   |    477    |    62     |    184    |    18     |
-------------------------------------------------------------
| disagree  |    24     |    33     |    18     |     0     |
-------------------------------------------------------------
|  discuss  |    237    |    57     |   1545    |    55     |
-------------------------------------------------------------
| unrelated |    24     |    10     |    53     |   6825    |
-------------------------------------------------------------
Score: 7080.75 out of 7516.5	(94.20275394132908%)
Accuracy: 0.9228850550821035
F1 overall: 0.6845293380518563
F1 per class: [0.6347305389221557, 0.27848101265822783, 0.836491608012994, 0.9884141926140478]
*******************************************


real	18m2.167s
user	17m7.615s
sys	6m8.293s
ubuntu@run-gpu-mg:~/fnd_implementation$ 
ubuntu@run-gpu-mg:~/fnd_implementation$ exit
exit

Script done on 2020-02-04 22:24:29+0000
